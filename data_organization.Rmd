---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r new option chain aggregation from discountoptiondata}

library(dplyr)
library(readr)
library(lubridate)
library(stringr)
library(RQuantLib)
library(bizdays)

load_quantlib_calendars("UnitedStates/NYSE",from="2000-01-01",to="2030-12-31")

option_chain_aggregator_new <- function(input_option_chain, min_strike_ratio=NULL, max_strike_ratio=NULL,
                                    min_avg_days_to_expiry=NULL, max_avg_days_to_expiry=NULL) {
  input_ticker <- unique(input_option_chain$Symbol)
  input_date <- unique(input_option_chain$DataDate)
  input_underlying_price <- unique(input_option_chain$UnderlyingPrice)
  
  input_option_chain$days_to_expiry <- as.integer(difftime(ymd(input_option_chain$ExpirationDate),
                                                            ymd(input_option_chain$DataDate), units = "days"))
  input_option_chain$business_days_to_expiry = as.numeric(bizdays(as.Date(input_option_chain$DataDate),
                                                                  as.Date(input_option_chain$ExpirationDate), "QuantLib/UnitedStates/NYSE"))
  
  input_option_chain$mean_days_to_expiry <- rowMeans(input_option_chain[c("days_to_expiry", "business_days_to_expiry")])
  input_option_chain$option_ratio <- input_option_chain$StrikePrice / input_option_chain$UnderlyingPrice
  
  if(length(input_ticker) > 1) {
    return("Error: Must provide input with only 1 included ticker")
  }
  if(length(input_date) > 1) {
    return("Error: Must provide input with only 1 quote date")
  }
  if(length(input_underlying_price) > 1) {
    return("Error: Differing underlying average for the same day")
  }
  
  if(is.null(min_strike_ratio) && is.null(max_strike_ratio)) {
    return("Error: Must provide strike ratios to aggregate on")
  } else {
    if(!is.null(min_strike_ratio) && !is.null(max_strike_ratio)) {
      input_option_chain <- input_option_chain %>%
        filter(option_ratio > min_strike_ratio & option_ratio <= max_strike_ratio)
    } else if(is.null(min_strike_ratio) && !is.null(max_strike_ratio)) {
      input_option_chain <- input_option_chain %>%
        filter(option_ratio <= max_strike_ratio)
    } else if(!is.null(min_strike_ratio) && is.null(max_strike_ratio)) {
      input_option_chain <- input_option_chain %>%
        filter(option_ratio > min_strike_ratio)
    }
  }
  
  if(is.null(min_avg_days_to_expiry) && is.null(max_avg_days_to_expiry)) {
    return("Error: Must provide expiration day ranges to aggregate on")
  } else {
    if(!is.null(min_avg_days_to_expiry) && !is.null(max_avg_days_to_expiry)) {
      input_option_chain <- input_option_chain %>%
        filter(mean_days_to_expiry >= min_avg_days_to_expiry & mean_days_to_expiry < max_avg_days_to_expiry)
    } else if(is.null(min_avg_days_to_expiry) && !is.null(max_avg_days_to_expiry)) {
      input_option_chain <- input_option_chain %>%
        filter(mean_days_to_expiry < max_avg_days_to_expiry)
    } else if(!is.null(min_avg_days_to_expiry) && is.null(max_avg_days_to_expiry)) {
      input_option_chain <- input_option_chain %>%
        filter(mean_days_to_expiry >= min_avg_days_to_expiry)
    }
  }
  
  call_data <- input_option_chain %>% filter(PutCall == "call")
  put_data <- input_option_chain %>% filter(PutCall == "put")
  
  temp_results <- list(
    option_underlying_ticker = input_ticker,
    option_quote_date = input_date,
    option_underlying_price = input_underlying_price,
    option_total_call_listings = nrow(call_data),
    option_call_total_volume = sum(call_data$Volume, na.rm = TRUE),
    option_call_total_open_interest = sum(call_data$OpenInterest, na.rm = TRUE),
    option_total_put_listings = nrow(put_data),
    option_put_total_volume = sum(put_data$Volume, na.rm = TRUE),
    option_put_total_open_interest = sum(put_data$OpenInterest, na.rm = TRUE)
  )
  
  return(as.data.frame(temp_results))
}

main_dir <- "E:/Market_Data/DiscountOptionData/DTNSubscription/"
setwd(main_dir)

raw_files <- list.files(main_dir, pattern = "\\.csv$")
temp_subset <- raw_files[str_detect(raw_files, fixed('.csv')) & str_detect(raw_files, fixed('OData1'))]
date_list <- unlist(lapply(temp_subset,function(x){paste0("D_",str_split(x,"_")[[1]][2])}))

timestamp <- Sys.time()

for(temp_date in date_list) {
  temp_file1 <- paste0(temp_date, "_OData1.csv")
  temp_file2 <- paste0(temp_date, "_OData2.csv")
  
  temp_df1 <- read_csv(temp_file1)
  temp_df2 <- read_csv(temp_file2)
  
  dfOptions <- bind_rows(temp_df1, temp_df2)
  
  all_tickers <- unique(dfOptions$Symbol)
  
  new_chain <- NULL
  for(temp_ticker in all_tickers) {
    test_chain <- dfOptions %>% filter(Symbol == temp_ticker)
    print(temp_ticker)
    
    # Suggest starting with <10, 10-25, 25-50, 50-100, 100-200, 200-350, >350
    min_strike_set = c(NA, 0.5, 0.75, 0.9, 0.95, 1, 1.05, 1.1, 1.25, 1.5)
    max_strike_set = c(0.5, 0.75, 0.9, 0.95, 1, 1.05, 1.1, 1.25, 1.5, NA)
    min_day_set = c(NA, 10, 25, 50, 100, 200, 350)
    max_day_set = c(10, 25, 50, 100, 200, 350, NA)
    for (temp_strike_i in 1:length(min_strike_set)){
      for (temp_day_i in 1:length(min_day_set)){
        # Aggregate over all strike ranges
        test_result = option_chain_aggregator_new(
            test_chain, min_strike_ratio=min_strike_set[temp_strike_i],
            max_strike_ratio=max_strike_set[temp_strike_i],
            min_avg_days_to_expiry=min_day_set[temp_day_i],
            max_avg_days_to_expiry=max_day_set[temp_day_i]
        )
        if(is.null(new_chain)) {
          new_chain <- test_result
        } else {
          new_chain <- bind_rows(new_chain, test_result)
        }
      }
    }
  }
  
  write_csv(new_chain, paste0("aggregate_files/", temp_date, "_aggregate.csv"))
  print(paste("Finished with", temp_date))
  print(timestamp)
}


```

```{r new test}

library(future)
library(furrr)
library(dplyr)
library(readr)
library(lubridate)
library(stringr)
library(RQuantLib)
library(bizdays)

plan(multisession)  # Use multicore, adjust based on your system capabilities

option_chain_aggregator_new <- function(input_option_chain, min_strike_ratio=NULL, max_strike_ratio=NULL,
                                    min_avg_days_to_expiry=NULL, max_avg_days_to_expiry=NULL) {
  load_quantlib_calendars("UnitedStates/NYSE", from = "2000-01-01", to = "2030-12-31")
  input_ticker <- unique(input_option_chain$Symbol)
  input_date <- unique(input_option_chain$DataDate)
  input_underlying_price <- unique(input_option_chain$UnderlyingPrice)
  
  input_option_chain$days_to_expiry <- as.integer(difftime(ymd(input_option_chain$ExpirationDate),
                                                            ymd(input_option_chain$DataDate), units = "days"))
  input_option_chain$business_days_to_expiry = as.numeric(bizdays(as.Date(input_option_chain$DataDate),
                                                                  as.Date(input_option_chain$ExpirationDate), "QuantLib/UnitedStates/NYSE"))
  
  input_option_chain$mean_days_to_expiry <- rowMeans(input_option_chain[c("days_to_expiry", "business_days_to_expiry")])
  input_option_chain$option_ratio <- input_option_chain$StrikePrice / input_option_chain$UnderlyingPrice
  
  if(length(input_ticker) > 1) {
    return("Error: Must provide input with only 1 included ticker")
  }
  if(length(input_date) > 1) {
    return("Error: Must provide input with only 1 quote date")
  }
  if(length(input_underlying_price) > 1) {
    return("Error: Differing underlying average for the same day")
  }
  
  if(is.null(min_strike_ratio) && is.null(max_strike_ratio)) {
    return("Error: Must provide strike ratios to aggregate on")
  } else {
    if(!is.null(min_strike_ratio) && !is.null(max_strike_ratio)) {
      input_option_chain <- input_option_chain %>%
        filter(option_ratio > min_strike_ratio & option_ratio <= max_strike_ratio)
    } else if(is.null(min_strike_ratio) && !is.null(max_strike_ratio)) {
      input_option_chain <- input_option_chain %>%
        filter(option_ratio <= max_strike_ratio)
    } else if(!is.null(min_strike_ratio) && is.null(max_strike_ratio)) {
      input_option_chain <- input_option_chain %>%
        filter(option_ratio > min_strike_ratio)
    }
  }
  
  if(is.null(min_avg_days_to_expiry) && is.null(max_avg_days_to_expiry)) {
    return("Error: Must provide expiration day ranges to aggregate on")
  } else {
    if(!is.null(min_avg_days_to_expiry) && !is.null(max_avg_days_to_expiry)) {
      input_option_chain <- input_option_chain %>%
        filter(mean_days_to_expiry >= min_avg_days_to_expiry & mean_days_to_expiry < max_avg_days_to_expiry)
    } else if(is.null(min_avg_days_to_expiry) && !is.null(max_avg_days_to_expiry)) {
      input_option_chain <- input_option_chain %>%
        filter(mean_days_to_expiry < max_avg_days_to_expiry)
    } else if(!is.null(min_avg_days_to_expiry) && is.null(max_avg_days_to_expiry)) {
      input_option_chain <- input_option_chain %>%
        filter(mean_days_to_expiry >= min_avg_days_to_expiry)
    }
  }
  
  call_data <- input_option_chain %>% filter(PutCall == "call")
  put_data <- input_option_chain %>% filter(PutCall == "put")
  
  temp_results <- list(
    option_underlying_ticker = input_ticker,
    option_quote_date = input_date,
    option_underlying_price = input_underlying_price,
    option_total_call_listings = nrow(call_data),
    option_call_total_volume = sum(call_data$Volume, na.rm = TRUE),
    option_call_total_open_interest = sum(call_data$OpenInterest, na.rm = TRUE),
    option_total_put_listings = nrow(put_data),
    option_put_total_volume = sum(put_data$Volume, na.rm = TRUE),
    option_put_total_open_interest = sum(put_data$OpenInterest, na.rm = TRUE)
  )
  
  return(as.data.frame(temp_results))
}

# Your option_chain_aggregator_new function remains unchanged

main_dir <- "E:/Market_Data/DiscountOptionData/DTNSubscription/"
setwd(main_dir)

raw_files <- list.files(main_dir, pattern = "\\.csv$")
temp_subset <- raw_files[str_detect(raw_files, fixed('.csv')) & str_detect(raw_files, fixed('OData1'))]
date_list <- unlist(lapply(temp_subset, function(x) {paste0("D_", str_split(x, "_")[[1]][2])}))

timestamp <- Sys.time()

for(temp_date in date_list) {
  temp_file1 <- paste0(temp_date, "_OData1.csv")
  temp_file2 <- paste0(temp_date, "_OData2.csv")
  
  temp_df1 <- read_csv(temp_file1)
  temp_df2 <- read_csv(temp_file2)
  
  dfOptions <- bind_rows(temp_df1, temp_df2)
  
  all_tickers <- unique(dfOptions$Symbol)

  # Define your sets outside of the loop to avoid redundancy
  min_strike_set <- c(NA, 0.5, 0.75, 0.9, 0.95, 1, 1.05, 1.1, 1.25, 1.5)
  max_strike_set <- c(0.5, 0.75, 0.9, 0.95, 1, 1.05, 1.1, 1.25, 1.5, NA)
  min_day_set <- c(NA, 10, 25, 50, 100, 200, 350)
  max_day_set <- c(10, 25, 50, 100, 200, 350, NA)

  results <- future_map(all_tickers, function(temp_ticker) {
    test_chain <- dfOptions %>% filter(Symbol == temp_ticker)

    new_chain <- NULL
    for(temp_strike_i in 1:length(min_strike_set)) {
      for(temp_day_i in 1:length(min_day_set)) {
        test_result <- option_chain_aggregator_new(
          test_chain, min_strike_ratio = min_strike_set[temp_strike_i],
          max_strike_ratio = max_strike_set[temp_strike_i],
          min_avg_days_to_expiry = min_day_set[temp_day_i],
          max_avg_days_to_expiry = max_day_set[temp_day_i]
        )
        new_chain <- if(is.null(new_chain)) test_result else bind_rows(new_chain, test_result)
      }
    }
    new_chain
  })

  final_chain <- bind_rows(results)
  write_csv(final_chain, paste0("aggregate_files/", temp_date, "_aggregate.csv"))
  print(paste("Finished with", temp_date))
  print(timestamp)
}


```

```{r redone option aggregator}

source("C:/Users/Andy/Downloads/Investing files/Investing_Project_Rstudio/finance_functions.R")
library(parallel)

# Function to process a single file in parallel

option_chain_aggregatorV2 = function(input_option_chain, min_strike_ratio=NA, max_strike_ratio=NA,min_avg_days_to_expiry=NA,max_avg_days_to_expiry=NA){
      input_ticker <- unique(input_option_chain$Symbol)
      input_date <- unique(input_option_chain$DataDate)
      input_underlying_price <- unique(input_option_chain$UnderlyingPrice)
      
      input_option_chain$days_to_expiry <- as.numeric(as.Date(input_option_chain$ExpirationDate)-as.Date(input_option_chain$DataDate))
      input_option_chain$business_days_to_expiry = as.numeric(bizdays(as.Date(input_option_chain$DataDate),
                                                                      as.Date(input_option_chain$ExpirationDate), "QuantLib/UnitedStates/NYSE"))
      
      input_option_chain$mean_days_to_expiry <- rowMeans(input_option_chain[c("days_to_expiry", "business_days_to_expiry")])
      input_option_chain$option_ratio <- input_option_chain$StrikePrice / input_option_chain$UnderlyingPrice
      if(length(input_ticker) > 1){
        return("Error: Must provide input with only 1 included ticker")
      }
      if(length(input_date) > 1){
        return("Error: Must provide input with only 1 quote date")
      }
      if(length(input_underlying_price) > 1){
        return("Error: Differing underlying average for the same day")
      }
      if(is.na(min_strike_ratio) & is.na(max_strike_ratio)){
        return("Error: Must provide strike ratios to aggregate on")
      }else if(is.na(min_strike_ratio) & !is.na(max_strike_ratio)){
        input_option_chain = input_option_chain[input_option_chain$option_ratio <= max_strike_ratio,]
        input_strike_range = paste0("x <= ", max_strike_ratio)
      }else if(!is.na(min_strike_ratio) & is.na(max_strike_ratio)){
        input_option_chain = input_option_chain[input_option_chain$option_ratio > min_strike_ratio,]
        input_strike_range = paste0(min_strike_ratio," < x")
      }else if(!is.na(min_strike_ratio) & !is.na(max_strike_ratio)){
        input_option_chain = input_option_chain[input_option_chain$option_ratio > min_strike_ratio,]
        input_option_chain = input_option_chain[input_option_chain$option_ratio <= max_strike_ratio,]
        input_strike_range = paste0(min_strike_ratio," < x <= ", max_strike_ratio)
      }
      if(is.na(min_avg_days_to_expiry) & is.na(max_avg_days_to_expiry)){
        return("Error: Must provide expiration day ranges to aggregate on")
      }else if(is.na(min_avg_days_to_expiry) & !is.na(max_avg_days_to_expiry)){
        input_option_chain = input_option_chain[input_option_chain$mean_days_to_expiry < max_avg_days_to_expiry,]
        input_expiry_range = paste0("x < ", max_avg_days_to_expiry)
      }else if(!is.na(min_avg_days_to_expiry) & is.na(max_avg_days_to_expiry)){
        input_option_chain = input_option_chain[input_option_chain$mean_days_to_expiry >= min_avg_days_to_expiry,]
        input_expiry_range = paste0(min_avg_days_to_expiry," <= x")
      }else if(!is.na(min_avg_days_to_expiry) & !is.na(max_avg_days_to_expiry)){
        input_option_chain = input_option_chain[input_option_chain$mean_days_to_expiry >= min_avg_days_to_expiry,]
        input_option_chain = input_option_chain[input_option_chain$mean_days_to_expiry < max_avg_days_to_expiry,]
        input_expiry_range = paste0(min_avg_days_to_expiry," <= x < ", max_avg_days_to_expiry)
      }
      
      temp_results <- list("option_underlying_ticker"=input_ticker,
                           "option_quote_date"=input_date,
                           "option_underlying_price"=input_underlying_price,
                           "option_strike_range"=input_strike_range,
                           "option_expiry_range"=input_expiry_range)
      
      if(nrow(input_option_chain[input_option_chain$PutCall == "call",]) > 0){
        temp_results[["option_total_call_listings"]]=nrow(input_option_chain[input_option_chain$PutCall == "call",])
        temp_results[["option_call_total_volume"]]=sum(input_option_chain$Volume[input_option_chain$PutCall == "call"],na.rm = TRUE)
        temp_results[["option_call_total_open_interest"]]=sum(input_option_chain$OpenInterest[input_option_chain$PutCall == "call"],na.rm = TRUE)
      }else{
        temp_results[["option_total_call_listings"]]=0
        temp_results[["option_call_total_volume"]]=0
        temp_results[["option_call_total_open_interest"]]=0
      }
      if(nrow(input_option_chain[input_option_chain$PutCall == "put",]) > 0){
        temp_results[["option_total_put_listings"]]=nrow(input_option_chain[input_option_chain$PutCall == "put",])
        temp_results[["option_put_total_volume"]]=sum(input_option_chain$Volume[input_option_chain$PutCall == "put"],na.rm = TRUE)
        temp_results[["option_put_total_open_interest"]]=sum(input_option_chain$OpenInterest[input_option_chain$PutCall == "put"],na.rm = TRUE)
      }else{
        temp_results[["option_total_put_listings"]]=0
        temp_results[["option_put_total_volume"]]=0
        temp_results[["option_put_total_open_interest"]]=0
      }
      temp_results <- as.data.frame(temp_results)
      return(temp_results)
    }

process_file <- function(file_index, date_list) {
      temp_date <- date_list[file_index]
      
      # Load options data
      temp_file1 <- paste0(main_dir, temp_date, "_OData1.csv")
      temp_file2 <- paste0(main_dir, temp_date, "_OData2.csv")
      
      # Use fread for faster reading of CSVs
      temp_df1 <- fread(temp_file1)
      temp_df2 <- fread(temp_file2)
      
      filteredOptions <- rbindlist(list(temp_df1, temp_df2))
      
      # Filter for the first 1000 unique tickers for demonstration
      all_tickers <- unique(filteredOptions$Symbol)[1:1000]
      
      # Calculate option_ratio
      filteredOptions[, option_ratio := StrikePrice / UnderlyingPrice]
      
      # Initialize an empty list to store results for each ticker
      new_chain_list <- list()
      
      for (temp_ticker in all_tickers) {
        test_chain <- filteredOptions[Symbol == temp_ticker]
        
        # Your aggregation logic here, consider using data.table for efficiency
        
        # Append the result for this ticker to the list
        new_chain_list[[temp_ticker]] <- test_chain # Replace test_chain with your actual result
      }
      
      # Combine all ticker results
      new_chain <- rbindlist(new_chain_list, use.names = TRUE, fill = TRUE)
      
      # Save the result
      saveRDS(new_chain, paste0("aggregate_files/", temp_date, "_aggregate.RDS"))
    }

##First merge stock data by date and calculate averages
##Second aggregate options by strike ranges
##Third aggregate options by expiry ranges (use average of days and business days to expiry)
##  Suggest starting with <10, 10-25, 25-50, 50-100, 100-200, 200-350, >350
##Fourth merge option ratio and expiry ranges by date and calculate averages

main_dir = "E:/Market_Data/DiscountOptionData/DTNSubscription/"

# Change the working directory
setwd(main_dir)

# Print the current working directory to verify the change
print(getwd())

# Get list of option and stock files

raw_files <- list.files(main_dir, pattern = "\\.csv$")
temp_subset <- raw_files[str_detect(raw_files, fixed('.csv')) & str_detect(raw_files, fixed('OData1'))]
date_list <- unlist(lapply(temp_subset, function(x) {paste0("D_", str_split(x, "_")[[1]][2])}))

# Use parallel processing to process files concurrently
num_cores <- detectCores()
cl <- makeCluster(num_cores)
timestamp()
result <- parLapply(cl, 1:length(date_list), process_file)
stopCluster(cl)

timestamp()


```

```{r main aggregation run}

library(data.table)  # For efficient data manipulation and reading
library(parallel)    # For parallel processing
library(bizdays)     # For business days calculation
library(stringr)

# Load the external script once, assuming it defines necessary functions
#source("C:/Users/Andy/Downloads/Investing files/Investing_Project_Rstudio/finance_functions.R")

option_chain_aggregatorV3 <- function(input_option_chain, min_strike_ratio=NA, max_strike_ratio=NA, min_avg_days_to_expiry=NA, max_avg_days_to_expiry=NA) {
  # Ensure input_option_chain is a data.table
  setDT(input_option_chain)

  # Check for unique ticker, date, and price
  if (uniqueN(input_option_chain$Symbol) > 1 || uniqueN(input_option_chain$DataDate) > 1 || uniqueN(input_option_chain$UnderlyingPrice) > 1) {
    stop("Error: Input must have only 1 ticker, 1 quote date, and a consistent underlying price.")
  }

  # Calculate days to expiry and option ratio
  input_option_chain[, `:=`( 
    days_to_expiry = as.numeric(as.Date(ExpirationDate) - as.Date(DataDate)),
    business_days_to_expiry = as.numeric(bizdays(as.Date(DataDate), as.Date(ExpirationDate), "QuantLib/UnitedStates/NYSE")) 
    )]
  input_option_chain[, mean_days_to_expiry := rowMeans(.SD, na.rm = TRUE), .SDcols = c("days_to_expiry", "business_days_to_expiry")]
  input_option_chain[, option_ratio := StrikePrice / UnderlyingPrice]

  # Apply filters
  strike_filter <- (is.na(min_strike_ratio) | input_option_chain$option_ratio > min_strike_ratio) & 
    (is.na(max_strike_ratio) | input_option_chain$option_ratio <= max_strike_ratio)
  days_filter <- (is.na(min_avg_days_to_expiry) | input_option_chain$mean_days_to_expiry >= min_avg_days_to_expiry) & 
    (is.na(max_avg_days_to_expiry) | input_option_chain$mean_days_to_expiry < max_avg_days_to_expiry)
  filtered_option_chain <- input_option_chain[strike_filter & days_filter]

  # Construct results
  temp_results <- list(
    option_underlying_ticker = input_option_chain$Symbol[1],
    option_quote_date = input_option_chain$DataDate[1],
    option_underlying_price = input_option_chain$UnderlyingPrice[1]#,
    #option_strike_range = paste(min_strike_ratio, "to", max_strike_ratio),
    #option_expiry_range = paste(min_avg_days_to_expiry, "to", max_avg_days_to_expiry)
  )

  # Aggregate call and put data
  call_data <- filtered_option_chain[PutCall == "call"]
  put_data <- filtered_option_chain[PutCall == "put"]

  temp_results <- c(temp_results, list(
    option_total_call_listings = nrow(call_data),
    option_call_total_volume = sum(call_data$Volume, na.rm = TRUE),
    option_call_total_open_interest = sum(call_data$OpenInterest, na.rm = TRUE),
    option_total_put_listings = nrow(put_data),
    option_put_total_volume = sum(put_data$Volume, na.rm = TRUE),
    option_put_total_open_interest = sum(put_data$OpenInterest, na.rm = TRUE)
  ))

  return(as.data.frame(temp_results))
}

process_fileV2 <- function(file_paths) {
  # Efficient data reading using fread from data.table
  combined_data <- rbindlist(lapply(file_paths, fread))
  combined_data <- combined_data[as.Date(combined_data$ExpirationDate) < as.Date("2030-12-31"),]
  
  # Filter for the first 1000 unique tickers for demonstration
  all_tickers <- unique(combined_data$Symbol)#[1:100]

  # Calculate option_ratio
  combined_data[, option_ratio := StrikePrice / UnderlyingPrice]
  
  results_list <- lapply(all_tickers, function(ticker) {
    test_chain <- combined_data[Symbol == ticker]

    # Suggest starting with <10, 10-25, 25-50, 50-100, 100-200, 200-350, >350
    min_strike_set = c(NA, 0.5, 0.75, 0.9, 0.95, 1, 1.05, 1.1, 1.25, 1.5)
    max_strike_set = c(0.5, 0.75, 0.9, 0.95, 1, 1.05, 1.1, 1.25, 1.5, NA)
    min_day_set = c(NA, 10, 25, 50, 100, 200, 350)
    max_day_set = c(10, 25, 50, 100, 200, 350, NA)
    merge_chain = NULL
    for (temp_strike_i in 1:length(min_strike_set)) {
      for (temp_day_i in 1:length(min_day_set)) {
        # Aggregate over all strike ranges
        test_result = option_chain_aggregatorV3(
          test_chain,
          min_strike_ratio = min_strike_set[temp_strike_i],
          max_strike_ratio = max_strike_set[temp_strike_i],
          min_avg_days_to_expiry = min_day_set[temp_day_i],
          max_avg_days_to_expiry = max_day_set[temp_day_i]
        )
        colnames(test_result)[!(colnames(test_result) %in% c("option_underlying_ticker",
                                       "option_quote_date",
                                       "option_underlying_price"))] = 
          paste0(colnames(test_result)[!(colnames(test_result) %in% c("option_underlying_ticker",
                                       "option_quote_date",
                                       "option_underlying_price"))],
                                     "_strike_",min_strike_set[temp_strike_i],"to",max_strike_set[temp_strike_i],
                                     "_expiry_",min_day_set[temp_day_i],"to",max_day_set[temp_day_i])
        if(temp_strike_i == 1 & temp_day_i == 1){
          merge_chain = test_result
        }else{
          merge_chain = cbind(merge_chain,
                              test_result[,!(colnames(test_result) %in% c("option_underlying_ticker",
                                                                          "option_quote_date",
                                                                          "option_underlying_price"))])
        }
      }
    }
    return(merge_chain)
  })

  # Combine all ticker results
  new_chain <- rbindlist(results_list, use.names = TRUE, fill = TRUE)

  return(new_chain)
}

# Set main directory and read file names
main_dir <- "E:/Market_Data/DiscountOptionData/DTNSubscription/"
setwd(main_dir)

raw_files <- list.files(pattern = "OData1\\.csv$")
date_list <- sapply(raw_files, function(x) sub("_(OData1\\.csv)$", "", x))

existing_files <- list.files(paste0(main_dir,"aggregate_files/"),pattern = "aggregate\\.RDS$")
existing_dates <- sapply(existing_files, function(x) sub("_(aggregate\\.RDS)$", "", x))

date_list <- date_list[!(date_list %in% existing_dates)]

# Prepare file paths for each date
file_paths <- lapply(date_list, function(date) {
  c(paste0(main_dir, date, "_OData1.csv"), paste0(main_dir, date, "_OData2.csv"))
})

# Parallel processing
num_cores <- detectCores()
batch_i <- 1
timestamp()
while(batch_i*12 < length(date_list)){
  sub_file_paths <- file_paths[(1+(12*(batch_i-1))):(12*(batch_i))]
  cl <- makeCluster(num_cores)
  clusterExport(cl, c("sub_file_paths", "option_chain_aggregatorV3", "process_fileV2"))
  clusterEvalQ(cl, {
    library(data.table)
    library(bizdays)
    library(stringr)
    load_quantlib_calendars("UnitedStates/NYSE",from="2000-01-01",to="2030-12-31")
    # Load any other libraries or source any scripts used in process_file or option_chain_aggregatorV2
  })

  # Execute in parallel and measure time
  results <- NULL
  system.time({
    results <- parLapply(cl, seq_along(sub_file_paths), function(i) {
      process_fileV2(sub_file_paths[[i]])
    })
  })
  stopCluster(cl)
  for(temp_i in 1:length(results)){
    temp_date <- results[[temp_i]]$option_quote_date[1]
    temp_date <- str_replace_all(temp_date,"-","")
    saveRDS(results[[temp_i]],file=paste0("aggregate_files/D_",temp_date,"_aggregate.RDS"))
  }
  print(paste0("Finished batch ",batch_i))
  timestamp()
  batch_i <- batch_i + 1
}
sub_file_paths <- file_paths[(1+(12*(batch_i-1))):(length(file_paths))]
cl <- makeCluster(num_cores)
clusterExport(cl, c("sub_file_paths", "option_chain_aggregatorV3", "process_fileV2"))
clusterEvalQ(cl, {
  library(data.table)
  library(bizdays)
  library(stringr)
  load_quantlib_calendars("UnitedStates/NYSE",from="2000-01-01",to="2030-12-31")
  # Load any other libraries or source any scripts used in process_file or option_chain_aggregatorV2
})
# Execute in parallel and measure time
results <- NULL
system.time({
  results <- parLapply(cl, seq_along(sub_file_paths), function(i) {
    process_fileV2(sub_file_paths[[i]])
  })
})
stopCluster(cl)
for(temp_i in 1:length(results)){
  temp_date <- results[[temp_i]]$option_quote_date[1]
  temp_date <- str_replace_all(temp_date,"-","")
  saveRDS(results[[temp_i]],file=paste0("aggregate_files/D_",temp_date,"_aggregate.RDS"))
}
print(paste0("Finished batch ",batch_i))
timestamp()






```

```{r prepare aggregate files}

library(dplyr)

###Get list of aggregate files
main_dir <- "E:/Market_Data/DiscountOptionData/DTNSubscription/"
aggregate_files <- list.files(paste0(main_dir,"aggregate_files/"), pattern = "aggregate\\.RDS$")
##Start with earliest aggregate file
aggregate_files <- aggregate_files[order(aggregate_files)]

###Load each day and add any new tickers to the current list
full_aggregate <- NULL
EMA8_df <- NULL
EMA20_df <- NULL
EMA50_df <- NULL
SMA8_df <- NULL
SMA20_df <- NULL
SMA50_df <- NULL
all_tickers <- c()
batch_counter_i <- 1
for(temp_file_i in 1:length(aggregate_files)){
  temp_file <- readRDS(paste0(main_dir,"aggregate_files/",aggregate_files[temp_file_i]))
  new_date <- unique(temp_file$option_quote_date)
  if(temp_file_i == 1){
    all_dates <- new_date
  }else{
    all_dates <- c(all_dates,new_date)
  }
  new_tickers <- unique(temp_file$option_underlying_ticker)
  all_tickers <- c(all_tickers,new_tickers[!(new_tickers %in% all_tickers)])
  ##Create full aggregate with volume and open interest and derived values
  if(is.null(full_aggregate)){
    full_aggregate <- temp_file
  }else{
    full_aggregate <- as.data.frame(rbind(full_aggregate,temp_file))
  }
  if(!is.null(EMA8_df)){
    #Get list of stocks with prior day EMA
    temp_EMA8_tickers <- EMA8_df$option_underlying_ticker[EMA8_df$option_quote_date == all_dates[(length(all_dates)-1)]]
  }
  if(!is.null(SMA8_df)){
    #Get list of stocks with prior day EMA
    temp_SMA8_tickers <- SMA8_df$option_underlying_ticker[SMA8_df$option_quote_date == all_dates[(length(all_dates)-1)]]
  }
  if(!is.null(EMA20_df)){
    #Get list of stocks with prior day EMA
    temp_EMA20_tickers <- EMA20_df$option_underlying_ticker[EMA20_df$option_quote_date == all_dates[(length(all_dates)-1)]]
  }
  if(!is.null(SMA20_df)){
    #Get list of stocks with prior day EMA
    temp_SMA20_tickers <- SMA20_df$option_underlying_ticker[SMA20_df$option_quote_date == all_dates[(length(all_dates)-1)]]
  }
  if(!is.null(EMA50_df)){
    #Get list of stocks with prior day EMA
    temp_EMA50_tickers <- EMA50_df$option_underlying_ticker[EMA50_df$option_quote_date == all_dates[(length(all_dates)-1)]]
  }
  if(!is.null(SMA50_df)){
    #Get list of stocks with prior day EMA
    temp_SMA50_tickers <- SMA50_df$option_underlying_ticker[SMA50_df$option_quote_date == all_dates[(length(all_dates)-1)]]
  }
  
  ##Calculate new EMA8 for all new stocks with prior EMA8
  sub_aggregate <- full_aggregate[full_aggregate$option_quote_date == new_date,]
  sub_tickers <- unique(sub_aggregate$option_underlying_ticker)
  if(!is.null(EMA8_df)){
    temp_tickers <- sub_tickers[sub_tickers %in% temp_EMA8_tickers]
    temp_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker %in% temp_tickers,]
    temp_aggregate <- temp_aggregate[order(temp_aggregate$option_underlying_ticker),]
    temp_ema8_cols <- temp_aggregate[,c("option_underlying_ticker","option_quote_date")]
    temp_aggregate <- temp_aggregate[,!(colnames(temp_aggregate) %in% c("option_underlying_ticker","option_quote_date"))]
    temp_ema8_df <- EMA8_df[EMA8_df$option_quote_date == all_dates[(length(all_dates)-1)],]
    temp_ema8_df <- temp_ema8_df[temp_ema8_df$option_underlying_ticker %in% temp_tickers,]
    temp_ema8_df <- temp_ema8_df[order(temp_ema8_df$option_underlying_ticker),]
    temp_ema8_df <- temp_ema8_df[,!(colnames(temp_ema8_df) %in% c("option_underlying_ticker","option_quote_date"))]
    if(nrow(temp_aggregate) == nrow(temp_ema8_df)){
      temp_ema8 <- (temp_aggregate) * (2/9) + (temp_ema8_df) * (1 - (2/9))
      temp_ema8 <- as.data.frame(cbind(temp_ema8_cols,round(temp_ema8,2)))
      EMA8_df <- as.data.frame(rbind(EMA8_df,temp_ema8))
      sub_tickers <- sub_tickers[!(sub_tickers %in% temp_EMA8_tickers)]
      print(paste0("EMA8 calculated from prior EMA for ",length(temp_tickers)," tickers"))
    }else(
      print(paste0("Error with EMA8 calculation for ", new_date))
    )
  }
  if(!is.null(SMA8_df)){
    temp_tickers <- sub_tickers[sub_tickers %in% temp_SMA8_tickers]
    temp_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker %in% temp_tickers,]
    temp_aggregate <- temp_aggregate[order(temp_aggregate$option_underlying_ticker),]
    temp_ema8_cols <- temp_aggregate[,c("option_underlying_ticker","option_quote_date")]
    temp_aggregate <- temp_aggregate[,!(colnames(temp_aggregate) %in% c("option_underlying_ticker","option_quote_date"))]
    temp_sma8_df <- SMA8_df[SMA8_df$option_quote_date == all_dates[(length(all_dates)-1)],]
    temp_sma8_df <- temp_sma8_df[temp_sma8_df$option_underlying_ticker %in% temp_tickers,]
    temp_sma8_df <- temp_sma8_df[order(temp_sma8_df$option_underlying_ticker),]
    temp_sma8_df <- temp_sma8_df[,!(colnames(temp_sma8_df) %in% c("option_underlying_ticker","option_quote_date"))]
    if(nrow(temp_aggregate) == nrow(temp_sma8_df)){
      temp_ema8 <- (temp_aggregate) * (2/9) + (temp_sma8_df) * (1 - (2/9))
      temp_ema8 <- as.data.frame(cbind(temp_ema8_cols,round(temp_ema8,2)))
      if(!is.null(EMA8_df)){
        EMA8_df <- as.data.frame(rbind(EMA8_df,temp_ema8))
      }else{
        EMA8_df <- as.data.frame(temp_ema8)
      }
      sub_tickers <- sub_tickers[!(sub_tickers %in% temp_SMA8_tickers)]
      print(paste0("EMA8 calculated from prior SMA for ",length(temp_tickers)," tickers"))
    }else(
      print(paste0("Error with SMA8 calculation for ", new_date))
    )
  }
  if(length(all_dates) >= 8){
    check_dates <- all_dates[(length(all_dates)-7):length(all_dates)]
    sub_aggregate <- full_aggregate[full_aggregate$option_quote_date %in% check_dates,]
    sub_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker %in% sub_tickers,]
    sub_aggregate <- sub_aggregate[order(sub_aggregate$option_underlying_ticker),]
    temp_tickers <- sub_tickers[sub_tickers %in% sub_aggregate$option_underlying_ticker]
    failed_tickers <- c()
    if(length(temp_tickers) > 0){
      if(length(temp_tickers) > 1000){
        print(paste0("Expect long run time for this date due to high number of SMA8 calculations"))
        timestamp()
      }
      for(temp_ticker_i in 1:length(temp_tickers)){
        temp_ticker <- temp_tickers[temp_ticker_i]
        temp_sma8_df <- data.frame(option_underlying_ticker=temp_ticker,option_quote_date=new_date)
        temp_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker == temp_ticker,]
        temp_aggregate <- temp_aggregate[,!(colnames(sub_aggregate) %in% c("option_underlying_ticker","option_quote_date"))]
        if(nrow(temp_aggregate) == 8){
          temp_sma8_df <- as.data.frame(cbind(temp_sma8_df,t(round(colMeans(temp_aggregate),4))))
          if(!is.null(SMA8_df)){
            SMA8_df <- as.data.frame(rbind(SMA8_df,temp_sma8_df))
          }else{
            SMA8_df <- as.data.frame(temp_sma8_df)
          }
          if(temp_ticker_i %% 1000 == 0){
            timestamp()
            print(paste0("SMA8 calculated for ",temp_ticker_i," tickers"))
          }
        }else{
          failed_tickers <- c(failed_tickers,temp_ticker)
        }
      }
    }
    sub_tickers <- sub_tickers[!(sub_tickers %in% temp_tickers)]
    print(paste0("SMA8 calculated for ",length(temp_tickers)," tickers"))
    failed_tickers <- c(sub_tickers,failed_tickers)
    print(paste0("Insufficient SMA8 data for ",length(failed_tickers)," tickers"))
  }else{
    print(paste0("Insufficient EMA8 or SMA8 data for ",length(sub_tickers)," tickers"))
  }
  
  sub_aggregate <- full_aggregate[full_aggregate$option_quote_date == new_date,]
  sub_tickers <- unique(sub_aggregate$option_underlying_ticker)
  if(!is.null(EMA20_df)){
    temp_tickers <- sub_tickers[sub_tickers %in% temp_EMA20_tickers]
    temp_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker %in% temp_tickers,]
    temp_aggregate <- temp_aggregate[order(temp_aggregate$option_underlying_ticker),]
    temp_ema20_cols <- temp_aggregate[,c("option_underlying_ticker","option_quote_date")]
    temp_aggregate <- temp_aggregate[,!(colnames(temp_aggregate) %in% c("option_underlying_ticker","option_quote_date"))]
    temp_ema20_df <- EMA20_df[EMA20_df$option_quote_date == all_dates[(length(all_dates)-1)],]
    temp_ema20_df <- temp_ema20_df[temp_ema20_df$option_underlying_ticker %in% temp_tickers,]
    temp_ema20_df <- temp_ema20_df[order(temp_ema20_df$option_underlying_ticker),]
    temp_ema20_df <- temp_ema20_df[,!(colnames(temp_ema20_df) %in% c("option_underlying_ticker","option_quote_date"))]
    if(nrow(temp_aggregate) == nrow(temp_ema20_df)){
      temp_ema20 <- (temp_aggregate) * (2/21) + (temp_ema20_df) * (1 - (2/21))
      temp_ema20 <- as.data.frame(cbind(temp_ema20_cols,round(temp_ema20,2)))
      EMA20_df <- as.data.frame(rbind(EMA20_df,temp_ema20))
      sub_tickers <- sub_tickers[!(sub_tickers %in% temp_EMA20_tickers)]
      print(paste0("EMA20 calculated from prior EMA for ",length(temp_tickers)," tickers"))
    }else(
      print(paste0("Error with EMA20 calculation for ", new_date))
    )
  }
  if(!is.null(SMA20_df)){
    temp_tickers <- sub_tickers[sub_tickers %in% temp_SMA20_tickers]
    temp_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker %in% temp_tickers,]
    temp_aggregate <- temp_aggregate[order(temp_aggregate$option_underlying_ticker),]
    temp_ema20_cols <- temp_aggregate[,c("option_underlying_ticker","option_quote_date")]
    temp_aggregate <- temp_aggregate[,!(colnames(temp_aggregate) %in% c("option_underlying_ticker","option_quote_date"))]
    temp_sma20_df <- SMA20_df[SMA20_df$option_quote_date == all_dates[(length(all_dates)-1)],]
    temp_sma20_df <- temp_sma20_df[temp_sma20_df$option_underlying_ticker %in% temp_tickers,]
    temp_sma20_df <- temp_sma20_df[order(temp_sma20_df$option_underlying_ticker),]
    temp_sma20_df <- temp_sma20_df[,!(colnames(temp_sma20_df) %in% c("option_underlying_ticker","option_quote_date"))]
    if(nrow(temp_aggregate) == nrow(temp_sma20_df)){
      temp_ema20 <- (temp_aggregate) * (2/21) + (temp_sma20_df) * (1 - (2/21))
      temp_ema20 <- as.data.frame(cbind(temp_ema20_cols,round(temp_ema20,2)))
      if(!is.null(EMA20_df)){
        EMA20_df <- as.data.frame(rbind(EMA20_df,temp_ema20))
      }else{
        EMA20_df <- as.data.frame(temp_ema20)
      }
      sub_tickers <- sub_tickers[!(sub_tickers %in% temp_SMA20_tickers)]
      print(paste0("EMA20 calculated from prior SMA for ",length(temp_tickers)," tickers"))
    }else(
      print(paste0("Error with SMA20 calculation for ", new_date))
    )
  }
  if(length(all_dates) >= 20){
    check_dates <- all_dates[(length(all_dates)-19):length(all_dates)]
    sub_aggregate <- full_aggregate[full_aggregate$option_quote_date %in% check_dates,]
    sub_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker %in% sub_tickers,]
    sub_aggregate <- sub_aggregate[order(sub_aggregate$option_underlying_ticker),]
    temp_tickers <- sub_tickers[sub_tickers %in% sub_aggregate$option_underlying_ticker]
    failed_tickers <- c()
    if(length(temp_tickers) > 0){
      if(length(temp_tickers) > 1000){
        print(paste0("Expect long run time for this date due to high number of SMA20 calculations"))
        timestamp()
      }
      for(temp_ticker_i in 1:length(temp_tickers)){
        temp_ticker <- temp_tickers[temp_ticker_i]
        temp_sma20_df <- data.frame(option_underlying_ticker=temp_ticker,option_quote_date=new_date)
        temp_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker == temp_ticker,]
        temp_aggregate <- temp_aggregate[,!(colnames(sub_aggregate) %in% c("option_underlying_ticker","option_quote_date"))]
        if(nrow(temp_aggregate) == 20){
          temp_sma20_df <- as.data.frame(cbind(temp_sma20_df,t(round(colMeans(temp_aggregate),4))))
          if(!is.null(SMA20_df)){
            SMA20_df <- as.data.frame(rbind(SMA20_df,temp_sma20_df))
          }else{
            SMA20_df <- as.data.frame(temp_sma20_df)
          }
          if(temp_ticker_i %% 1000 == 0){
            timestamp()
            print(paste0("SMA20 calculated for ",temp_ticker_i," tickers"))
          }
        }else{
          failed_tickers <- c(failed_tickers,temp_ticker)
        }
      }
    }
    sub_tickers <- sub_tickers[!(sub_tickers %in% temp_tickers)]
    print(paste0("SMA20 calculated for ",length(temp_tickers)," tickers"))
    failed_tickers <- c(sub_tickers,failed_tickers)
    print(paste0("Insufficient SMA20 data for ",length(failed_tickers)," tickers"))
  }else{
    print(paste0("Insufficient EMA20 or SMA20 data for ",length(sub_tickers)," tickers"))
  }
  
  sub_aggregate <- full_aggregate[full_aggregate$option_quote_date == new_date,]
  sub_tickers <- unique(sub_aggregate$option_underlying_ticker)
  if(!is.null(EMA50_df)){
    temp_tickers <- sub_tickers[sub_tickers %in% temp_EMA50_tickers]
    temp_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker %in% temp_tickers,]
    temp_aggregate <- temp_aggregate[order(temp_aggregate$option_underlying_ticker),]
    temp_ema50_cols <- temp_aggregate[,c("option_underlying_ticker","option_quote_date")]
    temp_aggregate <- temp_aggregate[,!(colnames(temp_aggregate) %in% c("option_underlying_ticker","option_quote_date"))]
    temp_ema50_df <- EMA50_df[EMA50_df$option_quote_date == all_dates[(length(all_dates)-1)],]
    temp_ema50_df <- temp_ema50_df[temp_ema50_df$option_underlying_ticker %in% temp_tickers,]
    temp_ema50_df <- temp_ema50_df[order(temp_ema50_df$option_underlying_ticker),]
    temp_ema50_df <- temp_ema50_df[,!(colnames(temp_ema50_df) %in% c("option_underlying_ticker","option_quote_date"))]
    if(nrow(temp_aggregate) == nrow(temp_ema50_df)){
      temp_ema50 <- (temp_aggregate) * (2/51) + (temp_ema50_df) * (1 - (2/51))
      temp_ema50 <- as.data.frame(cbind(temp_ema50_cols,round(temp_ema50,2)))
      EMA50_df <- as.data.frame(rbind(EMA50_df,temp_ema50))
      sub_tickers <- sub_tickers[!(sub_tickers %in% temp_EMA50_tickers)]
      print(paste0("EMA50 calculated from prior EMA for ",length(temp_tickers)," tickers"))
    }else(
      print(paste0("Error with EMA50 calculation for ", new_date))
    )
  }
  if(!is.null(SMA50_df)){
    temp_tickers <- sub_tickers[sub_tickers %in% temp_SMA50_tickers]
    temp_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker %in% temp_tickers,]
    temp_aggregate <- temp_aggregate[order(temp_aggregate$option_underlying_ticker),]
    temp_ema50_cols <- temp_aggregate[,c("option_underlying_ticker","option_quote_date")]
    temp_aggregate <- temp_aggregate[,!(colnames(temp_aggregate) %in% c("option_underlying_ticker","option_quote_date"))]
    temp_sma50_df <- SMA50_df[SMA50_df$option_quote_date == all_dates[(length(all_dates)-1)],]
    temp_sma50_df <- temp_sma50_df[temp_sma50_df$option_underlying_ticker %in% temp_tickers,]
    temp_sma50_df <- temp_sma50_df[order(temp_sma50_df$option_underlying_ticker),]
    temp_sma50_df <- temp_sma50_df[,!(colnames(temp_sma50_df) %in% c("option_underlying_ticker","option_quote_date"))]
    if(nrow(temp_aggregate) == nrow(temp_sma50_df)){
      temp_ema50 <- (temp_aggregate) * (2/51) + (temp_sma50_df) * (1 - (2/51))
      temp_ema50 <- as.data.frame(cbind(temp_ema50_cols,round(temp_ema50,2)))
      if(!is.null(EMA50_df)){
        EMA50_df <- as.data.frame(rbind(EMA50_df,temp_ema50))
      }else{
        EMA50_df <- as.data.frame(temp_ema50)
      }
      sub_tickers <- sub_tickers[!(sub_tickers %in% temp_SMA50_tickers)]
      print(paste0("EMA50 calculated from prior SMA for ",length(temp_tickers)," tickers"))
    }else(
      print(paste0("Error with SMA50 calculation for ", new_date))
    )
  }
  if(length(all_dates) >= 50){
    check_dates <- all_dates[(length(all_dates)-49):length(all_dates)]
    sub_aggregate <- full_aggregate[full_aggregate$option_quote_date %in% check_dates,]
    sub_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker %in% sub_tickers,]
    sub_aggregate <- sub_aggregate[order(sub_aggregate$option_underlying_ticker),]
    temp_tickers <- sub_tickers[sub_tickers %in% sub_aggregate$option_underlying_ticker]
    failed_tickers <- c()
    if(length(temp_tickers) > 0){
      if(length(temp_tickers) > 1000){
        print(paste0("Expect long run time for this date due to high number of SMA50 calculations"))
        timestamp()
      }
      for(temp_ticker_i in 1:length(temp_tickers)){
        temp_ticker <- temp_tickers[temp_ticker_i]
        temp_sma50_df <- data.frame(option_underlying_ticker=temp_ticker,option_quote_date=new_date)
        temp_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker == temp_ticker,]
        temp_aggregate <- temp_aggregate[,!(colnames(sub_aggregate) %in% c("option_underlying_ticker","option_quote_date"))]
        if(nrow(temp_aggregate) == 50){
          temp_sma50_df <- as.data.frame(cbind(temp_sma50_df,t(round(colMeans(temp_aggregate),4))))
          if(!is.null(SMA50_df)){
            SMA50_df <- as.data.frame(rbind(SMA50_df,temp_sma50_df))
          }else{
            SMA50_df <- as.data.frame(temp_sma50_df)
          }
          if(temp_ticker_i %% 1000 == 0){
            timestamp()
            print(paste0("SMA50 calculated for ",temp_ticker_i," tickers"))
          }
        }else{
          failed_tickers <- c(failed_tickers,temp_ticker)
        }
      }
    }
    sub_tickers <- sub_tickers[!(sub_tickers %in% temp_tickers)]
    print(paste0("SMA50 calculated for ",length(temp_tickers)," tickers"))
    failed_tickers <- c(sub_tickers,failed_tickers)
    print(paste0("Insufficient SMA50 data for ",length(failed_tickers)," tickers"))
  }else{
    print(paste0("Insufficient EMA50 or SMA50 data for ",length(sub_tickers)," tickers"))
  }
  print(paste0("Finished EMA calculations for ",new_date))
  
  ##Save data and reset objects while retaining values for continued EMA and SMA calculation
  if(length(all_dates) %% 100 == 0){
    temp_save_dates <- all_dates[(1+(100*(batch_counter_i-1))):(100*batch_counter_i)]
    temp_start_date <- min(temp_save_dates)
    temp_end_date <- max(temp_save_dates)
    temp_base_path <- "E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/"
    saveRDS(full_aggregate,
            file=paste0(temp_base_path,"full_option_aggregate_",
                        temp_start_date,"_to_",temp_end_date,".RDS"))
    saveRDS(SMA8_df,
            file=paste0(temp_base_path,"SMA8_aggregate_",
                        temp_start_date,"_to_",temp_end_date,".RDS"))
    saveRDS(SMA20_df,
            file=paste0(temp_base_path,"SMA20_aggregate_",
                        temp_start_date,"_to_",temp_end_date,".RDS"))
    saveRDS(SMA50_df,
            file=paste0(temp_base_path,"SMA50_aggregate_",
                        temp_start_date,"_to_",temp_end_date,".RDS"))
    saveRDS(EMA8_df,
            file=paste0(temp_base_path,"EMA8_aggregate_",
                        temp_start_date,"_to_",temp_end_date,".RDS"))
    saveRDS(EMA20_df,
            file=paste0(temp_base_path,"EMA20_aggregate_",
                        temp_start_date,"_to_",temp_end_date,".RDS"))
    saveRDS(EMA50_df,
            file=paste0(temp_base_path,"EMA50_aggregate_",
                        temp_start_date,"_to_",temp_end_date,".RDS"))
      dates_to_keep <- all_dates[((1+(100*(batch_counter_i-1)))+50):(100*batch_counter_i)]
      new_start_date <- min(dates_to_keep)
      new_end_date <- max(dates_to_keep)
      ##Update objects after save with dates to keep
      full_aggregate <- full_aggregate[full_aggregate$option_quote_date >= new_start_date &
                                        full_aggregate$option_quote_date <= new_end_date,]
      SMA8_df <- SMA8_df[SMA8_df$option_quote_date >= new_start_date &
                                        SMA8_df$option_quote_date <= new_end_date,]
      SMA20_df <- SMA20_df[SMA20_df$option_quote_date >= new_start_date &
                                        SMA20_df$option_quote_date <= new_end_date,]
      SMA50_df <- SMA50_df[SMA50_df$option_quote_date >= new_start_date &
                                        SMA50_df$option_quote_date <= new_end_date,]
      EMA8_df <- EMA8_df[EMA8_df$option_quote_date >= new_start_date &
                                        EMA8_df$option_quote_date <= new_end_date,]
      EMA20_df <- EMA20_df[EMA20_df$option_quote_date >= new_start_date &
                                        EMA20_df$option_quote_date <= new_end_date,]
      EMA50_df <- EMA50_df[EMA50_df$option_quote_date >= new_start_date &
                                        EMA50_df$option_quote_date <= new_end_date,]
      batch_counter_i <- batch_counter_i + 1
  }
  
}
temp_save_dates <- all_dates[(1+(100*(batch_counter_i-1))):length(all_dates)]
temp_start_date <- min(temp_save_dates)
temp_end_date <- max(temp_save_dates)
temp_base_path <- "E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/"
saveRDS(full_aggregate,
        file=paste0(temp_base_path,"full_option_aggregate_",
                    temp_start_date,"_to_",temp_end_date,".RDS"))
saveRDS(SMA8_df,
        file=paste0(temp_base_path,"SMA8_aggregate_",
                    temp_start_date,"_to_",temp_end_date,".RDS"))
saveRDS(SMA20_df,
        file=paste0(temp_base_path,"SMA20_aggregate_",
                    temp_start_date,"_to_",temp_end_date,".RDS"))
saveRDS(SMA50_df,
        file=paste0(temp_base_path,"SMA50_aggregate_",
                    temp_start_date,"_to_",temp_end_date,".RDS"))
saveRDS(EMA8_df,
        file=paste0(temp_base_path,"EMA8_aggregate_",
                    temp_start_date,"_to_",temp_end_date,".RDS"))
saveRDS(EMA20_df,
        file=paste0(temp_base_path,"EMA20_aggregate_",
                    temp_start_date,"_to_",temp_end_date,".RDS"))
saveRDS(EMA50_df,
        file=paste0(temp_base_path,"EMA50_aggregate_",
                    temp_start_date,"_to_",temp_end_date,".RDS"))


###Check for prior SMA if no EMA value is present and calculate new EMA if present

###Check for required number of days to calculate SMA and calculate if present


```

```{r new aggregation loop with error handling}

library(data.table)  # For efficient data manipulation and reading
library(parallel)    # For parallel processing
library(bizdays)     # For business days calculation
library(stringr)

# Load the external script once, assuming it defines necessary functions
#source("C:/Users/Andy/Downloads/Investing files/Investing_Project_Rstudio/finance_functions.R")

option_chain_aggregatorV3 <- function(input_option_chain, min_strike_ratio=NA, max_strike_ratio=NA, min_avg_days_to_expiry=NA, max_avg_days_to_expiry=NA) {
  # Ensure input_option_chain is a data.table
  setDT(input_option_chain)

  # Check for unique ticker, date, and price
  if (uniqueN(input_option_chain$Symbol) > 1 || uniqueN(input_option_chain$DataDate) > 1 || uniqueN(input_option_chain$UnderlyingPrice) > 1) {
    stop("Error: Input must have only 1 ticker, 1 quote date, and a consistent underlying price.")
  }

  # Calculate days to expiry and option ratio
  input_option_chain[, `:=`( 
    days_to_expiry = as.numeric(as.Date(ExpirationDate) - as.Date(DataDate)),
    business_days_to_expiry = as.numeric(bizdays(as.Date(DataDate), as.Date(ExpirationDate), "QuantLib/UnitedStates/NYSE")) 
    )]
  input_option_chain[, mean_days_to_expiry := rowMeans(.SD, na.rm = TRUE), .SDcols = c("days_to_expiry", "business_days_to_expiry")]
  input_option_chain[, option_ratio := StrikePrice / UnderlyingPrice]

  # Apply filters
  strike_filter <- (is.na(min_strike_ratio) | input_option_chain$option_ratio > min_strike_ratio) & 
    (is.na(max_strike_ratio) | input_option_chain$option_ratio <= max_strike_ratio)
  days_filter <- (is.na(min_avg_days_to_expiry) | input_option_chain$mean_days_to_expiry >= min_avg_days_to_expiry) & 
    (is.na(max_avg_days_to_expiry) | input_option_chain$mean_days_to_expiry < max_avg_days_to_expiry)
  filtered_option_chain <- input_option_chain[strike_filter & days_filter]

  # Construct results
  temp_results <- list(
    option_underlying_ticker = input_option_chain$Symbol[1],
    option_quote_date = input_option_chain$DataDate[1],
    option_underlying_price = input_option_chain$UnderlyingPrice[1]#,
    #option_strike_range = paste(min_strike_ratio, "to", max_strike_ratio),
    #option_expiry_range = paste(min_avg_days_to_expiry, "to", max_avg_days_to_expiry)
  )

  # Aggregate call and put data
  call_data <- filtered_option_chain[PutCall == "call"]
  put_data <- filtered_option_chain[PutCall == "put"]

  temp_results <- c(temp_results, list(
    option_total_call_listings = nrow(call_data),
    option_call_total_volume = sum(call_data$Volume, na.rm = TRUE),
    option_call_total_open_interest = sum(call_data$OpenInterest, na.rm = TRUE),
    option_total_put_listings = nrow(put_data),
    option_put_total_volume = sum(put_data$Volume, na.rm = TRUE),
    option_put_total_open_interest = sum(put_data$OpenInterest, na.rm = TRUE)
  ))

  return(as.data.frame(temp_results))
}

process_fileV2 <- function(file_paths) {
  # Efficient data reading using fread from data.table
  combined_data <- rbindlist(lapply(file_paths, fread))

  # Filter for the first 1000 unique tickers for demonstration
  all_tickers <- unique(combined_data$Symbol)#[1:100]

  # Calculate option_ratio
  combined_data[, option_ratio := StrikePrice / UnderlyingPrice]

  results_list <- lapply(all_tickers, function(ticker) {
    test_chain <- combined_data[Symbol == ticker]

    # Suggest starting with <10, 10-25, 25-50, 50-100, 100-200, 200-350, >350
    min_strike_set = c(NA, 0.5, 0.75, 0.9, 0.95, 1, 1.05, 1.1, 1.25, 1.5)
    max_strike_set = c(0.5, 0.75, 0.9, 0.95, 1, 1.05, 1.1, 1.25, 1.5, NA)
    min_day_set = c(NA, 10, 25, 50, 100, 200, 350)
    max_day_set = c(10, 25, 50, 100, 200, 350, NA)
    merge_chain = NULL
    for (temp_strike_i in 1:length(min_strike_set)) {
      for (temp_day_i in 1:length(min_day_set)) {
        # Aggregate over all strike ranges
        test_result = option_chain_aggregatorV3(
          test_chain,
          min_strike_ratio = min_strike_set[temp_strike_i],
          max_strike_ratio = max_strike_set[temp_strike_i],
          min_avg_days_to_expiry = min_day_set[temp_day_i],
          max_avg_days_to_expiry = max_day_set[temp_day_i]
        )
        colnames(test_result)[!(colnames(test_result) %in% c("option_underlying_ticker",
                                       "option_quote_date",
                                       "option_underlying_price"))] = 
          paste0(colnames(test_result)[!(colnames(test_result) %in% c("option_underlying_ticker",
                                       "option_quote_date",
                                       "option_underlying_price"))],
                                     "_strike_",min_strike_set[temp_strike_i],"to",max_strike_set[temp_strike_i],
                                     "_expiry_",min_day_set[temp_day_i],"to",max_day_set[temp_day_i])
        if(temp_strike_i == 1 & temp_day_i == 1){
          merge_chain = test_result
        }else{
          merge_chain = cbind(merge_chain,
                              test_result[,!(colnames(test_result) %in% c("option_underlying_ticker",
                                                                          "option_quote_date",
                                                                          "option_underlying_price"))])
        }
      }
    }
    return(merge_chain)
  })

  # Combine all ticker results
  new_chain <- rbindlist(results_list, use.names = TRUE, fill = TRUE)

  return(new_chain)
}

    
# Set main directory and read file names
main_dir <- "E:/Market_Data/DiscountOptionData/DTNSubscription/"
setwd(main_dir)
    
raw_files <- list.files(pattern = "OData1\\.csv$")
date_list <- sapply(raw_files, function(x) sub("_(OData1\\.csv)$", "", x))

existing_files <- list.files(paste0(main_dir,"aggregate_files/"),pattern = "aggregate\\.RDS$")
existing_dates <- sapply(existing_files, function(x) sub("_(aggregate\\.RDS)$", "", x))

date_list <- date_list[!(date_list %in% existing_dates)]

# Prepare file paths for each date
file_paths <- lapply(date_list, function(date) {
  c(paste0(main_dir, date, "_OData1.csv"), paste0(main_dir, date, "_OData2.csv"))
})
  
# Parallel processing
num_cores <- detectCores()
batch_i <- 1
  
while(batch_i*16 < length(date_list)){
  temp_success <- FALSE
  while(!temp_success){
    tryCatch({
      timestamp()
      sub_file_paths <- file_paths[(1+(16*(batch_i-1))):(16*(batch_i))]
      cl <- makeCluster(num_cores)
      clusterExport(cl, c("sub_file_paths", "option_chain_aggregatorV3", "process_fileV2"))
      clusterEvalQ(cl, {
        library(data.table)
        library(bizdays)
        library(stringr)
        load_quantlib_calendars("UnitedStates/NYSE",from="2000-01-01",to="2030-12-31")
        # Load any other libraries or source any scripts used in process_file or option_chain_aggregatorV2
      })
    
      # Execute in parallel and measure time
      results <- NULL
      system.time({
        results <- parLapply(cl, seq_along(sub_file_paths), function(i) {
          process_fileV2(sub_file_paths[[i]])
        })
      })
      stopCluster(cl)
      for(temp_i in 1:length(results)){
        temp_date <- results[[temp_i]]$option_quote_date[1]
        temp_date <- str_replace_all(temp_date,"-","")
        saveRDS(results[[temp_i]],file=paste0("aggregate_files/D_",temp_date,"_aggregate.RDS"))
      }
      print(paste0("Finished batch ",batch_i))
      timestamp()
      batch_i <- batch_i + 1
      temp_success <- TRUE
    }, error = function(e) {
      if (grepl("error reading from connection", e$message)) {
        cat("Caught the specific error, retrying...\n")
      } else {
        # If a different error occurs, rethrow it and exit the loop
        stop(e)
      }
    })
    if (!temp_success) {
      stopCluster(cl)
      Sys.sleep(1)  # Pause for 1 second
    }
  }
}
temp_success <- FALSE
while(!temp_success){
  tryCatch({
    timestamp()
    sub_file_paths <- file_paths[(1+(16*(batch_i-1))):(16*(batch_i))]
    cl <- makeCluster(num_cores)
    clusterExport(cl, c("sub_file_paths", "option_chain_aggregatorV3", "process_fileV2"))
    clusterEvalQ(cl, {
      library(data.table)
      library(bizdays)
      library(stringr)
      load_quantlib_calendars("UnitedStates/NYSE",from="2000-01-01",to="2030-12-31")
      # Load any other libraries or source any scripts used in process_file or option_chain_aggregatorV2
    })
    # Execute in parallel and measure time
    results <- NULL
    system.time({
      results <- parLapply(cl, seq_along(sub_file_paths), function(i) {
        process_fileV2(sub_file_paths[[i]])
      })
    })
    stopCluster(cl)
    for(temp_i in 1:length(results)){
      temp_date <- results[[temp_i]]$option_quote_date[1]
      temp_date <- str_replace_all(temp_date,"-","")
      saveRDS(results[[temp_i]],file=paste0("aggregate_files/D_",temp_date,"_aggregate.RDS"))
    }
    print(paste0("Finished batch ",batch_i))
    timestamp()
    temp_success <- TRUE
  }, error = function(e) {
    if (grepl("error reading from connection", e$message)) {
      cat("Caught the specific error, retrying...\n")
    } else {
      # If a different error occurs, rethrow it and exit the loop
      stop(e)
    }
  })
  if (!temp_success) {
    stopCluster(cl)
    Sys.sleep(1)  # Pause for 1 second
  }
}


```

```{r daily aggregation}

library(data.table)  # For efficient data manipulation and reading
library(parallel)    # For parallel processing
library(bizdays)     # For business days calculation
library(stringr)
load_quantlib_calendars("UnitedStates/NYSE",from="2000-01-01",to="2030-12-31")

# Load the external script once, assuming it defines necessary functions
#source("C:/Users/Andy/Downloads/Investing files/Investing_Project_Rstudio/finance_functions.R")

option_chain_aggregatorV3 <- function(input_option_chain, min_strike_ratio=NA, max_strike_ratio=NA, min_avg_days_to_expiry=NA, max_avg_days_to_expiry=NA) {
  # Ensure input_option_chain is a data.table
  setDT(input_option_chain)

  # Check for unique ticker, date, and price
  if (uniqueN(input_option_chain$Symbol) > 1 || uniqueN(input_option_chain$DataDate) > 1 || uniqueN(input_option_chain$UnderlyingPrice) > 1) {
    stop("Error: Input must have only 1 ticker, 1 quote date, and a consistent underlying price.")
  }

  # Calculate days to expiry and option ratio
  input_option_chain[, `:=`( 
    days_to_expiry = as.numeric(as.Date(ExpirationDate) - as.Date(DataDate)),
    business_days_to_expiry = as.numeric(bizdays(as.Date(DataDate), as.Date(ExpirationDate), "QuantLib/UnitedStates/NYSE")) 
    )]
  input_option_chain[, mean_days_to_expiry := rowMeans(.SD, na.rm = TRUE), .SDcols = c("days_to_expiry", "business_days_to_expiry")]
  input_option_chain[, option_ratio := StrikePrice / UnderlyingPrice]

  # Apply filters
  strike_filter <- (is.na(min_strike_ratio) | input_option_chain$option_ratio > min_strike_ratio) & 
    (is.na(max_strike_ratio) | input_option_chain$option_ratio <= max_strike_ratio)
  days_filter <- (is.na(min_avg_days_to_expiry) | input_option_chain$mean_days_to_expiry >= min_avg_days_to_expiry) & 
    (is.na(max_avg_days_to_expiry) | input_option_chain$mean_days_to_expiry < max_avg_days_to_expiry)
  filtered_option_chain <- input_option_chain[strike_filter & days_filter]

  # Construct results
  temp_results <- list(
    option_underlying_ticker = input_option_chain$Symbol[1],
    option_quote_date = input_option_chain$DataDate[1],
    option_underlying_price = input_option_chain$UnderlyingPrice[1]#,
    #option_strike_range = paste(min_strike_ratio, "to", max_strike_ratio),
    #option_expiry_range = paste(min_avg_days_to_expiry, "to", max_avg_days_to_expiry)
  )

  # Aggregate call and put data
  call_data <- filtered_option_chain[PutCall == "call"]
  put_data <- filtered_option_chain[PutCall == "put"]

  temp_results <- c(temp_results, list(
    option_total_call_listings = nrow(call_data),
    option_call_total_volume = sum(call_data$Volume, na.rm = TRUE),
    option_call_total_open_interest = sum(call_data$OpenInterest, na.rm = TRUE),
    option_total_put_listings = nrow(put_data),
    option_put_total_volume = sum(put_data$Volume, na.rm = TRUE),
    option_put_total_open_interest = sum(put_data$OpenInterest, na.rm = TRUE)
  ))

  return(as.data.frame(temp_results))
}

process_fileV2 <- function(file_paths) {
  # Efficient data reading using fread from data.table
  combined_data <- rbindlist(lapply(file_paths, fread))
  combined_data <- combined_data[as.Date(combined_data$ExpirationDate) < as.Date("2030-12-31"),]
  
  # Filter for the first 1000 unique tickers for demonstration
  all_tickers <- unique(combined_data$Symbol)#[1:100]

  # Calculate option_ratio
  combined_data[, option_ratio := StrikePrice / UnderlyingPrice]
  
  results_list <- lapply(all_tickers, function(ticker) {
    test_chain <- combined_data[Symbol == ticker]

    # Suggest starting with <10, 10-25, 25-50, 50-100, 100-200, 200-350, >350
    min_strike_set = c(NA, 0.5, 0.75, 0.9, 0.95, 1, 1.05, 1.1, 1.25, 1.5)
    max_strike_set = c(0.5, 0.75, 0.9, 0.95, 1, 1.05, 1.1, 1.25, 1.5, NA)
    min_day_set = c(NA, 10, 25, 50, 100, 200, 350)
    max_day_set = c(10, 25, 50, 100, 200, 350, NA)
    merge_chain = NULL
    for (temp_strike_i in 1:length(min_strike_set)) {
      for (temp_day_i in 1:length(min_day_set)) {
        # Aggregate over all strike ranges
        test_result = option_chain_aggregatorV3(
          test_chain,
          min_strike_ratio = min_strike_set[temp_strike_i],
          max_strike_ratio = max_strike_set[temp_strike_i],
          min_avg_days_to_expiry = min_day_set[temp_day_i],
          max_avg_days_to_expiry = max_day_set[temp_day_i]
        )
        colnames(test_result)[!(colnames(test_result) %in% c("option_underlying_ticker",
                                       "option_quote_date",
                                       "option_underlying_price"))] = 
          paste0(colnames(test_result)[!(colnames(test_result) %in% c("option_underlying_ticker",
                                       "option_quote_date",
                                       "option_underlying_price"))],
                                     "_strike_",min_strike_set[temp_strike_i],"to",max_strike_set[temp_strike_i],
                                     "_expiry_",min_day_set[temp_day_i],"to",max_day_set[temp_day_i])
        if(temp_strike_i == 1 & temp_day_i == 1){
          merge_chain = test_result
        }else{
          merge_chain = cbind(merge_chain,
                              test_result[,!(colnames(test_result) %in% c("option_underlying_ticker",
                                                                          "option_quote_date",
                                                                          "option_underlying_price"))])
        }
      }
    }
    return(merge_chain)
  })

  # Combine all ticker results
  new_chain <- rbindlist(results_list, use.names = TRUE, fill = TRUE)

  return(new_chain)
}

# Set main directory and read file names
main_dir <- "E:/Market_Data/DiscountOptionData/DTNSubscription/"
setwd(main_dir)

raw_files <- list.files(pattern = "OData1\\.csv$")
date_list <- sapply(raw_files, function(x) sub("_(OData1\\.csv)$", "", x))

existing_files <- list.files(paste0(main_dir,"aggregate_files/"),pattern = "aggregate\\.RDS$")
existing_dates <- sapply(existing_files, function(x) sub("_(aggregate\\.RDS)$", "", x))

date_list <- date_list[!(date_list %in% existing_dates)]

# Prepare file paths for each date
file_paths <- lapply(date_list, function(date) {
  c(paste0(main_dir, date, "_OData1.csv"), paste0(main_dir, date, "_OData2.csv"))
})

sub_file_paths <- file_paths
timestamp()
if(length(sub_file_paths) == 1){
  results <- process_fileV2(sub_file_paths[[1]])
  temp_date <- results$option_quote_date[1]
  temp_date <- str_replace_all(temp_date,"-","")
  saveRDS(results,file=paste0("aggregate_files/D_",temp_date,"_aggregate.RDS"))
}
timestamp()




```

```{r create new output dataset for NN modeling}

library(stringr)

##Create outcome tables
stock_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/full_option_aggregate_2024-01-22_to_2024-03-27.RDS")
stock_aggregate <- stock_aggregate[,1:3]
stock_aggregate <- stock_aggregate[stock_aggregate$option_quote_date >= "2024-01-22" & stock_aggregate$option_quote_date <= "2024-03-27",]
temp_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/full_option_aggregate_2023-09-04_to_2024-01-19.RDS")
temp_aggregate <- temp_aggregate[,1:3]
temp_aggregate <- temp_aggregate[temp_aggregate$option_quote_date >= "2023-09-04" & temp_aggregate$option_quote_date <= "2024-01-19",]
stock_aggregate <- as.data.frame(rbind(temp_aggregate,stock_aggregate))
temp_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/full_option_aggregate_2023-04-17_to_2023-09-01.RDS")
temp_aggregate <- temp_aggregate[,1:3]
temp_aggregate <- temp_aggregate[temp_aggregate$option_quote_date >= "2023-04-17" & temp_aggregate$option_quote_date <= "2023-09-01",]
stock_aggregate <- as.data.frame(rbind(temp_aggregate,stock_aggregate))
temp_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/full_option_aggregate_2022-11-28_to_2023-04-14.RDS")
temp_aggregate <- temp_aggregate[,1:3]
temp_aggregate <- temp_aggregate[temp_aggregate$option_quote_date >= "2022-11-28" & temp_aggregate$option_quote_date <= "2023-04-14",]
stock_aggregate <- as.data.frame(rbind(temp_aggregate,stock_aggregate))
temp_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/full_option_aggregate_2022-07-11_to_2022-11-25.RDS")
temp_aggregate <- temp_aggregate[,1:3]
temp_aggregate <- temp_aggregate[temp_aggregate$option_quote_date >= "2022-07-11" & temp_aggregate$option_quote_date <= "2022-11-25",]
stock_aggregate <- as.data.frame(rbind(temp_aggregate,stock_aggregate))
temp_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/full_option_aggregate_2022-02-21_to_2022-07-08.RDS")
temp_aggregate <- temp_aggregate[,1:3]
temp_aggregate <- temp_aggregate[temp_aggregate$option_quote_date >= "2022-02-21" & temp_aggregate$option_quote_date <= "2022-07-08",]
stock_aggregate <- as.data.frame(rbind(temp_aggregate,stock_aggregate))
temp_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/full_option_aggregate_2021-10-01_to_2022-02-18.RDS")
temp_aggregate <- temp_aggregate[,1:3]
temp_aggregate <- temp_aggregate[temp_aggregate$option_quote_date >= "2021-10-01" & temp_aggregate$option_quote_date <= "2022-02-18",]
stock_aggregate <- as.data.frame(rbind(temp_aggregate,stock_aggregate))
temp_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/full_option_aggregate_2021-05-14_to_2021-09-30.RDS")
temp_aggregate <- temp_aggregate[,1:3]
temp_aggregate <- temp_aggregate[temp_aggregate$option_quote_date >= "2021-05-14" & temp_aggregate$option_quote_date <= "2021-09-30",]
stock_aggregate <- as.data.frame(rbind(temp_aggregate,stock_aggregate))
stock_aggregate <- stock_aggregate[order(stock_aggregate$option_underlying_ticker,stock_aggregate$option_quote_date),]
all_tickers <- unique(stock_aggregate$option_underlying_ticker)
all_dates <- unique(stock_aggregate$option_quote_date)
filtered_tickers <- all_tickers

full_outcomes <- NULL
input_aggregate <- stock_aggregate[stock_aggregate$option_underlying_ticker %in% filtered_tickers,]
file_counter_i <- 1
for(temp_date_i in 1:length(all_dates)){
    temp_aggregate <- input_aggregate[input_aggregate$option_quote_date == all_dates[temp_date_i],]
    rownames(temp_aggregate) <- temp_aggregate$option_underlying_ticker
    temp_result = temp_aggregate[,c("option_underlying_ticker","option_quote_date")]
    for(temp_counter_i in 1:15){
        if((temp_date_i+temp_counter_i) < length(all_dates)){
            comp_aggregate = input_aggregate[input_aggregate$option_quote_date == all_dates[temp_date_i+temp_counter_i],]
            rownames(comp_aggregate) = comp_aggregate$option_underlying_ticker
            temp_result[,paste0("time",temp_counter_i,"_increase2")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] >= 1.02*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_increase025")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] >= 1.025*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_increase3")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] >= 1.03*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_increase035")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] >= 1.035*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_increase4")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] >= 1.04*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_increase045")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] >= 1.045*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_increase5")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] >= 1.05*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_increase7")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] >= 1.07*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_increase075")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] >= 1.075*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_increase8")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] >= 1.08*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_increase9")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] >= 1.09*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_increase10")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] >= 1.1*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_increase20")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] >= 1.2*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_increase50")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] >= 1.5*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_decrease2")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] <= 0.98*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_decrease025")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] <= 0.975*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_decrease5")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] <= 0.95*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_decrease075")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] <= 0.925*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_decrease10")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] <= 0.9*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_decrease20")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] <= 0.8*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_decrease50")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] <= 0.5*temp_aggregate$option_underlying_price)
            temp_result[,paste0("time",temp_counter_i,"_total_change")] = round(as.numeric(comp_aggregate[rownames(temp_aggregate),"option_underlying_price"] / temp_aggregate$option_underlying_price),5)
        }else{
            temp_result[,paste0("time",temp_counter_i,"_increase2")] = NA
            temp_result[,paste0("time",temp_counter_i,"_increase025")] = NA
            temp_result[,paste0("time",temp_counter_i,"_increase3")] = NA
            temp_result[,paste0("time",temp_counter_i,"_increase035")] = NA
            temp_result[,paste0("time",temp_counter_i,"_increase4")] = NA
            temp_result[,paste0("time",temp_counter_i,"_increase045")] = NA
            temp_result[,paste0("time",temp_counter_i,"_increase5")] = NA
            temp_result[,paste0("time",temp_counter_i,"_increase7")] = NA
            temp_result[,paste0("time",temp_counter_i,"_increase075")] = NA
            temp_result[,paste0("time",temp_counter_i,"_increase8")] = NA
            temp_result[,paste0("time",temp_counter_i,"_increase9")] = NA
            temp_result[,paste0("time",temp_counter_i,"_increase10")] = NA
            temp_result[,paste0("time",temp_counter_i,"_increase20")] = NA
            temp_result[,paste0("time",temp_counter_i,"_increase50")] = NA
            temp_result[,paste0("time",temp_counter_i,"_decrease2")] = NA
            temp_result[,paste0("time",temp_counter_i,"_decrease025")] = NA
            temp_result[,paste0("time",temp_counter_i,"_decrease5")] = NA
            temp_result[,paste0("time",temp_counter_i,"_decrease075")] = NA
            temp_result[,paste0("time",temp_counter_i,"_decrease10")] = NA
            temp_result[,paste0("time",temp_counter_i,"_decrease20")] = NA
            temp_result[,paste0("time",temp_counter_i,"_decrease50")] = NA
            temp_result[,paste0("time",temp_counter_i,"_total_change")] = NA
        }
    }
    #rownames(temp_result) <- paste0(temp_result$option_underlying_ticker,"_",
    #                                unlist(lapply(temp_result$option_quote_date,function(x){
    #                                  str_replace_all(x,"-","")
    #                                 })))
    if(is.null(full_outcomes)){
        full_outcomes = temp_result
    }else{
        full_outcomes = rbind(full_outcomes,temp_result)
    }
    print(paste0("Finished with day ",temp_date_i))
    if(temp_date_i %% 100 == 0){
      saveRDS(full_outcomes,file=paste0("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/full_outcomes_20210514_to_20240229_part",file_counter_i,".RDS"))
      full_outcomes <- NULL
      file_counter_i <- file_counter_i + 1
    }
}
if(temp_date_i %% 100 != 0){
  saveRDS(full_outcomes,file=paste0("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/full_outcomes_20210514_to_20240229_part",file_counter_i,".RDS"))
}

base_dir <- "E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/"
all_files <- list.files("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/")
all_files <- all_files[grepl("full_outcomes_20210514_to_20240229_part",all_files)]
full_outcomes <- NULL
for(temp_file_i in 1:length(all_files)){
  if(is.null(full_outcomes)){
    full_outcomes <- readRDS(paste0(base_dir,all_files[temp_file_i]))
  }else{
    temp_outcomes <- readRDS(paste0(base_dir,all_files[temp_file_i]))
    full_outcomes <- rbind(full_outcomes,temp_outcomes)
  }
}

saveRDS(full_outcomes,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/full_outcomesV2_20210514_to_20240229.RDS")

####


```

```{r create SP500 subset of tickers}

SP500_df <- read.table("E:/Market_Data/SP500_companies_alt_03042024.tsv",sep="\t",header=TRUE)
SP500_tickers <- unique(SP500_df$Symbol)
SP500_extras <- t(read.table("E:/Market_Data/SP500_extras_20210514_to_20240304.tsv",sep="\t",header=FALSE))
SP500_extras <- SP500_extras[!(SP500_extras %in% SP500_tickers)]
SP500_tickers <- c(SP500_tickers,SP500_extras)
saveRDS(SP500_tickers,"E:/Market_Data/SP500_tickers_03042024.RDS")

```

```{r get all stock splits}

library(quantmod)

SP500_tickers <- readRDS("E:/Market_Data/SP500_tickers_03042024.RDS")
SP500_tickers <- unlist(lapply(SP500_tickers,function(x){str_replace_all(x,"[.]","-")}))

stocks_to_drop = c()
#stocks_to_drop = c("ADS","AGN","AKS","ALXN","APC","AVP",
#                   "BBBY",,"CELG","CERN","COG","CTXS","CXO",
#                   "DF","DISCK","DLPH","DNR","DRE","DTV","ENDP","ESV","ETFC",
#                   "FB","FBHS","FII","FLIR","FRC","FRX","FTR","GRA","HFC","HRS",
#                   "JCP","JEC","KSU","LLL","LM","LSI","MON","MXIM",
#                   "NBL","NLSN","NYX","PBCT","QEP","RDC","RE","RHT","RRD","RTN",
#                   "SIVB","STI","TIF","TSS","VAR","VIAB","WCG","WIN","WPX","XEC","XL","XLNX","YHOO")
all_splits = NULL
for(temp_ticker_i in 1:length(SP500_tickers)){
  temp_ticker = SP500_tickers[temp_ticker_i]
  if(!(temp_ticker %in% stocks_to_drop)){
    splits <- getSplits(temp_ticker,from="2021-05-10",to="2024-03-27")
    temp_splits = as.data.frame(list(ticker=c(rep(temp_ticker,length(index(splits)))),date=c(index(splits))))
    if(is.null(all_splits)){
      all_splits = temp_splits
    }else{
      all_splits = rbind(all_splits,temp_splits)
    }
  }
  if(temp_ticker_i %% 50 == 0){
    print(paste0("Finished with ",temp_ticker_i," tickers"))
  }
}

saveRDS(all_splits,"E:/Market_Data/SP500_splits_03272024.RDS")

```

```{r derived interest rate EMAs}

all_rates <- read.csv("E:/Market_Data/DFF_20000101_to_20240329.csv")
all_rates <- all_rates[all_rates$DATE > "2021-01-01",]
all_rates <- all_rates[order(all_rates$DATE),]
rownames(all_rates) <- all_rates$DATE
all_dates <- all_rates$DATE
all_SMA8 <- c(rep(NA,length(all_dates)))
all_SMA20 <- c(rep(NA,length(all_dates)))
all_SMA50 <- c(rep(NA,length(all_dates)))
all_EMA8 <- c(rep(NA,length(all_dates)))
all_EMA20 <- c(rep(NA,length(all_dates)))
all_EMA50 <- c(rep(NA,length(all_dates)))
for(temp_date_i in 1:length(all_dates)){
  if(temp_date_i > 7){
    if(!is.na(all_EMA8[temp_date_i-1])){
      all_EMA8[temp_date_i] <- round((all_rates[temp_date_i,"DFF"] * (2/9) + all_EMA8[temp_date_i-1] * (1 - (2/9))),5)
    }else if(!is.na(all_SMA8[temp_date_i-1])){
      all_EMA8[temp_date_i] <- round((all_rates[temp_date_i,"DFF"] * (2/9) + all_SMA8[temp_date_i-1] * (1 - (2/9))),5)
    }else{
      all_SMA8[temp_date_i] <- round(mean(all_rates[all_dates[(temp_date_i-7):temp_date_i],"DFF"]),5)
    }
    if(temp_date_i > 19){
      if(!is.na(all_EMA20[temp_date_i-1])){
        all_EMA20[temp_date_i] <- round((all_rates[temp_date_i,"DFF"] * (2/21) + all_EMA20[temp_date_i-1] * (1 - (2/21))),5)
      }else if(!is.na(all_SMA20[temp_date_i-1])){
        all_EMA20[temp_date_i] <- round((all_rates[temp_date_i,"DFF"] * (2/21) + all_SMA20[temp_date_i-1] * (1 - (2/21))),5)
      }else{
        all_SMA20[temp_date_i] <- round(mean(all_rates[all_dates[(temp_date_i-19):temp_date_i],"DFF"]),5)
      }
    }
    if(temp_date_i > 49){
      if(!is.na(all_EMA50[temp_date_i-1])){
        all_EMA50[temp_date_i] <- round((all_rates[temp_date_i,"DFF"] * (2/51) + all_EMA50[temp_date_i-1] * (1 - (2/51))),5)
      }else if(!is.na(all_SMA50[temp_date_i-1])){
        all_EMA50[temp_date_i] <- round((all_rates[temp_date_i,"DFF"] * (2/51) + all_SMA50[temp_date_i-1] * (1 - (2/51))),5)
      }else{
        all_SMA50[temp_date_i] <- round(mean(all_rates[all_dates[(temp_date_i-49):temp_date_i],"DFF"]),5)
      }
    }
  }
}

rate_df <- as.data.frame(list(date=all_dates,EOD=all_rates$DFF,EMA8=all_EMA8,EMA20=all_EMA20,EMA50=all_EMA50))
saveRDS(rate_df,file="E:/Market_Data/FedRateDF_20000101_to_20240329.RDS")


```

```{r create input for NN modeling}

library(dplyr)

###Create filtered subset of tickers to start with (e.g. SP500)
SP500_tickers <- readRDS("E:/Market_Data/SP500_tickers_03042024.RDS")
SP500_tickers <- unlist(lapply(SP500_tickers,function(x){str_replace_all(x,"[.]","")}))

###Aggregate together daily, EMA8, and EMA20 data for option aggregates including underlying price
option_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/Backup/full_option_aggregate_2023-04-17_to_2024-02-29.RDS")
option_aggregate <- option_aggregate[option_aggregate$option_underlying_ticker %in% SP500_tickers,]
option_aggregate <- option_aggregate[option_aggregate$option_quote_date >= "2023-04-17" & option_aggregate$option_quote_date <= "2024-02-29",]
temp_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/Backup/full_option_aggregate_2022-05-02_to_2023-04-14.RDS")
temp_aggregate <- temp_aggregate[temp_aggregate$option_underlying_ticker %in% SP500_tickers,]
temp_aggregate <- temp_aggregate[temp_aggregate$option_quote_date >= "2022-05-02" & temp_aggregate$option_quote_date <= "2023-04-14",]
option_aggregate <- as.data.frame(rbind(temp_aggregate,option_aggregate))
temp_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/Backup/full_option_aggregate_2021-05-14_to_2022-04-29.RDS")
temp_aggregate <- temp_aggregate[temp_aggregate$option_underlying_ticker %in% SP500_tickers,]
temp_aggregate <- temp_aggregate[temp_aggregate$option_quote_date >= "2021-05-14" & temp_aggregate$option_quote_date <= "2022-04-29",]
option_aggregate <- as.data.frame(rbind(temp_aggregate,option_aggregate))
option_aggregate <- option_aggregate[order(option_aggregate$option_underlying_ticker,option_aggregate$option_quote_date),]

EMA8_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/Backup/EMA8_aggregate_2023-04-17_to_2024-02-29.RDS")
EMA8_aggregate <- EMA8_aggregate[EMA8_aggregate$option_underlying_ticker %in% SP500_tickers,]
EMA8_aggregate <- EMA8_aggregate[EMA8_aggregate$option_quote_date >= "2023-04-17" & EMA8_aggregate$option_quote_date <= "2024-02-29",]
temp_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/Backup/EMA8_aggregate_2022-05-02_to_2023-04-14.RDS")
temp_aggregate <- temp_aggregate[temp_aggregate$option_underlying_ticker %in% SP500_tickers,]
temp_aggregate <- temp_aggregate[temp_aggregate$option_quote_date >= "2022-05-02" & temp_aggregate$option_quote_date <= "2023-04-14",]
EMA8_aggregate <- as.data.frame(rbind(temp_aggregate,EMA8_aggregate))
temp_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/Backup/EMA8_aggregate_2021-05-14_to_2022-04-29.RDS")
temp_aggregate <- temp_aggregate[temp_aggregate$option_underlying_ticker %in% SP500_tickers,]
temp_aggregate <- temp_aggregate[temp_aggregate$option_quote_date >= "2021-05-14" & temp_aggregate$option_quote_date <= "2022-04-29",]
EMA8_aggregate <- as.data.frame(rbind(temp_aggregate,EMA8_aggregate))
EMA8_aggregate <- EMA8_aggregate[order(EMA8_aggregate$option_underlying_ticker,EMA8_aggregate$option_quote_date),]

EMA20_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/Backup/EMA20_aggregate_2023-04-17_to_2024-02-29.RDS")
EMA20_aggregate <- EMA20_aggregate[EMA20_aggregate$option_underlying_ticker %in% SP500_tickers,]
EMA20_aggregate <- EMA20_aggregate[EMA20_aggregate$option_quote_date >= "2023-04-17" & EMA20_aggregate$option_quote_date <= "2024-02-29",]
temp_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/Backup/EMA20_aggregate_2022-05-02_to_2023-04-14.RDS")
temp_aggregate <- temp_aggregate[temp_aggregate$option_underlying_ticker %in% SP500_tickers,]
temp_aggregate <- temp_aggregate[temp_aggregate$option_quote_date >= "2022-05-02" & temp_aggregate$option_quote_date <= "2023-04-14",]
EMA20_aggregate <- as.data.frame(rbind(temp_aggregate,EMA20_aggregate))
temp_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/Backup/EMA20_aggregate_2021-05-14_to_2022-04-29.RDS")
temp_aggregate <- temp_aggregate[temp_aggregate$option_underlying_ticker %in% SP500_tickers,]
temp_aggregate <- temp_aggregate[temp_aggregate$option_quote_date >= "2021-05-14" & temp_aggregate$option_quote_date <= "2022-04-29",]
EMA20_aggregate <- as.data.frame(rbind(temp_aggregate,EMA20_aggregate))
EMA20_aggregate <- EMA20_aggregate[order(EMA20_aggregate$option_underlying_ticker,EMA20_aggregate$option_quote_date),]

EMA50_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/Backup/EMA50_aggregate_2023-04-17_to_2024-02-29.RDS")
EMA50_aggregate <- EMA50_aggregate[EMA50_aggregate$option_underlying_ticker %in% SP500_tickers,]
EMA50_aggregate <- EMA50_aggregate[EMA50_aggregate$option_quote_date >= "2023-04-17" & EMA50_aggregate$option_quote_date <= "2024-02-29",]
temp_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/Backup/EMA50_aggregate_2022-05-02_to_2023-04-14.RDS")
temp_aggregate <- temp_aggregate[temp_aggregate$option_underlying_ticker %in% SP500_tickers,]
temp_aggregate <- temp_aggregate[temp_aggregate$option_quote_date >= "2022-05-02" & temp_aggregate$option_quote_date <= "2023-04-14",]
EMA50_aggregate <- as.data.frame(rbind(temp_aggregate,EMA50_aggregate))
temp_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/Backup/EMA50_aggregate_2021-05-14_to_2022-04-29.RDS")
temp_aggregate <- temp_aggregate[temp_aggregate$option_underlying_ticker %in% SP500_tickers,]
temp_aggregate <- temp_aggregate[temp_aggregate$option_quote_date >= "2021-05-14" & temp_aggregate$option_quote_date <= "2022-04-29",]
EMA50_aggregate <- as.data.frame(rbind(temp_aggregate,EMA50_aggregate))
EMA50_aggregate <- EMA50_aggregate[order(EMA50_aggregate$option_underlying_ticker,EMA50_aggregate$option_quote_date),]

###Remove dates surrounding stock splits
SP500_splits <- readRDS("E:/Market_Data/SP500_splits_03042024.RDS")

for(temp_split_i in 1:length(SP500_splits)){
  temp_ticker <- SP500_splits$ticker[temp_split_i]
  temp_date <- as.Date(SP500_splits$date[temp_split_i])
  temp_dates <- seq(from = temp_date-10, to = temp_date+10, by = "day")
  option_aggregate[option_aggregate$option_underlying_ticker != temp_ticker | !(option_aggregate$option_quote_date %in% temp_dates),]
  EMA8_aggregate[EMA8_aggregate$option_underlying_ticker != temp_ticker | !(EMA8_aggregate$option_quote_date %in% temp_dates),]
  EMA20_aggregate[EMA20_aggregate$option_underlying_ticker != temp_ticker | !(EMA20_aggregate$option_quote_date %in% temp_dates),]
  EMA50_aggregate[EMA50_aggregate$option_underlying_ticker != temp_ticker | !(EMA50_aggregate$option_quote_date %in% temp_dates),]
}

##Match dates across datasets and retain only those with data for all
match_dates <- unique(EMA50_aggregate$option_quote_date)
temp_dates <- unique(EMA20_aggregate$option_quote_date)
match_dates <- match_dates[match_dates %in% temp_dates]
temp_dates <- unique(EMA8_aggregate$option_quote_date)
match_dates <- match_dates[match_dates %in% temp_dates]
temp_dates <- unique(option_aggregate$option_quote_date)
match_dates <- match_dates[match_dates %in% temp_dates]
option_aggregate <- option_aggregate[option_aggregate$option_quote_date %in% match_dates,]
EMA8_aggregate <- EMA8_aggregate[EMA8_aggregate$option_quote_date %in% match_dates,]
EMA20_aggregate <- EMA20_aggregate[EMA20_aggregate$option_quote_date %in% match_dates,]
EMA50_aggregate <- EMA50_aggregate[EMA50_aggregate$option_quote_date %in% match_dates,]

###Make columns unique across datasets and merge
colnames(option_aggregate) <- paste0("EOD_",colnames(option_aggregate))
colnames(EMA8_aggregate) <- paste0("EMA8_",colnames(EMA8_aggregate))
colnames(EMA20_aggregate) <- paste0("EMA20_",colnames(EMA20_aggregate))
colnames(EMA50_aggregate) <- paste0("EMA50_",colnames(EMA50_aggregate))
rownames(option_aggregate) <- paste0(option_aggregate$EOD_option_underlying_ticker,"_",
                                     format(option_aggregate$EOD_option_quote_date, format = "%Y%m%d"))
rownames(EMA8_aggregate) <- paste0(EMA8_aggregate$EMA8_option_underlying_ticker,"_",
                                     format(EMA8_aggregate$EMA8_option_quote_date, format = "%Y%m%d"))
rownames(EMA20_aggregate) <- paste0(EMA20_aggregate$EMA20_option_underlying_ticker,"_",
                                     format(EMA20_aggregate$EMA20_option_quote_date, format = "%Y%m%d"))
rownames(EMA50_aggregate) <- paste0(EMA50_aggregate$EMA50_option_underlying_ticker,"_",
                                     format(EMA50_aggregate$EMA50_option_quote_date, format = "%Y%m%d"))

merge_aggregate <- as.data.frame(cbind(option_aggregate,
                                       EMA8_aggregate[rownames(option_aggregate),
                                                      !(colnames(EMA8_aggregate) %in% c("EMA8_option_underlying_ticker","EMA8_option_quote_date"))],
                                       EMA20_aggregate[rownames(option_aggregate),
                                                       !(colnames(EMA20_aggregate) %in% c("EMA20_option_underlying_ticker","EMA20_option_quote_date"))],
                                       EMA50_aggregate[rownames(option_aggregate),
                                                       !(colnames(EMA50_aggregate) %in% c("EMA50_option_underlying_ticker","EMA50_option_quote_date"))]))

###Add in daily interest rate for each date
all_rates <- readRDS("E:/Market_Data/FedRateDF_20000101_to_20240229.RDS")
colnames(all_rates) <- paste0(colnames(all_rates),"_FedInterestRate")
rownames(all_rates) <- all_rates$date_FedInterestRate
temp_dates <- format(merge_aggregate$EOD_option_quote_date, format = "%Y-%m-%d")
merge_aggregate$EOD_FedInterestRate <- all_rates[temp_dates,"EOD_FedInterestRate"]
merge_aggregate$EMA8_FedInterestRate <- all_rates[temp_dates,"EMA8_FedInterestRate"]
merge_aggregate$EMA20_FedInterestRate <- all_rates[temp_dates,"EMA20_FedInterestRate"]
merge_aggregate$EMA50_FedInterestRate <- all_rates[temp_dates,"EMA50_FedInterestRate"]

###Merge with outcomes
full_outcomes <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/full_outcomesV2_20210514_to_20240229.RDS")
colnames(full_outcomes) <- paste0("outcomes_",colnames(full_outcomes))
rownames(full_outcomes) <- paste0(full_outcomes$outcomes_option_underlying_ticker,"_",
                                     format(full_outcomes$outcomes_option_quote_date, format = "%Y%m%d"))
full_outcomes <- full_outcomes[rownames(full_outcomes) %in% rownames(merge_aggregate),]
merge_aggregate <- as.data.frame(cbind(merge_aggregate,
                                       full_outcomes[rownames(merge_aggregate),
                                                      !(colnames(full_outcomes) %in% c("outcomes_option_underlying_ticker","outcomes_option_quote_date"))]))

##Remove rows with any NA values
merge_aggregate <- merge_aggregate[rowSums(is.na(merge_aggregate)) == 0,]
#saveRDS(merge_aggregate,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/merged_aggregate_for_NN_20210514_to_20240229.RDS")
merge_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/merged_aggregate_for_NN_20210514_to_20240229.RDS")
test_input <- merge_aggregate[,grepl("_volume_",colnames(merge_aggregate)) | 
                                          grepl("_open_interest_",colnames(merge_aggregate))]
test_input <- test_input + 1
test_input[,grepl("EOD_",colnames(test_input))] <- test_input[,grepl("EOD_",colnames(test_input))] / rowSums(test_input[,grepl("EOD_",colnames(test_input))])
test_input[,grepl("EMA8_",colnames(test_input))] <- test_input[,grepl("EMA8_",colnames(test_input))] / rowSums(test_input[,grepl("EMA8_",colnames(test_input))])
test_input[,grepl("EMA20_",colnames(test_input))] <- test_input[,grepl("EMA20_",colnames(test_input))] / rowSums(test_input[,grepl("EMA20_",colnames(test_input))])
test_input <- log10(test_input)
robustScalerFxn <- function(x){
    x <- ((x - median(x)) / IQR(x))
}
test_input <- test_input %>%
    mutate(across(everything(), robustScalerFxn))
test_input <- round(test_input,3)

###Create NN test input and output datasets
#test_input = as.matrix(merge_aggregate[,!(colnames(merge_aggregate) %in% 
#                                            c("EOD_option_underlying_ticker",
#                                              "EOD_option_quote_date",
#                                              colnames(merge_aggregate)[grepl("outcomes_",colnames(merge_aggregate))],
#                                              colnames(merge_aggregate)[grepl("_listings_",colnames(merge_aggregate))]))])

#write.table(t(test_input),file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_input_for_NN_20210514_to_20240229.tsv",sep="\t")
write.table(t(test_input),file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_inputV2_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_increase2 > 0 | 
                         merge_aggregate$outcomes_time2_increase2 > 0 | 
                         merge_aggregate$outcomes_time3_increase2 > 0 | 
                         merge_aggregate$outcomes_time4_increase2 > 0 | 
                         merge_aggregate$outcomes_time5_increase2 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_2up5d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_increase5 > 0 | 
                         merge_aggregate$outcomes_time2_increase5 > 0 | 
                         merge_aggregate$outcomes_time3_increase5 > 0 | 
                         merge_aggregate$outcomes_time4_increase5 > 0 | 
                         merge_aggregate$outcomes_time5_increase5 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_5up5d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_decrease2 > 0 | 
                         merge_aggregate$outcomes_time2_decrease2 > 0 | 
                         merge_aggregate$outcomes_time3_decrease2 > 0 | 
                         merge_aggregate$outcomes_time4_decrease2 > 0 | 
                         merge_aggregate$outcomes_time5_decrease2 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_2down5d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_decrease5 > 0 | 
                         merge_aggregate$outcomes_time2_decrease5 > 0 | 
                         merge_aggregate$outcomes_time3_decrease5 > 0 | 
                         merge_aggregate$outcomes_time4_decrease5 > 0 | 
                         merge_aggregate$outcomes_time5_decrease5 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_5down5d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_increase2 > 0 | 
                         merge_aggregate$outcomes_time2_increase2 > 0 | 
                         merge_aggregate$outcomes_time3_increase2 > 0 | 
                         merge_aggregate$outcomes_time4_increase2 > 0 | 
                         merge_aggregate$outcomes_time5_increase2 > 0 | 
                         merge_aggregate$outcomes_time6_increase2 > 0 | 
                         merge_aggregate$outcomes_time7_increase2 > 0 | 
                         merge_aggregate$outcomes_time8_increase2 > 0 | 
                         merge_aggregate$outcomes_time9_increase2 > 0 | 
                         merge_aggregate$outcomes_time10_increase2 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_2up10d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_increase5 > 0 | 
                         merge_aggregate$outcomes_time2_increase5 > 0 | 
                         merge_aggregate$outcomes_time3_increase5 > 0 | 
                         merge_aggregate$outcomes_time4_increase5 > 0 | 
                         merge_aggregate$outcomes_time5_increase5 > 0 | 
                         merge_aggregate$outcomes_time6_increase5 > 0 | 
                         merge_aggregate$outcomes_time7_increase5 > 0 | 
                         merge_aggregate$outcomes_time8_increase5 > 0 | 
                         merge_aggregate$outcomes_time9_increase5 > 0 | 
                         merge_aggregate$outcomes_time10_increase5 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_5up10d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_decrease2 > 0 | 
                         merge_aggregate$outcomes_time2_decrease2 > 0 | 
                         merge_aggregate$outcomes_time3_decrease2 > 0 | 
                         merge_aggregate$outcomes_time4_decrease2 > 0 | 
                         merge_aggregate$outcomes_time5_decrease2 > 0 | 
                         merge_aggregate$outcomes_time6_decrease2 > 0 | 
                         merge_aggregate$outcomes_time7_decrease2 > 0 | 
                         merge_aggregate$outcomes_time8_decrease2 > 0 | 
                         merge_aggregate$outcomes_time9_decrease2 > 0 | 
                         merge_aggregate$outcomes_time10_decrease2 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_2down10d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_decrease5 > 0 | 
                         merge_aggregate$outcomes_time2_decrease5 > 0 | 
                         merge_aggregate$outcomes_time3_decrease5 > 0 | 
                         merge_aggregate$outcomes_time4_decrease5 > 0 | 
                         merge_aggregate$outcomes_time5_decrease5 > 0 | 
                         merge_aggregate$outcomes_time6_decrease5 > 0 | 
                         merge_aggregate$outcomes_time7_decrease5 > 0 | 
                         merge_aggregate$outcomes_time8_decrease5 > 0 | 
                         merge_aggregate$outcomes_time9_decrease5 > 0 | 
                         merge_aggregate$outcomes_time10_decrease5 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_5down10d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_decrease10 > 0 | 
                         merge_aggregate$outcomes_time2_decrease10 > 0 | 
                         merge_aggregate$outcomes_time3_decrease10 > 0 | 
                         merge_aggregate$outcomes_time4_decrease10 > 0 | 
                         merge_aggregate$outcomes_time5_decrease10 > 0 | 
                         merge_aggregate$outcomes_time6_decrease10 > 0 | 
                         merge_aggregate$outcomes_time7_decrease10 > 0 | 
                         merge_aggregate$outcomes_time8_decrease10 > 0 | 
                         merge_aggregate$outcomes_time9_decrease10 > 0 | 
                         merge_aggregate$outcomes_time10_decrease10 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_10down10d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_increase10 > 0 | 
                         merge_aggregate$outcomes_time2_increase10 > 0 | 
                         merge_aggregate$outcomes_time3_increase10 > 0 | 
                         merge_aggregate$outcomes_time4_increase10 > 0 | 
                         merge_aggregate$outcomes_time5_increase10 > 0 | 
                         merge_aggregate$outcomes_time6_increase10 > 0 | 
                         merge_aggregate$outcomes_time7_increase10 > 0 | 
                         merge_aggregate$outcomes_time8_increase10 > 0 | 
                         merge_aggregate$outcomes_time9_increase10 > 0 | 
                         merge_aggregate$outcomes_time10_increase10 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_10up10d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_decrease075 > 0 | 
                         merge_aggregate$outcomes_time2_decrease075 > 0 | 
                         merge_aggregate$outcomes_time3_decrease075 > 0 | 
                         merge_aggregate$outcomes_time4_decrease075 > 0 | 
                         merge_aggregate$outcomes_time5_decrease075 > 0 | 
                         merge_aggregate$outcomes_time6_decrease075 > 0 | 
                         merge_aggregate$outcomes_time7_decrease075 > 0 | 
                         merge_aggregate$outcomes_time8_decrease075 > 0 | 
                         merge_aggregate$outcomes_time9_decrease075 > 0 | 
                         merge_aggregate$outcomes_time10_decrease075 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_075down10d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_increase075 > 0 | 
                         merge_aggregate$outcomes_time2_increase075 > 0 | 
                         merge_aggregate$outcomes_time3_increase075 > 0 | 
                         merge_aggregate$outcomes_time4_increase075 > 0 | 
                         merge_aggregate$outcomes_time5_increase075 > 0 | 
                         merge_aggregate$outcomes_time6_increase075 > 0 | 
                         merge_aggregate$outcomes_time7_increase075 > 0 | 
                         merge_aggregate$outcomes_time8_increase075 > 0 | 
                         merge_aggregate$outcomes_time9_increase075 > 0 | 
                         merge_aggregate$outcomes_time10_increase075 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_075up10d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_increase7 > 0 | 
                         merge_aggregate$outcomes_time2_increase7 > 0 | 
                         merge_aggregate$outcomes_time3_increase7 > 0 | 
                         merge_aggregate$outcomes_time4_increase7 > 0 | 
                         merge_aggregate$outcomes_time5_increase7 > 0 | 
                         merge_aggregate$outcomes_time6_increase7 > 0 | 
                         merge_aggregate$outcomes_time7_increase7 > 0 | 
                         merge_aggregate$outcomes_time8_increase7 > 0 | 
                         merge_aggregate$outcomes_time9_increase7 > 0 | 
                         merge_aggregate$outcomes_time10_increase7 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_7up10d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_increase8 > 0 | 
                         merge_aggregate$outcomes_time2_increase8 > 0 | 
                         merge_aggregate$outcomes_time3_increase8 > 0 | 
                         merge_aggregate$outcomes_time4_increase8 > 0 | 
                         merge_aggregate$outcomes_time5_increase8 > 0 | 
                         merge_aggregate$outcomes_time6_increase8 > 0 | 
                         merge_aggregate$outcomes_time7_increase8 > 0 | 
                         merge_aggregate$outcomes_time8_increase8 > 0 | 
                         merge_aggregate$outcomes_time9_increase8 > 0 | 
                         merge_aggregate$outcomes_time10_increase8 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_8up10d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_increase9 > 0 | 
                         merge_aggregate$outcomes_time2_increase9 > 0 | 
                         merge_aggregate$outcomes_time3_increase9 > 0 | 
                         merge_aggregate$outcomes_time4_increase9 > 0 | 
                         merge_aggregate$outcomes_time5_increase9 > 0 | 
                         merge_aggregate$outcomes_time6_increase9 > 0 | 
                         merge_aggregate$outcomes_time7_increase9 > 0 | 
                         merge_aggregate$outcomes_time8_increase9 > 0 | 
                         merge_aggregate$outcomes_time9_increase9 > 0 | 
                         merge_aggregate$outcomes_time10_increase9 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_9up10d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_increase025 > 0 | 
                         merge_aggregate$outcomes_time2_increase025 > 0 | 
                         merge_aggregate$outcomes_time3_increase025 > 0 | 
                         merge_aggregate$outcomes_time4_increase025 > 0 | 
                         merge_aggregate$outcomes_time5_increase025 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_025up5d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_increase3 > 0 | 
                         merge_aggregate$outcomes_time2_increase3 > 0 | 
                         merge_aggregate$outcomes_time3_increase3 > 0 | 
                         merge_aggregate$outcomes_time4_increase3 > 0 | 
                         merge_aggregate$outcomes_time5_increase3 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_3up5d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_increase035 > 0 | 
                         merge_aggregate$outcomes_time2_increase035 > 0 | 
                         merge_aggregate$outcomes_time3_increase035 > 0 | 
                         merge_aggregate$outcomes_time4_increase035 > 0 | 
                         merge_aggregate$outcomes_time5_increase035 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_035up5d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_increase4 > 0 | 
                         merge_aggregate$outcomes_time2_increase4 > 0 | 
                         merge_aggregate$outcomes_time3_increase4 > 0 | 
                         merge_aggregate$outcomes_time4_increase4 > 0 | 
                         merge_aggregate$outcomes_time5_increase4 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_4up5d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_group = as.factor(merge_aggregate$outcomes_time1_increase045 > 0 | 
                         merge_aggregate$outcomes_time2_increase045 > 0 | 
                         merge_aggregate$outcomes_time3_increase045 > 0 | 
                         merge_aggregate$outcomes_time4_increase045 > 0 | 
                         merge_aggregate$outcomes_time5_increase045 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(test_output,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_045up5d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_df <- merge_aggregate[,grepl("_total_change",colnames(merge_aggregate))]
max_10d <- apply(test_df, MARGIN = 1, max)
##Save test input and output data for use in other models
write.table(max_10d,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_maxChange10d_for_NN_20210514_to_20240229.tsv",sep="\t")

test_df <- test_df[,colnames(test_df) %in% c("outcomes_time1_total_change",
                                             "outcomes_time2_total_change",
                                             "outcomes_time3_total_change",
                                             "outcomes_time4_total_change",
                                             "outcomes_time5_total_change")]
max_5d <- apply(test_df, MARGIN = 1, max)
##Save test input and output data for use in other models
write.table(max_5d,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_maxChange5d_for_NN_20210514_to_20240229.tsv",sep="\t")

change_1d <- merge_aggregate$outcomes_time1_total_change
write.table(change_1d,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_change1d_for_NN_20210514_to_20240229.tsv",sep="\t")
change_2d <- merge_aggregate$outcomes_time2_total_change
write.table(change_2d,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_change2d_for_NN_20210514_to_20240229.tsv",sep="\t")
change_3d <- merge_aggregate$outcomes_time3_total_change
write.table(change_3d,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_change3d_for_NN_20210514_to_20240229.tsv",sep="\t")
change_4d <- merge_aggregate$outcomes_time4_total_change
write.table(change_4d,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_change4d_for_NN_20210514_to_20240229.tsv",sep="\t")
change_5d <- merge_aggregate$outcomes_time5_total_change
write.table(change_5d,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_change5d_for_NN_20210514_to_20240229.tsv",sep="\t")
change_6d <- merge_aggregate$outcomes_time6_total_change
write.table(change_6d,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_change6d_for_NN_20210514_to_20240229.tsv",sep="\t")
change_7d <- merge_aggregate$outcomes_time7_total_change
write.table(change_7d,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_change7d_for_NN_20210514_to_20240229.tsv",sep="\t")
change_8d <- merge_aggregate$outcomes_time8_total_change
write.table(change_8d,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_change8d_for_NN_20210514_to_20240229.tsv",sep="\t")
change_9d <- merge_aggregate$outcomes_time9_total_change
write.table(change_9d,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_change9d_for_NN_20210514_to_20240229.tsv",sep="\t")
change_10d <- merge_aggregate$outcomes_time10_total_change
write.table(change_10d,file="E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_change10d_for_NN_20210514_to_20240229.tsv",sep="\t")


```

```{r rewrite daily aggregator in parallel}

library(googledrive)
drive_auth(email = "abbrowne@gmail.com")

googledrive_folder_id <- "14d9Yt6JZp6zSYnxxjXEOF87xAQlMGXXx"
files_in_folder <- drive_ls(as_id(googledrive_folder_id))

main_dir <- "E:/Market_Data/DiscountOptionData/DTNSubscription/"

existing_files <- list.files(paste0(main_dir,"Archives/"),pattern = ".zip$")
files_to_download <- files_in_folder$name[!(files_in_folder$name %in% existing_files)]
files_to_download <- files_to_download[order(files_to_download)]

for(temp_file_i in 1:length(files_to_download)){
  temp_file <- files_to_download[temp_file_i]
  drive_download(temp_file,path=paste0("E:/Market_Data/DiscountOptionData/DTNSubscription/Archives/",temp_file))
  unzip(zipfile=paste0("E:/Market_Data/DiscountOptionData/DTNSubscription/Archives/",temp_file),
        exdir="E:/Market_Data/DiscountOptionData/DTNSubscription/")
}

###Rewrite daily aggregation to use parallel processing across tickers
###Run with above code for now

###Load most recent batch data and use for calculation of new EMA/SMA values and append to existing file (or create new if > 250 days)
library(dplyr)

###Get list of aggregate files
main_dir <- "E:/Market_Data/DiscountOptionData/DTNSubscription/"
aggregate_files <- list.files(paste0(main_dir,"aggregate_files/"), pattern = "aggregate\\.RDS$")
##Start with earliest aggregate file
aggregate_files <- aggregate_files[order(aggregate_files)]
aggregate_dates <- unlist(lapply(aggregate_files,function(x){strsplit(x,"_")[[1]][2]}))
aggregate_dates <- as.Date(aggregate_dates,format="%Y%m%d")

temp_dir <- "E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/"
derived_aggregate_files <- list.files(temp_dir,pattern = "_to_")
temp_dates <- unlist(lapply(derived_aggregate_files, function(x){strsplit(x,"_to_")[[1]][2]}))
latest_date <- max(temp_dates)

aggregate_dates <- aggregate_dates[aggregate_dates > latest_date]
aggregate_files <- unlist(lapply(aggregate_dates,function(x){str_replace_all(x,"-","")}))
aggregate_files <- paste0("D_",aggregate_files,"_aggregate.RDS")

derived_aggregate_files <- derived_aggregate_files[grepl(latest_date,derived_aggregate_files)]

full_aggregate <- readRDS(paste0(temp_dir,derived_aggregate_files[grepl("option_aggregate",derived_aggregate_files)]))
SMA8_df <- readRDS(paste0(temp_dir,derived_aggregate_files[grepl("SMA8_aggregate",derived_aggregate_files)]))
SMA20_df <- readRDS(paste0(temp_dir,derived_aggregate_files[grepl("SMA20_aggregate",derived_aggregate_files)]))
EMA8_df <- readRDS(paste0(temp_dir,derived_aggregate_files[grepl("EMA8_aggregate",derived_aggregate_files)]))
EMA20_df <- readRDS(paste0(temp_dir,derived_aggregate_files[grepl("EMA20_aggregate",derived_aggregate_files)]))

all_tickers <- unique(full_aggregate$option_underlying_ticker)
all_tickers <- all_tickers[order(all_tickers)]
all_dates <- unique(full_aggregate$option_quote_date)
all_dates <- all_dates[order(all_dates)]
###Check if prior dataset has 300 dates and subset to the last 50 dates if so
if(length(all_dates)==300){
  dates_to_keep <- all_dates[251:300]
  new_start_date <- min(dates_to_keep)
  new_end_date <- max(dates_to_keep)
  full_aggregate <- full_aggregate[full_aggregate$option_quote_date >= new_start_date & 
                                     full_aggregate$option_quote_date <= new_end_date,]
  SMA8_df <- SMA8_df[SMA8_df$option_quote_date >= new_start_date & 
                       SMA8_df$option_quote_date <= new_end_date,]
  SMA20_df <- SMA20_df[SMA20_df$option_quote_date >= new_start_date & 
                         SMA20_df$option_quote_date <= new_end_date,]
  EMA8_df <- EMA8_df[EMA8_df$option_quote_date >= new_start_date & 
                       EMA8_df$option_quote_date <= new_end_date,]
  EMA20_df <- EMA20_df[EMA20_df$option_quote_date >= new_start_date & 
                         EMA20_df$option_quote_date <= new_end_date,]
}

#####



batch_counter_i <- 1
for(temp_file_i in 1:length(aggregate_files)){
  temp_file <- readRDS(paste0(main_dir,"aggregate_files/",aggregate_files[temp_file_i]))
  new_date <- unique(temp_file$option_quote_date)
  all_dates <- c(all_dates,new_date)
  new_tickers <- unique(temp_file$option_underlying_ticker)
  all_tickers <- c(all_tickers,new_tickers[!(new_tickers %in% all_tickers)])
  ##Create full aggregate with volume and open interest and derived values
  full_aggregate <- as.data.frame(rbind(full_aggregate,temp_file))
  temp_EMA8_tickers <- EMA8_df$option_underlying_ticker[EMA8_df$option_quote_date == all_dates[(length(all_dates)-1)]]
  temp_SMA8_tickers <- SMA8_df$option_underlying_ticker[SMA8_df$option_quote_date == all_dates[(length(all_dates)-1)]]
  temp_EMA20_tickers <- EMA20_df$option_underlying_ticker[EMA20_df$option_quote_date == all_dates[(length(all_dates)-1)]]
  temp_SMA20_tickers <- SMA20_df$option_underlying_ticker[SMA20_df$option_quote_date == all_dates[(length(all_dates)-1)]]
  
  ##Calculate new EMA8 for all new stocks with prior EMA8
  sub_aggregate <- full_aggregate[full_aggregate$option_quote_date == new_date,]
  sub_tickers <- unique(sub_aggregate$option_underlying_ticker)
  if(!is.null(EMA8_df)){
    temp_tickers <- sub_tickers[sub_tickers %in% temp_EMA8_tickers]
    temp_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker %in% temp_tickers,]
    temp_aggregate <- temp_aggregate[order(temp_aggregate$option_underlying_ticker),]
    temp_ema8_cols <- temp_aggregate[,c("option_underlying_ticker","option_quote_date")]
    temp_aggregate <- temp_aggregate[,!(colnames(temp_aggregate) %in% c("option_underlying_ticker","option_quote_date"))]
    temp_ema8_df <- EMA8_df[EMA8_df$option_quote_date == all_dates[(length(all_dates)-1)],]
    temp_ema8_df <- temp_ema8_df[temp_ema8_df$option_underlying_ticker %in% temp_tickers,]
    temp_ema8_df <- temp_ema8_df[order(temp_ema8_df$option_underlying_ticker),]
    temp_ema8_df <- temp_ema8_df[,!(colnames(temp_ema8_df) %in% c("option_underlying_ticker","option_quote_date"))]
    if(nrow(temp_aggregate) == nrow(temp_ema8_df)){
      temp_ema8 <- (temp_aggregate) * (2/9) + (temp_ema8_df) * (1 - (2/9))
      temp_ema8 <- as.data.frame(cbind(temp_ema8_cols,round(temp_ema8,2)))
      EMA8_df <- as.data.frame(rbind(EMA8_df,temp_ema8))
      sub_tickers <- sub_tickers[!(sub_tickers %in% temp_EMA8_tickers)]
      print(paste0("EMA8 calculated from prior EMA for ",length(temp_tickers)," tickers"))
    }else(
      print(paste0("Error with EMA8 calculation for ", new_date))
    )
  }
  if(!is.null(SMA8_df)){
    temp_tickers <- sub_tickers[sub_tickers %in% temp_SMA8_tickers]
    temp_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker %in% temp_tickers,]
    temp_aggregate <- temp_aggregate[order(temp_aggregate$option_underlying_ticker),]
    temp_ema8_cols <- temp_aggregate[,c("option_underlying_ticker","option_quote_date")]
    temp_aggregate <- temp_aggregate[,!(colnames(temp_aggregate) %in% c("option_underlying_ticker","option_quote_date"))]
    temp_sma8_df <- SMA8_df[SMA8_df$option_quote_date == all_dates[(length(all_dates)-1)],]
    temp_sma8_df <- temp_sma8_df[temp_sma8_df$option_underlying_ticker %in% temp_tickers,]
    temp_sma8_df <- temp_sma8_df[order(temp_sma8_df$option_underlying_ticker),]
    temp_sma8_df <- temp_sma8_df[,!(colnames(temp_sma8_df) %in% c("option_underlying_ticker","option_quote_date"))]
    if(nrow(temp_aggregate) == nrow(temp_sma8_df)){
      temp_ema8 <- (temp_aggregate) * (2/9) + (temp_sma8_df) * (1 - (2/9))
      temp_ema8 <- as.data.frame(cbind(temp_ema8_cols,round(temp_ema8,2)))
      if(!is.null(EMA8_df)){
        EMA8_df <- as.data.frame(rbind(EMA8_df,temp_ema8))
      }else{
        EMA8_df <- as.data.frame(temp_ema8)
      }
      sub_tickers <- sub_tickers[!(sub_tickers %in% temp_SMA8_tickers)]
      print(paste0("EMA8 calculated from prior SMA for ",length(temp_tickers)," tickers"))
    }else(
      print(paste0("Error with SMA8 calculation for ", new_date))
    )
  }
  if(length(all_dates) >= 8){
    check_dates <- all_dates[(length(all_dates)-7):length(all_dates)]
    sub_aggregate <- full_aggregate[full_aggregate$option_quote_date %in% check_dates,]
    sub_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker %in% sub_tickers,]
    sub_aggregate <- sub_aggregate[order(sub_aggregate$option_underlying_ticker),]
    temp_tickers <- sub_tickers[sub_tickers %in% sub_aggregate$option_underlying_ticker]
    failed_tickers <- c()
    if(length(temp_tickers) > 0){
      if(length(temp_tickers) > 1000){
        print(paste0("Expect long run time for this date due to high number of SMA8 calculations"))
        timestamp()
      }
      for(temp_ticker_i in 1:length(temp_tickers)){
        temp_ticker <- temp_tickers[temp_ticker_i]
        temp_sma8_df <- data.frame(option_underlying_ticker=temp_ticker,option_quote_date=new_date)
        temp_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker == temp_ticker,]
        temp_aggregate <- temp_aggregate[,!(colnames(sub_aggregate) %in% c("option_underlying_ticker","option_quote_date"))]
        if(nrow(temp_aggregate) == 8){
          temp_sma8_df <- as.data.frame(cbind(temp_sma8_df,t(round(colMeans(temp_aggregate),4))))
          if(!is.null(SMA8_df)){
            SMA8_df <- as.data.frame(rbind(SMA8_df,temp_sma8_df))
          }else{
            SMA8_df <- as.data.frame(temp_sma8_df)
          }
          if(temp_ticker_i %% 1000 == 0){
            timestamp()
            print(paste0("SMA8 calculated for ",temp_ticker_i," tickers"))
          }
        }else{
          failed_tickers <- c(failed_tickers,temp_ticker)
        }
      }
    }
    sub_tickers <- sub_tickers[!(sub_tickers %in% temp_tickers)]
    print(paste0("SMA8 calculated for ",length(temp_tickers)," tickers"))
    failed_tickers <- c(sub_tickers,failed_tickers)
    print(paste0("Insufficient SMA8 data for ",length(failed_tickers)," tickers"))
  }else{
    print(paste0("Insufficient EMA8 or SMA8 data for ",length(sub_tickers)," tickers"))
  }
  
  sub_aggregate <- full_aggregate[full_aggregate$option_quote_date == new_date,]
  sub_tickers <- unique(sub_aggregate$option_underlying_ticker)
  if(!is.null(EMA20_df)){
    temp_tickers <- sub_tickers[sub_tickers %in% temp_EMA20_tickers]
    temp_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker %in% temp_tickers,]
    temp_aggregate <- temp_aggregate[order(temp_aggregate$option_underlying_ticker),]
    temp_ema20_cols <- temp_aggregate[,c("option_underlying_ticker","option_quote_date")]
    temp_aggregate <- temp_aggregate[,!(colnames(temp_aggregate) %in% c("option_underlying_ticker","option_quote_date"))]
    temp_ema20_df <- EMA20_df[EMA20_df$option_quote_date == all_dates[(length(all_dates)-1)],]
    temp_ema20_df <- temp_ema20_df[temp_ema20_df$option_underlying_ticker %in% temp_tickers,]
    temp_ema20_df <- temp_ema20_df[order(temp_ema20_df$option_underlying_ticker),]
    temp_ema20_df <- temp_ema20_df[,!(colnames(temp_ema20_df) %in% c("option_underlying_ticker","option_quote_date"))]
    if(nrow(temp_aggregate) == nrow(temp_ema20_df)){
      temp_ema20 <- (temp_aggregate) * (2/9) + (temp_ema20_df) * (1 - (2/9))
      temp_ema20 <- as.data.frame(cbind(temp_ema20_cols,round(temp_ema20,2)))
      EMA20_df <- as.data.frame(rbind(EMA20_df,temp_ema20))
      sub_tickers <- sub_tickers[!(sub_tickers %in% temp_EMA20_tickers)]
      print(paste0("EMA20 calculated from prior EMA for ",length(temp_tickers)," tickers"))
    }else(
      print(paste0("Error with EMA20 calculation for ", new_date))
    )
  }
  if(!is.null(SMA20_df)){
    temp_tickers <- sub_tickers[sub_tickers %in% temp_SMA20_tickers]
    temp_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker %in% temp_tickers,]
    temp_aggregate <- temp_aggregate[order(temp_aggregate$option_underlying_ticker),]
    temp_ema20_cols <- temp_aggregate[,c("option_underlying_ticker","option_quote_date")]
    temp_aggregate <- temp_aggregate[,!(colnames(temp_aggregate) %in% c("option_underlying_ticker","option_quote_date"))]
    temp_sma20_df <- SMA20_df[SMA20_df$option_quote_date == all_dates[(length(all_dates)-1)],]
    temp_sma20_df <- temp_sma20_df[temp_sma20_df$option_underlying_ticker %in% temp_tickers,]
    temp_sma20_df <- temp_sma20_df[order(temp_sma20_df$option_underlying_ticker),]
    temp_sma20_df <- temp_sma20_df[,!(colnames(temp_sma20_df) %in% c("option_underlying_ticker","option_quote_date"))]
    if(nrow(temp_aggregate) == nrow(temp_sma20_df)){
      temp_ema20 <- (temp_aggregate) * (2/9) + (temp_sma20_df) * (1 - (2/9))
      temp_ema20 <- as.data.frame(cbind(temp_ema20_cols,round(temp_ema20,2)))
      if(!is.null(EMA20_df)){
        EMA20_df <- as.data.frame(rbind(EMA20_df,temp_ema20))
      }else{
        EMA20_df <- as.data.frame(temp_ema20)
      }
      sub_tickers <- sub_tickers[!(sub_tickers %in% temp_SMA20_tickers)]
      print(paste0("EMA20 calculated from prior SMA for ",length(temp_tickers)," tickers"))
    }else(
      print(paste0("Error with SMA20 calculation for ", new_date))
    )
  }
  if(length(all_dates) >= 20){
    check_dates <- all_dates[(length(all_dates)-19):length(all_dates)]
    sub_aggregate <- full_aggregate[full_aggregate$option_quote_date %in% check_dates,]
    sub_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker %in% sub_tickers,]
    sub_aggregate <- sub_aggregate[order(sub_aggregate$option_underlying_ticker),]
    temp_tickers <- sub_tickers[sub_tickers %in% sub_aggregate$option_underlying_ticker]
    failed_tickers <- c()
    if(length(temp_tickers) > 0){
      if(length(temp_tickers) > 1000){
        print(paste0("Expect long run time for this date due to high number of SMA20 calculations"))
        timestamp()
      }
      for(temp_ticker_i in 1:length(temp_tickers)){
        temp_ticker <- temp_tickers[temp_ticker_i]
        temp_sma20_df <- data.frame(option_underlying_ticker=temp_ticker,option_quote_date=new_date)
        temp_aggregate <- sub_aggregate[sub_aggregate$option_underlying_ticker == temp_ticker,]
        temp_aggregate <- temp_aggregate[,!(colnames(sub_aggregate) %in% c("option_underlying_ticker","option_quote_date"))]
        if(nrow(temp_aggregate) == 20){
          temp_sma20_df <- as.data.frame(cbind(temp_sma20_df,t(round(colMeans(temp_aggregate),4))))
          if(!is.null(SMA20_df)){
            SMA20_df <- as.data.frame(rbind(SMA20_df,temp_sma20_df))
          }else{
            SMA20_df <- as.data.frame(temp_sma20_df)
          }
          if(temp_ticker_i %% 1000 == 0){
            timestamp()
            print(paste0("SMA20 calculated for ",temp_ticker_i," tickers"))
          }
        }else{
          failed_tickers <- c(failed_tickers,temp_ticker)
        }
      }
    }
    sub_tickers <- sub_tickers[!(sub_tickers %in% temp_tickers)]
    print(paste0("SMA20 calculated for ",length(temp_tickers)," tickers"))
    failed_tickers <- c(sub_tickers,failed_tickers)
    print(paste0("Insufficient SMA20 data for ",length(failed_tickers)," tickers"))
  }else{
    print(paste0("Insufficient EMA20 or SMA20 data for ",length(sub_tickers)," tickers"))
  }
  print(paste0("Finished EMA calculations for ",new_date))
  
  ##Save data and reset objects while retaining values for continued EMA and SMA calculation
  if((length(all_dates)-50) %% 250 == 0){
    temp_save_dates <- all_dates[(51+(250*(batch_counter_i-1))):(50+(250*batch_counter_i))]
    temp_start_date <- min(temp_save_dates)
    temp_end_date <- max(temp_save_dates)
    temp_base_path <- "E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/"
    saveRDS(full_aggregate,
            file=paste0(temp_base_path,"full_option_aggregate_",
                        temp_start_date,"_to_",temp_end_date,".RDS"))
    saveRDS(SMA8_df,
            file=paste0(temp_base_path,"SMA8_aggregate_",
                        temp_start_date,"_to_",temp_end_date,".RDS"))
    saveRDS(SMA20_df,
            file=paste0(temp_base_path,"SMA20_aggregate_",
                        temp_start_date,"_to_",temp_end_date,".RDS"))
    saveRDS(EMA8_df,
            file=paste0(temp_base_path,"EMA8_aggregate_",
                        temp_start_date,"_to_",temp_end_date,".RDS"))
    saveRDS(EMA20_df,
            file=paste0(temp_base_path,"EMA20_aggregate_",
                        temp_start_date,"_to_",temp_end_date,".RDS"))
    dates_to_keep <- all_dates[(251+(250*(batch_counter_i-1))):(50+(250*batch_counter_i))]
    new_start_date <- min(dates_to_keep)
    new_end_date <- max(dates_to_keep)
    ##Update objects after save with dates to keep
    full_aggregate <- full_aggregate[full_aggregate$option_quote_date >= new_start_date &
                                      full_aggregate$option_quote_date <= new_end_date,]
    SMA8_df <- SMA8_df[SMA8_df$option_quote_date >= new_start_date &
                                      SMA8_df$option_quote_date <= new_end_date,]
    SMA20_df <- SMA20_df[SMA20_df$option_quote_date >= new_start_date &
                                      SMA20_df$option_quote_date <= new_end_date,]
    EMA8_df <- EMA8_df[EMA8_df$option_quote_date >= new_start_date &
                                      EMA8_df$option_quote_date <= new_end_date,]
    EMA20_df <- EMA20_df[EMA20_df$option_quote_date >= new_start_date &
                                      EMA20_df$option_quote_date <= new_end_date,]
    batch_counter_i <- batch_counter_i + 1
  }
  
}
if((length(all_dates)-50) %% 250 != 0){
  temp_save_dates <- all_dates[(51+(250*(batch_counter_i-1))):length(all_dates)]
  temp_start_date <- min(temp_save_dates)
  temp_end_date <- max(temp_save_dates)
  temp_base_path <- "E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/"
  saveRDS(full_aggregate,
          file=paste0(temp_base_path,"full_option_aggregate_",
                      temp_start_date,"_to_",temp_end_date,".RDS"))
  saveRDS(SMA8_df,
          file=paste0(temp_base_path,"SMA8_aggregate_",
                      temp_start_date,"_to_",temp_end_date,".RDS"))
  saveRDS(SMA20_df,
          file=paste0(temp_base_path,"SMA20_aggregate_",
                      temp_start_date,"_to_",temp_end_date,".RDS"))
  saveRDS(EMA8_df,
          file=paste0(temp_base_path,"EMA8_aggregate_",
                      temp_start_date,"_to_",temp_end_date,".RDS"))
  saveRDS(EMA20_df,
          file=paste0(temp_base_path,"EMA20_aggregate_",
                      temp_start_date,"_to_",temp_end_date,".RDS"))
}

temp_dir <- "E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/"
derived_aggregate_files <- list.files(temp_dir,pattern = "_to_")
temp_dates <- unlist(lapply(derived_aggregate_files, function(x){strsplit(strsplit(x,"_aggregate_")[[1]][2],"_to_")[[1]][1]}))
latest_date <- max(temp_dates)
if(sum(temp_dates == latest_date) > 5){
  temp_files <- list.files(temp_dir,pattern = paste0("_",latest_date,"_"))
  temp_dates <- unlist(lapply(temp_files, function(x){str_replace(strsplit(x,"_to_")[[1]][2],".RDS","")}))
  temp_max_date <- max(temp_dates)
  files_to_rm <- temp_files[!grepl(paste0("_to_",temp_max_date,".RDS"),temp_files)]
  print(files_to_rm)
}


#####

```

```{r test TSP classifier}

library(switchBox)
library(ncvreg)

full_aggregate <- readRDS("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/merged_aggregate_for_NN_20210514_to_20240229.RDS")
test_output <- read.table("E:/Market_Data/DiscountOptionData/DTNSubscription/Derived_Aggregates/test_output_5up10d_for_NN_20210514_to_20240229.tsv",sep="\t")
test_input <- full_aggregate[,grepl("volume",colnames(full_aggregate)) | 
                                          grepl("_open_interest_",colnames(full_aggregate))]
test_input[,grepl("EOD_",colnames(test_input))] <- test_input[,grepl("EOD_",colnames(test_input))] / rowSums(test_input[,grepl("EOD_",colnames(test_input))])
test_input[,grepl("EMA8_",colnames(test_input))] <- test_input[,grepl("EMA8_",colnames(test_input))] / rowSums(test_input[,grepl("EMA8_",colnames(test_input))])
test_input[,grepl("EMA20_",colnames(test_input))] <- test_input[,grepl("EMA20_",colnames(test_input))] / rowSums(test_input[,grepl("EMA20_",colnames(test_input))])
test_input <- test_input*10000
#test_input <- as.matrix(t(full_aggregate[,grepl("volume",colnames(full_aggregate)) | 
#                                          grepl("_open_interest_",colnames(full_aggregate))# | 
                                          #grepl("_underlying_price",colnames(full_aggregate)) | 
                                          #grepl("_FedInterestRate",colnames(full_aggregate))
#                                         ]))

#temp_filter <- rowSums(full_aggregate[,(grepl("_volume",colnames(full_aggregate)) | grepl("_open_interest",colnames(full_aggregate))) & grepl("EOD_",colnames(full_aggregate))])
#test_input <- test_input[,temp_filter > 5000]
#test_output <- test_output[temp_filter > 5000,,drop=FALSE]
test_group <- as.factor(test_output$x)
test_classifier = SWAP.Train.KTSP(test_input, test_group, krange=c(5:90))
test_classifier = as.data.frame(test_classifier$TSPs)

temp_mat = as.data.frame(t(test_input))
for(tsp_i in 1:nrow(test_classifier)){
  temp_mat[,paste0("tsp_comparison",tsp_i)] = as.numeric(temp_mat[,test_classifier$gene1[tsp_i]] > temp_mat[,test_classifier$gene2[tsp_i]])
}

input_x = temp_mat[,grepl("tsp_comparison",colnames(temp_mat))]
input_y = test_group
test_cvfit = cv.ncvreg(input_x, input_y,nfolds = 100,trace = TRUE)
test_coefs = coef(test_cvfit)
test_score = t(t(input_x) * test_coefs[2:length(test_coefs)])
test_score = rowSums(test_score)
test_score = exp(test_score)/(1+exp(test_score))

#####

##Derive TSPs for predicting selected outcomes

test_group = as.factor(test_mat$time1_increase2 > 0 | 
                         test_mat$time2_increase2 > 0 | 
                         test_mat$time3_increase2 > 0 | 
                         test_mat$time4_increase2 > 0 | 
                         test_mat$time5_increase2 > 0 | 
                         test_mat$time6_increase2 > 0 | 
                         test_mat$time7_increase2 > 0 | 
                         test_mat$time8_increase2 > 0 | 
                         test_mat$time9_increase2 > 0 | 
                         test_mat$time10_increase2 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(t(test_input),file="test_input.tsv",sep="\t")
write.table(test_output,file="test_output.tsv",sep="\t")





test_group2 = as.factor(test_mat$time10_decrease2 > 0)
test_classifier = SWAP.Train.KTSP(test_input, test_group2, krange=c(3:50))
test_classifier = as.data.frame(test_classifier$TSPs)

temp_mat = as.data.frame(t(test_input))
for(tsp_i in 1:nrow(test_classifier)){
  temp_mat[,paste0("tsp_comparison",tsp_i)] = as.numeric(temp_mat[,test_classifier$gene1[tsp_i]] > temp_mat[,test_classifier$gene2[tsp_i]])
}

input_x2 = temp_mat[,grepl("tsp_comparison",colnames(temp_mat))]
input_y2 = test_group2
test_cvfit = cv.ncvreg(input_x2, input_y2,nfolds = 10,trace = TRUE)
test_coefs = coef(test_cvfit)
test_score2 = t(t(input_x2) * test_coefs[2:length(test_coefs)])
test_score2 = rowSums(test_score2)
test_score2 = exp(test_score2)/(1+exp(test_score2))

#####

```

```{r retrieve sentiment score from marketbeat}

library(rvest)

getMBSentiment <- function(input_ticker){
  # Set the URL for the AAPL stock page on MarketBeat
  url <- paste0("https://www.marketbeat.com/stocks/NASDAQ/",input_ticker,"/")
  
  # Read the HTML content of the page
  page <- read_html(url)
  
  value <- page %>%
      html_nodes('div[data-slide-to="4"] .key-stat') %>%
      html_text()
  
  return(value)
}

getMBSentiment("AAPL")

```

```{r get stock sector}

##Not yet working
getYahooSector <- function(input_ticker){
    # Set the URL for the AAPL stock page on MarketBeat
    url <- paste0("https://finance.yahoo.com/quote/",input_ticker,"/profile")
    page <- read_html(url)
    print(head(page))
    
    # Read the HTML content of the page
    sector <- page %>%
        html_nodes('a.subtle-link.fin-size-large.svelte-wdkn18') %>%
        html_text(trim = TRUE)
    
    sector <- sector[1] # Assuming the first link contains the sector information
    
    return(sector)
}

getYahooSector("AAPL")

```


Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

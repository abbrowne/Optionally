---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r load packages}

#install.packages("haven")
#install.packages("readxl")
#install.packages("dplyr")
#install.packages('purrr')
#install.packages('RQuantLib')
#install.packages('bizdays')
library(readxl)
library(dplyr)
library(haven)
library(purrr)
library(stringr)
library(RQuantLib)
library(bizdays)
library(parallel)
##Update below with dates for full range of interest
load_quantlib_calendars("UnitedStates/NYSE",from="2000-01-01",to="2030-12-31")
##Custom functions

# Create function to aggregate formatted option chain into designated groups

```

```{r save all current and previous SP500 tickers}

new_directory = "C:/Users/Andy/Downloads/Investing files/"

# Change the working directory
setwd(new_directory)

# Print the current working directory to verify the change
print(getwd())

# Get list of option and stock files

# Load SP500 tickers
sp500_table = read_xlsx('SP500_companies.xlsx')
#print(sp500_table.head())
#print(sp500_table['Symbol'])
sp500_extras = read_xlsx('SP500_changes.xlsx')
sp500_tickers = unique(c(sp500_table$Symbol,sp500_extras$Added_Ticker,sp500_extras$Removed_Ticker))
sp500_tickers = sp500_tickers[!is.na(sp500_tickers)]
saveRDS(sp500_tickers,file="SP500_tickers.RDS")

```

```{r explore options data and aggregation}

source("C:/Users/Andy/Downloads/Investing files/finance_functions.R")

# Function to process a single file in parallel
process_file <- function(file_i) {
  source("C:/Users/Andy/Downloads/Investing files/finance_functions.R")
  new_directory = "C:/Users/Andy/Downloads/Investing files/"
  # Change the working directory
  setwd(new_directory)
  
  sp500_tickers = readRDS("SP500_tickers.RDS")
  
  all_option_files = list.files('./option_files')
  all_stock_files = list.files('./stock_files')

  temp_option_file <- all_option_files[file_i]
  temp_stock_file <- sub('options', 'stocks', temp_option_file)
  temp_date <- sub('options.cvs', '', temp_option_file)
  
  # Load options data
  dfOptions <- read.delim(paste0("option_files/", temp_option_file), header = TRUE, sep = ",")
  
  # Load stock data
  dfStocks <- read.delim(paste0("stock_files/", temp_stock_file), header = TRUE, sep = ",")
  
  # Filter stocks to SP500 tickers
  filteredStocks <- dfStocks %>% filter(symbol %in% sp500_tickers)
  
  # Filter options to SP500 tickers
  filteredOptions <- dfOptions %>% filter(underlying %in% sp500_tickers)
  
  # Determine daily average from open and close values for each ticker
  filteredStocks <- filteredStocks %>% mutate(open_close_avg = (open + close) / 2)
  
  # Add stock open-close average to options df and ratio with strike price
  filteredOptions$open_close_avg <- NA
  for (temp_i in 1:length(filteredStocks$symbol)) {
    temp_symbol <- filteredStocks$symbol[temp_i]
    filteredOptions$open_close_avg[filteredOptions$underlying == temp_symbol] <- filteredStocks$open_close_avg[filteredStocks$symbol == temp_symbol]
  }
  filteredOptions$option_ratio <- filteredOptions$strike / filteredOptions$open_close_avg
  
  new_chain <- NULL
  
  for (temp_ticker_i in 1:length(sp500_tickers)) {
    temp_ticker <- sp500_tickers[temp_ticker_i]
    if (temp_ticker %in% filteredOptions$underlying) {
      test_chain <- filteredOptions[filteredOptions$underlying == temp_ticker, ]
      
      # Suggest starting with <10, 10-25, 25-50, 50-100, 100-200, 200-350, >350
      min_strike_set <- c(NA, 0.5, 0.75, 0.9, 0.95, 1, 1.05, 1.1, 1.25, 1.5)
      max_strike_set <- c(0.5, 0.75, 0.9, 0.95, 1, 1.05, 1.1, 1.25, 1.5, NA)
      min_day_set <- c(NA, 10, 25, 50, 100, 200, 350)
      max_day_set <- c(10, 25, 50, 100, 200, 350, NA)
      
      for (temp_strike_i in 1:length(min_strike_set)) {
        for (temp_day_i in 1:length(min_day_set)) {
          # Aggregate over all strike ranges
          test_result <- option_chain_aggregator(
            test_chain,
            min_strike_ratio = min_strike_set[temp_strike_i],
            max_strike_ratio = max_strike_set[temp_strike_i],
            min_avg_days_to_expiry = min_day_set[temp_day_i],
            max_avg_days_to_expiry = max_day_set[temp_day_i]
          )
          if (is.null(new_chain)) {
            new_chain <- test_result
          } else {
            new_chain <- rbind(new_chain, test_result)
          }
        }
      }
    }
    if (temp_ticker_i %% 100 == 0) {
      print(paste0("Finished with ", temp_ticker_i, " tickers for ", temp_date))
      timestamp()
    }
  }
  
  saveRDS(new_chain, paste0("aggregate_files/", temp_date, "aggregate.RDS"))
  print(paste0("Finished with ", temp_date))
  timestamp()
}

##First merge stock data by date and calculate averages
##Second aggregate options by strike ranges
##Third aggregate options by expiry ranges (use average of days and business days to expiry)
##  Suggest starting with <10, 10-25, 25-50, 50-100, 100-200, 200-350, >350
##Fourth merge option ratio and expiry ranges by date and calculate averages

new_directory = "C:/Users/Andy/Downloads/Investing files/"

# Change the working directory
setwd(new_directory)

# Print the current working directory to verify the change
print(getwd())

# Get list of option and stock files

all_option_files = list.files('./option_files')
all_stock_files = list.files('./stock_files')

# Use parallel processing to process files concurrently
num_cores <- detectCores()
cl <- makeCluster(num_cores)
timestamp()
result <- parLapply(cl, 1:length(all_option_files), process_file)
stopCluster(cl)

timestamp()

#####

timestamp()
for(file_i in 1:length(all_option_files)){
  new_chain <- NULL
  temp_option_file = all_option_files[file_i]
  temp_stock_file = str_replace(temp_option_file,"options","stocks")
  temp_date = str_replace(temp_option_file,"options.cvs","")
  
  # Load options data
  dfOptions = read.delim(paste0("option_files/",temp_option_file),header=TRUE,sep=",")

  # Displaying the first few rows of the dataframe
  head(dfOptions)

  # Load stock data
  dfStocks = read.delim(paste0("stock_files/",temp_stock_file),header=TRUE,sep=",")
  head(dfStocks)

  #Filter stocks to SP500 tickers
  filteredStocks = dfStocks %>% 
    filter(symbol %in% sp500_tickers)
  #Filter options to SP500 tickers
  filteredOptions = dfOptions %>% 
    filter(underlying %in% sp500_tickers)
  #Determine daily average from open and close values for each ticker
  filteredStocks = filteredStocks %>% 
    mutate(open_close_avg = (filteredStocks$open + filteredStocks$close)/2)

  # Add stock openclose average to options df and ratio with strike price
  filteredOptions$open_close_avg = NA
  for(temp_i in 1:length(filteredStocks$symbol)){
    temp_symbol = filteredStocks$symbol[temp_i]
    filteredOptions$open_close_avg[filteredOptions$underlying == temp_symbol] = 
      filteredStocks$open_close_avg[filteredStocks$symbol == temp_symbol]
  }
  filteredOptions$option_ratio = filteredOptions$strike / filteredOptions$open_close_avg
  
  for(temp_ticker_i in 1:length(sp500_tickers)){
    temp_ticker = sp500_tickers[temp_ticker_i]
    if(temp_ticker %in% filteredOptions$underlying){
      test_chain = filteredOptions[filteredOptions$underlying == temp_ticker,]
    
      ##  Suggest starting with <10, 10-25, 25-50, 50-100, 100-200, 200-350, >350
      min_strike_set = c(NA,0.5,0.75,0.9,0.95,1,1.05,1.1,1.25,1.5)
      max_strike_set = c(0.5,0.75,0.9,0.95,1,1.05,1.1,1.25,1.5,NA)
      min_day_set = c(NA,10,25,50,100,200,350)
      max_day_set = c(10,25,50,100,200,350,NA)
      for(temp_strike_i in 1:length(min_strike_set)){
        for(temp_day_i in 1:length(min_day_set)){
          ##Aggregate over all strike ranges
          #min_avg_days_to_expiry=NA,max_avg_days_to_expiry=NA
          test_result = option_chain_aggregator(test_chain,min_strike_ratio = min_strike_set[temp_strike_i],
                                                max_strike_ratio = max_strike_set[temp_strike_i],
                                                min_avg_days_to_expiry=min_day_set[temp_day_i],
                                                max_avg_days_to_expiry=max_day_set[temp_day_i])
          if(is.null(new_chain)){
            new_chain = test_result
          }else{
            new_chain = rbind(new_chain,test_result)
          }
        }
      }
    }
    if(temp_ticker_i%%100==0){
      print(paste0("Finished with ",temp_ticker_i," tickers for ",temp_date))
      timestamp()
    }
  }
  saveRDS(new_chain,paste0("aggregate_files/",temp_date,"aggregate.RDS"))
  print(paste0("Finished with ",temp_date))
  timestamp()
}

##Calculate moving average volume for options at each strike range and expiry date with 8 and 20 day window

##Calculate moving average price for stock with 8 and 20 day window

##Calculate moving average volume for stock with 8 and 20 day window
  
  
  
```

```{r aggregate all stock data}

new_directory = "C:/Users/Andy/Downloads/Investing files/"

# Change the working directory
setwd(new_directory)

# Print the current working directory to verify the change
print(getwd())

# Get list of option and stock files
temp_files = list.files(getwd())
temp_files = temp_files[grepl("stocks.cvs",temp_files)]
# Merge all stock data into one dataframe
full_df = NULL
for(temp_file_i in 1:length(temp_files)){
  temp_filename = temp_files[temp_file_i]
  temp_date = str_replace(temp_filename,"stocks.cvs","")
  temp_df = read.delim(temp_filename,header=TRUE,sep=",")
  temp_df$stock_quote_date = temp_date
  if(is.null(full_df)){
    full_df = temp_df
  }else{
    full_df = rbind(full_df,temp_df)
  }
}

# Get list of all stock dates
temp_date_list = unique(full_df$stock_quote_date)

# Iterate through each ticker and calculate initial SMA20, SMA8, SMV20, and SMV8 from the earliest available dates
# Note the initial SMA20 and SMA8 as well as the earliest starting date for each ticker

# Use the SMA and SMV values to calculate the EMA20, EMA8, EMV20, and EMV8 values for each ticker

```

```{r aggregate all option data}

new_directory = "C:/Users/Andy/Downloads/Investing files/"

# Change the working directory
setwd(new_directory)

# Print the current working directory to verify the change
print(getwd())

# Get list of option and stock files
temp_files = list.files(getwd())
temp_files = temp_files[grepl("options.cvs",temp_files)]
# Merge all stock data into one dataframe
full_df = NULL
for(temp_file_i in 1:length(temp_files)){
  temp_filename = temp_files[temp_file_i]
  temp_date = str_replace(temp_filename,"options.cvs","")
  temp_df = read.delim(temp_filename,header=TRUE,sep=",")
  temp_df$option_quote_date = temp_date
  if(is.null(full_df)){
    full_df = temp_df
  }else{
    full_df = rbind(full_df,temp_df)
  }
}

# Get list of all stock dates
temp_date_list = unique(full_df$option_quote_date)

# Iterate through each ticker and calculate initial SMA20, SMA8, SMV20, and SMV8 from the earliest available dates
# Note the initial SMA20 and SMA8 as well as the earliest starting date for each ticker

# Use the SMA and SMV values to calculate the EMA20, EMA8, EMV20, and EMV8 values for each ticker

```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

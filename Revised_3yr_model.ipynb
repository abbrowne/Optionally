{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9934665-6cbd-47ba-b912-e97fb4b1f3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbe5480-807a-4d4d-91b9-432c1f72b4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    A_20210723  A_20210726  \\\n",
      "EOD_option_call_total_volume_strike_NAto0.5_exp...       0.392       0.386   \n",
      "EOD_option_call_total_open_interest_strike_NAto...       0.347       0.340   \n",
      "EOD_option_put_total_volume_strike_NAto0.5_expi...       0.389       0.382   \n",
      "EOD_option_put_total_open_interest_strike_NAto0...       0.245       0.238   \n",
      "EOD_option_call_total_volume_strike_NAto0.5_exp...       0.393       0.387   \n",
      "\n",
      "                                                    A_20210727  A_20210728  \\\n",
      "EOD_option_call_total_volume_strike_NAto0.5_exp...       0.381       0.353   \n",
      "EOD_option_call_total_open_interest_strike_NAto...       0.334       0.306   \n",
      "EOD_option_put_total_volume_strike_NAto0.5_expi...       0.377       0.350   \n",
      "EOD_option_put_total_open_interest_strike_NAto0...       0.234       0.208   \n",
      "EOD_option_call_total_volume_strike_NAto0.5_exp...       0.382       0.354   \n",
      "\n",
      "                                                    A_20210729  \n",
      "EOD_option_call_total_volume_strike_NAto0.5_exp...       0.352  \n",
      "EOD_option_call_total_open_interest_strike_NAto...       0.305  \n",
      "EOD_option_put_total_volume_strike_NAto0.5_expi...       0.349  \n",
      "EOD_option_put_total_open_interest_strike_NAto0...       0.207  \n",
      "EOD_option_call_total_volume_strike_NAto0.5_exp...       0.353  \n",
      "(1616, 316022)\n"
     ]
    }
   ],
   "source": [
    "###Import dataset\n",
    "\n",
    "input_file = 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_inputV2_for_NN_20210514_to_20240404.tsv'\n",
    "\n",
    "# Read the tab-separated file\n",
    "# The delimiter '\\t' specifies that the fields are separated by tabs\n",
    "input_dataset = pd.read_csv(input_file, delimiter='\\t')\n",
    "\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(input_dataset.iloc[:5,:5])\n",
    "print(input_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c1e935a-7a8c-488e-ac73-863c5ce3d45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x\n",
      "1  1.02226\n",
      "2  1.04186\n",
      "3  1.04381\n",
      "4  1.03341\n",
      "5  1.03589\n",
      "(316022, 1)\n",
      "   x\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "5  0\n",
      "(316022, 1)\n",
      "x\n",
      "0    234112\n",
      "1     81910\n",
      "dtype: int64\n",
      "   x\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "5  0\n",
      "(316022, 1)\n",
      "x\n",
      "0    286620\n",
      "1     29402\n",
      "dtype: int64\n",
      "   x\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "5  0\n",
      "(316022, 1)\n",
      "x\n",
      "0    265159\n",
      "1     50863\n",
      "dtype: int64\n",
      "   x\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "5  0\n",
      "(316022, 1)\n",
      "x\n",
      "0    229013\n",
      "1     87009\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "test_10d_change_file  = 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_output_change10d_for_NN_20210514_to_20240404.tsv'\n",
    "change10d_dataset = pd.read_csv(test_10d_change_file, delimiter='\\t')\n",
    "print(change10d_dataset.iloc[:5,:5])\n",
    "print(change10d_dataset.shape)\n",
    "\n",
    "neg_output_file = 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_output_5down10d_for_NN_20210514_to_20240404.tsv'\n",
    "neg_output_dataset = pd.read_csv(neg_output_file, delimiter='\\t')\n",
    "print(neg_output_dataset.iloc[:5,:5])\n",
    "print(neg_output_dataset.shape)\n",
    "print(neg_output_dataset.value_counts())\n",
    "\n",
    "output9up10d_file = 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_output_9up10d_for_NN_20210514_to_20240404.tsv'\n",
    "output9up10d_dataset = pd.read_csv(output9up10d_file, delimiter='\\t')\n",
    "print(output9up10d_dataset.iloc[:5,:5])\n",
    "print(output9up10d_dataset.shape)\n",
    "print(output9up10d_dataset.value_counts())\n",
    "\n",
    "output7up10d_file = 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_output_7up10d_for_NN_20210514_to_20240404.tsv'\n",
    "output7up10d_dataset = pd.read_csv(output7up10d_file, delimiter='\\t')\n",
    "print(output7up10d_dataset.iloc[:5,:5])\n",
    "print(output7up10d_dataset.shape)\n",
    "print(output7up10d_dataset.value_counts())\n",
    "\n",
    "output5up10d_file = 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_output_5up10d_for_NN_20210514_to_20240404.tsv'\n",
    "output5up10d_dataset = pd.read_csv(output5up10d_file, delimiter='\\t')\n",
    "print(output5up10d_dataset.iloc[:5,:5])\n",
    "print(output5up10d_dataset.shape)\n",
    "print(output5up10d_dataset.value_counts())\n",
    "\n",
    "# Shuffle column names\n",
    "shuffled_columns = np.random.permutation(input_dataset.columns)\n",
    "\n",
    "# Calculate split sizes\n",
    "total_columns = len(input_dataset.columns)\n",
    "train_size = int(0.6 * total_columns)\n",
    "cv_size = int(0.2 * total_columns)\n",
    "# The remaining columns will go to the test set\n",
    "\n",
    "# Split the columns\n",
    "train_columns = shuffled_columns[:train_size]\n",
    "cv_columns = shuffled_columns[train_size:train_size+cv_size]\n",
    "test_columns = shuffled_columns[train_size+cv_size:]\n",
    "\n",
    "# Create subsets of the DataFrame based on the columns\n",
    "train_df = input_dataset[train_columns]\n",
    "cv_df = input_dataset[cv_columns]\n",
    "test_df = input_dataset[test_columns]\n",
    "\n",
    "output9up10d_dataset.index = input_dataset.columns\n",
    "output7up10d_dataset.index = input_dataset.columns\n",
    "output5up10d_dataset.index = input_dataset.columns\n",
    "neg_output_dataset.index = input_dataset.columns\n",
    "change10d_dataset.index = input_dataset.columns\n",
    "\n",
    "train9up10d_output = output9up10d_dataset.T[train_columns].T\n",
    "cv9up10d_output = output9up10d_dataset.T[cv_columns].T\n",
    "test9up10d_output = output9up10d_dataset.T[test_columns].T\n",
    "\n",
    "train7up10d_output = output7up10d_dataset.T[train_columns].T\n",
    "cv7up10d_output = output7up10d_dataset.T[cv_columns].T\n",
    "test7up10d_output = output7up10d_dataset.T[test_columns].T\n",
    "\n",
    "train5up10d_output = output5up10d_dataset.T[train_columns].T\n",
    "cv5up10d_output = output5up10d_dataset.T[cv_columns].T\n",
    "test5up10d_output = output5up10d_dataset.T[test_columns].T\n",
    "\n",
    "train_negoutput = neg_output_dataset.T[train_columns].T\n",
    "cv_negoutput = neg_output_dataset.T[cv_columns].T\n",
    "test_negoutput = neg_output_dataset.T[test_columns].T\n",
    "\n",
    "train_10dChange = change10d_dataset.T[train_columns].T\n",
    "cv_10dChange = change10d_dataset.T[cv_columns].T\n",
    "test_10dChange = change10d_dataset.T[test_columns].T\n",
    "\n",
    "train9up10d_output.index = range(1, len(train9up10d_output) + 1)\n",
    "cv9up10d_output.index = range(1, len(cv9up10d_output) + 1)\n",
    "test9up10d_output.index = range(1, len(test9up10d_output) + 1)\n",
    "\n",
    "train7up10d_output.index = range(1, len(train7up10d_output) + 1)\n",
    "cv7up10d_output.index = range(1, len(cv7up10d_output) + 1)\n",
    "test7up10d_output.index = range(1, len(test7up10d_output) + 1)\n",
    "\n",
    "train5up10d_output.index = range(1, len(train5up10d_output) + 1)\n",
    "cv5up10d_output.index = range(1, len(cv5up10d_output) + 1)\n",
    "test5up10d_output.index = range(1, len(test5up10d_output) + 1)\n",
    "\n",
    "train_negoutput.index = range(1, len(train_negoutput) + 1)\n",
    "cv_negoutput.index = range(1, len(cv_negoutput) + 1)\n",
    "test_negoutput.index = range(1, len(test_negoutput) + 1)\n",
    "\n",
    "train_10dChange.index = range(1, len(train_10dChange) + 1)\n",
    "cv_10dChange.index = range(1, len(cv_10dChange) + 1)\n",
    "test_10dChange.index = range(1, len(test_10dChange) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2aae64a-54a1-4ff6-93fe-ca6912b44a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PimaClassifier(\n",
      "  (hidden1): Linear(in_features=1616, out_features=64, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (hidden2): Linear(in_features=64, out_features=12, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (hidden3): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (act3): ReLU()\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (act_output): Sigmoid()\n",
      ")\n",
      "Finished epoch 0, latest loss 0.9713118672370911\n",
      "Saved improved model\n",
      "Finished epoch 1, latest loss 0.9539806842803955\n",
      "Saved improved model\n",
      "Finished epoch 2, latest loss 0.9343343377113342\n",
      "Saved improved model\n",
      "Finished epoch 3, latest loss 0.9297536015510559\n",
      "Saved improved model\n",
      "Finished epoch 4, latest loss 0.9281354546546936\n",
      "Saved improved model\n",
      "Finished epoch 5, latest loss 0.9215038418769836\n",
      "Saved improved model\n",
      "Finished epoch 6, latest loss 0.9096908569335938\n",
      "Saved improved model\n",
      "Finished epoch 7, latest loss 0.9031732678413391\n",
      "Saved improved model\n",
      "Finished epoch 8, latest loss 0.8996759057044983\n",
      "Saved improved model\n",
      "Finished epoch 9, latest loss 0.8930892944335938\n",
      "Saved improved model\n",
      "Finished epoch 10, latest loss 0.8927292823791504\n",
      "Saved improved model\n",
      "Finished epoch 11, latest loss 0.8897623419761658\n",
      "Saved improved model\n",
      "Finished epoch 12, latest loss 0.8919147849082947\n",
      "Finished epoch 13, latest loss 0.8851656913757324\n",
      "Saved improved model\n",
      "Finished epoch 14, latest loss 0.8806823492050171\n",
      "Saved improved model\n",
      "Finished epoch 15, latest loss 0.8800392150878906\n",
      "Saved improved model\n",
      "Finished epoch 16, latest loss 0.8766658902168274\n",
      "Saved improved model\n",
      "Finished epoch 17, latest loss 0.8771583437919617\n",
      "Finished epoch 18, latest loss 0.8768445253372192\n",
      "Finished epoch 19, latest loss 0.8801873922348022\n",
      "Finished epoch 20, latest loss 0.8787878751754761\n",
      "Finished epoch 21, latest loss 0.87469881772995\n",
      "Saved improved model\n",
      "Finished epoch 22, latest loss 0.8735736012458801\n",
      "Saved improved model\n",
      "Finished epoch 23, latest loss 0.8728224635124207\n",
      "Saved improved model\n",
      "Finished epoch 24, latest loss 0.8790751099586487\n",
      "Finished epoch 25, latest loss 0.8716273307800293\n",
      "Saved improved model\n",
      "Finished epoch 26, latest loss 0.8693099021911621\n",
      "Saved improved model\n",
      "Finished epoch 27, latest loss 0.8710383772850037\n",
      "Finished epoch 28, latest loss 0.8669030666351318\n",
      "Saved improved model\n",
      "Finished epoch 29, latest loss 0.8676475882530212\n",
      "Finished epoch 30, latest loss 0.8661695122718811\n",
      "Saved improved model\n",
      "Finished epoch 31, latest loss 0.8710234761238098\n",
      "Finished epoch 32, latest loss 0.8696257472038269\n",
      "Finished epoch 33, latest loss 0.8655000329017639\n",
      "Saved improved model\n",
      "Finished epoch 34, latest loss 0.8712707161903381\n",
      "Finished epoch 35, latest loss 0.8654361367225647\n",
      "Saved improved model\n",
      "Finished epoch 36, latest loss 0.8677166104316711\n",
      "Finished epoch 37, latest loss 0.8665799498558044\n",
      "Finished epoch 38, latest loss 0.8652613759040833\n",
      "Saved improved model\n",
      "Finished epoch 39, latest loss 0.8631793260574341\n",
      "Saved improved model\n",
      "Finished epoch 40, latest loss 0.8583994507789612\n",
      "Saved improved model\n",
      "Finished epoch 41, latest loss 0.8612088561058044\n",
      "Finished epoch 42, latest loss 0.866544783115387\n",
      "Finished epoch 43, latest loss 0.8579794764518738\n",
      "Saved improved model\n",
      "Finished epoch 44, latest loss 0.8549140691757202\n",
      "Saved improved model\n",
      "Finished epoch 45, latest loss 0.8613376617431641\n",
      "Finished epoch 46, latest loss 0.856398344039917\n",
      "Finished epoch 47, latest loss 0.8741597533226013\n",
      "Finished epoch 48, latest loss 0.8667150735855103\n",
      "Finished epoch 49, latest loss 0.8607972264289856\n",
      "Finished epoch 50, latest loss 0.8640809059143066\n",
      "Finished epoch 51, latest loss 0.8658754229545593\n",
      "Finished epoch 52, latest loss 0.8614007234573364\n",
      "Finished epoch 53, latest loss 0.8612863421440125\n",
      "Finished epoch 54, latest loss 0.8603543639183044\n",
      "Finished epoch 55, latest loss 0.8543462157249451\n",
      "Saved improved model\n",
      "Finished epoch 56, latest loss 0.8581784963607788\n",
      "Finished epoch 57, latest loss 0.8522108793258667\n",
      "Saved improved model\n",
      "Finished epoch 58, latest loss 0.8608323931694031\n",
      "Finished epoch 59, latest loss 0.8589796423912048\n",
      "Finished epoch 60, latest loss 0.8596422672271729\n",
      "Finished epoch 61, latest loss 0.8613975048065186\n",
      "Finished epoch 62, latest loss 0.8567754626274109\n",
      "Finished epoch 63, latest loss 0.8567910194396973\n",
      "Finished epoch 64, latest loss 0.8524689674377441\n",
      "Finished epoch 65, latest loss 0.8550024032592773\n",
      "Finished epoch 66, latest loss 0.8559243679046631\n",
      "Finished epoch 67, latest loss 0.8563925623893738\n",
      "Finished epoch 68, latest loss 0.8513115048408508\n",
      "Saved improved model\n",
      "Finished epoch 69, latest loss 0.8515676856040955\n",
      "Finished epoch 70, latest loss 0.8514454364776611\n",
      "Finished epoch 71, latest loss 0.855323314666748\n",
      "Finished epoch 72, latest loss 0.8571100234985352\n",
      "Finished epoch 73, latest loss 0.8552336692810059\n",
      "Finished epoch 74, latest loss 0.8572151064872742\n",
      "Finished epoch 75, latest loss 0.854487419128418\n",
      "Finished epoch 76, latest loss 0.850132405757904\n",
      "Saved improved model\n",
      "Finished epoch 77, latest loss 0.8531020283699036\n",
      "Finished epoch 78, latest loss 0.850213348865509\n",
      "Finished epoch 79, latest loss 0.8483970165252686\n",
      "Saved improved model\n",
      "Finished epoch 80, latest loss 0.8516783118247986\n",
      "Finished epoch 81, latest loss 0.8532517552375793\n",
      "Finished epoch 82, latest loss 0.8483270406723022\n",
      "Saved improved model\n",
      "Finished epoch 83, latest loss 0.8523094654083252\n",
      "Finished epoch 84, latest loss 0.8506636023521423\n",
      "Finished epoch 85, latest loss 0.8472779989242554\n",
      "Saved improved model\n",
      "Finished epoch 86, latest loss 0.8513235449790955\n",
      "Finished epoch 87, latest loss 0.8489112854003906\n",
      "Finished epoch 88, latest loss 0.853386402130127\n",
      "Finished epoch 89, latest loss 0.8456159234046936\n",
      "Saved improved model\n",
      "Finished epoch 90, latest loss 0.8518279790878296\n",
      "Finished epoch 91, latest loss 0.8474918007850647\n",
      "Finished epoch 92, latest loss 0.844755232334137\n",
      "Saved improved model\n",
      "Finished epoch 93, latest loss 0.8515920042991638\n",
      "Finished epoch 94, latest loss 0.8471208810806274\n",
      "Finished epoch 95, latest loss 0.8482015132904053\n",
      "Finished epoch 96, latest loss 0.84590744972229\n",
      "Finished epoch 97, latest loss 0.8477359414100647\n",
      "Finished epoch 98, latest loss 0.8467699289321899\n",
      "Finished epoch 99, latest loss 0.8457515239715576\n",
      "Finished epoch 100, latest loss 0.845646858215332\n",
      "Finished epoch 101, latest loss 0.8472436666488647\n",
      "Finished epoch 102, latest loss 0.8480929732322693\n",
      "Finished epoch 103, latest loss 0.8507556319236755\n",
      "Finished epoch 104, latest loss 0.8533060550689697\n",
      "Finished epoch 105, latest loss 0.8517560958862305\n",
      "Finished epoch 106, latest loss 0.8466117978096008\n",
      "Finished epoch 107, latest loss 0.8438901901245117\n",
      "Saved improved model\n",
      "Finished epoch 108, latest loss 0.847327709197998\n",
      "Finished epoch 109, latest loss 0.8468506336212158\n",
      "Finished epoch 110, latest loss 0.8473890423774719\n",
      "Finished epoch 111, latest loss 0.8494124412536621\n",
      "Finished epoch 112, latest loss 0.8469282984733582\n",
      "Finished epoch 113, latest loss 0.8433349132537842\n",
      "Saved improved model\n",
      "Finished epoch 114, latest loss 0.8471336960792542\n",
      "Finished epoch 115, latest loss 0.8445820808410645\n",
      "Finished epoch 116, latest loss 0.8375324606895447\n",
      "Saved improved model\n",
      "Finished epoch 117, latest loss 0.8415312170982361\n",
      "Finished epoch 118, latest loss 0.8422431349754333\n",
      "Finished epoch 119, latest loss 0.8397886157035828\n",
      "Finished epoch 120, latest loss 0.8441768288612366\n",
      "Finished epoch 121, latest loss 0.840897798538208\n",
      "Finished epoch 122, latest loss 0.8434460163116455\n",
      "Finished epoch 123, latest loss 0.8425047993659973\n",
      "Finished epoch 124, latest loss 0.8435512781143188\n",
      "Finished epoch 125, latest loss 0.8407516479492188\n",
      "Finished epoch 126, latest loss 0.841096043586731\n",
      "Finished epoch 127, latest loss 0.8444463014602661\n",
      "Finished epoch 128, latest loss 0.8434223532676697\n",
      "Finished epoch 129, latest loss 0.8385913968086243\n",
      "Finished epoch 130, latest loss 0.8377642035484314\n",
      "Finished epoch 131, latest loss 0.8393804430961609\n",
      "Finished epoch 132, latest loss 0.835740864276886\n",
      "Saved improved model\n",
      "Finished epoch 133, latest loss 0.8403717875480652\n",
      "Finished epoch 134, latest loss 0.8457234501838684\n",
      "Finished epoch 135, latest loss 0.839754045009613\n",
      "Finished epoch 136, latest loss 0.8474706411361694\n",
      "Finished epoch 137, latest loss 0.8386353850364685\n",
      "Finished epoch 138, latest loss 0.8424290418624878\n",
      "Finished epoch 139, latest loss 0.8383578062057495\n",
      "Finished epoch 140, latest loss 0.8355094790458679\n",
      "Saved improved model\n",
      "Finished epoch 141, latest loss 0.8336206674575806\n",
      "Saved improved model\n",
      "Finished epoch 142, latest loss 0.8374143242835999\n",
      "Finished epoch 143, latest loss 0.833943247795105\n",
      "Finished epoch 144, latest loss 0.8336988091468811\n",
      "Finished epoch 145, latest loss 0.8350393772125244\n",
      "Finished epoch 146, latest loss 0.8388649821281433\n",
      "Finished epoch 147, latest loss 0.8391039967536926\n",
      "Finished epoch 148, latest loss 0.8386821150779724\n",
      "Finished epoch 149, latest loss 0.8341909050941467\n",
      "Finished epoch 150, latest loss 0.8449161648750305\n",
      "Finished epoch 151, latest loss 0.8350902795791626\n",
      "Finished epoch 152, latest loss 0.8350725769996643\n",
      "Finished epoch 153, latest loss 0.8347493410110474\n",
      "Finished epoch 154, latest loss 0.8365014791488647\n",
      "Finished epoch 155, latest loss 0.8383793234825134\n",
      "Finished epoch 156, latest loss 0.8307676315307617\n",
      "Saved improved model\n",
      "Finished epoch 157, latest loss 0.8331702947616577\n",
      "Finished epoch 158, latest loss 0.8331404328346252\n",
      "Finished epoch 159, latest loss 0.8406833410263062\n",
      "Finished epoch 160, latest loss 0.8398334980010986\n",
      "Finished epoch 161, latest loss 0.8430300354957581\n",
      "Finished epoch 162, latest loss 0.8343331813812256\n",
      "Finished epoch 163, latest loss 0.8356107473373413\n",
      "Finished epoch 164, latest loss 0.8342159986495972\n",
      "Finished epoch 165, latest loss 0.8372802734375\n",
      "Finished epoch 166, latest loss 0.8352128267288208\n",
      "Finished epoch 167, latest loss 0.8430356979370117\n",
      "Finished epoch 168, latest loss 0.832780122756958\n",
      "Finished epoch 169, latest loss 0.833636462688446\n",
      "Finished epoch 170, latest loss 0.8454092144966125\n",
      "Finished epoch 171, latest loss 0.8328224420547485\n",
      "Finished epoch 172, latest loss 0.8383919596672058\n",
      "Finished epoch 173, latest loss 0.8379271030426025\n",
      "Finished epoch 174, latest loss 0.836890697479248\n",
      "Finished epoch 175, latest loss 0.8319815993309021\n",
      "Finished epoch 176, latest loss 0.8349721431732178\n",
      "Finished epoch 177, latest loss 0.8342812657356262\n",
      "Finished epoch 178, latest loss 0.835155189037323\n",
      "Finished epoch 179, latest loss 0.8323400020599365\n",
      "Finished epoch 180, latest loss 0.8346424698829651\n",
      "Finished epoch 181, latest loss 0.8361905217170715\n",
      "Finished epoch 182, latest loss 0.8320172429084778\n",
      "Finished epoch 183, latest loss 0.8298484086990356\n",
      "Saved improved model\n",
      "Finished epoch 184, latest loss 0.8369428515434265\n",
      "Finished epoch 185, latest loss 0.8358622193336487\n",
      "Finished epoch 186, latest loss 0.8328157067298889\n",
      "Finished epoch 187, latest loss 0.83414626121521\n",
      "Finished epoch 188, latest loss 0.8314899802207947\n",
      "Finished epoch 189, latest loss 0.8345991969108582\n",
      "Finished epoch 190, latest loss 0.8302983045578003\n",
      "Finished epoch 191, latest loss 0.8280507922172546\n",
      "Saved improved model\n",
      "Finished epoch 192, latest loss 0.8319841623306274\n",
      "Finished epoch 193, latest loss 0.8326842188835144\n",
      "Finished epoch 194, latest loss 0.8341886401176453\n",
      "Finished epoch 195, latest loss 0.8310140371322632\n",
      "Finished epoch 196, latest loss 0.8310509324073792\n",
      "Finished epoch 197, latest loss 0.8371778130531311\n",
      "Finished epoch 198, latest loss 0.8287689089775085\n",
      "Finished epoch 199, latest loss 0.8288992643356323\n",
      "Finished epoch 200, latest loss 0.8340625762939453\n",
      "Finished epoch 201, latest loss 0.8327844142913818\n",
      "Finished epoch 202, latest loss 0.8315789699554443\n",
      "Finished epoch 203, latest loss 0.8290534615516663\n",
      "Finished epoch 204, latest loss 0.832727313041687\n",
      "Finished epoch 205, latest loss 0.8316702842712402\n",
      "Finished epoch 206, latest loss 0.8286906480789185\n",
      "Finished epoch 207, latest loss 0.8362193703651428\n",
      "Finished epoch 208, latest loss 0.8317145109176636\n",
      "Finished epoch 209, latest loss 0.8307771682739258\n",
      "Finished epoch 210, latest loss 0.83927983045578\n",
      "Finished epoch 211, latest loss 0.8307666778564453\n",
      "Finished epoch 212, latest loss 0.8350456357002258\n",
      "Finished epoch 213, latest loss 0.8308491110801697\n",
      "Finished epoch 214, latest loss 0.8313073515892029\n",
      "Finished epoch 215, latest loss 0.8311578631401062\n",
      "Finished epoch 216, latest loss 0.8325682878494263\n",
      "Finished epoch 217, latest loss 0.832521915435791\n",
      "Finished epoch 218, latest loss 0.8321211934089661\n",
      "Finished epoch 219, latest loss 0.8314136266708374\n",
      "Finished epoch 220, latest loss 0.8365308046340942\n",
      "Finished epoch 221, latest loss 0.8316558003425598\n",
      "Finished epoch 222, latest loss 0.832706093788147\n",
      "Finished epoch 223, latest loss 0.8297218680381775\n",
      "Finished epoch 224, latest loss 0.8308911919593811\n",
      "Finished epoch 225, latest loss 0.8290209174156189\n",
      "Finished epoch 226, latest loss 0.8339106440544128\n",
      "Finished epoch 227, latest loss 0.8329225182533264\n",
      "Finished epoch 228, latest loss 0.8320748209953308\n",
      "Finished epoch 229, latest loss 0.828552782535553\n",
      "Finished epoch 230, latest loss 0.8352699279785156\n",
      "Finished epoch 231, latest loss 0.8330499529838562\n",
      "Finished epoch 232, latest loss 0.8331433534622192\n",
      "Finished epoch 233, latest loss 0.8279103636741638\n",
      "Saved improved model\n",
      "Finished epoch 234, latest loss 0.8288558125495911\n",
      "Finished epoch 235, latest loss 0.8314414024353027\n",
      "Finished epoch 236, latest loss 0.8318063616752625\n",
      "Finished epoch 237, latest loss 0.8333753347396851\n",
      "Finished epoch 238, latest loss 0.8320909142494202\n",
      "Finished epoch 239, latest loss 0.8258163332939148\n",
      "Saved improved model\n",
      "Finished epoch 240, latest loss 0.8296266198158264\n",
      "Finished epoch 241, latest loss 0.8305837512016296\n",
      "Finished epoch 242, latest loss 0.8263362646102905\n",
      "Finished epoch 243, latest loss 0.8248932361602783\n",
      "Saved improved model\n",
      "Finished epoch 244, latest loss 0.8291817307472229\n",
      "Finished epoch 245, latest loss 0.8297195434570312\n",
      "Finished epoch 246, latest loss 0.8309186697006226\n",
      "Finished epoch 247, latest loss 0.8294524550437927\n",
      "Finished epoch 248, latest loss 0.8320732712745667\n",
      "Finished epoch 249, latest loss 0.8329213857650757\n",
      "Finished epoch 250, latest loss 0.8326745629310608\n",
      "Finished epoch 251, latest loss 0.8302934765815735\n",
      "Finished epoch 252, latest loss 0.8325423002243042\n",
      "Finished epoch 253, latest loss 0.827643871307373\n",
      "Finished epoch 254, latest loss 0.830685555934906\n",
      "Finished epoch 255, latest loss 0.8358303904533386\n",
      "Finished epoch 256, latest loss 0.8248845338821411\n",
      "Saved improved model\n",
      "Finished epoch 257, latest loss 0.8301864266395569\n",
      "Finished epoch 258, latest loss 0.8325625658035278\n",
      "Finished epoch 259, latest loss 0.8319962024688721\n",
      "Finished epoch 260, latest loss 0.8336114883422852\n",
      "Finished epoch 261, latest loss 0.8305982351303101\n",
      "Finished epoch 262, latest loss 0.8268135786056519\n",
      "Finished epoch 263, latest loss 0.8244685530662537\n",
      "Saved improved model\n",
      "Finished epoch 264, latest loss 0.8311753869056702\n",
      "Finished epoch 265, latest loss 0.828100323677063\n",
      "Finished epoch 266, latest loss 0.831052839756012\n",
      "Finished epoch 267, latest loss 0.8289275765419006\n",
      "Finished epoch 268, latest loss 0.8307182788848877\n",
      "Finished epoch 269, latest loss 0.8317840099334717\n",
      "Finished epoch 270, latest loss 0.8302367925643921\n",
      "Finished epoch 271, latest loss 0.824564516544342\n",
      "Finished epoch 272, latest loss 0.8281790614128113\n",
      "Finished epoch 273, latest loss 0.8289085030555725\n",
      "Finished epoch 274, latest loss 0.8312661647796631\n",
      "Finished epoch 275, latest loss 0.830234944820404\n",
      "Finished epoch 276, latest loss 0.8314856290817261\n",
      "Finished epoch 277, latest loss 0.8340823650360107\n",
      "Finished epoch 278, latest loss 0.8320802450180054\n",
      "Finished epoch 279, latest loss 0.8271068334579468\n",
      "Finished epoch 280, latest loss 0.8334739208221436\n",
      "Finished epoch 281, latest loss 0.8246228098869324\n",
      "Finished epoch 282, latest loss 0.8230574727058411\n",
      "Saved improved model\n",
      "Finished epoch 283, latest loss 0.8251965045928955\n",
      "Finished epoch 284, latest loss 0.8272557854652405\n",
      "Finished epoch 285, latest loss 0.8253461718559265\n",
      "Finished epoch 286, latest loss 0.8231952786445618\n",
      "Finished epoch 287, latest loss 0.8241392970085144\n",
      "Finished epoch 288, latest loss 0.8411663174629211\n",
      "Finished epoch 289, latest loss 0.8268259763717651\n",
      "Finished epoch 290, latest loss 0.8310129642486572\n",
      "Finished epoch 291, latest loss 0.8266782760620117\n",
      "Finished epoch 292, latest loss 0.8337408304214478\n",
      "Finished epoch 293, latest loss 0.8287732005119324\n",
      "Finished epoch 294, latest loss 0.8212528824806213\n",
      "Saved improved model\n",
      "Finished epoch 295, latest loss 0.8276355266571045\n",
      "Finished epoch 296, latest loss 0.8232610821723938\n",
      "Finished epoch 297, latest loss 0.8243400454521179\n",
      "Finished epoch 298, latest loss 0.8260625600814819\n",
      "Finished epoch 299, latest loss 0.8280749917030334\n",
      "Finished epoch 300, latest loss 0.824544370174408\n",
      "Finished epoch 301, latest loss 0.8273290395736694\n",
      "Finished epoch 302, latest loss 0.8327929973602295\n",
      "Finished epoch 303, latest loss 0.8273155093193054\n",
      "Finished epoch 304, latest loss 0.822537899017334\n",
      "Finished epoch 305, latest loss 0.8308428525924683\n",
      "Finished epoch 306, latest loss 0.8267099857330322\n",
      "Finished epoch 307, latest loss 0.8269369006156921\n",
      "Finished epoch 308, latest loss 0.8259993195533752\n",
      "Finished epoch 309, latest loss 0.8275726437568665\n",
      "Finished epoch 310, latest loss 0.8271945714950562\n",
      "Finished epoch 311, latest loss 0.8226632475852966\n",
      "Finished epoch 312, latest loss 0.8246826529502869\n",
      "Finished epoch 313, latest loss 0.8260860443115234\n",
      "Finished epoch 314, latest loss 0.8269385099411011\n",
      "Finished epoch 315, latest loss 0.8257041573524475\n",
      "Finished epoch 316, latest loss 0.8219535946846008\n",
      "Finished epoch 317, latest loss 0.8254355788230896\n",
      "Finished epoch 318, latest loss 0.8248476386070251\n",
      "Finished epoch 319, latest loss 0.8301149606704712\n",
      "Finished epoch 320, latest loss 0.8275457620620728\n",
      "Finished epoch 321, latest loss 0.8269381523132324\n",
      "Finished epoch 322, latest loss 0.8287870287895203\n",
      "Finished epoch 323, latest loss 0.8269408345222473\n",
      "Finished epoch 324, latest loss 0.8320964574813843\n",
      "Finished epoch 325, latest loss 0.8261757493019104\n",
      "Finished epoch 326, latest loss 0.8227970004081726\n",
      "Finished epoch 327, latest loss 0.8249003291130066\n",
      "Finished epoch 328, latest loss 0.8263370394706726\n",
      "Finished epoch 329, latest loss 0.8303185105323792\n",
      "Finished epoch 330, latest loss 0.8209488987922668\n",
      "Saved improved model\n",
      "Finished epoch 331, latest loss 0.8269227147102356\n",
      "Finished epoch 332, latest loss 0.8220335841178894\n",
      "Finished epoch 333, latest loss 0.8268885612487793\n",
      "Finished epoch 334, latest loss 0.8259470462799072\n",
      "Finished epoch 335, latest loss 0.8257040977478027\n",
      "Finished epoch 336, latest loss 0.8201788067817688\n",
      "Saved improved model\n",
      "Finished epoch 337, latest loss 0.8248018026351929\n",
      "Finished epoch 338, latest loss 0.822858452796936\n",
      "Finished epoch 339, latest loss 0.8263752460479736\n",
      "Finished epoch 340, latest loss 0.8196966052055359\n",
      "Saved improved model\n",
      "Finished epoch 341, latest loss 0.8244467973709106\n",
      "Finished epoch 342, latest loss 0.8202812671661377\n",
      "Finished epoch 343, latest loss 0.8196960091590881\n",
      "Saved improved model\n",
      "Finished epoch 344, latest loss 0.821155846118927\n",
      "Finished epoch 345, latest loss 0.8237664699554443\n",
      "Finished epoch 346, latest loss 0.8224718570709229\n",
      "Finished epoch 347, latest loss 0.8232783675193787\n",
      "Finished epoch 348, latest loss 0.8202247619628906\n",
      "Finished epoch 349, latest loss 0.8222863674163818\n",
      "Finished epoch 350, latest loss 0.8249208927154541\n",
      "Finished epoch 351, latest loss 0.8169364929199219\n",
      "Saved improved model\n",
      "Finished epoch 352, latest loss 0.8238214254379272\n",
      "Finished epoch 353, latest loss 0.8185779452323914\n",
      "Finished epoch 354, latest loss 0.8229475617408752\n",
      "Finished epoch 355, latest loss 0.816714346408844\n",
      "Saved improved model\n",
      "Finished epoch 356, latest loss 0.8167040348052979\n",
      "Saved improved model\n",
      "Finished epoch 357, latest loss 0.8197829723358154\n",
      "Finished epoch 358, latest loss 0.8171424269676208\n",
      "Finished epoch 359, latest loss 0.8144449591636658\n",
      "Saved improved model\n",
      "Finished epoch 360, latest loss 0.8214308619499207\n",
      "Finished epoch 361, latest loss 0.8254934549331665\n",
      "Finished epoch 362, latest loss 0.8207048773765564\n",
      "Finished epoch 363, latest loss 0.827163815498352\n",
      "Finished epoch 364, latest loss 0.8187187314033508\n",
      "Finished epoch 365, latest loss 0.819256067276001\n",
      "Finished epoch 366, latest loss 0.8188315629959106\n",
      "Finished epoch 367, latest loss 0.8151136040687561\n",
      "Finished epoch 368, latest loss 0.8179574012756348\n",
      "Finished epoch 369, latest loss 0.8154049515724182\n",
      "Finished epoch 370, latest loss 0.8156202435493469\n",
      "Finished epoch 371, latest loss 0.8214651346206665\n",
      "Finished epoch 372, latest loss 0.8185694217681885\n",
      "Finished epoch 373, latest loss 0.8217083811759949\n",
      "Finished epoch 374, latest loss 0.817822277545929\n",
      "Finished epoch 375, latest loss 0.8276557326316833\n",
      "Finished epoch 376, latest loss 0.8172482848167419\n",
      "Finished epoch 377, latest loss 0.8213838338851929\n",
      "Finished epoch 378, latest loss 0.8233526945114136\n",
      "Finished epoch 379, latest loss 0.8222666382789612\n",
      "Finished epoch 380, latest loss 0.8257848024368286\n",
      "Finished epoch 381, latest loss 0.8212674856185913\n",
      "Finished epoch 382, latest loss 0.8155671954154968\n",
      "Finished epoch 383, latest loss 0.8156408071517944\n",
      "Finished epoch 384, latest loss 0.8156386017799377\n",
      "Finished epoch 385, latest loss 0.823502242565155\n",
      "Finished epoch 386, latest loss 0.8205824494361877\n",
      "Finished epoch 387, latest loss 0.8178779482841492\n",
      "Finished epoch 388, latest loss 0.8146581649780273\n",
      "Finished epoch 389, latest loss 0.8208892345428467\n",
      "Finished epoch 390, latest loss 0.8141749501228333\n",
      "Saved improved model\n",
      "Finished epoch 391, latest loss 0.8191216588020325\n",
      "Finished epoch 392, latest loss 0.8167203068733215\n",
      "Finished epoch 393, latest loss 0.8193419575691223\n",
      "Finished epoch 394, latest loss 0.8170731067657471\n",
      "Finished epoch 395, latest loss 0.8154495358467102\n",
      "Finished epoch 396, latest loss 0.8172857165336609\n",
      "Finished epoch 397, latest loss 0.8181433081626892\n",
      "Finished epoch 398, latest loss 0.824510395526886\n",
      "Finished epoch 399, latest loss 0.8183633685112\n",
      "Finished epoch 400, latest loss 0.814877450466156\n",
      "Finished epoch 401, latest loss 0.8197709321975708\n",
      "Finished epoch 402, latest loss 0.8183903694152832\n",
      "Finished epoch 403, latest loss 0.8172643184661865\n",
      "Finished epoch 404, latest loss 0.8210049867630005\n",
      "Finished epoch 405, latest loss 0.8204298615455627\n",
      "Finished epoch 406, latest loss 0.8149310350418091\n",
      "Finished epoch 407, latest loss 0.8216227293014526\n",
      "Finished epoch 408, latest loss 0.8151645660400391\n",
      "Finished epoch 409, latest loss 0.8168551325798035\n",
      "Finished epoch 410, latest loss 0.8172886371612549\n",
      "Finished epoch 411, latest loss 0.8195381760597229\n",
      "Finished epoch 412, latest loss 0.820673406124115\n",
      "Finished epoch 413, latest loss 0.8170949816703796\n",
      "Finished epoch 414, latest loss 0.8166607618331909\n",
      "Finished epoch 415, latest loss 0.8181829452514648\n",
      "Finished epoch 416, latest loss 0.8179251551628113\n",
      "Finished epoch 417, latest loss 0.8196668028831482\n",
      "Finished epoch 418, latest loss 0.8176144957542419\n",
      "Finished epoch 419, latest loss 0.8175570964813232\n",
      "Finished epoch 420, latest loss 0.8135066628456116\n",
      "Saved improved model\n",
      "Finished epoch 421, latest loss 0.814041018486023\n",
      "Finished epoch 422, latest loss 0.8152077794075012\n",
      "Finished epoch 423, latest loss 0.8183525204658508\n",
      "Finished epoch 424, latest loss 0.8190646171569824\n",
      "Finished epoch 425, latest loss 0.8186073899269104\n",
      "Finished epoch 426, latest loss 0.8212829232215881\n",
      "Finished epoch 427, latest loss 0.8189469575881958\n",
      "Finished epoch 428, latest loss 0.815455436706543\n",
      "Finished epoch 429, latest loss 0.8168543577194214\n",
      "Finished epoch 430, latest loss 0.8156221508979797\n",
      "Finished epoch 431, latest loss 0.8161144852638245\n",
      "Finished epoch 432, latest loss 0.8175458908081055\n",
      "Finished epoch 433, latest loss 0.8181396126747131\n",
      "Finished epoch 434, latest loss 0.8176339268684387\n",
      "Finished epoch 435, latest loss 0.8140315413475037\n",
      "Finished epoch 436, latest loss 0.8250033855438232\n",
      "Finished epoch 437, latest loss 0.8213399648666382\n",
      "Finished epoch 438, latest loss 0.8288239240646362\n",
      "Finished epoch 439, latest loss 0.8213698267936707\n",
      "Finished epoch 440, latest loss 0.8140565752983093\n",
      "Finished epoch 441, latest loss 0.8179386258125305\n",
      "Finished epoch 442, latest loss 0.820632815361023\n",
      "Finished epoch 443, latest loss 0.8179672956466675\n",
      "Finished epoch 444, latest loss 0.8196988701820374\n",
      "Finished epoch 445, latest loss 0.8186424374580383\n",
      "Finished epoch 446, latest loss 0.8155044913291931\n",
      "Finished epoch 447, latest loss 0.8241623640060425\n",
      "Finished epoch 448, latest loss 0.8132027387619019\n",
      "Saved improved model\n",
      "Finished epoch 449, latest loss 0.818179190158844\n",
      "Finished epoch 450, latest loss 0.8196766376495361\n",
      "Finished epoch 451, latest loss 0.8167716860771179\n",
      "Finished epoch 452, latest loss 0.8171757459640503\n",
      "Finished epoch 453, latest loss 0.8126876950263977\n",
      "Saved improved model\n",
      "Finished epoch 454, latest loss 0.8145623803138733\n",
      "Finished epoch 455, latest loss 0.8203622102737427\n",
      "Finished epoch 456, latest loss 0.8154587149620056\n",
      "Finished epoch 457, latest loss 0.8178268671035767\n",
      "Finished epoch 458, latest loss 0.8165590167045593\n",
      "Finished epoch 459, latest loss 0.8171971440315247\n",
      "Finished epoch 460, latest loss 0.8214647173881531\n",
      "Finished epoch 461, latest loss 0.8164916038513184\n",
      "Finished epoch 462, latest loss 0.8175499439239502\n",
      "Finished epoch 463, latest loss 0.8224301934242249\n",
      "Finished epoch 464, latest loss 0.823658287525177\n",
      "Finished epoch 465, latest loss 0.8144263029098511\n",
      "Finished epoch 466, latest loss 0.8186641931533813\n",
      "Finished epoch 467, latest loss 0.8252701163291931\n",
      "Finished epoch 468, latest loss 0.8154715299606323\n",
      "Finished epoch 469, latest loss 0.8218764066696167\n",
      "Finished epoch 470, latest loss 0.8201262354850769\n",
      "Finished epoch 471, latest loss 0.8160651326179504\n",
      "Finished epoch 472, latest loss 0.8131595253944397\n",
      "Finished epoch 473, latest loss 0.8184407353401184\n",
      "Finished epoch 474, latest loss 0.8204233050346375\n",
      "Finished epoch 475, latest loss 0.8192181587219238\n",
      "Finished epoch 476, latest loss 0.8191270232200623\n",
      "Finished epoch 477, latest loss 0.8156096935272217\n",
      "Finished epoch 478, latest loss 0.8208543062210083\n",
      "Finished epoch 479, latest loss 0.8197923898696899\n",
      "Finished epoch 480, latest loss 0.8210350871086121\n",
      "Finished epoch 481, latest loss 0.8170034885406494\n",
      "Finished epoch 482, latest loss 0.8158755302429199\n",
      "Finished epoch 483, latest loss 0.8132864236831665\n",
      "Finished epoch 484, latest loss 0.8166261315345764\n",
      "Finished epoch 485, latest loss 0.8193329572677612\n",
      "Finished epoch 486, latest loss 0.8221803903579712\n",
      "Finished epoch 487, latest loss 0.8179600238800049\n",
      "Finished epoch 488, latest loss 0.8142898678779602\n",
      "Finished epoch 489, latest loss 0.8119399547576904\n",
      "Saved improved model\n",
      "Finished epoch 490, latest loss 0.8131935000419617\n",
      "Finished epoch 491, latest loss 0.8157271146774292\n",
      "Finished epoch 492, latest loss 0.8232962489128113\n",
      "Finished epoch 493, latest loss 0.8162208795547485\n",
      "Finished epoch 494, latest loss 0.8175647258758545\n",
      "Finished epoch 495, latest loss 0.8211498856544495\n",
      "Finished epoch 496, latest loss 0.8158400058746338\n",
      "Finished epoch 497, latest loss 0.8158664703369141\n",
      "Finished epoch 498, latest loss 0.8147613406181335\n",
      "Finished epoch 499, latest loss 0.8190863132476807\n",
      "Finished epoch 500, latest loss 0.8167215585708618\n",
      "Finished epoch 501, latest loss 0.8150520324707031\n",
      "Finished epoch 502, latest loss 0.8183286190032959\n",
      "Finished epoch 503, latest loss 0.8225356936454773\n",
      "Finished epoch 504, latest loss 0.816192090511322\n",
      "Finished epoch 505, latest loss 0.8163087368011475\n",
      "Finished epoch 506, latest loss 0.8294855952262878\n",
      "Finished epoch 507, latest loss 0.8181072473526001\n",
      "Finished epoch 508, latest loss 0.8162989020347595\n",
      "Finished epoch 509, latest loss 0.82027667760849\n",
      "Finished epoch 510, latest loss 0.8153892755508423\n",
      "Finished epoch 511, latest loss 0.8198817372322083\n",
      "Finished epoch 512, latest loss 0.81309574842453\n",
      "Finished epoch 513, latest loss 0.8146752715110779\n",
      "Finished epoch 514, latest loss 0.8098867535591125\n",
      "Saved improved model\n",
      "Finished epoch 515, latest loss 0.8151723146438599\n",
      "Finished epoch 516, latest loss 0.8124833703041077\n",
      "Finished epoch 517, latest loss 0.8174753189086914\n",
      "Finished epoch 518, latest loss 0.8159603476524353\n",
      "Finished epoch 519, latest loss 0.8155999779701233\n",
      "Finished epoch 520, latest loss 0.8139604926109314\n",
      "Finished epoch 521, latest loss 0.8202592134475708\n",
      "Finished epoch 522, latest loss 0.8182725310325623\n",
      "Finished epoch 523, latest loss 0.8156333565711975\n",
      "Finished epoch 524, latest loss 0.8176414966583252\n",
      "Finished epoch 525, latest loss 0.8106906414031982\n",
      "Finished epoch 526, latest loss 0.8160148859024048\n",
      "Finished epoch 527, latest loss 0.8130597472190857\n",
      "Finished epoch 528, latest loss 0.8204452395439148\n",
      "Finished epoch 529, latest loss 0.8135521411895752\n",
      "Finished epoch 530, latest loss 0.8146503567695618\n",
      "Finished epoch 531, latest loss 0.8178755044937134\n",
      "Finished epoch 532, latest loss 0.8172563910484314\n",
      "Finished epoch 533, latest loss 0.8094063401222229\n",
      "Saved improved model\n",
      "Finished epoch 534, latest loss 0.8197054862976074\n",
      "Finished epoch 535, latest loss 0.8182144165039062\n",
      "Finished epoch 536, latest loss 0.8118738532066345\n",
      "Finished epoch 537, latest loss 0.8202674984931946\n",
      "Finished epoch 538, latest loss 0.8140285015106201\n",
      "Finished epoch 539, latest loss 0.82504802942276\n",
      "Finished epoch 540, latest loss 0.8154600858688354\n",
      "Finished epoch 541, latest loss 0.808502197265625\n",
      "Saved improved model\n",
      "Finished epoch 542, latest loss 0.8127549290657043\n",
      "Finished epoch 543, latest loss 0.8105197548866272\n",
      "Finished epoch 544, latest loss 0.8151960372924805\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(X), batch_size):\n\u001b[0;32m     44\u001b[0m     Xbatch \u001b[38;5;241m=\u001b[39m X[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m---> 45\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mnegmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     ybatch \u001b[38;5;241m=\u001b[39m y[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m     47\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, ybatch)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[37], line 25\u001b[0m, in \u001b[0;36mPimaClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 25\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden2(x))\n\u001b[0;32m     27\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden3(x))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = torch.tensor(np.array(train_df.T), dtype=torch.float32)\n",
    "y = torch.tensor(np.array(train_negoutput), dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Check for CUDA and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move data to the chosen device\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(train_df.shape[0], 64)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(64, 12)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.hidden3 = nn.Linear(12, 8)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act3(self.hidden3(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    " \n",
    "negmodel = PimaClassifier().to(device)\n",
    "print(negmodel)\n",
    "\n",
    "pos_weight = torch.tensor([2.5], device=device)  # Set your_pos_weight based on your needs\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(negmodel.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 2000\n",
    "batch_size = 1000\n",
    "best_loss = float('inf')\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = negmodel(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        # Save model checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': negmodel.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }, 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_negmodel.pth')\n",
    "        print(\"Saved improved model\")\n",
    "\n",
    "test_model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_negmodel.pth')\n",
    "test_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = test_model(X)\n",
    " \n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")\n",
    "\n",
    "# make class predictions with the negmodel\n",
    "neg_predictions = (test_model(X) > 0.5).int().to('cpu')\n",
    "neg_predictions = neg_predictions.numpy()\n",
    "test_pred = pd.DataFrame(neg_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "actual_values = train_negoutput\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for negative predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "neg_predictions = 1 - neg_predictions\n",
    "\n",
    "X = torch.tensor(np.array(train_df.T), dtype=torch.float32)\n",
    "y = torch.tensor(np.array(train9up10d_output), dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Move data to the chosen device\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "model9up10d = PimaClassifier().to(device)\n",
    "print(model9up10d)\n",
    "\n",
    "pos_weight = torch.tensor([1.5], device=device)  # Set your_pos_weight based on your needs\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model9up10d.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 2000\n",
    "batch_size = 1000\n",
    "best_loss = float('inf')\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = model9up10d(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        # Save model checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model9up10d.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }, 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model9up10d.pth')\n",
    "        print(\"Saved improved model\")\n",
    "\n",
    "test_model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model9up10d.pth')\n",
    "test_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = test_model(X)\n",
    " \n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")\n",
    "\n",
    "# make class predictions with the model\n",
    "predictions = (test_model(X) > 0.5).int().to('cpu')\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "###\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "actual_values = train9up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "merge_predictions = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "merge_predictions.index = range(1, len(merge_predictions) + 1)\n",
    "actual_values = train9up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(merge_predictions)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct predictions:\", mean_value)\n",
    "\n",
    "X = torch.tensor(np.array(train_df.T), dtype=torch.float32)\n",
    "y = torch.tensor(np.array(train9up10d_output), dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Move data to the chosen device\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "model7up10d = PimaClassifier().to(device)\n",
    "print(model7up10d)\n",
    "\n",
    "pos_weight = torch.tensor([1.5], device=device)  # Set your_pos_weight based on your needs\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model7up10d.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 2000\n",
    "batch_size = 1000\n",
    "best_loss = float('inf')\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = model7up10d(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        # Save model checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model7up10d.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }, 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model7up10d.pth')\n",
    "        print(\"Saved improved model\")\n",
    "\n",
    "test_model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model7up10d.pth')\n",
    "test_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = test_model(X)\n",
    " \n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")\n",
    "\n",
    "# make class predictions with the model\n",
    "predictions = (test_model(X) > 0.5).int().to('cpu')\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "###\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "actual_values = train7up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "merge_predictions = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "merge_predictions.index = range(1, len(merge_predictions) + 1)\n",
    "actual_values = train7up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(merge_predictions)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct predictions:\", mean_value)\n",
    "\n",
    "X = torch.tensor(np.array(train_df.T), dtype=torch.float32)\n",
    "y = torch.tensor(np.array(train9up10d_output), dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Move data to the chosen device\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "model5up10d = PimaClassifier().to(device)\n",
    "print(model5up10d)\n",
    "\n",
    "pos_weight = torch.tensor([1.5], device=device)  # Set your_pos_weight based on your needs\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model5up10d.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 2000\n",
    "batch_size = 1000\n",
    "best_loss = float('inf')\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = model5up10d(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        # Save model checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model5up10d.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }, 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model5up10d.pth')\n",
    "        print(\"Saved improved model\")\n",
    "\n",
    "test_model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model5up10d.pth')\n",
    "test_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = test_model(X)\n",
    " \n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")\n",
    "\n",
    "# make class predictions with the model\n",
    "predictions = (test_model(X) > 0.5).int().to('cpu')\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "###\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "actual_values = train5up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "merge_predictions = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "merge_predictions.index = range(1, len(merge_predictions) + 1)\n",
    "actual_values = train5up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(merge_predictions)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct predictions:\", mean_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d6b1475-ca94-49db-b517-d180e078a7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63204\n",
      "63204\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1698                4116\n",
      "Actual Negative                 524               56866\n",
      "Positive predictive power:\n",
      "29.21%\n",
      "Positive predictive accuracy:\n",
      "76.42%\n",
      "Confusion Matrix for merged 9up10d predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1443                4371\n",
      "Actual Negative                 342               57048\n",
      "Positive predictive power for 9up10d:\n",
      "24.82%\n",
      "Positive predictive accuracy for 9up10d:\n",
      "80.84%\n",
      "Mean change for incorrect 9up10d predictions: 1.034\n",
      "Mean change for correct 9up10d predictions: 1.129\n",
      "63204\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1647                8464\n",
      "Actual Negative                 289               52804\n",
      "Positive predictive power:\n",
      "16.29%\n",
      "Positive predictive accuracy:\n",
      "85.07%\n",
      "Confusion Matrix for merged 7up10d predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1399                8712\n",
      "Actual Negative                 174               52919\n",
      "Positive predictive power for 7up10d:\n",
      "13.84%\n",
      "Positive predictive accuracy for 7up10d:\n",
      "88.94%\n",
      "Mean change for incorrect 7up10d predictions: 1.014\n",
      "Mean change for correct 7up10d predictions: 1.118\n",
      "63204\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                2073               15245\n",
      "Actual Negative                 178               45708\n",
      "Positive predictive power:\n",
      "11.97%\n",
      "Positive predictive accuracy:\n",
      "92.09%\n",
      "Confusion Matrix for merged 5up10d predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1759               15559\n",
      "Actual Negative                 103               45783\n",
      "Positive predictive power for 5up10d:\n",
      "10.16%\n",
      "Positive predictive accuracy for 5up10d:\n",
      "94.47%\n",
      "Mean change for incorrect 5up10d predictions: 1.002\n",
      "Mean change for correct 5up10d predictions: 1.116\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Move your model and input data to the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "negmodel = PimaClassifier().to(device)\n",
    "negcheckpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_negmodel.pth')\n",
    "negmodel.load_state_dict(negcheckpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(negcheckpoint['optimizer_state_dict'])\n",
    "epoch = negcheckpoint['epoch']\n",
    "loss = negcheckpoint['loss']\n",
    "negmodel.eval()\n",
    "negmodel = negmodel.to(device)\n",
    "\n",
    "# Step 2: Prepare your input data (assuming new_input is your raw data)\n",
    "# For example, if your model expects input size of (1, C, H, W)\n",
    "input_tensor = torch.tensor(np.array(cv_df.T), dtype=torch.float32)\n",
    "input_tensor = input_tensor.to(device)\n",
    "neg_predictions = (negmodel(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(neg_predictions))\n",
    "neg_predictions = neg_predictions.numpy()\n",
    "neg_predictions = 1 - neg_predictions\n",
    "\n",
    "model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model9up10d.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "input_tensor = torch.tensor(np.array(cv_df.T), dtype=torch.float32)\n",
    "input_tensor = input_tensor.to(device)\n",
    "predictions = (model(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(predictions))\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = cv9up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "test_pred = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = cv9up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged 9up10d predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power for 9up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy for 9up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(cv_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect 9up10d predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(cv_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct 9up10d predictions:\", mean_value)\n",
    "\n",
    "###\n",
    "\n",
    "model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model7up10d.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "input_tensor = torch.tensor(np.array(cv_df.T), dtype=torch.float32)\n",
    "input_tensor = input_tensor.to(device)\n",
    "predictions = (model(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(predictions))\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = cv7up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "test_pred = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = cv7up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged 7up10d predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power for 7up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy for 7up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(cv_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect 7up10d predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(cv_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct 7up10d predictions:\", mean_value)\n",
    "\n",
    "###\n",
    "\n",
    "model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model5up10d.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "input_tensor = torch.tensor(np.array(cv_df.T), dtype=torch.float32)\n",
    "input_tensor = input_tensor.to(device)\n",
    "predictions = (model(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(predictions))\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = cv5up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "test_pred = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = cv5up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged 5up10d predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power for 5up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy for 5up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(cv_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect 5up10d predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(cv_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct 5up10d predictions:\", mean_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a156ad0c-de9a-4c85-a9f1-e7a59a7f12d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63205\n",
      "63205\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1720                4205\n",
      "Actual Negative                 532               56748\n",
      "Positive predictive power:\n",
      "29.03%\n",
      "Positive predictive accuracy:\n",
      "76.38%\n",
      "Confusion Matrix for merged 9up10d predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1459                4466\n",
      "Actual Negative                 351               56929\n",
      "Positive predictive power for 9up10d:\n",
      "24.62%\n",
      "Positive predictive accuracy for 9up10d:\n",
      "80.61%\n",
      "Mean change for incorrect 9up10d predictions: 1.033\n",
      "Mean change for correct 9up10d predictions: 1.126\n",
      "63205\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1686                8435\n",
      "Actual Negative                 308               52776\n",
      "Positive predictive power:\n",
      "16.66%\n",
      "Positive predictive accuracy:\n",
      "84.55%\n",
      "Confusion Matrix for merged 7up10d predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1427                8694\n",
      "Actual Negative                 184               52900\n",
      "Positive predictive power for 7up10d:\n",
      "14.1%\n",
      "Positive predictive accuracy for 7up10d:\n",
      "88.58%\n",
      "Mean change for incorrect 7up10d predictions: 1.009\n",
      "Mean change for correct 7up10d predictions: 1.119\n",
      "63205\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                2040               15334\n",
      "Actual Negative                 158               45673\n",
      "Positive predictive power:\n",
      "11.74%\n",
      "Positive predictive accuracy:\n",
      "92.81%\n",
      "Confusion Matrix for merged 5up10d predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1720               15654\n",
      "Actual Negative                  92               45739\n",
      "Positive predictive power for 5up10d:\n",
      "9.9%\n",
      "Positive predictive accuracy for 5up10d:\n",
      "94.92%\n",
      "Mean change for incorrect 5up10d predictions: 0.993\n",
      "Mean change for correct 5up10d predictions: 1.115\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Move your model and input data to the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "negmodel = PimaClassifier().to(device)\n",
    "negcheckpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_negmodel.pth')\n",
    "negmodel.load_state_dict(negcheckpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(negcheckpoint['optimizer_state_dict'])\n",
    "epoch = negcheckpoint['epoch']\n",
    "loss = negcheckpoint['loss']\n",
    "negmodel.eval()\n",
    "negmodel = negmodel.to(device)\n",
    "\n",
    "# Step 2: Prepare your input data (assuming new_input is your raw data)\n",
    "# For example, if your model expects input size of (1, C, H, W)\n",
    "input_tensor = torch.tensor(np.array(test_df.T), dtype=torch.float32)\n",
    "input_tensor = input_tensor.to(device)\n",
    "neg_predictions = (negmodel(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(neg_predictions))\n",
    "neg_predictions = neg_predictions.numpy()\n",
    "neg_predictions = 1 - neg_predictions\n",
    "\n",
    "model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model9up10d.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "input_tensor = torch.tensor(np.array(test_df.T), dtype=torch.float32)\n",
    "input_tensor = input_tensor.to(device)\n",
    "predictions = (model(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(predictions))\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test9up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "test_pred = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test9up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged 9up10d predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power for 9up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy for 9up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect 9up10d predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct 9up10d predictions:\", mean_value)\n",
    "\n",
    "###\n",
    "\n",
    "model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model7up10d.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "input_tensor = torch.tensor(np.array(test_df.T), dtype=torch.float32)\n",
    "input_tensor = input_tensor.to(device)\n",
    "predictions = (model(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(predictions))\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test7up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "test_pred = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test7up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged 7up10d predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power for 7up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy for 7up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect 7up10d predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct 7up10d predictions:\", mean_value)\n",
    "\n",
    "###\n",
    "\n",
    "model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model5up10d.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "input_tensor = torch.tensor(np.array(test_df.T), dtype=torch.float32)\n",
    "input_tensor = input_tensor.to(device)\n",
    "predictions = (model(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(predictions))\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test5up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "test_pred = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test5up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged 5up10d predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power for 5up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy for 5up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect 5up10d predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct 5up10d predictions:\", mean_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c05733-4295-41c8-864b-0e848eee60ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d216a2c0-f5d4-41e4-a31c-165eb2e7ce52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x\n",
      "1  1.02226\n",
      "2  1.04186\n",
      "3  1.04381\n",
      "4  1.03341\n",
      "5  1.03589\n",
      "(316022, 1)\n",
      "   x\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "5  0\n",
      "(316022, 1)\n",
      "x\n",
      "0    234112\n",
      "1     81910\n",
      "dtype: int64\n",
      "   x\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "5  0\n",
      "(316022, 1)\n",
      "x\n",
      "0    286620\n",
      "1     29402\n",
      "dtype: int64\n",
      "   x\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "5  0\n",
      "(316022, 1)\n",
      "x\n",
      "0    265159\n",
      "1     50863\n",
      "dtype: int64\n",
      "   x\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "5  0\n",
      "(316022, 1)\n",
      "x\n",
      "0    229013\n",
      "1     87009\n",
      "dtype: int64\n",
      "x\n",
      "0    229340\n",
      "1     23477\n",
      "dtype: int64\n",
      "x\n",
      "0    57280\n",
      "1     5925\n",
      "dtype: int64\n",
      "x\n",
      "0    212075\n",
      "1     40742\n",
      "dtype: int64\n",
      "x\n",
      "0    53084\n",
      "1    10121\n",
      "dtype: int64\n",
      "x\n",
      "0    183182\n",
      "1     69635\n",
      "dtype: int64\n",
      "x\n",
      "0    45831\n",
      "1    17374\n",
      "dtype: int64\n",
      "x\n",
      "0    187334\n",
      "1     65483\n",
      "dtype: int64\n",
      "x\n",
      "0    46778\n",
      "1    16427\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "test_10d_change_file  = 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_output_change10d_for_NN_20210514_to_20240404.tsv'\n",
    "change10d_dataset = pd.read_csv(test_10d_change_file, delimiter='\\t')\n",
    "print(change10d_dataset.iloc[:5,:5])\n",
    "print(change10d_dataset.shape)\n",
    "\n",
    "neg_output_file = 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_output_5down10d_for_NN_20210514_to_20240404.tsv'\n",
    "neg_output_dataset = pd.read_csv(neg_output_file, delimiter='\\t')\n",
    "print(neg_output_dataset.iloc[:5,:5])\n",
    "print(neg_output_dataset.shape)\n",
    "print(neg_output_dataset.value_counts())\n",
    "\n",
    "output9up10d_file = 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_output_9up10d_for_NN_20210514_to_20240404.tsv'\n",
    "output9up10d_dataset = pd.read_csv(output9up10d_file, delimiter='\\t')\n",
    "print(output9up10d_dataset.iloc[:5,:5])\n",
    "print(output9up10d_dataset.shape)\n",
    "print(output9up10d_dataset.value_counts())\n",
    "\n",
    "output7up10d_file = 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_output_7up10d_for_NN_20210514_to_20240404.tsv'\n",
    "output7up10d_dataset = pd.read_csv(output7up10d_file, delimiter='\\t')\n",
    "print(output7up10d_dataset.iloc[:5,:5])\n",
    "print(output7up10d_dataset.shape)\n",
    "print(output7up10d_dataset.value_counts())\n",
    "\n",
    "output5up10d_file = 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_output_5up10d_for_NN_20210514_to_20240404.tsv'\n",
    "output5up10d_dataset = pd.read_csv(output5up10d_file, delimiter='\\t')\n",
    "print(output5up10d_dataset.iloc[:5,:5])\n",
    "print(output5up10d_dataset.shape)\n",
    "print(output5up10d_dataset.value_counts())\n",
    "\n",
    "# Shuffle column names\n",
    "shuffled_columns = np.random.permutation(input_dataset.columns)\n",
    "\n",
    "# Calculate split sizes\n",
    "total_columns = len(input_dataset.columns)\n",
    "train_size = int(0.8 * total_columns)\n",
    "# The remaining columns will go to the test set\n",
    "\n",
    "# Split the columns\n",
    "train_columns = shuffled_columns[:train_size]\n",
    "test_columns = shuffled_columns[train_size:]\n",
    "\n",
    "# Create subsets of the DataFrame based on the columns\n",
    "train_df = input_dataset[train_columns]\n",
    "test_df = input_dataset[test_columns]\n",
    "\n",
    "output9up10d_dataset.index = input_dataset.columns\n",
    "output7up10d_dataset.index = input_dataset.columns\n",
    "output5up10d_dataset.index = input_dataset.columns\n",
    "neg_output_dataset.index = input_dataset.columns\n",
    "change10d_dataset.index = input_dataset.columns\n",
    "\n",
    "train9up10d_output = output9up10d_dataset.T[train_columns].T\n",
    "test9up10d_output = output9up10d_dataset.T[test_columns].T\n",
    "\n",
    "train7up10d_output = output7up10d_dataset.T[train_columns].T\n",
    "test7up10d_output = output7up10d_dataset.T[test_columns].T\n",
    "\n",
    "train5up10d_output = output5up10d_dataset.T[train_columns].T\n",
    "test5up10d_output = output5up10d_dataset.T[test_columns].T\n",
    "\n",
    "train_negoutput = neg_output_dataset.T[train_columns].T\n",
    "test_negoutput = neg_output_dataset.T[test_columns].T\n",
    "\n",
    "train_10dChange = change10d_dataset.T[train_columns].T\n",
    "test_10dChange = change10d_dataset.T[test_columns].T\n",
    "\n",
    "train9up10d_output.index = range(1, len(train9up10d_output) + 1)\n",
    "test9up10d_output.index = range(1, len(test9up10d_output) + 1)\n",
    "print(train9up10d_output.value_counts())\n",
    "print(test9up10d_output.value_counts())\n",
    "\n",
    "train7up10d_output.index = range(1, len(train7up10d_output) + 1)\n",
    "test7up10d_output.index = range(1, len(test7up10d_output) + 1)\n",
    "print(train7up10d_output.value_counts())\n",
    "print(test7up10d_output.value_counts())\n",
    "\n",
    "train5up10d_output.index = range(1, len(train5up10d_output) + 1)\n",
    "test5up10d_output.index = range(1, len(test5up10d_output) + 1)\n",
    "print(train5up10d_output.value_counts())\n",
    "print(test5up10d_output.value_counts())\n",
    "\n",
    "train_negoutput.index = range(1, len(train_negoutput) + 1)\n",
    "test_negoutput.index = range(1, len(test_negoutput) + 1)\n",
    "print(train_negoutput.value_counts())\n",
    "print(test_negoutput.value_counts())\n",
    "\n",
    "train_10dChange.index = range(1, len(train_10dChange) + 1)\n",
    "test_10dChange.index = range(1, len(test_10dChange) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c83e9-d375-42ba-bbe7-d8607a24fd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PimaClassifier(\n",
      "  (hidden1): Linear(in_features=1616, out_features=64, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (hidden2): Linear(in_features=64, out_features=12, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (hidden3): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (act3): ReLU()\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (act_output): Sigmoid()\n",
      ")\n",
      "Finished epoch 0, latest loss 0.9376556873321533\n",
      "Saved improved model\n",
      "Finished epoch 1, latest loss 0.9235866665840149\n",
      "Saved improved model\n",
      "Finished epoch 2, latest loss 0.9074278473854065\n",
      "Saved improved model\n",
      "Finished epoch 3, latest loss 0.8991867303848267\n",
      "Saved improved model\n",
      "Finished epoch 4, latest loss 0.8910913467407227\n",
      "Saved improved model\n",
      "Finished epoch 5, latest loss 0.8820620775222778\n",
      "Saved improved model\n",
      "Finished epoch 6, latest loss 0.8773768544197083\n",
      "Saved improved model\n",
      "Finished epoch 7, latest loss 0.8694850206375122\n",
      "Saved improved model\n",
      "Finished epoch 8, latest loss 0.8654044270515442\n",
      "Saved improved model\n",
      "Finished epoch 9, latest loss 0.8597502112388611\n",
      "Saved improved model\n",
      "Finished epoch 10, latest loss 0.853003978729248\n",
      "Saved improved model\n",
      "Finished epoch 11, latest loss 0.8580030202865601\n",
      "Finished epoch 12, latest loss 0.860666036605835\n",
      "Finished epoch 13, latest loss 0.850889265537262\n",
      "Saved improved model\n",
      "Finished epoch 14, latest loss 0.853730320930481\n",
      "Finished epoch 15, latest loss 0.8481423258781433\n",
      "Saved improved model\n",
      "Finished epoch 16, latest loss 0.8408308029174805\n",
      "Saved improved model\n",
      "Finished epoch 17, latest loss 0.8505313992500305\n",
      "Finished epoch 18, latest loss 0.8453391790390015\n",
      "Finished epoch 19, latest loss 0.8418172001838684\n",
      "Finished epoch 20, latest loss 0.8409634828567505\n",
      "Finished epoch 21, latest loss 0.8397396206855774\n",
      "Saved improved model\n",
      "Finished epoch 22, latest loss 0.8335873484611511\n",
      "Saved improved model\n",
      "Finished epoch 23, latest loss 0.8351380228996277\n",
      "Finished epoch 24, latest loss 0.834703803062439\n",
      "Finished epoch 25, latest loss 0.836993396282196\n",
      "Finished epoch 26, latest loss 0.8330799341201782\n",
      "Saved improved model\n",
      "Finished epoch 27, latest loss 0.8321291208267212\n",
      "Saved improved model\n",
      "Finished epoch 28, latest loss 0.8469379544258118\n",
      "Finished epoch 29, latest loss 0.8281973004341125\n",
      "Saved improved model\n",
      "Finished epoch 30, latest loss 0.8300125002861023\n",
      "Finished epoch 31, latest loss 0.8322507739067078\n",
      "Finished epoch 32, latest loss 0.8339583277702332\n",
      "Finished epoch 33, latest loss 0.8328815698623657\n",
      "Finished epoch 34, latest loss 0.8262007236480713\n",
      "Saved improved model\n",
      "Finished epoch 35, latest loss 0.8325528502464294\n",
      "Finished epoch 36, latest loss 0.8274480104446411\n",
      "Finished epoch 37, latest loss 0.8238141536712646\n",
      "Saved improved model\n",
      "Finished epoch 38, latest loss 0.8354875445365906\n",
      "Finished epoch 39, latest loss 0.8328279256820679\n",
      "Finished epoch 40, latest loss 0.8247509598731995\n",
      "Finished epoch 41, latest loss 0.8293067812919617\n",
      "Finished epoch 42, latest loss 0.8287160396575928\n",
      "Finished epoch 43, latest loss 0.8203427791595459\n",
      "Saved improved model\n",
      "Finished epoch 44, latest loss 0.82471764087677\n",
      "Finished epoch 45, latest loss 0.8276499509811401\n",
      "Finished epoch 46, latest loss 0.8173558115959167\n",
      "Saved improved model\n",
      "Finished epoch 47, latest loss 0.8186835646629333\n",
      "Finished epoch 48, latest loss 0.8219635486602783\n",
      "Finished epoch 49, latest loss 0.8205267190933228\n",
      "Finished epoch 50, latest loss 0.8218713402748108\n",
      "Finished epoch 51, latest loss 0.8153541088104248\n",
      "Saved improved model\n",
      "Finished epoch 52, latest loss 0.8176429271697998\n",
      "Finished epoch 53, latest loss 0.8182125091552734\n",
      "Finished epoch 54, latest loss 0.8140362501144409\n",
      "Saved improved model\n",
      "Finished epoch 55, latest loss 0.8171130418777466\n",
      "Finished epoch 56, latest loss 0.8206143975257874\n",
      "Finished epoch 57, latest loss 0.8151444792747498\n",
      "Finished epoch 58, latest loss 0.8175495862960815\n",
      "Finished epoch 59, latest loss 0.8194177746772766\n",
      "Finished epoch 60, latest loss 0.8131858706474304\n",
      "Saved improved model\n",
      "Finished epoch 61, latest loss 0.8149825930595398\n",
      "Finished epoch 62, latest loss 0.8257929682731628\n",
      "Finished epoch 63, latest loss 0.8224318623542786\n",
      "Finished epoch 64, latest loss 0.817218005657196\n",
      "Finished epoch 65, latest loss 0.8206619024276733\n",
      "Finished epoch 66, latest loss 0.8208063244819641\n",
      "Finished epoch 67, latest loss 0.8174774050712585\n",
      "Finished epoch 68, latest loss 0.8119426369667053\n",
      "Saved improved model\n",
      "Finished epoch 69, latest loss 0.8150297999382019\n",
      "Finished epoch 70, latest loss 0.8128697872161865\n",
      "Finished epoch 71, latest loss 0.810703456401825\n",
      "Saved improved model\n",
      "Finished epoch 72, latest loss 0.8089233636856079\n",
      "Saved improved model\n",
      "Finished epoch 73, latest loss 0.8096497654914856\n",
      "Finished epoch 74, latest loss 0.8103277087211609\n",
      "Finished epoch 75, latest loss 0.8076807260513306\n",
      "Saved improved model\n",
      "Finished epoch 76, latest loss 0.8115140199661255\n",
      "Finished epoch 77, latest loss 0.8115993738174438\n",
      "Finished epoch 78, latest loss 0.8181646466255188\n",
      "Finished epoch 79, latest loss 0.8091699481010437\n",
      "Finished epoch 80, latest loss 0.8096065521240234\n",
      "Finished epoch 81, latest loss 0.8109911680221558\n",
      "Finished epoch 82, latest loss 0.8079503774642944\n",
      "Finished epoch 83, latest loss 0.8176615834236145\n",
      "Finished epoch 84, latest loss 0.8092384934425354\n",
      "Finished epoch 85, latest loss 0.8082756400108337\n",
      "Finished epoch 86, latest loss 0.8071202039718628\n",
      "Saved improved model\n",
      "Finished epoch 87, latest loss 0.8112017512321472\n",
      "Finished epoch 88, latest loss 0.8129054307937622\n",
      "Finished epoch 89, latest loss 0.8232589364051819\n",
      "Finished epoch 90, latest loss 0.8076425790786743\n",
      "Finished epoch 91, latest loss 0.8081659078598022\n",
      "Finished epoch 92, latest loss 0.8079925179481506\n",
      "Finished epoch 93, latest loss 0.8141646981239319\n",
      "Finished epoch 94, latest loss 0.8106616139411926\n",
      "Finished epoch 95, latest loss 0.8102408647537231\n",
      "Finished epoch 96, latest loss 0.8086948990821838\n",
      "Finished epoch 97, latest loss 0.8064877390861511\n",
      "Saved improved model\n",
      "Finished epoch 98, latest loss 0.8061943650245667\n",
      "Saved improved model\n",
      "Finished epoch 99, latest loss 0.8045271635055542\n",
      "Saved improved model\n",
      "Finished epoch 100, latest loss 0.805109441280365\n",
      "Finished epoch 101, latest loss 0.8048186898231506\n",
      "Finished epoch 102, latest loss 0.8051062226295471\n",
      "Finished epoch 103, latest loss 0.8033487796783447\n",
      "Saved improved model\n",
      "Finished epoch 104, latest loss 0.8050745129585266\n",
      "Finished epoch 105, latest loss 0.8083121180534363\n",
      "Finished epoch 106, latest loss 0.802946925163269\n",
      "Saved improved model\n",
      "Finished epoch 107, latest loss 0.8066598176956177\n",
      "Finished epoch 108, latest loss 0.8032643795013428\n",
      "Finished epoch 109, latest loss 0.8105790019035339\n",
      "Finished epoch 110, latest loss 0.8067904710769653\n",
      "Finished epoch 111, latest loss 0.8028236031532288\n",
      "Saved improved model\n",
      "Finished epoch 112, latest loss 0.8118419051170349\n",
      "Finished epoch 113, latest loss 0.8043289184570312\n",
      "Finished epoch 114, latest loss 0.8045729398727417\n",
      "Finished epoch 115, latest loss 0.8039464354515076\n",
      "Finished epoch 116, latest loss 0.8076431751251221\n",
      "Finished epoch 117, latest loss 0.8058534860610962\n",
      "Finished epoch 118, latest loss 0.8056870698928833\n",
      "Finished epoch 119, latest loss 0.8077055811882019\n",
      "Finished epoch 120, latest loss 0.8077065348625183\n",
      "Finished epoch 121, latest loss 0.8067004084587097\n",
      "Finished epoch 122, latest loss 0.8120304942131042\n",
      "Finished epoch 123, latest loss 0.8145896196365356\n",
      "Finished epoch 124, latest loss 0.8030998706817627\n",
      "Finished epoch 125, latest loss 0.804645836353302\n",
      "Finished epoch 126, latest loss 0.8107729554176331\n",
      "Finished epoch 127, latest loss 0.8060594201087952\n",
      "Finished epoch 128, latest loss 0.8061480522155762\n",
      "Finished epoch 129, latest loss 0.8022017478942871\n",
      "Saved improved model\n",
      "Finished epoch 130, latest loss 0.8038371801376343\n",
      "Finished epoch 131, latest loss 0.802657961845398\n",
      "Finished epoch 132, latest loss 0.8022568821907043\n",
      "Finished epoch 133, latest loss 0.8060505986213684\n",
      "Finished epoch 134, latest loss 0.8004299998283386\n",
      "Saved improved model\n",
      "Finished epoch 135, latest loss 0.8063764572143555\n",
      "Finished epoch 136, latest loss 0.8030642867088318\n",
      "Finished epoch 137, latest loss 0.7988669276237488\n",
      "Saved improved model\n",
      "Finished epoch 138, latest loss 0.8045194149017334\n",
      "Finished epoch 139, latest loss 0.8069722056388855\n",
      "Finished epoch 140, latest loss 0.8022999167442322\n",
      "Finished epoch 141, latest loss 0.8030330538749695\n",
      "Finished epoch 142, latest loss 0.8027962446212769\n",
      "Finished epoch 143, latest loss 0.8022950291633606\n",
      "Finished epoch 144, latest loss 0.8006464838981628\n",
      "Finished epoch 145, latest loss 0.8020913004875183\n",
      "Finished epoch 146, latest loss 0.8026400804519653\n",
      "Finished epoch 147, latest loss 0.8095936179161072\n",
      "Finished epoch 148, latest loss 0.8011754155158997\n",
      "Finished epoch 149, latest loss 0.8021115064620972\n",
      "Finished epoch 150, latest loss 0.7999027967453003\n",
      "Finished epoch 151, latest loss 0.8047217130661011\n",
      "Finished epoch 152, latest loss 0.8100134134292603\n",
      "Finished epoch 153, latest loss 0.8048100471496582\n",
      "Finished epoch 154, latest loss 0.802768886089325\n",
      "Finished epoch 155, latest loss 0.8025606274604797\n",
      "Finished epoch 156, latest loss 0.7984409332275391\n",
      "Saved improved model\n",
      "Finished epoch 157, latest loss 0.8029014468193054\n",
      "Finished epoch 158, latest loss 0.7990227341651917\n",
      "Finished epoch 159, latest loss 0.8033761978149414\n",
      "Finished epoch 160, latest loss 0.8041121363639832\n",
      "Finished epoch 161, latest loss 0.8035964369773865\n",
      "Finished epoch 162, latest loss 0.8065690398216248\n",
      "Finished epoch 163, latest loss 0.8019791841506958\n",
      "Finished epoch 164, latest loss 0.8032153248786926\n",
      "Finished epoch 165, latest loss 0.8030009269714355\n",
      "Finished epoch 166, latest loss 0.8021896481513977\n",
      "Finished epoch 167, latest loss 0.800528883934021\n",
      "Finished epoch 168, latest loss 0.8003342747688293\n",
      "Finished epoch 169, latest loss 0.8029745221138\n",
      "Finished epoch 170, latest loss 0.7979660034179688\n",
      "Saved improved model\n",
      "Finished epoch 171, latest loss 0.8008634448051453\n",
      "Finished epoch 172, latest loss 0.7971757650375366\n",
      "Saved improved model\n",
      "Finished epoch 173, latest loss 0.7971188426017761\n",
      "Saved improved model\n",
      "Finished epoch 174, latest loss 0.7992960810661316\n",
      "Finished epoch 175, latest loss 0.7969709634780884\n",
      "Saved improved model\n",
      "Finished epoch 176, latest loss 0.7990081906318665\n",
      "Finished epoch 177, latest loss 0.798621654510498\n",
      "Finished epoch 178, latest loss 0.806463897228241\n",
      "Finished epoch 179, latest loss 0.7954846620559692\n",
      "Saved improved model\n",
      "Finished epoch 180, latest loss 0.7987156510353088\n",
      "Finished epoch 181, latest loss 0.7971451282501221\n",
      "Finished epoch 182, latest loss 0.7960308194160461\n",
      "Finished epoch 183, latest loss 0.8009968400001526\n",
      "Finished epoch 184, latest loss 0.8017883896827698\n",
      "Finished epoch 185, latest loss 0.8016061186790466\n",
      "Finished epoch 186, latest loss 0.79832923412323\n",
      "Finished epoch 187, latest loss 0.8003356456756592\n",
      "Finished epoch 188, latest loss 0.7958965301513672\n",
      "Finished epoch 189, latest loss 0.7978821396827698\n",
      "Finished epoch 190, latest loss 0.7969441413879395\n",
      "Finished epoch 191, latest loss 0.7958066463470459\n",
      "Finished epoch 192, latest loss 0.7953840494155884\n",
      "Saved improved model\n",
      "Finished epoch 193, latest loss 0.8000304698944092\n",
      "Finished epoch 194, latest loss 0.7978426218032837\n",
      "Finished epoch 195, latest loss 0.7963516116142273\n",
      "Finished epoch 196, latest loss 0.8002121448516846\n",
      "Finished epoch 197, latest loss 0.7959399223327637\n",
      "Finished epoch 198, latest loss 0.7932050824165344\n",
      "Saved improved model\n",
      "Finished epoch 199, latest loss 0.8010333180427551\n",
      "Finished epoch 200, latest loss 0.800363302230835\n",
      "Finished epoch 201, latest loss 0.7993826270103455\n",
      "Finished epoch 202, latest loss 0.7993645071983337\n",
      "Finished epoch 203, latest loss 0.8002133965492249\n",
      "Finished epoch 204, latest loss 0.7990273237228394\n",
      "Finished epoch 205, latest loss 0.7980737686157227\n",
      "Finished epoch 206, latest loss 0.8005305528640747\n",
      "Finished epoch 207, latest loss 0.7977398037910461\n",
      "Finished epoch 208, latest loss 0.7958919405937195\n",
      "Finished epoch 209, latest loss 0.7953610420227051\n",
      "Finished epoch 210, latest loss 0.7954528331756592\n",
      "Finished epoch 211, latest loss 0.796522855758667\n",
      "Finished epoch 212, latest loss 0.7943370342254639\n",
      "Finished epoch 213, latest loss 0.7970578074455261\n",
      "Finished epoch 214, latest loss 0.8001940250396729\n",
      "Finished epoch 215, latest loss 0.798934817314148\n",
      "Finished epoch 216, latest loss 0.7976142168045044\n",
      "Finished epoch 217, latest loss 0.7969525456428528\n",
      "Finished epoch 218, latest loss 0.7949180006980896\n",
      "Finished epoch 219, latest loss 0.7985737919807434\n",
      "Finished epoch 220, latest loss 0.7948470115661621\n",
      "Finished epoch 221, latest loss 0.7959078550338745\n",
      "Finished epoch 222, latest loss 0.7946139574050903\n",
      "Finished epoch 223, latest loss 0.7996529936790466\n",
      "Finished epoch 224, latest loss 0.7952894568443298\n",
      "Finished epoch 225, latest loss 0.7939499616622925\n",
      "Finished epoch 226, latest loss 0.7972957491874695\n",
      "Finished epoch 227, latest loss 0.7954429388046265\n",
      "Finished epoch 228, latest loss 0.7953723669052124\n",
      "Finished epoch 229, latest loss 0.7996073365211487\n",
      "Finished epoch 230, latest loss 0.7957553267478943\n",
      "Finished epoch 231, latest loss 0.8014476299285889\n",
      "Finished epoch 232, latest loss 0.797654926776886\n",
      "Finished epoch 233, latest loss 0.7928840517997742\n",
      "Saved improved model\n",
      "Finished epoch 234, latest loss 0.7914914488792419\n",
      "Saved improved model\n",
      "Finished epoch 235, latest loss 0.7965884208679199\n",
      "Finished epoch 236, latest loss 0.7984210848808289\n",
      "Finished epoch 237, latest loss 0.7936566472053528\n",
      "Finished epoch 238, latest loss 0.7926689386367798\n",
      "Finished epoch 239, latest loss 0.7929892539978027\n",
      "Finished epoch 240, latest loss 0.795770525932312\n",
      "Finished epoch 241, latest loss 0.7941548228263855\n",
      "Finished epoch 242, latest loss 0.794787585735321\n",
      "Finished epoch 243, latest loss 0.7912641167640686\n",
      "Saved improved model\n",
      "Finished epoch 244, latest loss 0.7955250144004822\n",
      "Finished epoch 245, latest loss 0.7950116991996765\n",
      "Finished epoch 246, latest loss 0.7972245812416077\n",
      "Finished epoch 247, latest loss 0.7936302423477173\n",
      "Finished epoch 248, latest loss 0.793661892414093\n",
      "Finished epoch 249, latest loss 0.7955139875411987\n",
      "Finished epoch 250, latest loss 0.795381486415863\n",
      "Finished epoch 251, latest loss 0.7977098822593689\n",
      "Finished epoch 252, latest loss 0.7972888946533203\n",
      "Finished epoch 253, latest loss 0.7926744222640991\n",
      "Finished epoch 254, latest loss 0.7914342880249023\n",
      "Finished epoch 255, latest loss 0.7951862215995789\n",
      "Finished epoch 256, latest loss 0.7964512705802917\n",
      "Finished epoch 257, latest loss 0.7948558330535889\n",
      "Finished epoch 258, latest loss 0.7943781018257141\n",
      "Finished epoch 259, latest loss 0.7952266335487366\n",
      "Finished epoch 260, latest loss 0.7943989634513855\n",
      "Finished epoch 261, latest loss 0.7968736886978149\n",
      "Finished epoch 262, latest loss 0.7915668487548828\n",
      "Finished epoch 263, latest loss 0.7966098189353943\n",
      "Finished epoch 264, latest loss 0.792341947555542\n",
      "Finished epoch 265, latest loss 0.7977348566055298\n",
      "Finished epoch 266, latest loss 0.8075587153434753\n",
      "Finished epoch 267, latest loss 0.790198802947998\n",
      "Saved improved model\n",
      "Finished epoch 268, latest loss 0.8020927906036377\n",
      "Finished epoch 269, latest loss 0.7959203124046326\n",
      "Finished epoch 270, latest loss 0.7968022227287292\n",
      "Finished epoch 271, latest loss 0.7976993322372437\n",
      "Finished epoch 272, latest loss 0.796771764755249\n",
      "Finished epoch 273, latest loss 0.797905445098877\n",
      "Finished epoch 274, latest loss 0.7997280359268188\n",
      "Finished epoch 275, latest loss 0.7915012836456299\n",
      "Finished epoch 276, latest loss 0.7984529733657837\n",
      "Finished epoch 277, latest loss 0.7971467971801758\n",
      "Finished epoch 278, latest loss 0.7991330623626709\n",
      "Finished epoch 279, latest loss 0.7993165850639343\n",
      "Finished epoch 280, latest loss 0.798581600189209\n",
      "Finished epoch 281, latest loss 0.7930019497871399\n",
      "Finished epoch 282, latest loss 0.7986382246017456\n",
      "Finished epoch 283, latest loss 0.7933101058006287\n",
      "Finished epoch 284, latest loss 0.7990480661392212\n",
      "Finished epoch 285, latest loss 0.8028391003608704\n",
      "Finished epoch 286, latest loss 0.7912806272506714\n",
      "Finished epoch 287, latest loss 0.7958665490150452\n",
      "Finished epoch 288, latest loss 0.7924749255180359\n",
      "Finished epoch 289, latest loss 0.7922130823135376\n",
      "Finished epoch 290, latest loss 0.7931322455406189\n",
      "Finished epoch 291, latest loss 0.7898837327957153\n",
      "Saved improved model\n",
      "Finished epoch 292, latest loss 0.7958680391311646\n",
      "Finished epoch 293, latest loss 0.7908562421798706\n",
      "Finished epoch 294, latest loss 0.8000438809394836\n",
      "Finished epoch 295, latest loss 0.8000864386558533\n",
      "Finished epoch 296, latest loss 0.7989954948425293\n",
      "Finished epoch 297, latest loss 0.7971296310424805\n",
      "Finished epoch 298, latest loss 0.7930002808570862\n",
      "Finished epoch 299, latest loss 0.7952592372894287\n",
      "Finished epoch 300, latest loss 0.7943950295448303\n",
      "Finished epoch 301, latest loss 0.7951868772506714\n",
      "Finished epoch 302, latest loss 0.7961694598197937\n",
      "Finished epoch 303, latest loss 0.7964987754821777\n",
      "Finished epoch 304, latest loss 0.7939556241035461\n",
      "Finished epoch 305, latest loss 0.7942259311676025\n",
      "Finished epoch 306, latest loss 0.7935526967048645\n",
      "Finished epoch 307, latest loss 0.7940357327461243\n",
      "Finished epoch 308, latest loss 0.7977015376091003\n",
      "Finished epoch 309, latest loss 0.7964573502540588\n",
      "Finished epoch 310, latest loss 0.7952594757080078\n",
      "Finished epoch 311, latest loss 0.794632613658905\n",
      "Finished epoch 312, latest loss 0.7940648794174194\n",
      "Finished epoch 313, latest loss 0.7943491339683533\n",
      "Finished epoch 314, latest loss 0.7956348061561584\n",
      "Finished epoch 315, latest loss 0.8011173009872437\n",
      "Finished epoch 316, latest loss 0.7948474884033203\n",
      "Finished epoch 317, latest loss 0.7958633303642273\n",
      "Finished epoch 318, latest loss 0.7954414486885071\n",
      "Finished epoch 319, latest loss 0.792131781578064\n",
      "Finished epoch 320, latest loss 0.79450923204422\n",
      "Finished epoch 321, latest loss 0.7907682061195374\n",
      "Finished epoch 322, latest loss 0.7956849932670593\n",
      "Finished epoch 323, latest loss 0.7970492839813232\n",
      "Finished epoch 324, latest loss 0.7927373051643372\n",
      "Finished epoch 325, latest loss 0.7955652475357056\n",
      "Finished epoch 326, latest loss 0.794348418712616\n",
      "Finished epoch 327, latest loss 0.795933187007904\n",
      "Finished epoch 328, latest loss 0.793847382068634\n",
      "Finished epoch 329, latest loss 0.7938944697380066\n",
      "Finished epoch 330, latest loss 0.7980589866638184\n",
      "Finished epoch 331, latest loss 0.790349006652832\n",
      "Finished epoch 332, latest loss 0.7894195914268494\n",
      "Saved improved model\n",
      "Finished epoch 333, latest loss 0.7974274754524231\n",
      "Finished epoch 334, latest loss 0.7947694659233093\n",
      "Finished epoch 335, latest loss 0.7906274795532227\n",
      "Finished epoch 336, latest loss 0.794826090335846\n",
      "Finished epoch 337, latest loss 0.7959235310554504\n",
      "Finished epoch 338, latest loss 0.7915394902229309\n",
      "Finished epoch 339, latest loss 0.7943711280822754\n",
      "Finished epoch 340, latest loss 0.7926031351089478\n",
      "Finished epoch 341, latest loss 0.7914471626281738\n",
      "Finished epoch 342, latest loss 0.7959933280944824\n",
      "Finished epoch 343, latest loss 0.7971864938735962\n",
      "Finished epoch 344, latest loss 0.790562629699707\n",
      "Finished epoch 345, latest loss 0.7984263896942139\n",
      "Finished epoch 346, latest loss 0.795330286026001\n",
      "Finished epoch 347, latest loss 0.792153537273407\n",
      "Finished epoch 348, latest loss 0.7940399050712585\n",
      "Finished epoch 349, latest loss 0.792697548866272\n",
      "Finished epoch 350, latest loss 0.7923855781555176\n",
      "Finished epoch 351, latest loss 0.7941311001777649\n",
      "Finished epoch 352, latest loss 0.7926054000854492\n",
      "Finished epoch 353, latest loss 0.7942173480987549\n",
      "Finished epoch 354, latest loss 0.7942032217979431\n",
      "Finished epoch 355, latest loss 0.7944220304489136\n",
      "Finished epoch 356, latest loss 0.7943674921989441\n",
      "Finished epoch 357, latest loss 0.802439272403717\n",
      "Finished epoch 358, latest loss 0.8012979030609131\n",
      "Finished epoch 359, latest loss 0.7936968803405762\n",
      "Finished epoch 360, latest loss 0.7950959801673889\n",
      "Finished epoch 361, latest loss 0.7924569249153137\n",
      "Finished epoch 362, latest loss 0.7953234314918518\n",
      "Finished epoch 363, latest loss 0.7913358807563782\n",
      "Finished epoch 364, latest loss 0.7912102937698364\n",
      "Finished epoch 365, latest loss 0.8011491894721985\n",
      "Finished epoch 366, latest loss 0.7954439520835876\n",
      "Finished epoch 367, latest loss 0.7929006218910217\n",
      "Finished epoch 368, latest loss 0.7922633290290833\n",
      "Finished epoch 369, latest loss 0.7953003644943237\n",
      "Finished epoch 370, latest loss 0.7917703986167908\n",
      "Finished epoch 371, latest loss 0.7927110195159912\n",
      "Finished epoch 372, latest loss 0.7905204892158508\n",
      "Finished epoch 373, latest loss 0.7934661507606506\n",
      "Finished epoch 374, latest loss 0.7917002439498901\n",
      "Finished epoch 375, latest loss 0.7940016388893127\n",
      "Finished epoch 376, latest loss 0.7925898432731628\n",
      "Finished epoch 377, latest loss 0.7950084209442139\n",
      "Finished epoch 378, latest loss 0.7905197143554688\n",
      "Finished epoch 379, latest loss 0.7919303178787231\n",
      "Finished epoch 380, latest loss 0.7913578748703003\n",
      "Finished epoch 381, latest loss 0.7955306172370911\n",
      "Finished epoch 382, latest loss 0.7906659841537476\n",
      "Finished epoch 383, latest loss 0.7911807298660278\n",
      "Finished epoch 384, latest loss 0.7899869084358215\n",
      "Finished epoch 385, latest loss 0.7920374870300293\n",
      "Finished epoch 386, latest loss 0.7946048378944397\n",
      "Finished epoch 387, latest loss 0.7915559411048889\n",
      "Finished epoch 388, latest loss 0.7913199663162231\n",
      "Finished epoch 389, latest loss 0.791129469871521\n",
      "Finished epoch 390, latest loss 0.7982307076454163\n",
      "Finished epoch 391, latest loss 0.7980237007141113\n",
      "Finished epoch 392, latest loss 0.7950841784477234\n",
      "Finished epoch 393, latest loss 0.7931503057479858\n",
      "Finished epoch 394, latest loss 0.7927775979042053\n",
      "Finished epoch 395, latest loss 0.7895394563674927\n",
      "Finished epoch 396, latest loss 0.7913525700569153\n",
      "Finished epoch 397, latest loss 0.7951603531837463\n",
      "Finished epoch 398, latest loss 0.7932982444763184\n",
      "Finished epoch 399, latest loss 0.7920888662338257\n",
      "Finished epoch 400, latest loss 0.7945030331611633\n",
      "Finished epoch 401, latest loss 0.7951955199241638\n",
      "Finished epoch 402, latest loss 0.7935662865638733\n",
      "Finished epoch 403, latest loss 0.790329098701477\n",
      "Finished epoch 404, latest loss 0.7892535924911499\n",
      "Saved improved model\n",
      "Finished epoch 405, latest loss 0.7902070879936218\n",
      "Finished epoch 406, latest loss 0.7927418947219849\n",
      "Finished epoch 407, latest loss 0.7886408567428589\n",
      "Saved improved model\n",
      "Finished epoch 408, latest loss 0.7921059131622314\n",
      "Finished epoch 409, latest loss 0.7892459034919739\n",
      "Finished epoch 410, latest loss 0.7940593361854553\n",
      "Finished epoch 411, latest loss 0.792966365814209\n",
      "Finished epoch 412, latest loss 0.7918494939804077\n",
      "Finished epoch 413, latest loss 0.7939596772193909\n",
      "Finished epoch 414, latest loss 0.7899255156517029\n",
      "Finished epoch 415, latest loss 0.7930577993392944\n",
      "Finished epoch 416, latest loss 0.7908956408500671\n",
      "Finished epoch 417, latest loss 0.7950338125228882\n",
      "Finished epoch 418, latest loss 0.7940358519554138\n",
      "Finished epoch 419, latest loss 0.7927560806274414\n",
      "Finished epoch 420, latest loss 0.7907065153121948\n",
      "Finished epoch 421, latest loss 0.7907543778419495\n",
      "Finished epoch 422, latest loss 0.7901428937911987\n",
      "Finished epoch 423, latest loss 0.7920938730239868\n",
      "Finished epoch 424, latest loss 0.7944742441177368\n",
      "Finished epoch 425, latest loss 0.7919115424156189\n",
      "Finished epoch 426, latest loss 0.7965694665908813\n",
      "Finished epoch 427, latest loss 0.7944756150245667\n",
      "Finished epoch 428, latest loss 0.7892941236495972\n",
      "Finished epoch 429, latest loss 0.7972632050514221\n",
      "Finished epoch 430, latest loss 0.7893030643463135\n",
      "Finished epoch 431, latest loss 0.7907494306564331\n",
      "Finished epoch 432, latest loss 0.7938524484634399\n",
      "Finished epoch 433, latest loss 0.7975144982337952\n",
      "Finished epoch 434, latest loss 0.7917059063911438\n",
      "Finished epoch 435, latest loss 0.7930173873901367\n",
      "Finished epoch 436, latest loss 0.7925085425376892\n",
      "Finished epoch 437, latest loss 0.7918233871459961\n",
      "Finished epoch 438, latest loss 0.7926634550094604\n",
      "Finished epoch 439, latest loss 0.7939196228981018\n",
      "Finished epoch 440, latest loss 0.7901970148086548\n",
      "Finished epoch 441, latest loss 0.7899712324142456\n",
      "Finished epoch 442, latest loss 0.7926156520843506\n",
      "Finished epoch 443, latest loss 0.7931016087532043\n",
      "Finished epoch 444, latest loss 0.7960907220840454\n",
      "Finished epoch 445, latest loss 0.792144238948822\n",
      "Finished epoch 446, latest loss 0.7919407486915588\n",
      "Finished epoch 447, latest loss 0.7934148907661438\n",
      "Finished epoch 448, latest loss 0.7940731644630432\n",
      "Finished epoch 449, latest loss 0.7904245853424072\n",
      "Finished epoch 450, latest loss 0.7917881608009338\n",
      "Finished epoch 451, latest loss 0.7944119572639465\n",
      "Finished epoch 452, latest loss 0.7933405041694641\n",
      "Finished epoch 453, latest loss 0.7901082634925842\n",
      "Finished epoch 454, latest loss 0.7916012406349182\n",
      "Finished epoch 455, latest loss 0.7911315560340881\n",
      "Finished epoch 456, latest loss 0.7930706739425659\n",
      "Finished epoch 457, latest loss 0.793989896774292\n",
      "Finished epoch 458, latest loss 0.7930857539176941\n",
      "Finished epoch 459, latest loss 0.7949329614639282\n",
      "Finished epoch 460, latest loss 0.7897629737854004\n",
      "Finished epoch 461, latest loss 0.7918546199798584\n",
      "Finished epoch 462, latest loss 0.7942726612091064\n",
      "Finished epoch 463, latest loss 0.7974669933319092\n",
      "Finished epoch 464, latest loss 0.7914263010025024\n",
      "Finished epoch 465, latest loss 0.7946755290031433\n",
      "Finished epoch 466, latest loss 0.7915987968444824\n",
      "Finished epoch 467, latest loss 0.7929968237876892\n",
      "Finished epoch 468, latest loss 0.7919066548347473\n",
      "Finished epoch 469, latest loss 0.7915478348731995\n",
      "Finished epoch 470, latest loss 0.7910597324371338\n",
      "Finished epoch 471, latest loss 0.7905769348144531\n",
      "Finished epoch 472, latest loss 0.7905181050300598\n",
      "Finished epoch 473, latest loss 0.7904088497161865\n",
      "Finished epoch 474, latest loss 0.790378987789154\n",
      "Finished epoch 475, latest loss 0.7905808687210083\n",
      "Finished epoch 476, latest loss 0.7928014993667603\n",
      "Finished epoch 477, latest loss 0.7974535226821899\n",
      "Finished epoch 478, latest loss 0.7946828007698059\n",
      "Finished epoch 479, latest loss 0.7905916571617126\n",
      "Finished epoch 480, latest loss 0.7928748726844788\n",
      "Finished epoch 481, latest loss 0.7916601896286011\n",
      "Finished epoch 482, latest loss 0.7894492745399475\n",
      "Finished epoch 483, latest loss 0.7925516963005066\n",
      "Finished epoch 484, latest loss 0.7920815944671631\n",
      "Finished epoch 485, latest loss 0.7949919700622559\n",
      "Finished epoch 486, latest loss 0.7940024137496948\n",
      "Finished epoch 487, latest loss 0.7900428771972656\n",
      "Finished epoch 488, latest loss 0.7953956127166748\n",
      "Finished epoch 489, latest loss 0.7956595420837402\n",
      "Finished epoch 490, latest loss 0.7904900908470154\n",
      "Finished epoch 491, latest loss 0.7899752855300903\n",
      "Finished epoch 492, latest loss 0.7927083373069763\n",
      "Finished epoch 493, latest loss 0.7896769046783447\n",
      "Finished epoch 494, latest loss 0.7940629720687866\n",
      "Finished epoch 495, latest loss 0.7918434143066406\n",
      "Finished epoch 496, latest loss 0.7887254953384399\n",
      "Finished epoch 497, latest loss 0.790134847164154\n",
      "Finished epoch 498, latest loss 0.7936520576477051\n",
      "Finished epoch 499, latest loss 0.7951782941818237\n",
      "Finished epoch 500, latest loss 0.7900371551513672\n",
      "Finished epoch 501, latest loss 0.7930256724357605\n",
      "Finished epoch 502, latest loss 0.7920834422111511\n",
      "Finished epoch 503, latest loss 0.7937732934951782\n",
      "Finished epoch 504, latest loss 0.7922130227088928\n",
      "Finished epoch 505, latest loss 0.7907298803329468\n",
      "Finished epoch 506, latest loss 0.7893080711364746\n",
      "Finished epoch 507, latest loss 0.7908250689506531\n",
      "Finished epoch 508, latest loss 0.7921988368034363\n",
      "Finished epoch 509, latest loss 0.7936305403709412\n",
      "Finished epoch 510, latest loss 0.7915952205657959\n",
      "Finished epoch 511, latest loss 0.789465606212616\n",
      "Finished epoch 512, latest loss 0.7900504469871521\n",
      "Finished epoch 513, latest loss 0.7920958995819092\n",
      "Finished epoch 514, latest loss 0.7916502952575684\n",
      "Finished epoch 515, latest loss 0.7954355478286743\n",
      "Finished epoch 516, latest loss 0.7916654348373413\n",
      "Finished epoch 517, latest loss 0.7916476726531982\n",
      "Finished epoch 518, latest loss 0.7907112836837769\n",
      "Finished epoch 519, latest loss 0.7898423075675964\n",
      "Finished epoch 520, latest loss 0.7939246296882629\n",
      "Finished epoch 521, latest loss 0.7917511463165283\n",
      "Finished epoch 522, latest loss 0.7924169898033142\n",
      "Finished epoch 523, latest loss 0.7930960655212402\n",
      "Finished epoch 524, latest loss 0.7905204892158508\n",
      "Finished epoch 525, latest loss 0.7920605540275574\n",
      "Finished epoch 526, latest loss 0.7923380732536316\n",
      "Finished epoch 527, latest loss 0.7925826907157898\n",
      "Finished epoch 528, latest loss 0.7924461364746094\n",
      "Finished epoch 529, latest loss 0.7932102680206299\n",
      "Finished epoch 530, latest loss 0.7903810739517212\n",
      "Finished epoch 531, latest loss 0.7892742156982422\n",
      "Finished epoch 532, latest loss 0.7903512120246887\n",
      "Finished epoch 533, latest loss 0.7922607660293579\n",
      "Finished epoch 534, latest loss 0.7894489169120789\n",
      "Finished epoch 535, latest loss 0.7906973958015442\n",
      "Finished epoch 536, latest loss 0.7914368510246277\n",
      "Finished epoch 537, latest loss 0.7921940684318542\n",
      "Finished epoch 538, latest loss 0.7914595603942871\n",
      "Finished epoch 539, latest loss 0.7899155020713806\n",
      "Finished epoch 540, latest loss 0.791968584060669\n",
      "Finished epoch 541, latest loss 0.7919942736625671\n",
      "Finished epoch 542, latest loss 0.7904995679855347\n",
      "Finished epoch 543, latest loss 0.7933012843132019\n",
      "Finished epoch 544, latest loss 0.7926000356674194\n",
      "Finished epoch 545, latest loss 0.7920628786087036\n",
      "Finished epoch 546, latest loss 0.7877357006072998\n",
      "Saved improved model\n",
      "Finished epoch 547, latest loss 0.7902182340621948\n",
      "Finished epoch 548, latest loss 0.7951403856277466\n",
      "Finished epoch 549, latest loss 0.7899941802024841\n",
      "Finished epoch 550, latest loss 0.7912523746490479\n",
      "Finished epoch 551, latest loss 0.7918765544891357\n",
      "Finished epoch 552, latest loss 0.7894997000694275\n",
      "Finished epoch 553, latest loss 0.7890834212303162\n",
      "Finished epoch 554, latest loss 0.7894589304924011\n",
      "Finished epoch 555, latest loss 0.7926968336105347\n",
      "Finished epoch 556, latest loss 0.7922917604446411\n",
      "Finished epoch 557, latest loss 0.7886398434638977\n",
      "Finished epoch 558, latest loss 0.7910786867141724\n",
      "Finished epoch 559, latest loss 0.7893468737602234\n",
      "Finished epoch 560, latest loss 0.7891718745231628\n",
      "Finished epoch 561, latest loss 0.7909985184669495\n",
      "Finished epoch 562, latest loss 0.7885953187942505\n",
      "Finished epoch 563, latest loss 0.7900699973106384\n",
      "Finished epoch 564, latest loss 0.7947059869766235\n",
      "Finished epoch 565, latest loss 0.7929019927978516\n",
      "Finished epoch 566, latest loss 0.7906661629676819\n",
      "Finished epoch 567, latest loss 0.7871341705322266\n",
      "Saved improved model\n",
      "Finished epoch 568, latest loss 0.7844309210777283\n",
      "Saved improved model\n",
      "Finished epoch 569, latest loss 0.7904599905014038\n",
      "Finished epoch 570, latest loss 0.7873340249061584\n",
      "Finished epoch 571, latest loss 0.7888696193695068\n",
      "Finished epoch 572, latest loss 0.7897399663925171\n",
      "Finished epoch 573, latest loss 0.789189338684082\n",
      "Finished epoch 574, latest loss 0.7885026335716248\n",
      "Finished epoch 575, latest loss 0.7896968722343445\n",
      "Finished epoch 576, latest loss 0.7874251008033752\n",
      "Finished epoch 577, latest loss 0.790143609046936\n",
      "Finished epoch 578, latest loss 0.788747251033783\n",
      "Finished epoch 579, latest loss 0.7899304032325745\n",
      "Finished epoch 580, latest loss 0.7866824865341187\n",
      "Finished epoch 581, latest loss 0.7900195717811584\n",
      "Finished epoch 582, latest loss 0.7934566140174866\n",
      "Finished epoch 583, latest loss 0.7867522835731506\n",
      "Finished epoch 584, latest loss 0.7901621460914612\n",
      "Finished epoch 585, latest loss 0.7876003384590149\n",
      "Finished epoch 586, latest loss 0.7892504930496216\n",
      "Finished epoch 587, latest loss 0.7895233035087585\n",
      "Finished epoch 588, latest loss 0.7900395393371582\n",
      "Finished epoch 589, latest loss 0.7901641130447388\n",
      "Finished epoch 590, latest loss 0.7881855964660645\n",
      "Finished epoch 591, latest loss 0.7900314331054688\n",
      "Finished epoch 592, latest loss 0.7897971272468567\n",
      "Finished epoch 593, latest loss 0.7861870527267456\n",
      "Finished epoch 594, latest loss 0.7902719974517822\n",
      "Finished epoch 595, latest loss 0.7880774140357971\n",
      "Finished epoch 596, latest loss 0.7882972359657288\n",
      "Finished epoch 597, latest loss 0.7901387214660645\n",
      "Finished epoch 598, latest loss 0.7876590490341187\n",
      "Finished epoch 599, latest loss 0.7899546027183533\n",
      "Finished epoch 600, latest loss 0.7862224578857422\n",
      "Finished epoch 601, latest loss 0.7865476012229919\n",
      "Finished epoch 602, latest loss 0.787451982498169\n",
      "Finished epoch 603, latest loss 0.7853378653526306\n",
      "Finished epoch 604, latest loss 0.7888466119766235\n",
      "Finished epoch 605, latest loss 0.7938010096549988\n",
      "Finished epoch 606, latest loss 0.7871090173721313\n",
      "Finished epoch 607, latest loss 0.7881169319152832\n",
      "Finished epoch 608, latest loss 0.7893676161766052\n",
      "Finished epoch 609, latest loss 0.7897915840148926\n",
      "Finished epoch 610, latest loss 0.7887519001960754\n",
      "Finished epoch 611, latest loss 0.7892555594444275\n",
      "Finished epoch 612, latest loss 0.7897012233734131\n",
      "Finished epoch 613, latest loss 0.7861416339874268\n",
      "Finished epoch 614, latest loss 0.7883986234664917\n",
      "Finished epoch 615, latest loss 0.7869386076927185\n",
      "Finished epoch 616, latest loss 0.7881714105606079\n",
      "Finished epoch 617, latest loss 0.7879416346549988\n",
      "Finished epoch 618, latest loss 0.7868881225585938\n",
      "Finished epoch 619, latest loss 0.7864544987678528\n",
      "Finished epoch 620, latest loss 0.788445234298706\n",
      "Finished epoch 621, latest loss 0.7869361639022827\n",
      "Finished epoch 622, latest loss 0.786570131778717\n",
      "Finished epoch 623, latest loss 0.7854717373847961\n",
      "Finished epoch 624, latest loss 0.7877798080444336\n",
      "Finished epoch 625, latest loss 0.7881479859352112\n",
      "Finished epoch 626, latest loss 0.7852632403373718\n",
      "Finished epoch 627, latest loss 0.7879641652107239\n",
      "Finished epoch 628, latest loss 0.785685658454895\n",
      "Finished epoch 629, latest loss 0.7871812582015991\n",
      "Finished epoch 630, latest loss 0.7896109819412231\n",
      "Finished epoch 631, latest loss 0.7860748767852783\n",
      "Finished epoch 632, latest loss 0.7847652435302734\n",
      "Finished epoch 633, latest loss 0.7906850576400757\n",
      "Finished epoch 634, latest loss 0.7883853912353516\n",
      "Finished epoch 635, latest loss 0.7872030138969421\n",
      "Finished epoch 636, latest loss 0.7857217788696289\n",
      "Finished epoch 637, latest loss 0.786234438419342\n",
      "Finished epoch 638, latest loss 0.7864948511123657\n",
      "Finished epoch 639, latest loss 0.7874518632888794\n",
      "Finished epoch 640, latest loss 0.7915533781051636\n",
      "Finished epoch 641, latest loss 0.7865396738052368\n",
      "Finished epoch 642, latest loss 0.7900172472000122\n",
      "Finished epoch 643, latest loss 0.7914154529571533\n",
      "Finished epoch 644, latest loss 0.7880648970603943\n",
      "Finished epoch 645, latest loss 0.7863312363624573\n",
      "Finished epoch 646, latest loss 0.7849276661872864\n",
      "Finished epoch 647, latest loss 0.7921380400657654\n",
      "Finished epoch 648, latest loss 0.7913181781768799\n",
      "Finished epoch 649, latest loss 0.7921719551086426\n",
      "Finished epoch 650, latest loss 0.7842251062393188\n",
      "Saved improved model\n",
      "Finished epoch 651, latest loss 0.7921087145805359\n",
      "Finished epoch 652, latest loss 0.7851132154464722\n",
      "Finished epoch 653, latest loss 0.7881708145141602\n",
      "Finished epoch 654, latest loss 0.7858299612998962\n",
      "Finished epoch 655, latest loss 0.78750079870224\n",
      "Finished epoch 656, latest loss 0.7855716943740845\n",
      "Finished epoch 657, latest loss 0.7856597900390625\n",
      "Finished epoch 658, latest loss 0.7848348021507263\n",
      "Finished epoch 659, latest loss 0.788038432598114\n",
      "Finished epoch 660, latest loss 0.7907166481018066\n",
      "Finished epoch 661, latest loss 0.7878249883651733\n",
      "Finished epoch 662, latest loss 0.7872292399406433\n",
      "Finished epoch 663, latest loss 0.7846079468727112\n",
      "Finished epoch 664, latest loss 0.7872750759124756\n",
      "Finished epoch 665, latest loss 0.7858423590660095\n",
      "Finished epoch 666, latest loss 0.784756064414978\n",
      "Finished epoch 667, latest loss 0.7929344177246094\n",
      "Finished epoch 668, latest loss 0.7869837880134583\n",
      "Finished epoch 669, latest loss 0.7827935814857483\n",
      "Saved improved model\n",
      "Finished epoch 670, latest loss 0.7867979407310486\n",
      "Finished epoch 671, latest loss 0.7853640913963318\n",
      "Finished epoch 672, latest loss 0.7843257784843445\n",
      "Finished epoch 673, latest loss 0.7889633178710938\n",
      "Finished epoch 674, latest loss 0.786769449710846\n",
      "Finished epoch 675, latest loss 0.7886401414871216\n",
      "Finished epoch 676, latest loss 0.7855621576309204\n",
      "Finished epoch 677, latest loss 0.786891520023346\n",
      "Finished epoch 678, latest loss 0.7864776849746704\n",
      "Finished epoch 679, latest loss 0.7835551500320435\n",
      "Finished epoch 680, latest loss 0.7891984581947327\n",
      "Finished epoch 681, latest loss 0.7868903279304504\n",
      "Finished epoch 682, latest loss 0.7854472994804382\n",
      "Finished epoch 683, latest loss 0.7850217819213867\n",
      "Finished epoch 684, latest loss 0.783988893032074\n",
      "Finished epoch 685, latest loss 0.7849944233894348\n",
      "Finished epoch 686, latest loss 0.7855810523033142\n",
      "Finished epoch 687, latest loss 0.784230649471283\n",
      "Finished epoch 688, latest loss 0.7827218770980835\n",
      "Saved improved model\n",
      "Finished epoch 689, latest loss 0.7860947251319885\n",
      "Finished epoch 690, latest loss 0.7841666340827942\n",
      "Finished epoch 691, latest loss 0.7827348709106445\n",
      "Finished epoch 692, latest loss 0.7878862023353577\n",
      "Finished epoch 693, latest loss 0.7818287014961243\n",
      "Saved improved model\n",
      "Finished epoch 694, latest loss 0.784745991230011\n",
      "Finished epoch 695, latest loss 0.7861678004264832\n",
      "Finished epoch 696, latest loss 0.7866742014884949\n",
      "Finished epoch 697, latest loss 0.7843652963638306\n",
      "Finished epoch 698, latest loss 0.7840022444725037\n",
      "Finished epoch 699, latest loss 0.7852849960327148\n",
      "Finished epoch 700, latest loss 0.7898169159889221\n",
      "Finished epoch 701, latest loss 0.7829102277755737\n",
      "Finished epoch 702, latest loss 0.7837830185890198\n",
      "Finished epoch 703, latest loss 0.7869595289230347\n",
      "Finished epoch 704, latest loss 0.7841516733169556\n",
      "Finished epoch 705, latest loss 0.7843833565711975\n",
      "Finished epoch 706, latest loss 0.7830615043640137\n",
      "Finished epoch 707, latest loss 0.7825601100921631\n",
      "Finished epoch 708, latest loss 0.7874842882156372\n",
      "Finished epoch 709, latest loss 0.7885385155677795\n",
      "Finished epoch 710, latest loss 0.7858151197433472\n",
      "Finished epoch 711, latest loss 0.7842339277267456\n",
      "Finished epoch 712, latest loss 0.7847673892974854\n",
      "Finished epoch 713, latest loss 0.785588800907135\n",
      "Finished epoch 714, latest loss 0.7851002216339111\n",
      "Finished epoch 715, latest loss 0.7864912748336792\n",
      "Finished epoch 716, latest loss 0.7852628231048584\n",
      "Finished epoch 717, latest loss 0.7890840172767639\n",
      "Finished epoch 718, latest loss 0.7847148180007935\n",
      "Finished epoch 719, latest loss 0.7838882207870483\n",
      "Finished epoch 720, latest loss 0.7859411239624023\n",
      "Finished epoch 721, latest loss 0.7884518504142761\n",
      "Finished epoch 722, latest loss 0.784365177154541\n",
      "Finished epoch 723, latest loss 0.7853509187698364\n",
      "Finished epoch 724, latest loss 0.7822266221046448\n",
      "Finished epoch 725, latest loss 0.7888357639312744\n",
      "Finished epoch 726, latest loss 0.7859423756599426\n",
      "Finished epoch 727, latest loss 0.7874388694763184\n",
      "Finished epoch 728, latest loss 0.7859798073768616\n",
      "Finished epoch 729, latest loss 0.7843136191368103\n",
      "Finished epoch 730, latest loss 0.7858126163482666\n",
      "Finished epoch 731, latest loss 0.7868683934211731\n",
      "Finished epoch 732, latest loss 0.7872438430786133\n",
      "Finished epoch 733, latest loss 0.7883827090263367\n",
      "Finished epoch 734, latest loss 0.784805417060852\n",
      "Finished epoch 735, latest loss 0.7918353080749512\n",
      "Finished epoch 736, latest loss 0.7832679748535156\n",
      "Finished epoch 737, latest loss 0.7855054140090942\n",
      "Finished epoch 738, latest loss 0.7849946022033691\n",
      "Finished epoch 739, latest loss 0.782373309135437\n",
      "Finished epoch 740, latest loss 0.7882696986198425\n",
      "Finished epoch 741, latest loss 0.7851497530937195\n",
      "Finished epoch 742, latest loss 0.7845061421394348\n",
      "Finished epoch 743, latest loss 0.7840189337730408\n",
      "Finished epoch 744, latest loss 0.7825442552566528\n",
      "Finished epoch 745, latest loss 0.7835875749588013\n",
      "Finished epoch 746, latest loss 0.7834774851799011\n",
      "Finished epoch 747, latest loss 0.7824779152870178\n",
      "Finished epoch 748, latest loss 0.7842536568641663\n",
      "Finished epoch 749, latest loss 0.7822267413139343\n",
      "Finished epoch 750, latest loss 0.7843204736709595\n",
      "Finished epoch 751, latest loss 0.78387850522995\n",
      "Finished epoch 752, latest loss 0.7853703498840332\n",
      "Finished epoch 753, latest loss 0.7841386198997498\n",
      "Finished epoch 754, latest loss 0.7831311225891113\n",
      "Finished epoch 755, latest loss 0.7850975394248962\n",
      "Finished epoch 756, latest loss 0.7822513580322266\n",
      "Finished epoch 757, latest loss 0.7857691645622253\n",
      "Finished epoch 758, latest loss 0.7884376645088196\n",
      "Finished epoch 759, latest loss 0.7862905263900757\n",
      "Finished epoch 760, latest loss 0.784559965133667\n",
      "Finished epoch 761, latest loss 0.7846645712852478\n",
      "Finished epoch 762, latest loss 0.7861944437026978\n",
      "Finished epoch 763, latest loss 0.7858104705810547\n",
      "Finished epoch 764, latest loss 0.7838155031204224\n",
      "Finished epoch 765, latest loss 0.7854587435722351\n",
      "Finished epoch 766, latest loss 0.7842251062393188\n",
      "Finished epoch 767, latest loss 0.7853637933731079\n",
      "Finished epoch 768, latest loss 0.7829939723014832\n",
      "Finished epoch 769, latest loss 0.7836588621139526\n",
      "Finished epoch 770, latest loss 0.7851845026016235\n",
      "Finished epoch 771, latest loss 0.7840056419372559\n",
      "Finished epoch 772, latest loss 0.783826470375061\n",
      "Finished epoch 773, latest loss 0.7841992974281311\n",
      "Finished epoch 774, latest loss 0.789316713809967\n",
      "Finished epoch 775, latest loss 0.7889848947525024\n",
      "Finished epoch 776, latest loss 0.7872992753982544\n",
      "Finished epoch 777, latest loss 0.7837934494018555\n",
      "Finished epoch 778, latest loss 0.7842347621917725\n",
      "Finished epoch 779, latest loss 0.785605251789093\n",
      "Finished epoch 780, latest loss 0.7836887836456299\n",
      "Finished epoch 781, latest loss 0.7855620384216309\n",
      "Finished epoch 782, latest loss 0.7844712138175964\n",
      "Finished epoch 783, latest loss 0.7849510312080383\n",
      "Finished epoch 784, latest loss 0.7815776467323303\n",
      "Saved improved model\n",
      "Finished epoch 785, latest loss 0.7835516929626465\n",
      "Finished epoch 786, latest loss 0.7835466265678406\n",
      "Finished epoch 787, latest loss 0.7864234447479248\n",
      "Finished epoch 788, latest loss 0.7838735580444336\n",
      "Finished epoch 789, latest loss 0.7845928072929382\n",
      "Finished epoch 790, latest loss 0.7851859331130981\n",
      "Finished epoch 791, latest loss 0.7884453535079956\n",
      "Finished epoch 792, latest loss 0.7855870127677917\n",
      "Finished epoch 793, latest loss 0.7841489315032959\n",
      "Finished epoch 794, latest loss 0.7838160395622253\n",
      "Finished epoch 795, latest loss 0.7844682931900024\n",
      "Finished epoch 796, latest loss 0.7866155505180359\n",
      "Finished epoch 797, latest loss 0.7884503602981567\n",
      "Finished epoch 798, latest loss 0.7858791351318359\n",
      "Finished epoch 799, latest loss 0.783033549785614\n",
      "Finished epoch 800, latest loss 0.7827085852622986\n",
      "Finished epoch 801, latest loss 0.7856600880622864\n",
      "Finished epoch 802, latest loss 0.7834773063659668\n",
      "Finished epoch 803, latest loss 0.7822579741477966\n",
      "Finished epoch 804, latest loss 0.783391535282135\n",
      "Finished epoch 805, latest loss 0.78351229429245\n",
      "Finished epoch 806, latest loss 0.7852808833122253\n",
      "Finished epoch 807, latest loss 0.7829890251159668\n",
      "Finished epoch 808, latest loss 0.7838977575302124\n",
      "Finished epoch 809, latest loss 0.787212610244751\n",
      "Finished epoch 810, latest loss 0.7844918370246887\n",
      "Finished epoch 811, latest loss 0.7843369841575623\n",
      "Finished epoch 812, latest loss 0.7895543575286865\n",
      "Finished epoch 813, latest loss 0.78819340467453\n",
      "Finished epoch 814, latest loss 0.7864919900894165\n",
      "Finished epoch 815, latest loss 0.7842793464660645\n",
      "Finished epoch 816, latest loss 0.7884303331375122\n",
      "Finished epoch 817, latest loss 0.7835410833358765\n",
      "Finished epoch 818, latest loss 0.7856106758117676\n",
      "Finished epoch 819, latest loss 0.7838149666786194\n",
      "Finished epoch 820, latest loss 0.7853596210479736\n",
      "Finished epoch 821, latest loss 0.7858163714408875\n",
      "Finished epoch 822, latest loss 0.7888858318328857\n",
      "Finished epoch 823, latest loss 0.7854486107826233\n",
      "Finished epoch 824, latest loss 0.7870635986328125\n",
      "Finished epoch 825, latest loss 0.7821147441864014\n",
      "Finished epoch 826, latest loss 0.7843022346496582\n",
      "Finished epoch 827, latest loss 0.7841811776161194\n",
      "Finished epoch 828, latest loss 0.7830609083175659\n",
      "Finished epoch 829, latest loss 0.7833157777786255\n",
      "Finished epoch 830, latest loss 0.786328136920929\n",
      "Finished epoch 831, latest loss 0.7844001054763794\n",
      "Finished epoch 832, latest loss 0.786968469619751\n",
      "Finished epoch 833, latest loss 0.7819541692733765\n",
      "Finished epoch 834, latest loss 0.7838081121444702\n",
      "Finished epoch 835, latest loss 0.7872214317321777\n",
      "Finished epoch 836, latest loss 0.7833763360977173\n",
      "Finished epoch 837, latest loss 0.7880937457084656\n",
      "Finished epoch 838, latest loss 0.7827637791633606\n",
      "Finished epoch 839, latest loss 0.7870296239852905\n",
      "Finished epoch 840, latest loss 0.783890426158905\n",
      "Finished epoch 841, latest loss 0.7820979356765747\n",
      "Finished epoch 842, latest loss 0.7854845523834229\n",
      "Finished epoch 843, latest loss 0.7840840816497803\n",
      "Finished epoch 844, latest loss 0.7827946543693542\n",
      "Finished epoch 845, latest loss 0.7861020565032959\n",
      "Finished epoch 846, latest loss 0.7836673855781555\n",
      "Finished epoch 847, latest loss 0.785270094871521\n",
      "Finished epoch 848, latest loss 0.7854198217391968\n",
      "Finished epoch 849, latest loss 0.7838638424873352\n",
      "Finished epoch 850, latest loss 0.7836268544197083\n",
      "Finished epoch 851, latest loss 0.7887340784072876\n",
      "Finished epoch 852, latest loss 0.7830837368965149\n",
      "Finished epoch 853, latest loss 0.7824403643608093\n",
      "Finished epoch 854, latest loss 0.7851136922836304\n",
      "Finished epoch 855, latest loss 0.7856810092926025\n",
      "Finished epoch 856, latest loss 0.7867752313613892\n",
      "Finished epoch 857, latest loss 0.7857812643051147\n",
      "Finished epoch 858, latest loss 0.7849020957946777\n",
      "Finished epoch 859, latest loss 0.7855408787727356\n",
      "Finished epoch 860, latest loss 0.7853378057479858\n",
      "Finished epoch 861, latest loss 0.7862707376480103\n",
      "Finished epoch 862, latest loss 0.7832077145576477\n",
      "Finished epoch 863, latest loss 0.7848118543624878\n",
      "Finished epoch 864, latest loss 0.7882716059684753\n",
      "Finished epoch 865, latest loss 0.788317859172821\n",
      "Finished epoch 866, latest loss 0.7831900119781494\n",
      "Finished epoch 867, latest loss 0.7836569547653198\n",
      "Finished epoch 868, latest loss 0.7880390286445618\n",
      "Finished epoch 869, latest loss 0.7909114956855774\n",
      "Finished epoch 870, latest loss 0.7843989133834839\n",
      "Finished epoch 871, latest loss 0.7817922830581665\n",
      "Finished epoch 872, latest loss 0.7844486236572266\n",
      "Finished epoch 873, latest loss 0.7855106592178345\n",
      "Finished epoch 874, latest loss 0.7823715209960938\n",
      "Finished epoch 875, latest loss 0.784662127494812\n",
      "Finished epoch 876, latest loss 0.7808982729911804\n",
      "Saved improved model\n",
      "Finished epoch 877, latest loss 0.7849330306053162\n",
      "Finished epoch 878, latest loss 0.7850075960159302\n",
      "Finished epoch 879, latest loss 0.785784125328064\n",
      "Finished epoch 880, latest loss 0.7830299735069275\n",
      "Finished epoch 881, latest loss 0.7838745713233948\n",
      "Finished epoch 882, latest loss 0.78670734167099\n",
      "Finished epoch 883, latest loss 0.7828056812286377\n",
      "Finished epoch 884, latest loss 0.7827203869819641\n",
      "Finished epoch 885, latest loss 0.7855955362319946\n",
      "Finished epoch 886, latest loss 0.7808870673179626\n",
      "Saved improved model\n",
      "Finished epoch 887, latest loss 0.782293975353241\n",
      "Finished epoch 888, latest loss 0.7830691337585449\n",
      "Finished epoch 889, latest loss 0.7872077226638794\n",
      "Finished epoch 890, latest loss 0.7833223938941956\n",
      "Finished epoch 891, latest loss 0.7857031226158142\n",
      "Finished epoch 892, latest loss 0.7826955914497375\n",
      "Finished epoch 893, latest loss 0.7834938168525696\n",
      "Finished epoch 894, latest loss 0.7857889533042908\n",
      "Finished epoch 895, latest loss 0.785611093044281\n",
      "Finished epoch 896, latest loss 0.7840296626091003\n",
      "Finished epoch 897, latest loss 0.7869949340820312\n",
      "Finished epoch 898, latest loss 0.7807475328445435\n",
      "Saved improved model\n",
      "Finished epoch 899, latest loss 0.7861042022705078\n",
      "Finished epoch 900, latest loss 0.7842557430267334\n",
      "Finished epoch 901, latest loss 0.7829877138137817\n",
      "Finished epoch 902, latest loss 0.7829716205596924\n",
      "Finished epoch 903, latest loss 0.7839905619621277\n",
      "Finished epoch 904, latest loss 0.7843111157417297\n",
      "Finished epoch 905, latest loss 0.7822995781898499\n",
      "Finished epoch 906, latest loss 0.7846420407295227\n",
      "Finished epoch 907, latest loss 0.788447380065918\n",
      "Finished epoch 908, latest loss 0.7864794731140137\n",
      "Finished epoch 909, latest loss 0.7851483225822449\n",
      "Finished epoch 910, latest loss 0.7852098941802979\n",
      "Finished epoch 911, latest loss 0.7853769659996033\n",
      "Finished epoch 912, latest loss 0.7899444699287415\n",
      "Finished epoch 913, latest loss 0.7835653424263\n",
      "Finished epoch 914, latest loss 0.7856883406639099\n",
      "Finished epoch 915, latest loss 0.7848533391952515\n",
      "Finished epoch 916, latest loss 0.7848218679428101\n",
      "Finished epoch 917, latest loss 0.7845393419265747\n",
      "Finished epoch 918, latest loss 0.785374641418457\n",
      "Finished epoch 919, latest loss 0.7830600738525391\n",
      "Finished epoch 920, latest loss 0.7846845388412476\n",
      "Finished epoch 921, latest loss 0.785719096660614\n",
      "Finished epoch 922, latest loss 0.7845935821533203\n",
      "Finished epoch 923, latest loss 0.7842315435409546\n",
      "Finished epoch 924, latest loss 0.787956714630127\n",
      "Finished epoch 925, latest loss 0.7829724550247192\n",
      "Finished epoch 926, latest loss 0.7839920520782471\n",
      "Finished epoch 927, latest loss 0.7828678488731384\n",
      "Finished epoch 928, latest loss 0.7835454344749451\n",
      "Finished epoch 929, latest loss 0.7855353355407715\n",
      "Finished epoch 930, latest loss 0.7883220911026001\n",
      "Finished epoch 931, latest loss 0.7845087051391602\n",
      "Finished epoch 932, latest loss 0.7832908630371094\n",
      "Finished epoch 933, latest loss 0.7875683903694153\n",
      "Finished epoch 934, latest loss 0.786899745464325\n",
      "Finished epoch 935, latest loss 0.7906893491744995\n",
      "Finished epoch 936, latest loss 0.7895125150680542\n",
      "Finished epoch 937, latest loss 0.7837120294570923\n",
      "Finished epoch 938, latest loss 0.7860860824584961\n",
      "Finished epoch 939, latest loss 0.7857974171638489\n",
      "Finished epoch 940, latest loss 0.7838929295539856\n",
      "Finished epoch 941, latest loss 0.7858543395996094\n",
      "Finished epoch 942, latest loss 0.7859310507774353\n",
      "Finished epoch 943, latest loss 0.7880457639694214\n",
      "Finished epoch 944, latest loss 0.7862914800643921\n",
      "Finished epoch 945, latest loss 0.7828648090362549\n",
      "Finished epoch 946, latest loss 0.7823338508605957\n",
      "Finished epoch 947, latest loss 0.7827074527740479\n",
      "Finished epoch 948, latest loss 0.784071683883667\n",
      "Finished epoch 949, latest loss 0.7846433520317078\n",
      "Finished epoch 950, latest loss 0.7838106751441956\n",
      "Finished epoch 951, latest loss 0.7836628556251526\n",
      "Finished epoch 952, latest loss 0.7863249182701111\n",
      "Finished epoch 953, latest loss 0.7833830118179321\n",
      "Finished epoch 954, latest loss 0.7856576442718506\n",
      "Finished epoch 955, latest loss 0.7825384140014648\n",
      "Finished epoch 956, latest loss 0.7848474383354187\n",
      "Finished epoch 957, latest loss 0.7835545539855957\n",
      "Finished epoch 958, latest loss 0.7829307317733765\n",
      "Finished epoch 959, latest loss 0.7878171801567078\n",
      "Finished epoch 960, latest loss 0.7824671268463135\n",
      "Finished epoch 961, latest loss 0.7863754630088806\n",
      "Finished epoch 962, latest loss 0.7843918204307556\n",
      "Finished epoch 963, latest loss 0.7840890288352966\n",
      "Finished epoch 964, latest loss 0.7815003991127014\n",
      "Finished epoch 965, latest loss 0.7836583852767944\n",
      "Finished epoch 966, latest loss 0.7827306985855103\n",
      "Finished epoch 967, latest loss 0.786272406578064\n",
      "Finished epoch 968, latest loss 0.7834288477897644\n",
      "Finished epoch 969, latest loss 0.7820009589195251\n",
      "Finished epoch 970, latest loss 0.7823287844657898\n",
      "Finished epoch 971, latest loss 0.7831311225891113\n",
      "Finished epoch 972, latest loss 0.7836813926696777\n",
      "Finished epoch 973, latest loss 0.7813209295272827\n",
      "Finished epoch 974, latest loss 0.7859804034233093\n",
      "Finished epoch 975, latest loss 0.7893248796463013\n",
      "Finished epoch 976, latest loss 0.7853339910507202\n",
      "Finished epoch 977, latest loss 0.7832684516906738\n",
      "Finished epoch 978, latest loss 0.7846062779426575\n",
      "Finished epoch 979, latest loss 0.7841876149177551\n",
      "Finished epoch 980, latest loss 0.7860431671142578\n",
      "Finished epoch 981, latest loss 0.782731294631958\n",
      "Finished epoch 982, latest loss 0.7839368581771851\n",
      "Finished epoch 983, latest loss 0.7844266891479492\n",
      "Finished epoch 984, latest loss 0.7808129787445068\n",
      "Finished epoch 985, latest loss 0.783404529094696\n",
      "Finished epoch 986, latest loss 0.7831574082374573\n",
      "Finished epoch 987, latest loss 0.7869552969932556\n",
      "Finished epoch 988, latest loss 0.7867439389228821\n",
      "Finished epoch 989, latest loss 0.7839069962501526\n",
      "Finished epoch 990, latest loss 0.7836954593658447\n",
      "Finished epoch 991, latest loss 0.7829485535621643\n",
      "Finished epoch 992, latest loss 0.7839487195014954\n",
      "Finished epoch 993, latest loss 0.7838993072509766\n",
      "Finished epoch 994, latest loss 0.7838998436927795\n",
      "Finished epoch 995, latest loss 0.7822571396827698\n",
      "Finished epoch 996, latest loss 0.7874366044998169\n",
      "Finished epoch 997, latest loss 0.7846911549568176\n",
      "Finished epoch 998, latest loss 0.7906992435455322\n",
      "Finished epoch 999, latest loss 0.7849200963973999\n",
      "Finished epoch 1000, latest loss 0.7831951975822449\n",
      "Finished epoch 1001, latest loss 0.7820908427238464\n",
      "Finished epoch 1002, latest loss 0.7910625338554382\n",
      "Finished epoch 1003, latest loss 0.7887766361236572\n",
      "Finished epoch 1004, latest loss 0.7837476134300232\n",
      "Finished epoch 1005, latest loss 0.7810820937156677\n",
      "Finished epoch 1006, latest loss 0.7842064499855042\n",
      "Finished epoch 1007, latest loss 0.7842162847518921\n",
      "Finished epoch 1008, latest loss 0.7934380769729614\n",
      "Finished epoch 1009, latest loss 0.7838186621665955\n",
      "Finished epoch 1010, latest loss 0.7847144603729248\n",
      "Finished epoch 1011, latest loss 0.7853107452392578\n",
      "Finished epoch 1012, latest loss 0.7849931716918945\n",
      "Finished epoch 1013, latest loss 0.7809982299804688\n",
      "Finished epoch 1014, latest loss 0.7830764651298523\n",
      "Finished epoch 1015, latest loss 0.7809040546417236\n",
      "Finished epoch 1016, latest loss 0.7815259695053101\n",
      "Finished epoch 1017, latest loss 0.7841474413871765\n",
      "Finished epoch 1018, latest loss 0.7815026640892029\n",
      "Finished epoch 1019, latest loss 0.7813758850097656\n",
      "Finished epoch 1020, latest loss 0.7849761247634888\n",
      "Finished epoch 1021, latest loss 0.7819743752479553\n",
      "Finished epoch 1022, latest loss 0.7828462719917297\n",
      "Finished epoch 1023, latest loss 0.7834380269050598\n",
      "Finished epoch 1024, latest loss 0.7832614183425903\n",
      "Finished epoch 1025, latest loss 0.781650960445404\n",
      "Finished epoch 1026, latest loss 0.7807592749595642\n",
      "Finished epoch 1027, latest loss 0.7836987376213074\n",
      "Finished epoch 1028, latest loss 0.781520426273346\n",
      "Finished epoch 1029, latest loss 0.7818578481674194\n",
      "Finished epoch 1030, latest loss 0.784096896648407\n",
      "Finished epoch 1031, latest loss 0.7838098406791687\n",
      "Finished epoch 1032, latest loss 0.782210648059845\n",
      "Finished epoch 1033, latest loss 0.785319447517395\n",
      "Finished epoch 1034, latest loss 0.7866783142089844\n",
      "Finished epoch 1035, latest loss 0.7859944701194763\n",
      "Finished epoch 1036, latest loss 0.7843603491783142\n",
      "Finished epoch 1037, latest loss 0.7895618677139282\n",
      "Finished epoch 1038, latest loss 0.7876760959625244\n",
      "Finished epoch 1039, latest loss 0.7885721325874329\n",
      "Finished epoch 1040, latest loss 0.7845108509063721\n",
      "Finished epoch 1041, latest loss 0.78693026304245\n",
      "Finished epoch 1042, latest loss 0.7871788740158081\n",
      "Finished epoch 1043, latest loss 0.7854406833648682\n",
      "Finished epoch 1044, latest loss 0.7811151146888733\n",
      "Finished epoch 1045, latest loss 0.7894266247749329\n",
      "Finished epoch 1046, latest loss 0.783107340335846\n",
      "Finished epoch 1047, latest loss 0.783953845500946\n",
      "Finished epoch 1048, latest loss 0.7809237837791443\n",
      "Finished epoch 1049, latest loss 0.7824212312698364\n",
      "Finished epoch 1050, latest loss 0.787167489528656\n",
      "Finished epoch 1051, latest loss 0.7835952043533325\n",
      "Finished epoch 1052, latest loss 0.7829687595367432\n",
      "Finished epoch 1053, latest loss 0.7812188863754272\n",
      "Finished epoch 1054, latest loss 0.7833470106124878\n",
      "Finished epoch 1055, latest loss 0.7815945744514465\n",
      "Finished epoch 1056, latest loss 0.7840598821640015\n",
      "Finished epoch 1057, latest loss 0.7826977968215942\n",
      "Finished epoch 1058, latest loss 0.7827571630477905\n",
      "Finished epoch 1059, latest loss 0.7829825282096863\n",
      "Finished epoch 1060, latest loss 0.7828173041343689\n",
      "Finished epoch 1061, latest loss 0.7820501327514648\n",
      "Finished epoch 1062, latest loss 0.7810949087142944\n",
      "Finished epoch 1063, latest loss 0.7810856699943542\n",
      "Finished epoch 1064, latest loss 0.7857751846313477\n",
      "Finished epoch 1065, latest loss 0.7817766666412354\n",
      "Finished epoch 1066, latest loss 0.7838736176490784\n",
      "Finished epoch 1067, latest loss 0.7833096981048584\n",
      "Finished epoch 1068, latest loss 0.7819788455963135\n",
      "Finished epoch 1069, latest loss 0.7850338816642761\n",
      "Finished epoch 1070, latest loss 0.782405436038971\n",
      "Finished epoch 1071, latest loss 0.7822450995445251\n",
      "Finished epoch 1072, latest loss 0.7846624255180359\n",
      "Finished epoch 1073, latest loss 0.785315215587616\n",
      "Finished epoch 1074, latest loss 0.7826640605926514\n",
      "Finished epoch 1075, latest loss 0.783355712890625\n",
      "Finished epoch 1076, latest loss 0.78243488073349\n",
      "Finished epoch 1077, latest loss 0.7836491465568542\n",
      "Finished epoch 1078, latest loss 0.7815879583358765\n",
      "Finished epoch 1079, latest loss 0.7821758985519409\n",
      "Finished epoch 1080, latest loss 0.782023549079895\n",
      "Finished epoch 1081, latest loss 0.7818402051925659\n",
      "Finished epoch 1082, latest loss 0.7838000655174255\n",
      "Finished epoch 1083, latest loss 0.7834205627441406\n",
      "Finished epoch 1084, latest loss 0.7830635905265808\n",
      "Finished epoch 1085, latest loss 0.7845176458358765\n",
      "Finished epoch 1086, latest loss 0.7841055989265442\n",
      "Finished epoch 1087, latest loss 0.782640278339386\n",
      "Finished epoch 1088, latest loss 0.7838163375854492\n",
      "Finished epoch 1089, latest loss 0.7824540734291077\n",
      "Finished epoch 1090, latest loss 0.7840315103530884\n",
      "Finished epoch 1091, latest loss 0.7817553877830505\n",
      "Finished epoch 1092, latest loss 0.7818608283996582\n",
      "Finished epoch 1093, latest loss 0.7801188826560974\n",
      "Saved improved model\n",
      "Finished epoch 1094, latest loss 0.781056821346283\n",
      "Finished epoch 1095, latest loss 0.7818998098373413\n",
      "Finished epoch 1096, latest loss 0.7841445803642273\n",
      "Finished epoch 1097, latest loss 0.7812619805335999\n",
      "Finished epoch 1098, latest loss 0.7855363488197327\n",
      "Finished epoch 1099, latest loss 0.7826153635978699\n",
      "Finished epoch 1100, latest loss 0.7865254282951355\n",
      "Finished epoch 1101, latest loss 0.783008873462677\n",
      "Finished epoch 1102, latest loss 0.7857783436775208\n",
      "Finished epoch 1103, latest loss 0.7845388054847717\n",
      "Finished epoch 1104, latest loss 0.7829718589782715\n",
      "Finished epoch 1105, latest loss 0.7834484577178955\n",
      "Finished epoch 1106, latest loss 0.7830835580825806\n",
      "Finished epoch 1107, latest loss 0.7816963195800781\n",
      "Finished epoch 1108, latest loss 0.7805595993995667\n",
      "Finished epoch 1109, latest loss 0.781722903251648\n",
      "Finished epoch 1110, latest loss 0.7815197706222534\n",
      "Finished epoch 1111, latest loss 0.784130871295929\n",
      "Finished epoch 1112, latest loss 0.7809867262840271\n",
      "Finished epoch 1113, latest loss 0.7805845141410828\n",
      "Finished epoch 1114, latest loss 0.7831532955169678\n",
      "Finished epoch 1115, latest loss 0.7830010652542114\n",
      "Finished epoch 1116, latest loss 0.7819071412086487\n",
      "Finished epoch 1117, latest loss 0.7808778882026672\n",
      "Finished epoch 1118, latest loss 0.7803424596786499\n",
      "Finished epoch 1119, latest loss 0.7809262275695801\n",
      "Finished epoch 1120, latest loss 0.7830249071121216\n",
      "Finished epoch 1121, latest loss 0.7845264673233032\n",
      "Finished epoch 1122, latest loss 0.783322811126709\n",
      "Finished epoch 1123, latest loss 0.7848874926567078\n",
      "Finished epoch 1124, latest loss 0.7857884764671326\n",
      "Finished epoch 1125, latest loss 0.7896094918251038\n",
      "Finished epoch 1126, latest loss 0.7843625545501709\n",
      "Finished epoch 1127, latest loss 0.7822704911231995\n",
      "Finished epoch 1128, latest loss 0.7818275094032288\n",
      "Finished epoch 1129, latest loss 0.7875012755393982\n",
      "Finished epoch 1130, latest loss 0.7820776104927063\n",
      "Finished epoch 1131, latest loss 0.786050021648407\n",
      "Finished epoch 1132, latest loss 0.784313440322876\n",
      "Finished epoch 1133, latest loss 0.7843600511550903\n",
      "Finished epoch 1134, latest loss 0.7825900316238403\n",
      "Finished epoch 1135, latest loss 0.7856905460357666\n",
      "Finished epoch 1136, latest loss 0.7856259942054749\n",
      "Finished epoch 1137, latest loss 0.7832234501838684\n",
      "Finished epoch 1138, latest loss 0.7838317155838013\n",
      "Finished epoch 1139, latest loss 0.783078134059906\n",
      "Finished epoch 1140, latest loss 0.7855774760246277\n",
      "Finished epoch 1141, latest loss 0.7828522324562073\n",
      "Finished epoch 1142, latest loss 0.7821572422981262\n",
      "Finished epoch 1143, latest loss 0.7841778993606567\n",
      "Finished epoch 1144, latest loss 0.7887495160102844\n",
      "Finished epoch 1145, latest loss 0.7843323945999146\n",
      "Finished epoch 1146, latest loss 0.7838515639305115\n",
      "Finished epoch 1147, latest loss 0.7827341556549072\n",
      "Finished epoch 1148, latest loss 0.7818964719772339\n",
      "Finished epoch 1149, latest loss 0.7826741933822632\n",
      "Finished epoch 1150, latest loss 0.7812275886535645\n",
      "Finished epoch 1151, latest loss 0.7808754444122314\n",
      "Finished epoch 1152, latest loss 0.7889737486839294\n",
      "Finished epoch 1153, latest loss 0.7841018438339233\n",
      "Finished epoch 1154, latest loss 0.7834925651550293\n",
      "Finished epoch 1155, latest loss 0.7813305258750916\n",
      "Finished epoch 1156, latest loss 0.7853050827980042\n",
      "Finished epoch 1157, latest loss 0.7815695405006409\n",
      "Finished epoch 1158, latest loss 0.7857517004013062\n",
      "Finished epoch 1159, latest loss 0.7833658456802368\n",
      "Finished epoch 1160, latest loss 0.7870537042617798\n",
      "Finished epoch 1161, latest loss 0.7824108004570007\n",
      "Finished epoch 1162, latest loss 0.7837163805961609\n",
      "Finished epoch 1163, latest loss 0.7855382561683655\n",
      "Finished epoch 1164, latest loss 0.7872365117073059\n",
      "Finished epoch 1165, latest loss 0.7822388410568237\n",
      "Finished epoch 1166, latest loss 0.7811582088470459\n",
      "Finished epoch 1167, latest loss 0.7845212817192078\n",
      "Finished epoch 1168, latest loss 0.7810943126678467\n",
      "Finished epoch 1169, latest loss 0.7817662358283997\n",
      "Finished epoch 1170, latest loss 0.78040611743927\n",
      "Finished epoch 1171, latest loss 0.7835938334465027\n",
      "Finished epoch 1172, latest loss 0.7854080200195312\n",
      "Finished epoch 1173, latest loss 0.7863972187042236\n",
      "Finished epoch 1174, latest loss 0.7822153568267822\n",
      "Finished epoch 1175, latest loss 0.782547116279602\n",
      "Finished epoch 1176, latest loss 0.7811133861541748\n",
      "Finished epoch 1177, latest loss 0.7826130986213684\n",
      "Finished epoch 1178, latest loss 0.7816771268844604\n",
      "Finished epoch 1179, latest loss 0.7828428745269775\n",
      "Finished epoch 1180, latest loss 0.7898896336555481\n",
      "Finished epoch 1181, latest loss 0.7833741307258606\n",
      "Finished epoch 1182, latest loss 0.7873479723930359\n",
      "Finished epoch 1183, latest loss 0.782701313495636\n",
      "Finished epoch 1184, latest loss 0.7839855551719666\n",
      "Finished epoch 1185, latest loss 0.7849246859550476\n",
      "Finished epoch 1186, latest loss 0.7847205996513367\n",
      "Finished epoch 1187, latest loss 0.7852761149406433\n",
      "Finished epoch 1188, latest loss 0.7848529815673828\n",
      "Finished epoch 1189, latest loss 0.7821024060249329\n",
      "Finished epoch 1190, latest loss 0.7852122783660889\n",
      "Finished epoch 1191, latest loss 0.781619668006897\n",
      "Finished epoch 1192, latest loss 0.7832330465316772\n",
      "Finished epoch 1193, latest loss 0.781924307346344\n",
      "Finished epoch 1194, latest loss 0.7834793925285339\n",
      "Finished epoch 1195, latest loss 0.781854510307312\n",
      "Finished epoch 1196, latest loss 0.7839312553405762\n",
      "Finished epoch 1197, latest loss 0.7842007875442505\n",
      "Finished epoch 1198, latest loss 0.783947765827179\n",
      "Finished epoch 1199, latest loss 0.7842049598693848\n",
      "Finished epoch 1200, latest loss 0.7834677696228027\n",
      "Finished epoch 1201, latest loss 0.7866079807281494\n",
      "Finished epoch 1202, latest loss 0.7837119102478027\n",
      "Finished epoch 1203, latest loss 0.7830681204795837\n",
      "Finished epoch 1204, latest loss 0.7850928902626038\n",
      "Finished epoch 1205, latest loss 0.7831944823265076\n",
      "Finished epoch 1206, latest loss 0.782123327255249\n",
      "Finished epoch 1207, latest loss 0.7831521034240723\n",
      "Finished epoch 1208, latest loss 0.7852603197097778\n",
      "Finished epoch 1209, latest loss 0.7809320688247681\n",
      "Finished epoch 1210, latest loss 0.7821213603019714\n",
      "Finished epoch 1211, latest loss 0.7847293019294739\n",
      "Finished epoch 1212, latest loss 0.7844558954238892\n",
      "Finished epoch 1213, latest loss 0.7805776596069336\n",
      "Finished epoch 1214, latest loss 0.7825042009353638\n",
      "Finished epoch 1215, latest loss 0.7809988260269165\n",
      "Finished epoch 1216, latest loss 0.7810918688774109\n",
      "Finished epoch 1217, latest loss 0.7847208976745605\n",
      "Finished epoch 1218, latest loss 0.7860628962516785\n",
      "Finished epoch 1219, latest loss 0.7823764085769653\n",
      "Finished epoch 1220, latest loss 0.7885293960571289\n",
      "Finished epoch 1221, latest loss 0.7831627726554871\n",
      "Finished epoch 1222, latest loss 0.783616840839386\n",
      "Finished epoch 1223, latest loss 0.7819121479988098\n",
      "Finished epoch 1224, latest loss 0.7834844589233398\n",
      "Finished epoch 1225, latest loss 0.7813389301300049\n",
      "Finished epoch 1226, latest loss 0.7818084359169006\n",
      "Finished epoch 1227, latest loss 0.7803856134414673\n",
      "Finished epoch 1228, latest loss 0.7819116115570068\n",
      "Finished epoch 1229, latest loss 0.7810983657836914\n",
      "Finished epoch 1230, latest loss 0.7846755981445312\n",
      "Finished epoch 1231, latest loss 0.7805485129356384\n",
      "Finished epoch 1232, latest loss 0.782824695110321\n",
      "Finished epoch 1233, latest loss 0.7826213836669922\n",
      "Finished epoch 1234, latest loss 0.7868792414665222\n",
      "Finished epoch 1235, latest loss 0.7835456728935242\n",
      "Finished epoch 1236, latest loss 0.7845777273178101\n",
      "Finished epoch 1237, latest loss 0.7836182117462158\n",
      "Finished epoch 1238, latest loss 0.7834979295730591\n",
      "Finished epoch 1239, latest loss 0.7843530774116516\n",
      "Finished epoch 1240, latest loss 0.7824950814247131\n",
      "Finished epoch 1241, latest loss 0.7839230298995972\n",
      "Finished epoch 1242, latest loss 0.7845238447189331\n",
      "Finished epoch 1243, latest loss 0.7829506397247314\n",
      "Finished epoch 1244, latest loss 0.7803795337677002\n",
      "Finished epoch 1245, latest loss 0.7862421870231628\n",
      "Finished epoch 1246, latest loss 0.782963752746582\n",
      "Finished epoch 1247, latest loss 0.7847866415977478\n",
      "Finished epoch 1248, latest loss 0.781152069568634\n",
      "Finished epoch 1249, latest loss 0.782662570476532\n",
      "Finished epoch 1250, latest loss 0.7807528376579285\n",
      "Finished epoch 1251, latest loss 0.7830562591552734\n",
      "Finished epoch 1252, latest loss 0.7822946310043335\n",
      "Finished epoch 1253, latest loss 0.7836026549339294\n",
      "Finished epoch 1254, latest loss 0.7819075584411621\n",
      "Finished epoch 1255, latest loss 0.7863736748695374\n",
      "Finished epoch 1256, latest loss 0.7844396829605103\n",
      "Finished epoch 1257, latest loss 0.7834323644638062\n",
      "Finished epoch 1258, latest loss 0.7839139103889465\n",
      "Finished epoch 1259, latest loss 0.7822521328926086\n",
      "Finished epoch 1260, latest loss 0.784652590751648\n",
      "Finished epoch 1261, latest loss 0.7821468114852905\n",
      "Finished epoch 1262, latest loss 0.7864219546318054\n",
      "Finished epoch 1263, latest loss 0.7857313752174377\n",
      "Finished epoch 1264, latest loss 0.7864872217178345\n",
      "Finished epoch 1265, latest loss 0.7849727869033813\n",
      "Finished epoch 1266, latest loss 0.7821673154830933\n",
      "Finished epoch 1267, latest loss 0.785528302192688\n",
      "Finished epoch 1268, latest loss 0.7832566499710083\n",
      "Finished epoch 1269, latest loss 0.7832720279693604\n",
      "Finished epoch 1270, latest loss 0.783490002155304\n",
      "Finished epoch 1271, latest loss 0.7821462154388428\n",
      "Finished epoch 1272, latest loss 0.7819373607635498\n",
      "Finished epoch 1273, latest loss 0.7847371697425842\n",
      "Finished epoch 1274, latest loss 0.7821571230888367\n",
      "Finished epoch 1275, latest loss 0.7840529084205627\n",
      "Finished epoch 1276, latest loss 0.7825033664703369\n",
      "Finished epoch 1277, latest loss 0.7858086824417114\n",
      "Finished epoch 1278, latest loss 0.7848658561706543\n",
      "Finished epoch 1279, latest loss 0.7809253334999084\n",
      "Finished epoch 1280, latest loss 0.782577633857727\n",
      "Finished epoch 1281, latest loss 0.781015932559967\n",
      "Finished epoch 1282, latest loss 0.7816159129142761\n",
      "Finished epoch 1283, latest loss 0.7808287143707275\n",
      "Finished epoch 1284, latest loss 0.7823761105537415\n",
      "Finished epoch 1285, latest loss 0.7811981439590454\n",
      "Finished epoch 1286, latest loss 0.780329167842865\n",
      "Finished epoch 1287, latest loss 0.7833119034767151\n",
      "Finished epoch 1288, latest loss 0.781895637512207\n",
      "Finished epoch 1289, latest loss 0.7807517051696777\n",
      "Finished epoch 1290, latest loss 0.7813982367515564\n",
      "Finished epoch 1291, latest loss 0.780480146408081\n",
      "Finished epoch 1292, latest loss 0.7815720438957214\n",
      "Finished epoch 1293, latest loss 0.7809961438179016\n",
      "Finished epoch 1294, latest loss 0.7818004488945007\n",
      "Finished epoch 1295, latest loss 0.7819613218307495\n",
      "Finished epoch 1296, latest loss 0.7813034057617188\n",
      "Finished epoch 1297, latest loss 0.7817344069480896\n",
      "Finished epoch 1298, latest loss 0.7841277122497559\n",
      "Finished epoch 1299, latest loss 0.7855205535888672\n",
      "Finished epoch 1300, latest loss 0.784921407699585\n",
      "Finished epoch 1301, latest loss 0.782494843006134\n",
      "Finished epoch 1302, latest loss 0.7829933762550354\n",
      "Finished epoch 1303, latest loss 0.7823930382728577\n",
      "Finished epoch 1304, latest loss 0.7880437970161438\n",
      "Finished epoch 1305, latest loss 0.783412516117096\n",
      "Finished epoch 1306, latest loss 0.7814701199531555\n",
      "Finished epoch 1307, latest loss 0.7915366291999817\n",
      "Finished epoch 1308, latest loss 0.78290194272995\n",
      "Finished epoch 1309, latest loss 0.7880383729934692\n",
      "Finished epoch 1310, latest loss 0.7833607792854309\n",
      "Finished epoch 1311, latest loss 0.7814961075782776\n",
      "Finished epoch 1312, latest loss 0.7826685309410095\n",
      "Finished epoch 1313, latest loss 0.7811535000801086\n",
      "Finished epoch 1314, latest loss 0.7814708352088928\n",
      "Finished epoch 1315, latest loss 0.784633457660675\n",
      "Finished epoch 1316, latest loss 0.7873185873031616\n",
      "Finished epoch 1317, latest loss 0.7823963165283203\n",
      "Finished epoch 1318, latest loss 0.7828186750411987\n",
      "Finished epoch 1319, latest loss 0.7836812734603882\n",
      "Finished epoch 1320, latest loss 0.7812350988388062\n",
      "Finished epoch 1321, latest loss 0.7850284576416016\n",
      "Finished epoch 1322, latest loss 0.7823222279548645\n",
      "Finished epoch 1323, latest loss 0.7828053832054138\n",
      "Finished epoch 1324, latest loss 0.7837895750999451\n",
      "Finished epoch 1325, latest loss 0.7823966145515442\n",
      "Finished epoch 1326, latest loss 0.7879626750946045\n",
      "Finished epoch 1327, latest loss 0.7858104109764099\n",
      "Finished epoch 1328, latest loss 0.7803893685340881\n",
      "Finished epoch 1329, latest loss 0.782391369342804\n",
      "Finished epoch 1330, latest loss 0.7816519141197205\n",
      "Finished epoch 1331, latest loss 0.7833526730537415\n",
      "Finished epoch 1332, latest loss 0.7837042808532715\n",
      "Finished epoch 1333, latest loss 0.7862469553947449\n",
      "Finished epoch 1334, latest loss 0.7812169790267944\n",
      "Finished epoch 1335, latest loss 0.7835487127304077\n",
      "Finished epoch 1336, latest loss 0.7832657694816589\n",
      "Finished epoch 1337, latest loss 0.781366229057312\n",
      "Finished epoch 1338, latest loss 0.7840247750282288\n",
      "Finished epoch 1339, latest loss 0.7888002991676331\n",
      "Finished epoch 1340, latest loss 0.7869160771369934\n",
      "Finished epoch 1341, latest loss 0.7856406569480896\n",
      "Finished epoch 1342, latest loss 0.7795722484588623\n",
      "Saved improved model\n",
      "Finished epoch 1343, latest loss 0.7826404571533203\n",
      "Finished epoch 1344, latest loss 0.7807298898696899\n",
      "Finished epoch 1345, latest loss 0.7803366780281067\n",
      "Finished epoch 1346, latest loss 0.7819047570228577\n",
      "Finished epoch 1347, latest loss 0.781055748462677\n",
      "Finished epoch 1348, latest loss 0.7853056788444519\n",
      "Finished epoch 1349, latest loss 0.7860218286514282\n",
      "Finished epoch 1350, latest loss 0.7822343707084656\n",
      "Finished epoch 1351, latest loss 0.7801673412322998\n",
      "Finished epoch 1352, latest loss 0.7810963988304138\n",
      "Finished epoch 1353, latest loss 0.7875754237174988\n",
      "Finished epoch 1354, latest loss 0.7816697359085083\n",
      "Finished epoch 1355, latest loss 0.7817363739013672\n",
      "Finished epoch 1356, latest loss 0.7807225584983826\n",
      "Finished epoch 1357, latest loss 0.7806292176246643\n",
      "Finished epoch 1358, latest loss 0.7814165949821472\n",
      "Finished epoch 1359, latest loss 0.7826946377754211\n",
      "Finished epoch 1360, latest loss 0.8003186583518982\n",
      "Finished epoch 1361, latest loss 0.782507598400116\n",
      "Finished epoch 1362, latest loss 0.7819362878799438\n",
      "Finished epoch 1363, latest loss 0.7845209836959839\n",
      "Finished epoch 1364, latest loss 0.7798753976821899\n",
      "Finished epoch 1365, latest loss 0.7824900150299072\n",
      "Finished epoch 1366, latest loss 0.7896364331245422\n",
      "Finished epoch 1367, latest loss 0.7800219655036926\n",
      "Finished epoch 1368, latest loss 0.7826383709907532\n",
      "Finished epoch 1369, latest loss 0.7820647358894348\n",
      "Finished epoch 1370, latest loss 0.7814104557037354\n",
      "Finished epoch 1371, latest loss 0.7810975313186646\n",
      "Finished epoch 1372, latest loss 0.7828391790390015\n",
      "Finished epoch 1373, latest loss 0.7855502367019653\n",
      "Finished epoch 1374, latest loss 0.7817121744155884\n",
      "Finished epoch 1375, latest loss 0.7840144634246826\n",
      "Finished epoch 1376, latest loss 0.7809290885925293\n",
      "Finished epoch 1377, latest loss 0.7809129357337952\n",
      "Finished epoch 1378, latest loss 0.7834429740905762\n",
      "Finished epoch 1379, latest loss 0.7813736796379089\n",
      "Finished epoch 1380, latest loss 0.7847399711608887\n",
      "Finished epoch 1381, latest loss 0.7826119661331177\n",
      "Finished epoch 1382, latest loss 0.786844789981842\n",
      "Finished epoch 1383, latest loss 0.7803420424461365\n",
      "Finished epoch 1384, latest loss 0.7831189632415771\n",
      "Finished epoch 1385, latest loss 0.7810901403427124\n",
      "Finished epoch 1386, latest loss 0.7826065421104431\n",
      "Finished epoch 1387, latest loss 0.7843601107597351\n",
      "Finished epoch 1388, latest loss 0.7808862924575806\n",
      "Finished epoch 1389, latest loss 0.7822167277336121\n",
      "Finished epoch 1390, latest loss 0.7824260592460632\n",
      "Finished epoch 1391, latest loss 0.7834489345550537\n",
      "Finished epoch 1392, latest loss 0.7815816402435303\n",
      "Finished epoch 1393, latest loss 0.7830661535263062\n",
      "Finished epoch 1394, latest loss 0.7846735119819641\n",
      "Finished epoch 1395, latest loss 0.7816798686981201\n",
      "Finished epoch 1396, latest loss 0.7853886485099792\n",
      "Finished epoch 1397, latest loss 0.7837119102478027\n",
      "Finished epoch 1398, latest loss 0.7841334342956543\n",
      "Finished epoch 1399, latest loss 0.7810884714126587\n",
      "Finished epoch 1400, latest loss 0.7827379703521729\n",
      "Finished epoch 1401, latest loss 0.782995879650116\n",
      "Finished epoch 1402, latest loss 0.7828230857849121\n",
      "Finished epoch 1403, latest loss 0.7920522689819336\n",
      "Finished epoch 1404, latest loss 0.7836216688156128\n",
      "Finished epoch 1405, latest loss 0.781494140625\n",
      "Finished epoch 1406, latest loss 0.7817288637161255\n",
      "Finished epoch 1407, latest loss 0.7826732993125916\n",
      "Finished epoch 1408, latest loss 0.7830638885498047\n",
      "Finished epoch 1409, latest loss 0.7796146869659424\n",
      "Finished epoch 1410, latest loss 0.7810511589050293\n",
      "Finished epoch 1411, latest loss 0.7848710417747498\n",
      "Finished epoch 1412, latest loss 0.7845931053161621\n",
      "Finished epoch 1413, latest loss 0.7869269251823425\n",
      "Finished epoch 1414, latest loss 0.7815136313438416\n",
      "Finished epoch 1415, latest loss 0.7837617993354797\n",
      "Finished epoch 1416, latest loss 0.7822281718254089\n",
      "Finished epoch 1417, latest loss 0.7826549410820007\n",
      "Finished epoch 1418, latest loss 0.7861180901527405\n",
      "Finished epoch 1419, latest loss 0.7847793102264404\n",
      "Finished epoch 1420, latest loss 0.7829380035400391\n",
      "Finished epoch 1421, latest loss 0.7835432887077332\n",
      "Finished epoch 1422, latest loss 0.7804402112960815\n",
      "Finished epoch 1423, latest loss 0.7822456955909729\n",
      "Finished epoch 1424, latest loss 0.7828195691108704\n",
      "Finished epoch 1425, latest loss 0.781395673751831\n",
      "Finished epoch 1426, latest loss 0.7796116471290588\n",
      "Finished epoch 1427, latest loss 0.7828465104103088\n",
      "Finished epoch 1428, latest loss 0.7805269956588745\n",
      "Finished epoch 1429, latest loss 0.7837694883346558\n",
      "Finished epoch 1430, latest loss 0.7831244468688965\n",
      "Finished epoch 1431, latest loss 0.7807269096374512\n",
      "Finished epoch 1432, latest loss 0.7834681272506714\n",
      "Finished epoch 1433, latest loss 0.7849119901657104\n",
      "Finished epoch 1434, latest loss 0.7809029221534729\n",
      "Finished epoch 1435, latest loss 0.7829412221908569\n",
      "Finished epoch 1436, latest loss 0.7826143503189087\n",
      "Finished epoch 1437, latest loss 0.7813968658447266\n",
      "Finished epoch 1438, latest loss 0.7816975116729736\n",
      "Finished epoch 1439, latest loss 0.7812404632568359\n",
      "Finished epoch 1440, latest loss 0.7810837030410767\n",
      "Finished epoch 1441, latest loss 0.7832993865013123\n",
      "Finished epoch 1442, latest loss 0.7858021259307861\n",
      "Finished epoch 1443, latest loss 0.7834050059318542\n",
      "Finished epoch 1444, latest loss 0.782244086265564\n",
      "Finished epoch 1445, latest loss 0.784082293510437\n",
      "Finished epoch 1446, latest loss 0.7811779379844666\n",
      "Finished epoch 1447, latest loss 0.7807164788246155\n",
      "Finished epoch 1448, latest loss 0.7841867208480835\n",
      "Finished epoch 1449, latest loss 0.7850204706192017\n",
      "Finished epoch 1450, latest loss 0.7830178737640381\n",
      "Finished epoch 1451, latest loss 0.7827153205871582\n",
      "Finished epoch 1452, latest loss 0.7871933579444885\n",
      "Finished epoch 1453, latest loss 0.7832745313644409\n",
      "Finished epoch 1454, latest loss 0.7840738892555237\n",
      "Finished epoch 1455, latest loss 0.7810822129249573\n",
      "Finished epoch 1456, latest loss 0.7806159853935242\n",
      "Finished epoch 1457, latest loss 0.7813011407852173\n",
      "Finished epoch 1458, latest loss 0.7823919653892517\n",
      "Finished epoch 1459, latest loss 0.7820098996162415\n",
      "Finished epoch 1460, latest loss 0.7845672965049744\n",
      "Finished epoch 1461, latest loss 0.7805036306381226\n",
      "Finished epoch 1462, latest loss 0.7835230231285095\n",
      "Finished epoch 1463, latest loss 0.782693088054657\n",
      "Finished epoch 1464, latest loss 0.7820941805839539\n",
      "Finished epoch 1465, latest loss 0.7837769389152527\n",
      "Finished epoch 1466, latest loss 0.7841296195983887\n",
      "Finished epoch 1467, latest loss 0.7811638712882996\n",
      "Finished epoch 1468, latest loss 0.7824220657348633\n",
      "Finished epoch 1469, latest loss 0.7830747961997986\n",
      "Finished epoch 1470, latest loss 0.7803866863250732\n",
      "Finished epoch 1471, latest loss 0.783755898475647\n",
      "Finished epoch 1472, latest loss 0.7803333401679993\n",
      "Finished epoch 1473, latest loss 0.7811728119850159\n",
      "Finished epoch 1474, latest loss 0.7826236486434937\n",
      "Finished epoch 1475, latest loss 0.7837644815444946\n",
      "Finished epoch 1476, latest loss 0.7814943194389343\n",
      "Finished epoch 1477, latest loss 0.7822193503379822\n",
      "Finished epoch 1478, latest loss 0.7811799645423889\n",
      "Finished epoch 1479, latest loss 0.7810218334197998\n",
      "Finished epoch 1480, latest loss 0.7826817631721497\n",
      "Finished epoch 1481, latest loss 0.7825460433959961\n",
      "Finished epoch 1482, latest loss 0.7835513353347778\n",
      "Finished epoch 1483, latest loss 0.7814940810203552\n",
      "Finished epoch 1484, latest loss 0.7826592922210693\n",
      "Finished epoch 1485, latest loss 0.7826788425445557\n",
      "Finished epoch 1486, latest loss 0.7823682427406311\n",
      "Finished epoch 1487, latest loss 0.7823376059532166\n",
      "Finished epoch 1488, latest loss 0.7836573719978333\n",
      "Finished epoch 1489, latest loss 0.7829430103302002\n",
      "Finished epoch 1490, latest loss 0.7857638001441956\n",
      "Finished epoch 1491, latest loss 0.7836501002311707\n",
      "Finished epoch 1492, latest loss 0.784328281879425\n",
      "Finished epoch 1493, latest loss 0.783070981502533\n",
      "Finished epoch 1494, latest loss 0.7900828719139099\n",
      "Finished epoch 1495, latest loss 0.78375643491745\n",
      "Finished epoch 1496, latest loss 0.7816093564033508\n",
      "Finished epoch 1497, latest loss 0.7812278866767883\n",
      "Finished epoch 1498, latest loss 0.781872034072876\n",
      "Finished epoch 1499, latest loss 0.7861271500587463\n",
      "Finished epoch 1500, latest loss 0.7830234169960022\n",
      "Finished epoch 1501, latest loss 0.7838391661643982\n",
      "Finished epoch 1502, latest loss 0.7810881733894348\n",
      "Finished epoch 1503, latest loss 0.7832310795783997\n",
      "Finished epoch 1504, latest loss 0.781182050704956\n",
      "Finished epoch 1505, latest loss 0.7872874736785889\n",
      "Finished epoch 1506, latest loss 0.7807878255844116\n",
      "Finished epoch 1507, latest loss 0.7818312048912048\n",
      "Finished epoch 1508, latest loss 0.7815530896186829\n",
      "Finished epoch 1509, latest loss 0.7819392681121826\n",
      "Finished epoch 1510, latest loss 0.7851232290267944\n",
      "Finished epoch 1511, latest loss 0.7831969857215881\n",
      "Finished epoch 1512, latest loss 0.7838257551193237\n",
      "Finished epoch 1513, latest loss 0.7814785242080688\n",
      "Finished epoch 1514, latest loss 0.7793964147567749\n",
      "Saved improved model\n",
      "Finished epoch 1515, latest loss 0.7823907136917114\n",
      "Finished epoch 1516, latest loss 0.7826954126358032\n",
      "Finished epoch 1517, latest loss 0.7832581400871277\n",
      "Finished epoch 1518, latest loss 0.7825797200202942\n",
      "Finished epoch 1519, latest loss 0.7840213775634766\n",
      "Finished epoch 1520, latest loss 0.7833483815193176\n",
      "Finished epoch 1521, latest loss 0.7826336026191711\n",
      "Finished epoch 1522, latest loss 0.7802515029907227\n",
      "Finished epoch 1523, latest loss 0.782098650932312\n",
      "Finished epoch 1524, latest loss 0.7822471857070923\n",
      "Finished epoch 1525, latest loss 0.7824085354804993\n",
      "Finished epoch 1526, latest loss 0.7836682796478271\n",
      "Finished epoch 1527, latest loss 0.7822630405426025\n",
      "Finished epoch 1528, latest loss 0.7836216688156128\n",
      "Finished epoch 1529, latest loss 0.78300940990448\n",
      "Finished epoch 1530, latest loss 0.7807817459106445\n",
      "Finished epoch 1531, latest loss 0.7820359468460083\n",
      "Finished epoch 1532, latest loss 0.7848411798477173\n",
      "Finished epoch 1533, latest loss 0.779589831829071\n",
      "Finished epoch 1534, latest loss 0.7814456224441528\n",
      "Finished epoch 1535, latest loss 0.7842113971710205\n",
      "Finished epoch 1536, latest loss 0.7810523509979248\n",
      "Finished epoch 1537, latest loss 0.7844911217689514\n",
      "Finished epoch 1538, latest loss 0.7816383242607117\n",
      "Finished epoch 1539, latest loss 0.7818396091461182\n",
      "Finished epoch 1540, latest loss 0.7806546092033386\n",
      "Finished epoch 1541, latest loss 0.7814465165138245\n",
      "Finished epoch 1542, latest loss 0.779597818851471\n",
      "Finished epoch 1543, latest loss 0.7803581953048706\n",
      "Finished epoch 1544, latest loss 0.7912417650222778\n",
      "Finished epoch 1545, latest loss 0.7826372385025024\n",
      "Finished epoch 1546, latest loss 0.7822789549827576\n",
      "Finished epoch 1547, latest loss 0.7840151786804199\n",
      "Finished epoch 1548, latest loss 0.7820995450019836\n",
      "Finished epoch 1549, latest loss 0.7807499170303345\n",
      "Finished epoch 1550, latest loss 0.7818365097045898\n",
      "Finished epoch 1551, latest loss 0.7792643308639526\n",
      "Saved improved model\n",
      "Finished epoch 1552, latest loss 0.7831491827964783\n",
      "Finished epoch 1553, latest loss 0.7830818295478821\n",
      "Finished epoch 1554, latest loss 0.780698835849762\n",
      "Finished epoch 1555, latest loss 0.7834028005599976\n",
      "Finished epoch 1556, latest loss 0.7791799902915955\n",
      "Saved improved model\n",
      "Finished epoch 1557, latest loss 0.77919602394104\n",
      "Finished epoch 1558, latest loss 0.7791668176651001\n",
      "Saved improved model\n",
      "Finished epoch 1559, latest loss 0.7830546498298645\n",
      "Finished epoch 1560, latest loss 0.7818076014518738\n",
      "Finished epoch 1561, latest loss 0.7814923524856567\n",
      "Finished epoch 1562, latest loss 0.7830178737640381\n",
      "Finished epoch 1563, latest loss 0.7867521643638611\n",
      "Finished epoch 1564, latest loss 0.7814971208572388\n",
      "Finished epoch 1565, latest loss 0.7809053063392639\n",
      "Finished epoch 1566, latest loss 0.7803301811218262\n",
      "Finished epoch 1567, latest loss 0.7815741896629333\n",
      "Finished epoch 1568, latest loss 0.7841029763221741\n",
      "Finished epoch 1569, latest loss 0.7850374579429626\n",
      "Finished epoch 1570, latest loss 0.7842777371406555\n",
      "Finished epoch 1571, latest loss 0.7854936122894287\n",
      "Finished epoch 1572, latest loss 0.7808277606964111\n",
      "Finished epoch 1573, latest loss 0.7861831784248352\n",
      "Finished epoch 1574, latest loss 0.7790417075157166\n",
      "Saved improved model\n",
      "Finished epoch 1575, latest loss 0.7811909914016724\n",
      "Finished epoch 1576, latest loss 0.7817918062210083\n",
      "Finished epoch 1577, latest loss 0.7797656059265137\n",
      "Finished epoch 1578, latest loss 0.7830707430839539\n",
      "Finished epoch 1579, latest loss 0.780710756778717\n",
      "Finished epoch 1580, latest loss 0.7800947427749634\n",
      "Finished epoch 1581, latest loss 0.7822710871696472\n",
      "Finished epoch 1582, latest loss 0.7832412123680115\n",
      "Finished epoch 1583, latest loss 0.7810940146446228\n",
      "Finished epoch 1584, latest loss 0.7829105257987976\n",
      "Finished epoch 1585, latest loss 0.7838453650474548\n",
      "Finished epoch 1586, latest loss 0.7830764651298523\n",
      "Finished epoch 1587, latest loss 0.7799673080444336\n",
      "Finished epoch 1588, latest loss 0.7787493467330933\n",
      "Saved improved model\n",
      "Finished epoch 1589, latest loss 0.7814344763755798\n",
      "Finished epoch 1590, latest loss 0.7831143736839294\n",
      "Finished epoch 1591, latest loss 0.780530571937561\n",
      "Finished epoch 1592, latest loss 0.7821025848388672\n",
      "Finished epoch 1593, latest loss 0.7814908623695374\n",
      "Finished epoch 1594, latest loss 0.7813038229942322\n",
      "Finished epoch 1595, latest loss 0.779573917388916\n",
      "Finished epoch 1596, latest loss 0.779936671257019\n",
      "Finished epoch 1597, latest loss 0.7784133553504944\n",
      "Saved improved model\n",
      "Finished epoch 1598, latest loss 0.7804645299911499\n",
      "Finished epoch 1599, latest loss 0.7839692234992981\n",
      "Finished epoch 1600, latest loss 0.7805163860321045\n",
      "Finished epoch 1601, latest loss 0.7830556631088257\n",
      "Finished epoch 1602, latest loss 0.7811261415481567\n",
      "Finished epoch 1603, latest loss 0.7825650572776794\n",
      "Finished epoch 1604, latest loss 0.7821854948997498\n",
      "Finished epoch 1605, latest loss 0.7815046906471252\n",
      "Finished epoch 1606, latest loss 0.7814610004425049\n",
      "Finished epoch 1607, latest loss 0.7835789322853088\n",
      "Finished epoch 1608, latest loss 0.7823981046676636\n",
      "Finished epoch 1609, latest loss 0.7803941965103149\n",
      "Finished epoch 1610, latest loss 0.7837948203086853\n",
      "Finished epoch 1611, latest loss 0.7870246767997742\n",
      "Finished epoch 1612, latest loss 0.7837520837783813\n",
      "Finished epoch 1613, latest loss 0.7842809557914734\n",
      "Finished epoch 1614, latest loss 0.779403030872345\n",
      "Finished epoch 1615, latest loss 0.7835268974304199\n",
      "Finished epoch 1616, latest loss 0.7799646854400635\n",
      "Finished epoch 1617, latest loss 0.7803694009780884\n",
      "Finished epoch 1618, latest loss 0.7798613905906677\n",
      "Finished epoch 1619, latest loss 0.7817841172218323\n",
      "Finished epoch 1620, latest loss 0.7819883823394775\n",
      "Finished epoch 1621, latest loss 0.7845231890678406\n",
      "Finished epoch 1622, latest loss 0.7820578813552856\n",
      "Finished epoch 1623, latest loss 0.781181275844574\n",
      "Finished epoch 1624, latest loss 0.7784526944160461\n",
      "Finished epoch 1625, latest loss 0.7810883522033691\n",
      "Finished epoch 1626, latest loss 0.7805236577987671\n",
      "Finished epoch 1627, latest loss 0.7807339429855347\n",
      "Finished epoch 1628, latest loss 0.7814164757728577\n",
      "Finished epoch 1629, latest loss 0.7794029712677002\n",
      "Finished epoch 1630, latest loss 0.7827475666999817\n",
      "Finished epoch 1631, latest loss 0.7784101963043213\n",
      "Saved improved model\n",
      "Finished epoch 1632, latest loss 0.7834205627441406\n",
      "Finished epoch 1633, latest loss 0.7821860909461975\n",
      "Finished epoch 1634, latest loss 0.7825963497161865\n",
      "Finished epoch 1635, latest loss 0.7815129160881042\n",
      "Finished epoch 1636, latest loss 0.7835250496864319\n",
      "Finished epoch 1637, latest loss 0.7797154784202576\n",
      "Finished epoch 1638, latest loss 0.7813859581947327\n",
      "Finished epoch 1639, latest loss 0.7836710810661316\n",
      "Finished epoch 1640, latest loss 0.7799973487854004\n",
      "Finished epoch 1641, latest loss 0.7810842394828796\n",
      "Finished epoch 1642, latest loss 0.779225766658783\n",
      "Finished epoch 1643, latest loss 0.780716598033905\n",
      "Finished epoch 1644, latest loss 0.7797344923019409\n",
      "Finished epoch 1645, latest loss 0.782240629196167\n",
      "Finished epoch 1646, latest loss 0.7811427116394043\n",
      "Finished epoch 1647, latest loss 0.7796667814254761\n",
      "Finished epoch 1648, latest loss 0.788425087928772\n",
      "Finished epoch 1649, latest loss 0.7828778028488159\n",
      "Finished epoch 1650, latest loss 0.7807613015174866\n",
      "Finished epoch 1651, latest loss 0.7839918732643127\n",
      "Finished epoch 1652, latest loss 0.7815811038017273\n",
      "Finished epoch 1653, latest loss 0.7811127305030823\n",
      "Finished epoch 1654, latest loss 0.7834809422492981\n",
      "Finished epoch 1655, latest loss 0.7836029529571533\n",
      "Finished epoch 1656, latest loss 0.7803862690925598\n",
      "Finished epoch 1657, latest loss 0.7820868492126465\n",
      "Finished epoch 1658, latest loss 0.7805072069168091\n",
      "Finished epoch 1659, latest loss 0.7823414206504822\n",
      "Finished epoch 1660, latest loss 0.7807554602622986\n",
      "Finished epoch 1661, latest loss 0.7813454866409302\n",
      "Finished epoch 1662, latest loss 0.7811490893363953\n",
      "Finished epoch 1663, latest loss 0.7791768908500671\n",
      "Finished epoch 1664, latest loss 0.7839791774749756\n",
      "Finished epoch 1665, latest loss 0.7822834253311157\n",
      "Finished epoch 1666, latest loss 0.7807194590568542\n",
      "Finished epoch 1667, latest loss 0.7800454497337341\n",
      "Finished epoch 1668, latest loss 0.7803831100463867\n",
      "Finished epoch 1669, latest loss 0.7799348831176758\n",
      "Finished epoch 1670, latest loss 0.7833932042121887\n",
      "Finished epoch 1671, latest loss 0.7849722504615784\n",
      "Finished epoch 1672, latest loss 0.7798160910606384\n",
      "Finished epoch 1673, latest loss 0.7827983498573303\n",
      "Finished epoch 1674, latest loss 0.782871663570404\n",
      "Finished epoch 1675, latest loss 0.7803332209587097\n",
      "Finished epoch 1676, latest loss 0.7811194062232971\n",
      "Finished epoch 1677, latest loss 0.7807925343513489\n",
      "Finished epoch 1678, latest loss 0.7799808382987976\n",
      "Finished epoch 1679, latest loss 0.7810738682746887\n",
      "Finished epoch 1680, latest loss 0.7838602662086487\n",
      "Finished epoch 1681, latest loss 0.7866582274436951\n",
      "Finished epoch 1682, latest loss 0.7822017073631287\n",
      "Finished epoch 1683, latest loss 0.7801752686500549\n",
      "Finished epoch 1684, latest loss 0.7806145548820496\n",
      "Finished epoch 1685, latest loss 0.7866567969322205\n",
      "Finished epoch 1686, latest loss 0.784125566482544\n",
      "Finished epoch 1687, latest loss 0.7835580110549927\n",
      "Finished epoch 1688, latest loss 0.781725287437439\n",
      "Finished epoch 1689, latest loss 0.7809506058692932\n",
      "Finished epoch 1690, latest loss 0.7809156179428101\n",
      "Finished epoch 1691, latest loss 0.7826177477836609\n",
      "Finished epoch 1692, latest loss 0.7829184532165527\n",
      "Finished epoch 1693, latest loss 0.7826396226882935\n",
      "Finished epoch 1694, latest loss 0.7816656827926636\n",
      "Finished epoch 1695, latest loss 0.7819480895996094\n",
      "Finished epoch 1696, latest loss 0.7836393713951111\n",
      "Finished epoch 1697, latest loss 0.7817221283912659\n",
      "Finished epoch 1698, latest loss 0.7802220582962036\n",
      "Finished epoch 1699, latest loss 0.7795698642730713\n",
      "Finished epoch 1700, latest loss 0.7801263332366943\n",
      "Finished epoch 1701, latest loss 0.7842256426811218\n",
      "Finished epoch 1702, latest loss 0.7803320288658142\n",
      "Finished epoch 1703, latest loss 0.7799685001373291\n",
      "Finished epoch 1704, latest loss 0.7807566523551941\n",
      "Finished epoch 1705, latest loss 0.7803489565849304\n",
      "Finished epoch 1706, latest loss 0.7799201607704163\n",
      "Finished epoch 1707, latest loss 0.7805961966514587\n",
      "Finished epoch 1708, latest loss 0.7785149812698364\n",
      "Finished epoch 1709, latest loss 0.7822969555854797\n",
      "Finished epoch 1710, latest loss 0.7814954519271851\n",
      "Finished epoch 1711, latest loss 0.7833265066146851\n",
      "Finished epoch 1712, latest loss 0.7812855243682861\n",
      "Finished epoch 1713, latest loss 0.7824051380157471\n",
      "Finished epoch 1714, latest loss 0.7849603891372681\n",
      "Finished epoch 1715, latest loss 0.7852432131767273\n",
      "Finished epoch 1716, latest loss 0.7826251983642578\n",
      "Finished epoch 1717, latest loss 0.7797088027000427\n",
      "Finished epoch 1718, latest loss 0.7826189994812012\n",
      "Finished epoch 1719, latest loss 0.7828996777534485\n",
      "Finished epoch 1720, latest loss 0.7813347578048706\n",
      "Finished epoch 1721, latest loss 0.7795690298080444\n",
      "Finished epoch 1722, latest loss 0.7816816568374634\n",
      "Finished epoch 1723, latest loss 0.7795776128768921\n",
      "Finished epoch 1724, latest loss 0.783399760723114\n",
      "Finished epoch 1725, latest loss 0.7806998491287231\n",
      "Finished epoch 1726, latest loss 0.7808061838150024\n",
      "Finished epoch 1727, latest loss 0.7833316326141357\n",
      "Finished epoch 1728, latest loss 0.781432569026947\n",
      "Finished epoch 1729, latest loss 0.7806844711303711\n",
      "Finished epoch 1730, latest loss 0.7841698527336121\n",
      "Finished epoch 1731, latest loss 0.7791671752929688\n",
      "Finished epoch 1732, latest loss 0.7815704941749573\n",
      "Finished epoch 1733, latest loss 0.7817213535308838\n",
      "Finished epoch 1734, latest loss 0.7830624580383301\n",
      "Finished epoch 1735, latest loss 0.7834581732749939\n",
      "Finished epoch 1736, latest loss 0.7809698581695557\n",
      "Finished epoch 1737, latest loss 0.7841069102287292\n",
      "Finished epoch 1738, latest loss 0.7819344997406006\n",
      "Finished epoch 1739, latest loss 0.782203733921051\n",
      "Finished epoch 1740, latest loss 0.7816922664642334\n",
      "Finished epoch 1741, latest loss 0.7830145955085754\n",
      "Finished epoch 1742, latest loss 0.7799471616744995\n",
      "Finished epoch 1743, latest loss 0.7799277901649475\n",
      "Finished epoch 1744, latest loss 0.7816464304924011\n",
      "Finished epoch 1745, latest loss 0.7815873622894287\n",
      "Finished epoch 1746, latest loss 0.7867748737335205\n",
      "Finished epoch 1747, latest loss 0.783715009689331\n",
      "Finished epoch 1748, latest loss 0.7810866236686707\n",
      "Finished epoch 1749, latest loss 0.7811036705970764\n",
      "Finished epoch 1750, latest loss 0.780919075012207\n",
      "Finished epoch 1751, latest loss 0.7807263135910034\n",
      "Finished epoch 1752, latest loss 0.7848693132400513\n",
      "Finished epoch 1753, latest loss 0.7811879515647888\n",
      "Finished epoch 1754, latest loss 0.7813434600830078\n",
      "Finished epoch 1755, latest loss 0.7804385423660278\n",
      "Finished epoch 1756, latest loss 0.7822223901748657\n",
      "Finished epoch 1757, latest loss 0.7809759974479675\n",
      "Finished epoch 1758, latest loss 0.7795701622962952\n",
      "Finished epoch 1759, latest loss 0.7805020809173584\n",
      "Finished epoch 1760, latest loss 0.7841600775718689\n",
      "Finished epoch 1761, latest loss 0.7806702852249146\n",
      "Finished epoch 1762, latest loss 0.7839707732200623\n",
      "Finished epoch 1763, latest loss 0.7826114892959595\n",
      "Finished epoch 1764, latest loss 0.7825115323066711\n",
      "Finished epoch 1765, latest loss 0.7810385823249817\n",
      "Finished epoch 1766, latest loss 0.7818644046783447\n",
      "Finished epoch 1767, latest loss 0.7821925282478333\n",
      "Finished epoch 1768, latest loss 0.7822188138961792\n",
      "Finished epoch 1769, latest loss 0.7799299359321594\n",
      "Finished epoch 1770, latest loss 0.7815404534339905\n",
      "Finished epoch 1771, latest loss 0.782824695110321\n",
      "Finished epoch 1772, latest loss 0.7814512848854065\n",
      "Finished epoch 1773, latest loss 0.7820307016372681\n",
      "Finished epoch 1774, latest loss 0.7848831415176392\n",
      "Finished epoch 1775, latest loss 0.7819991707801819\n",
      "Finished epoch 1776, latest loss 0.7812747955322266\n",
      "Finished epoch 1777, latest loss 0.7808921933174133\n",
      "Finished epoch 1778, latest loss 0.7799838185310364\n",
      "Finished epoch 1779, latest loss 0.780049204826355\n",
      "Finished epoch 1780, latest loss 0.7792150378227234\n",
      "Finished epoch 1781, latest loss 0.7796236276626587\n",
      "Finished epoch 1782, latest loss 0.7792797088623047\n",
      "Finished epoch 1783, latest loss 0.7805396914482117\n",
      "Finished epoch 1784, latest loss 0.7784242630004883\n",
      "Finished epoch 1785, latest loss 0.7818581461906433\n",
      "Finished epoch 1786, latest loss 0.7803378701210022\n",
      "Finished epoch 1787, latest loss 0.7823317646980286\n",
      "Finished epoch 1788, latest loss 0.78257817029953\n",
      "Finished epoch 1789, latest loss 0.7814468145370483\n",
      "Finished epoch 1790, latest loss 0.7808969020843506\n",
      "Finished epoch 1791, latest loss 0.7805261611938477\n",
      "Finished epoch 1792, latest loss 0.7795105576515198\n",
      "Finished epoch 1793, latest loss 0.7795757055282593\n",
      "Finished epoch 1794, latest loss 0.7816997170448303\n",
      "Finished epoch 1795, latest loss 0.7799258232116699\n",
      "Finished epoch 1796, latest loss 0.7803370952606201\n",
      "Finished epoch 1797, latest loss 0.7844483256340027\n",
      "Finished epoch 1798, latest loss 0.7824727892875671\n",
      "Finished epoch 1799, latest loss 0.783492386341095\n",
      "Finished epoch 1800, latest loss 0.7818199992179871\n",
      "Finished epoch 1801, latest loss 0.7803942561149597\n",
      "Finished epoch 1802, latest loss 0.7795701622962952\n",
      "Finished epoch 1803, latest loss 0.779754102230072\n",
      "Finished epoch 1804, latest loss 0.779628574848175\n",
      "Finished epoch 1805, latest loss 0.779944121837616\n",
      "Finished epoch 1806, latest loss 0.7802653312683105\n",
      "Finished epoch 1807, latest loss 0.7815846800804138\n",
      "Finished epoch 1808, latest loss 0.7827229499816895\n",
      "Finished epoch 1809, latest loss 0.7799256443977356\n",
      "Finished epoch 1810, latest loss 0.7796169519424438\n",
      "Finished epoch 1811, latest loss 0.7787926197052002\n",
      "Finished epoch 1812, latest loss 0.7818487286567688\n",
      "Finished epoch 1813, latest loss 0.7846091389656067\n",
      "Finished epoch 1814, latest loss 0.7799208164215088\n",
      "Finished epoch 1815, latest loss 0.7814916372299194\n",
      "Finished epoch 1816, latest loss 0.7837568521499634\n",
      "Finished epoch 1817, latest loss 0.7784337997436523\n",
      "Finished epoch 1818, latest loss 0.7799257636070251\n",
      "Finished epoch 1819, latest loss 0.7857388257980347\n",
      "Finished epoch 1820, latest loss 0.7826935052871704\n",
      "Finished epoch 1821, latest loss 0.7818479537963867\n",
      "Finished epoch 1822, latest loss 0.7840999364852905\n",
      "Finished epoch 1823, latest loss 0.7843421101570129\n",
      "Finished epoch 1824, latest loss 0.7812755107879639\n",
      "Finished epoch 1825, latest loss 0.7825562357902527\n",
      "Finished epoch 1826, latest loss 0.7832691669464111\n",
      "Finished epoch 1827, latest loss 0.7814148664474487\n",
      "Finished epoch 1828, latest loss 0.7870898246765137\n",
      "Finished epoch 1829, latest loss 0.7810966372489929\n",
      "Finished epoch 1830, latest loss 0.780048131942749\n",
      "Finished epoch 1831, latest loss 0.7821546792984009\n",
      "Finished epoch 1832, latest loss 0.7825846672058105\n",
      "Finished epoch 1833, latest loss 0.7801658511161804\n",
      "Finished epoch 1834, latest loss 0.7824246287345886\n",
      "Finished epoch 1835, latest loss 0.7813791036605835\n",
      "Finished epoch 1836, latest loss 0.7810860872268677\n",
      "Finished epoch 1837, latest loss 0.7801654934883118\n",
      "Finished epoch 1838, latest loss 0.7806017398834229\n",
      "Finished epoch 1839, latest loss 0.7803306579589844\n",
      "Finished epoch 1840, latest loss 0.7805165648460388\n",
      "Finished epoch 1841, latest loss 0.7807838916778564\n",
      "Finished epoch 1842, latest loss 0.7791531682014465\n",
      "Finished epoch 1843, latest loss 0.7784297466278076\n",
      "Finished epoch 1844, latest loss 0.7799331545829773\n",
      "Finished epoch 1845, latest loss 0.7819840908050537\n",
      "Finished epoch 1846, latest loss 0.7793698906898499\n",
      "Finished epoch 1847, latest loss 0.7815272212028503\n",
      "Finished epoch 1848, latest loss 0.7813758254051208\n",
      "Finished epoch 1849, latest loss 0.7784080505371094\n",
      "Saved improved model\n",
      "Finished epoch 1850, latest loss 0.780717134475708\n",
      "Finished epoch 1851, latest loss 0.7795267701148987\n",
      "Finished epoch 1852, latest loss 0.7803592085838318\n",
      "Finished epoch 1853, latest loss 0.785849392414093\n",
      "Finished epoch 1854, latest loss 0.7809412479400635\n",
      "Finished epoch 1855, latest loss 0.7843777537345886\n",
      "Finished epoch 1856, latest loss 0.7829335927963257\n",
      "Finished epoch 1857, latest loss 0.7792056202888489\n",
      "Finished epoch 1858, latest loss 0.7831469774246216\n",
      "Finished epoch 1859, latest loss 0.7838267683982849\n",
      "Finished epoch 1860, latest loss 0.7810871005058289\n",
      "Finished epoch 1861, latest loss 0.7820541262626648\n",
      "Finished epoch 1862, latest loss 0.7787557244300842\n",
      "Finished epoch 1863, latest loss 0.7803254723548889\n",
      "Finished epoch 1864, latest loss 0.780899167060852\n",
      "Finished epoch 1865, latest loss 0.7840753197669983\n",
      "Finished epoch 1866, latest loss 0.7803571224212646\n",
      "Finished epoch 1867, latest loss 0.7793847322463989\n",
      "Finished epoch 1868, latest loss 0.7817426323890686\n",
      "Finished epoch 1869, latest loss 0.7861583232879639\n",
      "Finished epoch 1870, latest loss 0.7791752815246582\n",
      "Finished epoch 1871, latest loss 0.7833095192909241\n",
      "Finished epoch 1872, latest loss 0.7858447432518005\n",
      "Finished epoch 1873, latest loss 0.7811487913131714\n",
      "Finished epoch 1874, latest loss 0.780327558517456\n",
      "Finished epoch 1875, latest loss 0.7834060192108154\n",
      "Finished epoch 1876, latest loss 0.7816506028175354\n",
      "Finished epoch 1877, latest loss 0.7812366485595703\n",
      "Finished epoch 1878, latest loss 0.7835016846656799\n",
      "Finished epoch 1879, latest loss 0.7799307703971863\n",
      "Finished epoch 1880, latest loss 0.7814518809318542\n",
      "Finished epoch 1881, latest loss 0.7826390862464905\n",
      "Finished epoch 1882, latest loss 0.7785242795944214\n",
      "Finished epoch 1883, latest loss 0.7794014811515808\n",
      "Finished epoch 1884, latest loss 0.7795711159706116\n",
      "Finished epoch 1885, latest loss 0.7813478708267212\n",
      "Finished epoch 1886, latest loss 0.7799592614173889\n",
      "Finished epoch 1887, latest loss 0.7836527228355408\n",
      "Finished epoch 1888, latest loss 0.7810100317001343\n",
      "Finished epoch 1889, latest loss 0.7805491089820862\n",
      "Finished epoch 1890, latest loss 0.7833029627799988\n",
      "Finished epoch 1891, latest loss 0.7810871601104736\n",
      "Finished epoch 1892, latest loss 0.7817284464836121\n",
      "Finished epoch 1893, latest loss 0.7849043011665344\n",
      "Finished epoch 1894, latest loss 0.7846738696098328\n",
      "Finished epoch 1895, latest loss 0.7810702919960022\n",
      "Finished epoch 1896, latest loss 0.7806048393249512\n",
      "Finished epoch 1897, latest loss 0.7811158299446106\n",
      "Finished epoch 1898, latest loss 0.7809177041053772\n",
      "Finished epoch 1899, latest loss 0.7811530232429504\n",
      "Finished epoch 1900, latest loss 0.780707061290741\n",
      "Finished epoch 1901, latest loss 0.7806885242462158\n",
      "Finished epoch 1902, latest loss 0.7838122248649597\n",
      "Finished epoch 1903, latest loss 0.7832667231559753\n",
      "Finished epoch 1904, latest loss 0.7826104164123535\n",
      "Finished epoch 1905, latest loss 0.7820767164230347\n",
      "Finished epoch 1906, latest loss 0.7785211205482483\n",
      "Finished epoch 1907, latest loss 0.7824403643608093\n",
      "Finished epoch 1908, latest loss 0.7851764559745789\n",
      "Finished epoch 1909, latest loss 0.7846870422363281\n",
      "Finished epoch 1910, latest loss 0.7848156094551086\n",
      "Finished epoch 1911, latest loss 0.7797986268997192\n",
      "Finished epoch 1912, latest loss 0.7818475365638733\n",
      "Finished epoch 1913, latest loss 0.7807444930076599\n",
      "Finished epoch 1914, latest loss 0.7802648544311523\n",
      "Finished epoch 1915, latest loss 0.7835739850997925\n",
      "Finished epoch 1916, latest loss 0.7817944884300232\n",
      "Finished epoch 1917, latest loss 0.7812965512275696\n",
      "Finished epoch 1918, latest loss 0.7805349230766296\n",
      "Finished epoch 1919, latest loss 0.7807593941688538\n",
      "Finished epoch 1920, latest loss 0.7819077372550964\n",
      "Finished epoch 1921, latest loss 0.7822335958480835\n",
      "Finished epoch 1922, latest loss 0.7796042561531067\n",
      "Finished epoch 1923, latest loss 0.7792468070983887\n",
      "Finished epoch 1924, latest loss 0.7791668772697449\n",
      "Finished epoch 1925, latest loss 0.7802066802978516\n",
      "Finished epoch 1926, latest loss 0.781514048576355\n",
      "Finished epoch 1927, latest loss 0.7794603705406189\n",
      "Finished epoch 1928, latest loss 0.7776738405227661\n",
      "Saved improved model\n",
      "Finished epoch 1929, latest loss 0.7795681953430176\n",
      "Finished epoch 1930, latest loss 0.7791473269462585\n",
      "Finished epoch 1931, latest loss 0.7772467732429504\n",
      "Saved improved model\n",
      "Finished epoch 1932, latest loss 0.7792066335678101\n",
      "Finished epoch 1933, latest loss 0.7813241481781006\n",
      "Finished epoch 1934, latest loss 0.7796335220336914\n",
      "Finished epoch 1935, latest loss 0.7793726921081543\n",
      "Finished epoch 1936, latest loss 0.7795447111129761\n",
      "Finished epoch 1937, latest loss 0.7825765013694763\n",
      "Finished epoch 1938, latest loss 0.7774310111999512\n",
      "Finished epoch 1939, latest loss 0.7834537625312805\n",
      "Finished epoch 1940, latest loss 0.7809622287750244\n",
      "Finished epoch 1941, latest loss 0.778049111366272\n",
      "Finished epoch 1942, latest loss 0.7819134593009949\n",
      "Finished epoch 1943, latest loss 0.7804021239280701\n",
      "Finished epoch 1944, latest loss 0.7780167460441589\n",
      "Finished epoch 1945, latest loss 0.7795247435569763\n",
      "Finished epoch 1946, latest loss 0.7838138341903687\n",
      "Finished epoch 1947, latest loss 0.7811354994773865\n",
      "Finished epoch 1948, latest loss 0.7799181342124939\n",
      "Finished epoch 1949, latest loss 0.7795130610466003\n",
      "Finished epoch 1950, latest loss 0.7816112041473389\n",
      "Finished epoch 1951, latest loss 0.7795955538749695\n",
      "Finished epoch 1952, latest loss 0.7823846340179443\n",
      "Finished epoch 1953, latest loss 0.7782877683639526\n",
      "Finished epoch 1954, latest loss 0.7810682654380798\n",
      "Finished epoch 1955, latest loss 0.7811703085899353\n",
      "Finished epoch 1956, latest loss 0.7833976745605469\n",
      "Finished epoch 1957, latest loss 0.7780432105064392\n",
      "Finished epoch 1958, latest loss 0.7852565050125122\n",
      "Finished epoch 1959, latest loss 0.7793657779693604\n",
      "Finished epoch 1960, latest loss 0.7784223556518555\n",
      "Finished epoch 1961, latest loss 0.7816510200500488\n",
      "Finished epoch 1962, latest loss 0.7779455780982971\n",
      "Finished epoch 1963, latest loss 0.7802886962890625\n",
      "Finished epoch 1964, latest loss 0.7828419804573059\n",
      "Finished epoch 1965, latest loss 0.7822774052619934\n",
      "Finished epoch 1966, latest loss 0.7795239686965942\n",
      "Finished epoch 1967, latest loss 0.7814747095108032\n",
      "Finished epoch 1968, latest loss 0.7795571684837341\n",
      "Finished epoch 1969, latest loss 0.7815280556678772\n",
      "Finished epoch 1970, latest loss 0.7826107740402222\n",
      "Finished epoch 1971, latest loss 0.7804122567176819\n",
      "Finished epoch 1972, latest loss 0.7796034812927246\n",
      "Finished epoch 1973, latest loss 0.779235303401947\n",
      "Finished epoch 1974, latest loss 0.7822494506835938\n",
      "Finished epoch 1975, latest loss 0.7786228656768799\n",
      "Finished epoch 1976, latest loss 0.7816389799118042\n",
      "Finished epoch 1977, latest loss 0.7807475328445435\n",
      "Finished epoch 1978, latest loss 0.7799316048622131\n",
      "Finished epoch 1979, latest loss 0.7791326642036438\n",
      "Finished epoch 1980, latest loss 0.7780241966247559\n",
      "Finished epoch 1981, latest loss 0.778918445110321\n",
      "Finished epoch 1982, latest loss 0.7803681492805481\n",
      "Finished epoch 1983, latest loss 0.7814598083496094\n",
      "Finished epoch 1984, latest loss 0.7780036926269531\n",
      "Finished epoch 1985, latest loss 0.7791803479194641\n",
      "Finished epoch 1986, latest loss 0.7784120440483093\n",
      "Finished epoch 1987, latest loss 0.7803495526313782\n",
      "Finished epoch 1988, latest loss 0.7857716679573059\n",
      "Finished epoch 1989, latest loss 0.7809246182441711\n",
      "Finished epoch 1990, latest loss 0.7783418893814087\n",
      "Finished epoch 1991, latest loss 0.780796229839325\n",
      "Finished epoch 1992, latest loss 0.7827152013778687\n",
      "Finished epoch 1993, latest loss 0.7803459167480469\n",
      "Finished epoch 1994, latest loss 0.7795851230621338\n",
      "Finished epoch 1995, latest loss 0.779880166053772\n",
      "Finished epoch 1996, latest loss 0.7788265943527222\n",
      "Finished epoch 1997, latest loss 0.7833988666534424\n",
      "Finished epoch 1998, latest loss 0.782990574836731\n",
      "Finished epoch 1999, latest loss 0.7852072715759277\n",
      "Accuracy 0.9236602187156677\n",
      "Confusion Matrix for negative predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive               50058               15425\n",
      "Actual Negative                3875              183459\n",
      "Positive predictive power:\n",
      "76.44%\n",
      "Positive predictive accuracy:\n",
      "92.82%\n",
      "PimaClassifier(\n",
      "  (hidden1): Linear(in_features=1616, out_features=64, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (hidden2): Linear(in_features=64, out_features=12, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (hidden3): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (act3): ReLU()\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (act_output): Sigmoid()\n",
      ")\n",
      "Finished epoch 0, latest loss 0.7263023853302002\n",
      "Saved improved model\n",
      "Finished epoch 1, latest loss 0.7262384295463562\n",
      "Saved improved model\n",
      "Finished epoch 2, latest loss 0.7262336015701294\n",
      "Saved improved model\n",
      "Finished epoch 3, latest loss 0.7262333631515503\n",
      "Saved improved model\n",
      "Finished epoch 4, latest loss 0.7262334823608398\n",
      "Finished epoch 5, latest loss 0.7262336611747742\n",
      "Finished epoch 6, latest loss 0.7262337803840637\n",
      "Finished epoch 7, latest loss 0.726233959197998\n",
      "Finished epoch 8, latest loss 0.7262340188026428\n",
      "Finished epoch 9, latest loss 0.7262340784072876\n",
      "Finished epoch 10, latest loss 0.7262341976165771\n",
      "Finished epoch 11, latest loss 0.7262342572212219\n",
      "Finished epoch 12, latest loss 0.7262342572212219\n",
      "Finished epoch 13, latest loss 0.7262343168258667\n",
      "Finished epoch 14, latest loss 0.7262343168258667\n",
      "Finished epoch 15, latest loss 0.7262343764305115\n",
      "Finished epoch 16, latest loss 0.7262343764305115\n",
      "Finished epoch 17, latest loss 0.7262343764305115\n",
      "Finished epoch 18, latest loss 0.7262343764305115\n",
      "Finished epoch 19, latest loss 0.7262343764305115\n",
      "Finished epoch 20, latest loss 0.7262343764305115\n",
      "Finished epoch 21, latest loss 0.7262343764305115\n",
      "Finished epoch 22, latest loss 0.7262342572212219\n",
      "Finished epoch 23, latest loss 0.726233959197998\n",
      "Finished epoch 24, latest loss 0.7262337803840637\n",
      "Finished epoch 25, latest loss 0.7262340188026428\n",
      "Finished epoch 26, latest loss 0.7262340784072876\n",
      "Finished epoch 27, latest loss 0.7262333035469055\n",
      "Saved improved model\n",
      "Finished epoch 28, latest loss 0.7262327075004578\n",
      "Saved improved model\n",
      "Finished epoch 29, latest loss 0.7262327671051025\n",
      "Finished epoch 30, latest loss 0.7262294888496399\n",
      "Saved improved model\n",
      "Finished epoch 31, latest loss 0.7262119650840759\n",
      "Saved improved model\n",
      "Finished epoch 32, latest loss 0.7262231707572937\n",
      "Finished epoch 33, latest loss 0.7262350916862488\n",
      "Finished epoch 34, latest loss 0.7262343168258667\n",
      "Finished epoch 35, latest loss 0.7262345552444458\n",
      "Finished epoch 36, latest loss 0.7262355089187622\n",
      "Finished epoch 37, latest loss 0.7262350916862488\n",
      "Finished epoch 38, latest loss 0.7262365221977234\n",
      "Finished epoch 39, latest loss 0.7262350916862488\n",
      "Finished epoch 40, latest loss 0.7262372374534607\n",
      "Finished epoch 41, latest loss 0.7265236377716064\n",
      "Finished epoch 42, latest loss 0.7262349724769592\n",
      "Finished epoch 43, latest loss 0.7262349724769592\n",
      "Finished epoch 44, latest loss 0.7262349724769592\n",
      "Finished epoch 45, latest loss 0.7262349724769592\n",
      "Finished epoch 46, latest loss 0.7262349724769592\n",
      "Finished epoch 47, latest loss 0.7262349724769592\n",
      "Finished epoch 48, latest loss 0.7262349724769592\n",
      "Finished epoch 49, latest loss 0.7262349724769592\n",
      "Finished epoch 50, latest loss 0.7262349724769592\n",
      "Finished epoch 51, latest loss 0.7262349724769592\n",
      "Finished epoch 52, latest loss 0.7262349724769592\n",
      "Finished epoch 53, latest loss 0.7262349724769592\n",
      "Finished epoch 54, latest loss 0.7262349724769592\n",
      "Finished epoch 55, latest loss 0.7262349724769592\n",
      "Finished epoch 56, latest loss 0.7262349724769592\n",
      "Finished epoch 57, latest loss 0.7262349724769592\n",
      "Finished epoch 58, latest loss 0.7262349724769592\n",
      "Finished epoch 59, latest loss 0.7262349724769592\n",
      "Finished epoch 60, latest loss 0.7262349724769592\n",
      "Finished epoch 61, latest loss 0.7262349724769592\n",
      "Finished epoch 62, latest loss 0.7262349724769592\n",
      "Finished epoch 63, latest loss 0.7262349724769592\n",
      "Finished epoch 64, latest loss 0.7262349724769592\n",
      "Finished epoch 65, latest loss 0.7262349724769592\n",
      "Finished epoch 66, latest loss 0.7262349724769592\n",
      "Finished epoch 67, latest loss 0.7262349724769592\n",
      "Finished epoch 68, latest loss 0.7262349724769592\n",
      "Finished epoch 69, latest loss 0.7262349724769592\n",
      "Finished epoch 70, latest loss 0.7262349724769592\n",
      "Finished epoch 71, latest loss 0.7262349724769592\n",
      "Finished epoch 72, latest loss 0.7262349724769592\n",
      "Finished epoch 73, latest loss 0.7262349724769592\n",
      "Finished epoch 74, latest loss 0.7262349724769592\n",
      "Finished epoch 75, latest loss 0.7262349724769592\n",
      "Finished epoch 76, latest loss 0.7262349724769592\n",
      "Finished epoch 77, latest loss 0.7262349724769592\n",
      "Finished epoch 78, latest loss 0.7262349724769592\n",
      "Finished epoch 79, latest loss 0.7262349724769592\n",
      "Finished epoch 80, latest loss 0.7262349724769592\n",
      "Finished epoch 81, latest loss 0.7262349724769592\n",
      "Finished epoch 82, latest loss 0.7262349724769592\n",
      "Finished epoch 83, latest loss 0.7262349724769592\n",
      "Finished epoch 84, latest loss 0.7255375385284424\n",
      "Saved improved model\n",
      "Finished epoch 85, latest loss 0.7262349724769592\n",
      "Finished epoch 86, latest loss 0.7262349724769592\n",
      "Finished epoch 87, latest loss 0.7255882024765015\n",
      "Finished epoch 88, latest loss 0.7255375981330872\n",
      "Finished epoch 89, latest loss 0.7255414128303528\n",
      "Finished epoch 90, latest loss 0.725538432598114\n",
      "Finished epoch 91, latest loss 0.7255378365516663\n",
      "Finished epoch 92, latest loss 0.726296603679657\n",
      "Finished epoch 93, latest loss 0.7261773347854614\n",
      "Finished epoch 94, latest loss 0.7262077927589417\n",
      "Finished epoch 95, latest loss 0.7255710363388062\n",
      "Finished epoch 96, latest loss 0.7262309789657593\n",
      "Finished epoch 97, latest loss 0.7259101867675781\n",
      "Finished epoch 98, latest loss 0.7262349724769592\n",
      "Finished epoch 99, latest loss 0.7262349724769592\n",
      "Finished epoch 100, latest loss 0.7262349724769592\n",
      "Finished epoch 101, latest loss 0.725558876991272\n",
      "Finished epoch 102, latest loss 0.7262349724769592\n",
      "Finished epoch 103, latest loss 0.7262349724769592\n",
      "Finished epoch 104, latest loss 0.7262349724769592\n",
      "Finished epoch 105, latest loss 0.7260767817497253\n",
      "Finished epoch 106, latest loss 0.7251814603805542\n",
      "Saved improved model\n",
      "Finished epoch 107, latest loss 0.7258707284927368\n",
      "Finished epoch 108, latest loss 0.7248461842536926\n",
      "Saved improved model\n",
      "Finished epoch 109, latest loss 0.7250071167945862\n",
      "Finished epoch 110, latest loss 0.7248404622077942\n",
      "Saved improved model\n",
      "Finished epoch 111, latest loss 0.7248402833938599\n",
      "Saved improved model\n",
      "Finished epoch 112, latest loss 0.724840521812439\n",
      "Finished epoch 113, latest loss 0.7248402833938599\n",
      "Finished epoch 114, latest loss 0.7248410582542419\n",
      "Finished epoch 115, latest loss 0.7248411774635315\n",
      "Finished epoch 116, latest loss 0.7249262928962708\n",
      "Finished epoch 117, latest loss 0.7248404622077942\n",
      "Finished epoch 118, latest loss 0.7248407006263733\n",
      "Finished epoch 119, latest loss 0.7247852683067322\n",
      "Saved improved model\n",
      "Finished epoch 120, latest loss 0.7241429686546326\n",
      "Saved improved model\n",
      "Finished epoch 121, latest loss 0.7241432666778564\n",
      "Finished epoch 122, latest loss 0.7241432070732117\n",
      "Finished epoch 123, latest loss 0.7241435050964355\n",
      "Finished epoch 124, latest loss 0.7241438627243042\n",
      "Finished epoch 125, latest loss 0.7241452932357788\n",
      "Finished epoch 126, latest loss 0.7241458892822266\n",
      "Finished epoch 127, latest loss 0.7241461873054504\n",
      "Finished epoch 128, latest loss 0.7241442799568176\n",
      "Finished epoch 129, latest loss 0.7248445153236389\n",
      "Finished epoch 130, latest loss 0.723764181137085\n",
      "Saved improved model\n",
      "Finished epoch 131, latest loss 0.7234826683998108\n",
      "Saved improved model\n",
      "Finished epoch 132, latest loss 0.7246334552764893\n",
      "Finished epoch 133, latest loss 0.7234847545623779\n",
      "Finished epoch 134, latest loss 0.7234455943107605\n",
      "Saved improved model\n",
      "Finished epoch 135, latest loss 0.7234455943107605\n",
      "Finished epoch 136, latest loss 0.7234463691711426\n",
      "Finished epoch 137, latest loss 0.7234457731246948\n",
      "Finished epoch 138, latest loss 0.724139928817749\n",
      "Finished epoch 139, latest loss 0.7235109210014343\n",
      "Finished epoch 140, latest loss 0.723445475101471\n",
      "Saved improved model\n",
      "Finished epoch 141, latest loss 0.7241430878639221\n",
      "Finished epoch 142, latest loss 0.7234976291656494\n",
      "Finished epoch 143, latest loss 0.7238791584968567\n",
      "Finished epoch 144, latest loss 0.7234454154968262\n",
      "Saved improved model\n",
      "Finished epoch 145, latest loss 0.7234455943107605\n",
      "Finished epoch 146, latest loss 0.7234452366828918\n",
      "Saved improved model\n",
      "Finished epoch 147, latest loss 0.7234452962875366\n",
      "Finished epoch 148, latest loss 0.7234452962875366\n",
      "Finished epoch 149, latest loss 0.7234452962875366\n",
      "Finished epoch 150, latest loss 0.7234455943107605\n",
      "Finished epoch 151, latest loss 0.7234460711479187\n",
      "Finished epoch 152, latest loss 0.7234452962875366\n",
      "Finished epoch 153, latest loss 0.7234452962875366\n",
      "Finished epoch 154, latest loss 0.7234452962875366\n",
      "Finished epoch 155, latest loss 0.7234452962875366\n",
      "Finished epoch 156, latest loss 0.7234464287757874\n",
      "Finished epoch 157, latest loss 0.72344571352005\n",
      "Finished epoch 158, latest loss 0.7234799861907959\n",
      "Finished epoch 159, latest loss 0.7234463095664978\n",
      "Finished epoch 160, latest loss 0.7234461903572083\n",
      "Finished epoch 161, latest loss 0.723445475101471\n",
      "Finished epoch 162, latest loss 0.7232294082641602\n",
      "Saved improved model\n",
      "Finished epoch 163, latest loss 0.7227485775947571\n",
      "Saved improved model\n",
      "Finished epoch 164, latest loss 0.7227790951728821\n",
      "Finished epoch 165, latest loss 0.7227774858474731\n",
      "Finished epoch 166, latest loss 0.7237247228622437\n",
      "Finished epoch 167, latest loss 0.7227513790130615\n",
      "Finished epoch 168, latest loss 0.7227565050125122\n",
      "Finished epoch 169, latest loss 0.7227485775947571\n",
      "Finished epoch 170, latest loss 0.7227482199668884\n",
      "Saved improved model\n",
      "Finished epoch 171, latest loss 0.7234449982643127\n",
      "Finished epoch 172, latest loss 0.7227711081504822\n",
      "Finished epoch 173, latest loss 0.7230103015899658\n",
      "Finished epoch 174, latest loss 0.7220576405525208\n",
      "Saved improved model\n",
      "Finished epoch 175, latest loss 0.7237308621406555\n",
      "Finished epoch 176, latest loss 0.7230222225189209\n",
      "Finished epoch 177, latest loss 0.722878634929657\n",
      "Finished epoch 178, latest loss 0.7227483987808228\n",
      "Finished epoch 179, latest loss 0.7227599620819092\n",
      "Finished epoch 180, latest loss 0.7220503687858582\n",
      "Saved improved model\n",
      "Finished epoch 181, latest loss 0.7221925854682922\n",
      "Finished epoch 182, latest loss 0.7226657271385193\n",
      "Finished epoch 183, latest loss 0.7213538289070129\n",
      "Saved improved model\n",
      "Finished epoch 184, latest loss 0.7213883399963379\n",
      "Finished epoch 185, latest loss 0.7213572859764099\n",
      "Finished epoch 186, latest loss 0.7220508456230164\n",
      "Finished epoch 187, latest loss 0.7221291065216064\n",
      "Finished epoch 188, latest loss 0.7213538885116577\n",
      "Finished epoch 189, latest loss 0.7220672965049744\n",
      "Finished epoch 190, latest loss 0.7213535904884338\n",
      "Saved improved model\n",
      "Finished epoch 191, latest loss 0.7213590741157532\n",
      "Finished epoch 192, latest loss 0.7213543653488159\n",
      "Finished epoch 193, latest loss 0.7219111323356628\n",
      "Finished epoch 194, latest loss 0.7214349508285522\n",
      "Finished epoch 195, latest loss 0.7213611602783203\n",
      "Finished epoch 196, latest loss 0.7213529348373413\n",
      "Saved improved model\n",
      "Finished epoch 197, latest loss 0.7213549017906189\n",
      "Finished epoch 198, latest loss 0.721356213092804\n",
      "Finished epoch 199, latest loss 0.7213547825813293\n",
      "Finished epoch 200, latest loss 0.7213532328605652\n",
      "Finished epoch 201, latest loss 0.7213530540466309\n",
      "Finished epoch 202, latest loss 0.7217127680778503\n",
      "Finished epoch 203, latest loss 0.7213530540466309\n",
      "Finished epoch 204, latest loss 0.7221121191978455\n",
      "Finished epoch 205, latest loss 0.7221119403839111\n",
      "Finished epoch 206, latest loss 0.7213588953018188\n",
      "Finished epoch 207, latest loss 0.7221121191978455\n",
      "Finished epoch 208, latest loss 0.7221174240112305\n",
      "Finished epoch 209, latest loss 0.721433162689209\n",
      "Finished epoch 210, latest loss 0.7213529348373413\n",
      "Finished epoch 211, latest loss 0.721352756023407\n",
      "Saved improved model\n",
      "Finished epoch 212, latest loss 0.7215679883956909\n",
      "Finished epoch 213, latest loss 0.7213533520698547\n",
      "Finished epoch 214, latest loss 0.7213596701622009\n",
      "Finished epoch 215, latest loss 0.7207576036453247\n",
      "Saved improved model\n",
      "Finished epoch 216, latest loss 0.7207165956497192\n",
      "Saved improved model\n",
      "Finished epoch 217, latest loss 0.7215666174888611\n",
      "Finished epoch 218, latest loss 0.7214391231536865\n",
      "Finished epoch 219, latest loss 0.7206563949584961\n",
      "Saved improved model\n",
      "Finished epoch 220, latest loss 0.7206560969352722\n",
      "Saved improved model\n",
      "Finished epoch 221, latest loss 0.7206608653068542\n",
      "Finished epoch 222, latest loss 0.7215390205383301\n",
      "Finished epoch 223, latest loss 0.7214159965515137\n",
      "Finished epoch 224, latest loss 0.7214149236679077\n",
      "Finished epoch 225, latest loss 0.7215160727500916\n",
      "Finished epoch 226, latest loss 0.7206880450248718\n",
      "Finished epoch 227, latest loss 0.7207435369491577\n",
      "Finished epoch 228, latest loss 0.720655620098114\n",
      "Saved improved model\n",
      "Finished epoch 229, latest loss 0.7206557989120483\n",
      "Finished epoch 230, latest loss 0.72141432762146\n",
      "Finished epoch 231, latest loss 0.7206557989120483\n",
      "Finished epoch 232, latest loss 0.720655620098114\n",
      "Finished epoch 233, latest loss 0.7206553816795349\n",
      "Saved improved model\n",
      "Finished epoch 234, latest loss 0.7213871479034424\n",
      "Finished epoch 235, latest loss 0.7206557989120483\n",
      "Finished epoch 236, latest loss 0.7209429740905762\n",
      "Finished epoch 237, latest loss 0.7206555008888245\n",
      "Finished epoch 238, latest loss 0.7206556797027588\n",
      "Finished epoch 239, latest loss 0.721169650554657\n",
      "Finished epoch 240, latest loss 0.72065669298172\n",
      "Finished epoch 241, latest loss 0.720655620098114\n",
      "Finished epoch 242, latest loss 0.7206555604934692\n",
      "Finished epoch 243, latest loss 0.7206553220748901\n",
      "Saved improved model\n",
      "Finished epoch 244, latest loss 0.7206553816795349\n",
      "Finished epoch 245, latest loss 0.7214068174362183\n",
      "Finished epoch 246, latest loss 0.7206553220748901\n",
      "Finished epoch 247, latest loss 0.7206553816795349\n",
      "Finished epoch 248, latest loss 0.7206555008888245\n",
      "Finished epoch 249, latest loss 0.7206556797027588\n",
      "Finished epoch 250, latest loss 0.7206493616104126\n",
      "Saved improved model\n",
      "Finished epoch 251, latest loss 0.7206555604934692\n",
      "Finished epoch 252, latest loss 0.7206555008888245\n",
      "Finished epoch 253, latest loss 0.7206584811210632\n",
      "Finished epoch 254, latest loss 0.7206553220748901\n",
      "Finished epoch 255, latest loss 0.7206555008888245\n",
      "Finished epoch 256, latest loss 0.7206555008888245\n",
      "Finished epoch 257, latest loss 0.7199578881263733\n",
      "Saved improved model\n",
      "Finished epoch 258, latest loss 0.720655620098114\n",
      "Finished epoch 259, latest loss 0.7206553220748901\n",
      "Finished epoch 260, latest loss 0.7206555008888245\n",
      "Finished epoch 261, latest loss 0.7199604511260986\n",
      "Finished epoch 262, latest loss 0.7206553220748901\n",
      "Finished epoch 263, latest loss 0.7206553220748901\n",
      "Finished epoch 264, latest loss 0.7206555008888245\n",
      "Finished epoch 265, latest loss 0.7209716439247131\n",
      "Finished epoch 266, latest loss 0.7206618785858154\n",
      "Finished epoch 267, latest loss 0.7206522822380066\n",
      "Finished epoch 268, latest loss 0.719958484172821\n",
      "Finished epoch 269, latest loss 0.7206555008888245\n",
      "Finished epoch 270, latest loss 0.7214113473892212\n",
      "Finished epoch 271, latest loss 0.7206565141677856\n",
      "Finished epoch 272, latest loss 0.7206577658653259\n",
      "Finished epoch 273, latest loss 0.72071772813797\n",
      "Finished epoch 274, latest loss 0.7206567525863647\n",
      "Finished epoch 275, latest loss 0.7207192778587341\n",
      "Finished epoch 276, latest loss 0.7200757265090942\n",
      "Finished epoch 277, latest loss 0.7200570702552795\n",
      "Finished epoch 278, latest loss 0.719260573387146\n",
      "Saved improved model\n",
      "Finished epoch 279, latest loss 0.720660388469696\n",
      "Finished epoch 280, latest loss 0.7199580073356628\n",
      "Finished epoch 281, latest loss 0.7199767827987671\n",
      "Finished epoch 282, latest loss 0.7199579477310181\n",
      "Finished epoch 283, latest loss 0.7200661897659302\n",
      "Finished epoch 284, latest loss 0.7199580073356628\n",
      "Finished epoch 285, latest loss 0.7199579477310181\n",
      "Finished epoch 286, latest loss 0.7199578881263733\n",
      "Finished epoch 287, latest loss 0.7199589014053345\n",
      "Finished epoch 288, latest loss 0.7199580073356628\n",
      "Finished epoch 289, latest loss 0.7199580073356628\n",
      "Finished epoch 290, latest loss 0.7199617624282837\n",
      "Finished epoch 291, latest loss 0.7196105718612671\n",
      "Finished epoch 292, latest loss 0.7191343307495117\n",
      "Saved improved model\n",
      "Finished epoch 293, latest loss 0.7199563980102539\n",
      "Finished epoch 294, latest loss 0.7192604541778564\n",
      "Finished epoch 295, latest loss 0.719260573387146\n",
      "Finished epoch 296, latest loss 0.7192606329917908\n",
      "Finished epoch 297, latest loss 0.719260573387146\n",
      "Finished epoch 298, latest loss 0.7192705869674683\n",
      "Finished epoch 299, latest loss 0.7192603945732117\n",
      "Finished epoch 300, latest loss 0.719260573387146\n",
      "Finished epoch 301, latest loss 0.719260573387146\n",
      "Finished epoch 302, latest loss 0.7192606329917908\n",
      "Finished epoch 303, latest loss 0.7192603945732117\n",
      "Finished epoch 304, latest loss 0.719260573387146\n",
      "Finished epoch 305, latest loss 0.7194471955299377\n",
      "Finished epoch 306, latest loss 0.7192604541778564\n",
      "Finished epoch 307, latest loss 0.7192696928977966\n",
      "Finished epoch 308, latest loss 0.7192603945732117\n",
      "Finished epoch 309, latest loss 0.7192604541778564\n",
      "Finished epoch 310, latest loss 0.7192604541778564\n",
      "Finished epoch 311, latest loss 0.7192603945732117\n",
      "Finished epoch 312, latest loss 0.7192604541778564\n",
      "Finished epoch 313, latest loss 0.7192604541778564\n",
      "Finished epoch 314, latest loss 0.7192603945732117\n",
      "Finished epoch 315, latest loss 0.7192603945732117\n",
      "Finished epoch 316, latest loss 0.7192604541778564\n",
      "Finished epoch 317, latest loss 0.7192938923835754\n",
      "Finished epoch 318, latest loss 0.7192603945732117\n",
      "Finished epoch 319, latest loss 0.7192603945732117\n",
      "Finished epoch 320, latest loss 0.7192630171775818\n",
      "Finished epoch 321, latest loss 0.719260573387146\n",
      "Finished epoch 322, latest loss 0.7192603945732117\n",
      "Finished epoch 323, latest loss 0.7195777297019958\n",
      "Finished epoch 324, latest loss 0.7192603349685669\n",
      "Finished epoch 325, latest loss 0.7192603945732117\n",
      "Finished epoch 326, latest loss 0.7192604541778564\n",
      "Finished epoch 327, latest loss 0.7185792326927185\n",
      "Saved improved model\n",
      "Finished epoch 328, latest loss 0.7199580073356628\n",
      "Finished epoch 329, latest loss 0.7185875773429871\n",
      "Finished epoch 330, latest loss 0.7192606329917908\n",
      "Finished epoch 331, latest loss 0.7192603945732117\n",
      "Finished epoch 332, latest loss 0.7195821404457092\n",
      "Finished epoch 333, latest loss 0.7185677289962769\n",
      "Saved improved model\n",
      "Finished epoch 334, latest loss 0.71994549036026\n",
      "Finished epoch 335, latest loss 0.7192603945732117\n",
      "Finished epoch 336, latest loss 0.7192604541778564\n",
      "Finished epoch 337, latest loss 0.7192603945732117\n",
      "Finished epoch 338, latest loss 0.7192604541778564\n",
      "Finished epoch 339, latest loss 0.7192603945732117\n",
      "Finished epoch 340, latest loss 0.7192603945732117\n",
      "Finished epoch 341, latest loss 0.719260573387146\n",
      "Finished epoch 342, latest loss 0.7192606329917908\n",
      "Finished epoch 343, latest loss 0.7192604541778564\n",
      "Finished epoch 344, latest loss 0.719265341758728\n",
      "Finished epoch 345, latest loss 0.7192607522010803\n",
      "Finished epoch 346, latest loss 0.7192603945732117\n",
      "Finished epoch 347, latest loss 0.7192606925964355\n",
      "Finished epoch 348, latest loss 0.7192604541778564\n",
      "Finished epoch 349, latest loss 0.7192603945732117\n",
      "Finished epoch 350, latest loss 0.7192604541778564\n",
      "Finished epoch 351, latest loss 0.7192603945732117\n",
      "Finished epoch 352, latest loss 0.7192603945732117\n",
      "Finished epoch 353, latest loss 0.719260573387146\n",
      "Finished epoch 354, latest loss 0.7192983627319336\n",
      "Finished epoch 355, latest loss 0.7192603945732117\n",
      "Finished epoch 356, latest loss 0.7192603945732117\n",
      "Finished epoch 357, latest loss 0.7192606925964355\n",
      "Finished epoch 358, latest loss 0.7192603945732117\n",
      "Finished epoch 359, latest loss 0.7199580073356628\n",
      "Finished epoch 360, latest loss 0.7192604541778564\n",
      "Finished epoch 361, latest loss 0.7192603945732117\n",
      "Finished epoch 362, latest loss 0.7193623185157776\n",
      "Finished epoch 363, latest loss 0.7189906239509583\n",
      "Finished epoch 364, latest loss 0.7185629606246948\n",
      "Saved improved model\n",
      "Finished epoch 365, latest loss 0.7185629606246948\n",
      "Finished epoch 366, latest loss 0.7185629606246948\n",
      "Finished epoch 367, latest loss 0.7186161279678345\n",
      "Finished epoch 368, latest loss 0.7185707688331604\n",
      "Finished epoch 369, latest loss 0.7185629606246948\n",
      "Finished epoch 370, latest loss 0.7201694250106812\n",
      "Finished epoch 371, latest loss 0.7185630798339844\n",
      "Finished epoch 372, latest loss 0.7185629606246948\n",
      "Finished epoch 373, latest loss 0.7185629606246948\n",
      "Finished epoch 374, latest loss 0.7185629606246948\n",
      "Finished epoch 375, latest loss 0.7185629606246948\n",
      "Finished epoch 376, latest loss 0.7185640931129456\n",
      "Finished epoch 377, latest loss 0.7185629606246948\n",
      "Finished epoch 378, latest loss 0.7185629606246948\n",
      "Finished epoch 379, latest loss 0.7187226414680481\n",
      "Finished epoch 380, latest loss 0.719321072101593\n",
      "Finished epoch 381, latest loss 0.7193199992179871\n",
      "Finished epoch 382, latest loss 0.7187508344650269\n",
      "Finished epoch 383, latest loss 0.7185629606246948\n",
      "Finished epoch 384, latest loss 0.7185629606246948\n",
      "Finished epoch 385, latest loss 0.7186487913131714\n",
      "Finished epoch 386, latest loss 0.7185629606246948\n",
      "Finished epoch 387, latest loss 0.7185629606246948\n",
      "Finished epoch 388, latest loss 0.7185629606246948\n",
      "Finished epoch 389, latest loss 0.7185630798339844\n",
      "Finished epoch 390, latest loss 0.7178657650947571\n",
      "Saved improved model\n",
      "Finished epoch 391, latest loss 0.7186120748519897\n",
      "Finished epoch 392, latest loss 0.7185629606246948\n",
      "Finished epoch 393, latest loss 0.7178654670715332\n",
      "Saved improved model\n",
      "Finished epoch 394, latest loss 0.7178656458854675\n",
      "Finished epoch 395, latest loss 0.7178654670715332\n",
      "Finished epoch 396, latest loss 0.7178654670715332\n",
      "Finished epoch 397, latest loss 0.7178654670715332\n",
      "Finished epoch 398, latest loss 0.7185629606246948\n",
      "Finished epoch 399, latest loss 0.7185627818107605\n",
      "Finished epoch 400, latest loss 0.7178671956062317\n",
      "Finished epoch 401, latest loss 0.7188197374343872\n",
      "Finished epoch 402, latest loss 0.7185632586479187\n",
      "Finished epoch 403, latest loss 0.7185776829719543\n",
      "Finished epoch 404, latest loss 0.7192602753639221\n",
      "Finished epoch 405, latest loss 0.7178732752799988\n",
      "Finished epoch 406, latest loss 0.7184264063835144\n",
      "Finished epoch 407, latest loss 0.7178654670715332\n",
      "Finished epoch 408, latest loss 0.7178654670715332\n",
      "Finished epoch 409, latest loss 0.7178654670715332\n",
      "Finished epoch 410, latest loss 0.7178654670715332\n",
      "Finished epoch 411, latest loss 0.7185629606246948\n",
      "Finished epoch 412, latest loss 0.7178654670715332\n",
      "Finished epoch 413, latest loss 0.7178654670715332\n",
      "Finished epoch 414, latest loss 0.7179076075553894\n",
      "Finished epoch 415, latest loss 0.7185577154159546\n",
      "Finished epoch 416, latest loss 0.7178662419319153\n",
      "Finished epoch 417, latest loss 0.7178654670715332\n",
      "Finished epoch 418, latest loss 0.7178654670715332\n",
      "Finished epoch 419, latest loss 0.7178654670715332\n",
      "Finished epoch 420, latest loss 0.7178654670715332\n",
      "Finished epoch 421, latest loss 0.7185629606246948\n",
      "Finished epoch 422, latest loss 0.7178654670715332\n",
      "Finished epoch 423, latest loss 0.7178654670715332\n",
      "Finished epoch 424, latest loss 0.7178654670715332\n",
      "Finished epoch 425, latest loss 0.7178654670715332\n",
      "Finished epoch 426, latest loss 0.7178654670715332\n",
      "Finished epoch 427, latest loss 0.7178659439086914\n",
      "Finished epoch 428, latest loss 0.7179493308067322\n",
      "Finished epoch 429, latest loss 0.7185629606246948\n",
      "Finished epoch 430, latest loss 0.7178656458854675\n",
      "Finished epoch 431, latest loss 0.7178654670715332\n",
      "Finished epoch 432, latest loss 0.7185627818107605\n",
      "Finished epoch 433, latest loss 0.7178672552108765\n",
      "Finished epoch 434, latest loss 0.7178654670715332\n",
      "Finished epoch 435, latest loss 0.7179600596427917\n",
      "Finished epoch 436, latest loss 0.7187867164611816\n",
      "Finished epoch 437, latest loss 0.7178654670715332\n",
      "Finished epoch 438, latest loss 0.7178654670715332\n",
      "Finished epoch 439, latest loss 0.7178654670715332\n",
      "Finished epoch 440, latest loss 0.7178654670715332\n",
      "Finished epoch 441, latest loss 0.7178656458854675\n",
      "Finished epoch 442, latest loss 0.7178656458854675\n",
      "Finished epoch 443, latest loss 0.7178654670715332\n",
      "Finished epoch 444, latest loss 0.7178654670715332\n",
      "Finished epoch 445, latest loss 0.7178654670715332\n",
      "Finished epoch 446, latest loss 0.7178654670715332\n",
      "Finished epoch 447, latest loss 0.7178654670715332\n",
      "Finished epoch 448, latest loss 0.7178654670715332\n",
      "Finished epoch 449, latest loss 0.7171680331230164\n",
      "Saved improved model\n",
      "Finished epoch 450, latest loss 0.7171680927276611\n",
      "Finished epoch 451, latest loss 0.7186213135719299\n",
      "Finished epoch 452, latest loss 0.7171680331230164\n",
      "Finished epoch 453, latest loss 0.7178654670715332\n",
      "Finished epoch 454, latest loss 0.7171681523323059\n",
      "Finished epoch 455, latest loss 0.7178654670715332\n",
      "Finished epoch 456, latest loss 0.7178400158882141\n",
      "Finished epoch 457, latest loss 0.7171680331230164\n",
      "Finished epoch 458, latest loss 0.7171680331230164\n",
      "Finished epoch 459, latest loss 0.7172281742095947\n",
      "Finished epoch 460, latest loss 0.7178635597229004\n",
      "Finished epoch 461, latest loss 0.7179250121116638\n",
      "Finished epoch 462, latest loss 0.7171687483787537\n",
      "Finished epoch 463, latest loss 0.7172128558158875\n",
      "Finished epoch 464, latest loss 0.717807412147522\n",
      "Finished epoch 465, latest loss 0.7164772152900696\n",
      "Saved improved model\n",
      "Finished epoch 466, latest loss 0.7171680331230164\n",
      "Finished epoch 467, latest loss 0.716476559638977\n",
      "Saved improved model\n",
      "Finished epoch 468, latest loss 0.7171680331230164\n",
      "Finished epoch 469, latest loss 0.7178648710250854\n",
      "Finished epoch 470, latest loss 0.7172214984893799\n",
      "Finished epoch 471, latest loss 0.7171680331230164\n",
      "Finished epoch 472, latest loss 0.7171680331230164\n",
      "Finished epoch 473, latest loss 0.7171680927276611\n",
      "Finished epoch 474, latest loss 0.7171680331230164\n",
      "Finished epoch 475, latest loss 0.7171680331230164\n",
      "Finished epoch 476, latest loss 0.7164706587791443\n",
      "Saved improved model\n",
      "Finished epoch 477, latest loss 0.7168877124786377\n",
      "Finished epoch 478, latest loss 0.7164707183837891\n",
      "Finished epoch 479, latest loss 0.7171681523323059\n",
      "Finished epoch 480, latest loss 0.7171693444252014\n",
      "Finished epoch 481, latest loss 0.7171680331230164\n",
      "Finished epoch 482, latest loss 0.7171680331230164\n",
      "Finished epoch 483, latest loss 0.7171680331230164\n",
      "Finished epoch 484, latest loss 0.7171680331230164\n",
      "Finished epoch 485, latest loss 0.7171680331230164\n",
      "Finished epoch 486, latest loss 0.7179270386695862\n",
      "Finished epoch 487, latest loss 0.7171680331230164\n",
      "Finished epoch 488, latest loss 0.7171680331230164\n",
      "Finished epoch 489, latest loss 0.7179255485534668\n",
      "Finished epoch 490, latest loss 0.7171680331230164\n",
      "Finished epoch 491, latest loss 0.7171680331230164\n",
      "Finished epoch 492, latest loss 0.7164705395698547\n",
      "Saved improved model\n",
      "Finished epoch 493, latest loss 0.7164709568023682\n",
      "Finished epoch 494, latest loss 0.7164705395698547\n",
      "Finished epoch 495, latest loss 0.7179270386695862\n",
      "Finished epoch 496, latest loss 0.7176280617713928\n",
      "Finished epoch 497, latest loss 0.7164707779884338\n",
      "Finished epoch 498, latest loss 0.7164706587791443\n",
      "Finished epoch 499, latest loss 0.7164728045463562\n",
      "Finished epoch 500, latest loss 0.7171608805656433\n",
      "Finished epoch 501, latest loss 0.7171682715415955\n",
      "Finished epoch 502, latest loss 0.7171681523323059\n",
      "Finished epoch 503, latest loss 0.7171680331230164\n",
      "Finished epoch 504, latest loss 0.7171683311462402\n",
      "Finished epoch 505, latest loss 0.7171778678894043\n",
      "Finished epoch 506, latest loss 0.7171680927276611\n",
      "Finished epoch 507, latest loss 0.7171681523323059\n",
      "Finished epoch 508, latest loss 0.7165022492408752\n",
      "Finished epoch 509, latest loss 0.7164708971977234\n",
      "Finished epoch 510, latest loss 0.7171681523323059\n",
      "Finished epoch 511, latest loss 0.7171680331230164\n",
      "Finished epoch 512, latest loss 0.7171681523323059\n",
      "Finished epoch 513, latest loss 0.7171680331230164\n",
      "Finished epoch 514, latest loss 0.7178656458854675\n",
      "Finished epoch 515, latest loss 0.7178655862808228\n",
      "Finished epoch 516, latest loss 0.7178658843040466\n",
      "Finished epoch 517, latest loss 0.7178654074668884\n",
      "Finished epoch 518, latest loss 0.7171680927276611\n",
      "Finished epoch 519, latest loss 0.7164774537086487\n",
      "Finished epoch 520, latest loss 0.7171787023544312\n",
      "Finished epoch 521, latest loss 0.7164707779884338\n",
      "Finished epoch 522, latest loss 0.7171680331230164\n",
      "Finished epoch 523, latest loss 0.7178618907928467\n",
      "Finished epoch 524, latest loss 0.717166006565094\n",
      "Finished epoch 525, latest loss 0.7164706587791443\n",
      "Finished epoch 526, latest loss 0.7171680927276611\n",
      "Finished epoch 527, latest loss 0.7164706587791443\n",
      "Finished epoch 528, latest loss 0.7178675532341003\n",
      "Finished epoch 529, latest loss 0.7164706587791443\n",
      "Finished epoch 530, latest loss 0.7158650159835815\n",
      "Saved improved model\n",
      "Finished epoch 531, latest loss 0.7157735824584961\n",
      "Saved improved model\n",
      "Finished epoch 532, latest loss 0.716532289981842\n",
      "Finished epoch 533, latest loss 0.7164706587791443\n",
      "Finished epoch 534, latest loss 0.7157731056213379\n",
      "Saved improved model\n",
      "Finished epoch 535, latest loss 0.7157731056213379\n",
      "Finished epoch 536, latest loss 0.7157731056213379\n",
      "Finished epoch 537, latest loss 0.7157732844352722\n",
      "Finished epoch 538, latest loss 0.7164710164070129\n",
      "Finished epoch 539, latest loss 0.7157731652259827\n",
      "Finished epoch 540, latest loss 0.7164562940597534\n",
      "Finished epoch 541, latest loss 0.7164837718009949\n",
      "Finished epoch 542, latest loss 0.7157731056213379\n",
      "Finished epoch 543, latest loss 0.7157731652259827\n",
      "Finished epoch 544, latest loss 0.7157731652259827\n",
      "Finished epoch 545, latest loss 0.7164604067802429\n",
      "Finished epoch 546, latest loss 0.7163060903549194\n",
      "Finished epoch 547, latest loss 0.7157744765281677\n",
      "Finished epoch 548, latest loss 0.7157735824584961\n",
      "Finished epoch 549, latest loss 0.7157731056213379\n",
      "Finished epoch 550, latest loss 0.7157731056213379\n",
      "Finished epoch 551, latest loss 0.7157731056213379\n",
      "Finished epoch 552, latest loss 0.7158920168876648\n",
      "Finished epoch 553, latest loss 0.7157731056213379\n",
      "Finished epoch 554, latest loss 0.7157731056213379\n",
      "Finished epoch 555, latest loss 0.7157730460166931\n",
      "Saved improved model\n",
      "Finished epoch 556, latest loss 0.7157730460166931\n",
      "Finished epoch 557, latest loss 0.7157751321792603\n",
      "Finished epoch 558, latest loss 0.7157730460166931\n",
      "Finished epoch 559, latest loss 0.7157730460166931\n",
      "Finished epoch 560, latest loss 0.7157732844352722\n",
      "Finished epoch 561, latest loss 0.7157730460166931\n",
      "Finished epoch 562, latest loss 0.7171675562858582\n",
      "Finished epoch 563, latest loss 0.7159210443496704\n",
      "Finished epoch 564, latest loss 0.7157731056213379\n",
      "Finished epoch 565, latest loss 0.7157784700393677\n",
      "Finished epoch 566, latest loss 0.7154188752174377\n",
      "Saved improved model\n",
      "Finished epoch 567, latest loss 0.7157737016677856\n",
      "Finished epoch 568, latest loss 0.7157732844352722\n",
      "Finished epoch 569, latest loss 0.7157697677612305\n",
      "Finished epoch 570, latest loss 0.715075671672821\n",
      "Saved improved model\n",
      "Finished epoch 571, latest loss 0.7150755524635315\n",
      "Saved improved model\n",
      "Finished epoch 572, latest loss 0.7150757312774658\n",
      "Finished epoch 573, latest loss 0.7150755524635315\n",
      "Finished epoch 574, latest loss 0.7150755524635315\n",
      "Finished epoch 575, latest loss 0.7150757312774658\n",
      "Finished epoch 576, latest loss 0.7150755524635315\n",
      "Finished epoch 577, latest loss 0.7150755524635315\n",
      "Finished epoch 578, latest loss 0.7150755524635315\n",
      "Finished epoch 579, latest loss 0.7150755524635315\n",
      "Finished epoch 580, latest loss 0.715772807598114\n",
      "Finished epoch 581, latest loss 0.7153064012527466\n",
      "Finished epoch 582, latest loss 0.715075671672821\n",
      "Finished epoch 583, latest loss 0.7150755524635315\n",
      "Finished epoch 584, latest loss 0.7150755524635315\n",
      "Finished epoch 585, latest loss 0.7150755524635315\n",
      "Finished epoch 586, latest loss 0.7150755524635315\n",
      "Finished epoch 587, latest loss 0.7150755524635315\n",
      "Finished epoch 588, latest loss 0.7150762677192688\n",
      "Finished epoch 589, latest loss 0.7150763869285583\n",
      "Finished epoch 590, latest loss 0.7150755524635315\n",
      "Finished epoch 591, latest loss 0.7150755524635315\n",
      "Finished epoch 592, latest loss 0.7150755524635315\n",
      "Finished epoch 593, latest loss 0.715075671672821\n",
      "Finished epoch 594, latest loss 0.7150755524635315\n",
      "Finished epoch 595, latest loss 0.7150755524635315\n",
      "Finished epoch 596, latest loss 0.7150755524635315\n",
      "Finished epoch 597, latest loss 0.7152226567268372\n",
      "Finished epoch 598, latest loss 0.715075671672821\n",
      "Finished epoch 599, latest loss 0.7158336043357849\n",
      "Finished epoch 600, latest loss 0.7150755524635315\n",
      "Finished epoch 601, latest loss 0.715075671672821\n",
      "Finished epoch 602, latest loss 0.715075671672821\n",
      "Finished epoch 603, latest loss 0.715075671672821\n",
      "Finished epoch 604, latest loss 0.7150757312774658\n",
      "Finished epoch 605, latest loss 0.7157383561134338\n",
      "Finished epoch 606, latest loss 0.71647047996521\n",
      "Finished epoch 607, latest loss 0.7158135771751404\n",
      "Finished epoch 608, latest loss 0.7150755524635315\n",
      "Finished epoch 609, latest loss 0.7150755524635315\n",
      "Finished epoch 610, latest loss 0.7150755524635315\n",
      "Finished epoch 611, latest loss 0.7150917649269104\n",
      "Finished epoch 612, latest loss 0.7155437469482422\n",
      "Finished epoch 613, latest loss 0.7150755524635315\n",
      "Finished epoch 614, latest loss 0.7150755524635315\n",
      "Finished epoch 615, latest loss 0.7150755524635315\n",
      "Finished epoch 616, latest loss 0.7150755524635315\n",
      "Finished epoch 617, latest loss 0.7150755524635315\n",
      "Finished epoch 618, latest loss 0.7150755524635315\n",
      "Finished epoch 619, latest loss 0.7150755524635315\n",
      "Finished epoch 620, latest loss 0.7150755524635315\n",
      "Finished epoch 621, latest loss 0.7150755524635315\n",
      "Finished epoch 622, latest loss 0.7150755524635315\n",
      "Finished epoch 623, latest loss 0.7150755524635315\n",
      "Finished epoch 624, latest loss 0.7150755524635315\n",
      "Finished epoch 625, latest loss 0.7157731056213379\n",
      "Finished epoch 626, latest loss 0.715770959854126\n",
      "Finished epoch 627, latest loss 0.7150755524635315\n",
      "Finished epoch 628, latest loss 0.7156440019607544\n",
      "Finished epoch 629, latest loss 0.7150755524635315\n",
      "Finished epoch 630, latest loss 0.7150755524635315\n",
      "Finished epoch 631, latest loss 0.715075671672821\n",
      "Finished epoch 632, latest loss 0.7150755524635315\n",
      "Finished epoch 633, latest loss 0.7150755524635315\n",
      "Finished epoch 634, latest loss 0.715075671672821\n",
      "Finished epoch 635, latest loss 0.7150755524635315\n",
      "Finished epoch 636, latest loss 0.715075671672821\n",
      "Finished epoch 637, latest loss 0.7150799036026001\n",
      "Finished epoch 638, latest loss 0.7158954739570618\n",
      "Finished epoch 639, latest loss 0.7150755524635315\n",
      "Finished epoch 640, latest loss 0.7150770425796509\n",
      "Finished epoch 641, latest loss 0.7150757312774658\n",
      "Finished epoch 642, latest loss 0.7153691649436951\n",
      "Finished epoch 643, latest loss 0.7153467535972595\n",
      "Finished epoch 644, latest loss 0.7150755524635315\n",
      "Finished epoch 645, latest loss 0.7157734632492065\n",
      "Finished epoch 646, latest loss 0.715075671672821\n",
      "Finished epoch 647, latest loss 0.715075671672821\n",
      "Finished epoch 648, latest loss 0.7151134610176086\n",
      "Finished epoch 649, latest loss 0.7150755524635315\n",
      "Finished epoch 650, latest loss 0.7150755524635315\n",
      "Finished epoch 651, latest loss 0.715075671672821\n",
      "Finished epoch 652, latest loss 0.7150755524635315\n",
      "Finished epoch 653, latest loss 0.7158342003822327\n",
      "Finished epoch 654, latest loss 0.7150755524635315\n",
      "Finished epoch 655, latest loss 0.7150755524635315\n",
      "Finished epoch 656, latest loss 0.7150755524635315\n",
      "Finished epoch 657, latest loss 0.7150783538818359\n",
      "Finished epoch 658, latest loss 0.7151105403900146\n",
      "Finished epoch 659, latest loss 0.7150755524635315\n",
      "Finished epoch 660, latest loss 0.7150755524635315\n",
      "Finished epoch 661, latest loss 0.7150755524635315\n",
      "Finished epoch 662, latest loss 0.7150755524635315\n",
      "Finished epoch 663, latest loss 0.7150755524635315\n",
      "Finished epoch 664, latest loss 0.7150755524635315\n",
      "Finished epoch 665, latest loss 0.7150755524635315\n",
      "Finished epoch 666, latest loss 0.7150755524635315\n",
      "Finished epoch 667, latest loss 0.7150755524635315\n",
      "Finished epoch 668, latest loss 0.7150755524635315\n",
      "Finished epoch 669, latest loss 0.7158346176147461\n",
      "Finished epoch 670, latest loss 0.7150755524635315\n",
      "Finished epoch 671, latest loss 0.7150755524635315\n",
      "Finished epoch 672, latest loss 0.7150755524635315\n",
      "Finished epoch 673, latest loss 0.7150755524635315\n",
      "Finished epoch 674, latest loss 0.7150755524635315\n",
      "Finished epoch 675, latest loss 0.7150755524635315\n",
      "Finished epoch 676, latest loss 0.7150755524635315\n",
      "Finished epoch 677, latest loss 0.7150755524635315\n",
      "Finished epoch 678, latest loss 0.7150757908821106\n",
      "Finished epoch 679, latest loss 0.7150755524635315\n",
      "Finished epoch 680, latest loss 0.7150755524635315\n",
      "Finished epoch 681, latest loss 0.7150757312774658\n",
      "Finished epoch 682, latest loss 0.7150755524635315\n",
      "Finished epoch 683, latest loss 0.7150777578353882\n",
      "Finished epoch 684, latest loss 0.7150755524635315\n",
      "Finished epoch 685, latest loss 0.7150755524635315\n",
      "Finished epoch 686, latest loss 0.7157730460166931\n",
      "Finished epoch 687, latest loss 0.7150755524635315\n",
      "Finished epoch 688, latest loss 0.7150755524635315\n",
      "Finished epoch 689, latest loss 0.7150755524635315\n",
      "Finished epoch 690, latest loss 0.7150755524635315\n",
      "Finished epoch 691, latest loss 0.7150755524635315\n",
      "Finished epoch 692, latest loss 0.7150755524635315\n",
      "Finished epoch 693, latest loss 0.7150812745094299\n",
      "Finished epoch 694, latest loss 0.7150755524635315\n",
      "Finished epoch 695, latest loss 0.7150757908821106\n",
      "Finished epoch 696, latest loss 0.7150755524635315\n",
      "Finished epoch 697, latest loss 0.7150755524635315\n",
      "Finished epoch 698, latest loss 0.7150755524635315\n",
      "Finished epoch 699, latest loss 0.7150755524635315\n",
      "Finished epoch 700, latest loss 0.7150755524635315\n",
      "Finished epoch 701, latest loss 0.7150755524635315\n",
      "Finished epoch 702, latest loss 0.715075671672821\n",
      "Finished epoch 703, latest loss 0.7150755524635315\n",
      "Finished epoch 704, latest loss 0.7150755524635315\n",
      "Finished epoch 705, latest loss 0.7150755524635315\n",
      "Finished epoch 706, latest loss 0.7150755524635315\n",
      "Finished epoch 707, latest loss 0.7150755524635315\n",
      "Finished epoch 708, latest loss 0.7165325880050659\n",
      "Finished epoch 709, latest loss 0.7150755524635315\n",
      "Finished epoch 710, latest loss 0.7150755524635315\n",
      "Finished epoch 711, latest loss 0.7150755524635315\n",
      "Finished epoch 712, latest loss 0.7150755524635315\n",
      "Finished epoch 713, latest loss 0.7163752317428589\n",
      "Finished epoch 714, latest loss 0.7151076793670654\n",
      "Finished epoch 715, latest loss 0.7150755524635315\n",
      "Finished epoch 716, latest loss 0.7150755524635315\n",
      "Finished epoch 717, latest loss 0.7150755524635315\n",
      "Finished epoch 718, latest loss 0.7150755524635315\n",
      "Finished epoch 719, latest loss 0.7150755524635315\n",
      "Finished epoch 720, latest loss 0.7150755524635315\n",
      "Finished epoch 721, latest loss 0.7150755524635315\n",
      "Finished epoch 722, latest loss 0.7153964638710022\n",
      "Finished epoch 723, latest loss 0.7158346176147461\n",
      "Finished epoch 724, latest loss 0.7150755524635315\n",
      "Finished epoch 725, latest loss 0.7150755524635315\n",
      "Finished epoch 726, latest loss 0.7150755524635315\n",
      "Finished epoch 727, latest loss 0.7150755524635315\n",
      "Finished epoch 728, latest loss 0.7150755524635315\n",
      "Finished epoch 729, latest loss 0.7150755524635315\n",
      "Finished epoch 730, latest loss 0.7150755524635315\n",
      "Finished epoch 731, latest loss 0.7151625156402588\n",
      "Finished epoch 732, latest loss 0.7150755524635315\n",
      "Finished epoch 733, latest loss 0.7150755524635315\n",
      "Finished epoch 734, latest loss 0.7157654762268066\n",
      "Finished epoch 735, latest loss 0.7150755524635315\n",
      "Finished epoch 736, latest loss 0.7150755524635315\n",
      "Finished epoch 737, latest loss 0.7150755524635315\n",
      "Finished epoch 738, latest loss 0.7150755524635315\n",
      "Finished epoch 739, latest loss 0.7155207991600037\n",
      "Finished epoch 740, latest loss 0.7150755524635315\n",
      "Finished epoch 741, latest loss 0.7150755524635315\n",
      "Finished epoch 742, latest loss 0.7150755524635315\n",
      "Finished epoch 743, latest loss 0.7150755524635315\n",
      "Finished epoch 744, latest loss 0.7150755524635315\n",
      "Finished epoch 745, latest loss 0.7150755524635315\n",
      "Finished epoch 746, latest loss 0.7150755524635315\n",
      "Finished epoch 747, latest loss 0.7150755524635315\n",
      "Finished epoch 748, latest loss 0.7156141400337219\n",
      "Finished epoch 749, latest loss 0.7150755524635315\n",
      "Finished epoch 750, latest loss 0.7150755524635315\n",
      "Finished epoch 751, latest loss 0.7150755524635315\n",
      "Finished epoch 752, latest loss 0.7150755524635315\n",
      "Finished epoch 753, latest loss 0.7150755524635315\n",
      "Finished epoch 754, latest loss 0.7150755524635315\n",
      "Finished epoch 755, latest loss 0.7150755524635315\n",
      "Finished epoch 756, latest loss 0.7150755524635315\n",
      "Finished epoch 757, latest loss 0.7150755524635315\n",
      "Finished epoch 758, latest loss 0.7150755524635315\n",
      "Finished epoch 759, latest loss 0.7150755524635315\n",
      "Finished epoch 760, latest loss 0.7150755524635315\n",
      "Finished epoch 761, latest loss 0.7150755524635315\n",
      "Finished epoch 762, latest loss 0.7150755524635315\n",
      "Finished epoch 763, latest loss 0.7150755524635315\n",
      "Finished epoch 764, latest loss 0.7150755524635315\n",
      "Finished epoch 765, latest loss 0.7150759696960449\n",
      "Finished epoch 766, latest loss 0.7157726883888245\n",
      "Finished epoch 767, latest loss 0.7150755524635315\n",
      "Finished epoch 768, latest loss 0.7150763869285583\n",
      "Finished epoch 769, latest loss 0.7150755524635315\n",
      "Finished epoch 770, latest loss 0.7150755524635315\n",
      "Finished epoch 771, latest loss 0.7150755524635315\n",
      "Finished epoch 772, latest loss 0.7150755524635315\n",
      "Finished epoch 773, latest loss 0.7150755524635315\n",
      "Finished epoch 774, latest loss 0.715075671672821\n",
      "Finished epoch 775, latest loss 0.7150755524635315\n",
      "Finished epoch 776, latest loss 0.7150755524635315\n",
      "Finished epoch 777, latest loss 0.7152886986732483\n",
      "Finished epoch 778, latest loss 0.7150755524635315\n",
      "Finished epoch 779, latest loss 0.7150755524635315\n",
      "Finished epoch 780, latest loss 0.7150755524635315\n",
      "Finished epoch 781, latest loss 0.7150755524635315\n",
      "Finished epoch 782, latest loss 0.7150755524635315\n",
      "Finished epoch 783, latest loss 0.7150835990905762\n",
      "Finished epoch 784, latest loss 0.7150755524635315\n",
      "Finished epoch 785, latest loss 0.7150755524635315\n",
      "Finished epoch 786, latest loss 0.7150755524635315\n",
      "Finished epoch 787, latest loss 0.7150755524635315\n",
      "Finished epoch 788, latest loss 0.7150755524635315\n",
      "Finished epoch 789, latest loss 0.7150755524635315\n",
      "Finished epoch 790, latest loss 0.7157730460166931\n",
      "Finished epoch 791, latest loss 0.7150755524635315\n",
      "Finished epoch 792, latest loss 0.7150755524635315\n",
      "Finished epoch 793, latest loss 0.7150755524635315\n",
      "Finished epoch 794, latest loss 0.7150755524635315\n",
      "Finished epoch 795, latest loss 0.7150755524635315\n",
      "Finished epoch 796, latest loss 0.7157674431800842\n",
      "Finished epoch 797, latest loss 0.7150755524635315\n",
      "Finished epoch 798, latest loss 0.7150755524635315\n",
      "Finished epoch 799, latest loss 0.7150844931602478\n",
      "Finished epoch 800, latest loss 0.715155839920044\n",
      "Finished epoch 801, latest loss 0.7150755524635315\n",
      "Finished epoch 802, latest loss 0.7151526212692261\n",
      "Finished epoch 803, latest loss 0.7150755524635315\n",
      "Finished epoch 804, latest loss 0.7150755524635315\n",
      "Finished epoch 805, latest loss 0.715075671672821\n",
      "Finished epoch 806, latest loss 0.7150755524635315\n",
      "Finished epoch 807, latest loss 0.7150755524635315\n",
      "Finished epoch 808, latest loss 0.7150755524635315\n",
      "Finished epoch 809, latest loss 0.7150777578353882\n",
      "Finished epoch 810, latest loss 0.7150755524635315\n",
      "Finished epoch 811, latest loss 0.7150755524635315\n",
      "Finished epoch 812, latest loss 0.7150755524635315\n",
      "Finished epoch 813, latest loss 0.7150755524635315\n",
      "Finished epoch 814, latest loss 0.7157730460166931\n",
      "Finished epoch 815, latest loss 0.7150755524635315\n",
      "Finished epoch 816, latest loss 0.7150755524635315\n",
      "Finished epoch 817, latest loss 0.7150755524635315\n",
      "Finished epoch 818, latest loss 0.7150755524635315\n",
      "Finished epoch 819, latest loss 0.7156437635421753\n",
      "Finished epoch 820, latest loss 0.7150755524635315\n",
      "Finished epoch 821, latest loss 0.7150755524635315\n",
      "Finished epoch 822, latest loss 0.7150755524635315\n",
      "Finished epoch 823, latest loss 0.7150755524635315\n",
      "Finished epoch 824, latest loss 0.7150755524635315\n",
      "Finished epoch 825, latest loss 0.7150755524635315\n",
      "Finished epoch 826, latest loss 0.7150755524635315\n",
      "Finished epoch 827, latest loss 0.7150755524635315\n",
      "Finished epoch 828, latest loss 0.7150755524635315\n",
      "Finished epoch 829, latest loss 0.7150755524635315\n",
      "Finished epoch 830, latest loss 0.7150755524635315\n",
      "Finished epoch 831, latest loss 0.7150755524635315\n",
      "Finished epoch 832, latest loss 0.715075671672821\n",
      "Finished epoch 833, latest loss 0.7150755524635315\n",
      "Finished epoch 834, latest loss 0.7150755524635315\n",
      "Finished epoch 835, latest loss 0.7150755524635315\n",
      "Finished epoch 836, latest loss 0.7150755524635315\n",
      "Finished epoch 837, latest loss 0.7150755524635315\n",
      "Finished epoch 838, latest loss 0.7150755524635315\n",
      "Finished epoch 839, latest loss 0.715075671672821\n",
      "Finished epoch 840, latest loss 0.7150755524635315\n",
      "Finished epoch 841, latest loss 0.7150738835334778\n",
      "Saved improved model\n",
      "Finished epoch 842, latest loss 0.715753972530365\n",
      "Finished epoch 843, latest loss 0.7150755524635315\n",
      "Finished epoch 844, latest loss 0.7150755524635315\n",
      "Finished epoch 845, latest loss 0.7150755524635315\n",
      "Finished epoch 846, latest loss 0.7150867581367493\n",
      "Finished epoch 847, latest loss 0.7150755524635315\n",
      "Finished epoch 848, latest loss 0.7150755524635315\n",
      "Finished epoch 849, latest loss 0.7150755524635315\n",
      "Finished epoch 850, latest loss 0.7150755524635315\n",
      "Finished epoch 851, latest loss 0.715075671672821\n",
      "Finished epoch 852, latest loss 0.7157291769981384\n",
      "Finished epoch 853, latest loss 0.7150755524635315\n",
      "Finished epoch 854, latest loss 0.7150755524635315\n",
      "Finished epoch 855, latest loss 0.7157730460166931\n",
      "Finished epoch 856, latest loss 0.7150755524635315\n",
      "Finished epoch 857, latest loss 0.7150755524635315\n",
      "Finished epoch 858, latest loss 0.7150755524635315\n",
      "Finished epoch 859, latest loss 0.7150755524635315\n",
      "Finished epoch 860, latest loss 0.7150755524635315\n",
      "Finished epoch 861, latest loss 0.7150755524635315\n",
      "Finished epoch 862, latest loss 0.7150755524635315\n",
      "Finished epoch 863, latest loss 0.7158346176147461\n",
      "Finished epoch 864, latest loss 0.7150755524635315\n",
      "Finished epoch 865, latest loss 0.7154567837715149\n",
      "Finished epoch 866, latest loss 0.7150755524635315\n",
      "Finished epoch 867, latest loss 0.7150755524635315\n",
      "Finished epoch 868, latest loss 0.7150755524635315\n",
      "Finished epoch 869, latest loss 0.7150821685791016\n",
      "Finished epoch 870, latest loss 0.7150755524635315\n",
      "Finished epoch 871, latest loss 0.7150755524635315\n",
      "Finished epoch 872, latest loss 0.7150755524635315\n",
      "Finished epoch 873, latest loss 0.7150755524635315\n",
      "Finished epoch 874, latest loss 0.7150755524635315\n",
      "Finished epoch 875, latest loss 0.7150755524635315\n",
      "Finished epoch 876, latest loss 0.7150755524635315\n",
      "Finished epoch 877, latest loss 0.7158346176147461\n",
      "Finished epoch 878, latest loss 0.7158379554748535\n",
      "Finished epoch 879, latest loss 0.7158346176147461\n",
      "Finished epoch 880, latest loss 0.7158346176147461\n",
      "Finished epoch 881, latest loss 0.7158346176147461\n",
      "Finished epoch 882, latest loss 0.7150755524635315\n",
      "Finished epoch 883, latest loss 0.7157730460166931\n",
      "Finished epoch 884, latest loss 0.7157730460166931\n",
      "Finished epoch 885, latest loss 0.7150755524635315\n",
      "Finished epoch 886, latest loss 0.7150755524635315\n",
      "Finished epoch 887, latest loss 0.7150755524635315\n",
      "Finished epoch 888, latest loss 0.7150755524635315\n",
      "Finished epoch 889, latest loss 0.7157730460166931\n",
      "Finished epoch 890, latest loss 0.7151715755462646\n",
      "Finished epoch 891, latest loss 0.7150755524635315\n",
      "Finished epoch 892, latest loss 0.7150755524635315\n",
      "Finished epoch 893, latest loss 0.7150755524635315\n",
      "Finished epoch 894, latest loss 0.7151376605033875\n",
      "Finished epoch 895, latest loss 0.7150755524635315\n",
      "Finished epoch 896, latest loss 0.7150755524635315\n",
      "Finished epoch 897, latest loss 0.7150755524635315\n",
      "Finished epoch 898, latest loss 0.7150755524635315\n",
      "Finished epoch 899, latest loss 0.7150755524635315\n",
      "Finished epoch 900, latest loss 0.7150755524635315\n",
      "Finished epoch 901, latest loss 0.715075671672821\n",
      "Finished epoch 902, latest loss 0.7152087688446045\n",
      "Finished epoch 903, latest loss 0.7150755524635315\n",
      "Finished epoch 904, latest loss 0.7150755524635315\n",
      "Finished epoch 905, latest loss 0.7150755524635315\n",
      "Finished epoch 906, latest loss 0.7150755524635315\n",
      "Finished epoch 907, latest loss 0.7157621383666992\n",
      "Finished epoch 908, latest loss 0.7150755524635315\n",
      "Finished epoch 909, latest loss 0.7150755524635315\n",
      "Finished epoch 910, latest loss 0.7150755524635315\n",
      "Finished epoch 911, latest loss 0.7150755524635315\n",
      "Finished epoch 912, latest loss 0.715075671672821\n",
      "Finished epoch 913, latest loss 0.7150755524635315\n",
      "Finished epoch 914, latest loss 0.7150755524635315\n",
      "Finished epoch 915, latest loss 0.7150755524635315\n",
      "Finished epoch 916, latest loss 0.7150755524635315\n",
      "Finished epoch 917, latest loss 0.7150755524635315\n",
      "Finished epoch 918, latest loss 0.7150755524635315\n",
      "Finished epoch 919, latest loss 0.7150755524635315\n",
      "Finished epoch 920, latest loss 0.7150755524635315\n",
      "Finished epoch 921, latest loss 0.7150755524635315\n",
      "Finished epoch 922, latest loss 0.7150755524635315\n",
      "Finished epoch 923, latest loss 0.7150755524635315\n",
      "Finished epoch 924, latest loss 0.7150755524635315\n",
      "Finished epoch 925, latest loss 0.7150755524635315\n",
      "Finished epoch 926, latest loss 0.7150755524635315\n",
      "Finished epoch 927, latest loss 0.7150755524635315\n",
      "Finished epoch 928, latest loss 0.7150755524635315\n",
      "Finished epoch 929, latest loss 0.7150755524635315\n",
      "Finished epoch 930, latest loss 0.7150755524635315\n",
      "Finished epoch 931, latest loss 0.7150755524635315\n",
      "Finished epoch 932, latest loss 0.7150755524635315\n",
      "Finished epoch 933, latest loss 0.7150755524635315\n",
      "Finished epoch 934, latest loss 0.7150755524635315\n",
      "Finished epoch 935, latest loss 0.7164300680160522\n",
      "Finished epoch 936, latest loss 0.7150755524635315\n",
      "Finished epoch 937, latest loss 0.7150755524635315\n",
      "Finished epoch 938, latest loss 0.7152800559997559\n",
      "Finished epoch 939, latest loss 0.7150755524635315\n",
      "Finished epoch 940, latest loss 0.7150755524635315\n",
      "Finished epoch 941, latest loss 0.7150755524635315\n",
      "Finished epoch 942, latest loss 0.7150755524635315\n",
      "Finished epoch 943, latest loss 0.7150755524635315\n",
      "Finished epoch 944, latest loss 0.7150755524635315\n",
      "Finished epoch 945, latest loss 0.7150755524635315\n",
      "Finished epoch 946, latest loss 0.7150755524635315\n",
      "Finished epoch 947, latest loss 0.7150755524635315\n",
      "Finished epoch 948, latest loss 0.7150755524635315\n",
      "Finished epoch 949, latest loss 0.7150755524635315\n",
      "Finished epoch 950, latest loss 0.7158344984054565\n",
      "Finished epoch 951, latest loss 0.7150755524635315\n",
      "Finished epoch 952, latest loss 0.7150819301605225\n",
      "Finished epoch 953, latest loss 0.7150755524635315\n",
      "Finished epoch 954, latest loss 0.715075671672821\n",
      "Finished epoch 955, latest loss 0.7150755524635315\n",
      "Finished epoch 956, latest loss 0.7150755524635315\n",
      "Finished epoch 957, latest loss 0.7150755524635315\n",
      "Finished epoch 958, latest loss 0.7150755524635315\n",
      "Finished epoch 959, latest loss 0.7150755524635315\n",
      "Finished epoch 960, latest loss 0.7150755524635315\n",
      "Finished epoch 961, latest loss 0.7150755524635315\n",
      "Finished epoch 962, latest loss 0.7150755524635315\n",
      "Finished epoch 963, latest loss 0.7150755524635315\n",
      "Finished epoch 964, latest loss 0.7153019905090332\n",
      "Finished epoch 965, latest loss 0.7150755524635315\n",
      "Finished epoch 966, latest loss 0.7150755524635315\n",
      "Finished epoch 967, latest loss 0.7150755524635315\n",
      "Finished epoch 968, latest loss 0.7150755524635315\n",
      "Finished epoch 969, latest loss 0.7150755524635315\n",
      "Finished epoch 970, latest loss 0.7150755524635315\n",
      "Finished epoch 971, latest loss 0.715075671672821\n",
      "Finished epoch 972, latest loss 0.7150755524635315\n",
      "Finished epoch 973, latest loss 0.7150755524635315\n",
      "Finished epoch 974, latest loss 0.7150755524635315\n",
      "Finished epoch 975, latest loss 0.7150755524635315\n",
      "Finished epoch 976, latest loss 0.7150755524635315\n",
      "Finished epoch 977, latest loss 0.7150755524635315\n",
      "Finished epoch 978, latest loss 0.7150755524635315\n",
      "Finished epoch 979, latest loss 0.7150755524635315\n",
      "Finished epoch 980, latest loss 0.7150755524635315\n",
      "Finished epoch 981, latest loss 0.7150755524635315\n",
      "Finished epoch 982, latest loss 0.7150757312774658\n",
      "Finished epoch 983, latest loss 0.7150755524635315\n",
      "Finished epoch 984, latest loss 0.7150755524635315\n",
      "Finished epoch 985, latest loss 0.7150755524635315\n",
      "Finished epoch 986, latest loss 0.7150755524635315\n",
      "Finished epoch 987, latest loss 0.7151311635971069\n",
      "Finished epoch 988, latest loss 0.7150755524635315\n",
      "Finished epoch 989, latest loss 0.7150755524635315\n",
      "Finished epoch 990, latest loss 0.7150755524635315\n",
      "Finished epoch 991, latest loss 0.7150996327400208\n",
      "Finished epoch 992, latest loss 0.7150755524635315\n",
      "Finished epoch 993, latest loss 0.7150755524635315\n",
      "Finished epoch 994, latest loss 0.7150755524635315\n",
      "Finished epoch 995, latest loss 0.7150755524635315\n",
      "Finished epoch 996, latest loss 0.7150755524635315\n",
      "Finished epoch 997, latest loss 0.7158346176147461\n",
      "Finished epoch 998, latest loss 0.7150755524635315\n",
      "Finished epoch 999, latest loss 0.7150755524635315\n",
      "Finished epoch 1000, latest loss 0.7150755524635315\n",
      "Finished epoch 1001, latest loss 0.715075671672821\n",
      "Finished epoch 1002, latest loss 0.7150755524635315\n",
      "Finished epoch 1003, latest loss 0.7150755524635315\n",
      "Finished epoch 1004, latest loss 0.7150755524635315\n",
      "Finished epoch 1005, latest loss 0.7150755524635315\n",
      "Finished epoch 1006, latest loss 0.7150835990905762\n",
      "Finished epoch 1007, latest loss 0.7150755524635315\n",
      "Finished epoch 1008, latest loss 0.7150755524635315\n",
      "Finished epoch 1009, latest loss 0.7150755524635315\n",
      "Finished epoch 1010, latest loss 0.7151374220848083\n",
      "Finished epoch 1011, latest loss 0.7150755524635315\n",
      "Finished epoch 1012, latest loss 0.7150755524635315\n",
      "Finished epoch 1013, latest loss 0.7150755524635315\n",
      "Finished epoch 1014, latest loss 0.7150755524635315\n",
      "Finished epoch 1015, latest loss 0.7150755524635315\n",
      "Finished epoch 1016, latest loss 0.7150755524635315\n",
      "Finished epoch 1017, latest loss 0.7150755524635315\n",
      "Finished epoch 1018, latest loss 0.7150755524635315\n",
      "Finished epoch 1019, latest loss 0.7150755524635315\n",
      "Finished epoch 1020, latest loss 0.7165320515632629\n",
      "Finished epoch 1021, latest loss 0.7157730460166931\n",
      "Finished epoch 1022, latest loss 0.7160877585411072\n",
      "Finished epoch 1023, latest loss 0.7150755524635315\n",
      "Finished epoch 1024, latest loss 0.7157711386680603\n",
      "Finished epoch 1025, latest loss 0.7151175141334534\n",
      "Finished epoch 1026, latest loss 0.7150755524635315\n",
      "Finished epoch 1027, latest loss 0.7150755524635315\n",
      "Finished epoch 1028, latest loss 0.7158346176147461\n",
      "Finished epoch 1029, latest loss 0.7150755524635315\n",
      "Finished epoch 1030, latest loss 0.715075671672821\n",
      "Finished epoch 1031, latest loss 0.7158358693122864\n",
      "Finished epoch 1032, latest loss 0.7150755524635315\n",
      "Finished epoch 1033, latest loss 0.7157727479934692\n",
      "Finished epoch 1034, latest loss 0.7150755524635315\n",
      "Finished epoch 1035, latest loss 0.7150755524635315\n",
      "Finished epoch 1036, latest loss 0.7150755524635315\n",
      "Finished epoch 1037, latest loss 0.7150755524635315\n",
      "Finished epoch 1038, latest loss 0.7150755524635315\n",
      "Finished epoch 1039, latest loss 0.7150755524635315\n",
      "Finished epoch 1040, latest loss 0.7150755524635315\n",
      "Finished epoch 1041, latest loss 0.7158346176147461\n",
      "Finished epoch 1042, latest loss 0.7150755524635315\n",
      "Finished epoch 1043, latest loss 0.7150755524635315\n",
      "Finished epoch 1044, latest loss 0.7157730460166931\n",
      "Finished epoch 1045, latest loss 0.7157730460166931\n",
      "Finished epoch 1046, latest loss 0.7157730460166931\n",
      "Finished epoch 1047, latest loss 0.715075671672821\n",
      "Finished epoch 1048, latest loss 0.7150760889053345\n",
      "Finished epoch 1049, latest loss 0.7150804400444031\n",
      "Finished epoch 1050, latest loss 0.7157730460166931\n",
      "Finished epoch 1051, latest loss 0.7158346176147461\n",
      "Finished epoch 1052, latest loss 0.7157730460166931\n",
      "Finished epoch 1053, latest loss 0.7150755524635315\n",
      "Finished epoch 1054, latest loss 0.7150755524635315\n",
      "Finished epoch 1055, latest loss 0.7150755524635315\n",
      "Finished epoch 1056, latest loss 0.7158346772193909\n",
      "Finished epoch 1057, latest loss 0.7158346176147461\n",
      "Finished epoch 1058, latest loss 0.7151194214820862\n",
      "Finished epoch 1059, latest loss 0.7150755524635315\n",
      "Finished epoch 1060, latest loss 0.715772807598114\n",
      "Finished epoch 1061, latest loss 0.7150755524635315\n",
      "Finished epoch 1062, latest loss 0.7157730460166931\n",
      "Finished epoch 1063, latest loss 0.7150755524635315\n",
      "Finished epoch 1064, latest loss 0.7150755524635315\n",
      "Finished epoch 1065, latest loss 0.7150755524635315\n",
      "Finished epoch 1066, latest loss 0.7150755524635315\n",
      "Finished epoch 1067, latest loss 0.7150755524635315\n",
      "Finished epoch 1068, latest loss 0.7150755524635315\n",
      "Finished epoch 1069, latest loss 0.7150755524635315\n",
      "Finished epoch 1070, latest loss 0.7150755524635315\n",
      "Finished epoch 1071, latest loss 0.7150755524635315\n",
      "Finished epoch 1072, latest loss 0.7150755524635315\n",
      "Finished epoch 1073, latest loss 0.7150755524635315\n",
      "Finished epoch 1074, latest loss 0.7150755524635315\n",
      "Finished epoch 1075, latest loss 0.7150755524635315\n",
      "Finished epoch 1076, latest loss 0.7150755524635315\n",
      "Finished epoch 1077, latest loss 0.7150755524635315\n",
      "Finished epoch 1078, latest loss 0.7150755524635315\n",
      "Finished epoch 1079, latest loss 0.7150755524635315\n",
      "Finished epoch 1080, latest loss 0.7150755524635315\n",
      "Finished epoch 1081, latest loss 0.7150755524635315\n",
      "Finished epoch 1082, latest loss 0.7157730460166931\n",
      "Finished epoch 1083, latest loss 0.7157730460166931\n",
      "Finished epoch 1084, latest loss 0.7157743573188782\n",
      "Finished epoch 1085, latest loss 0.7150993943214417\n",
      "Finished epoch 1086, latest loss 0.7150755524635315\n",
      "Finished epoch 1087, latest loss 0.7150755524635315\n",
      "Finished epoch 1088, latest loss 0.7157732844352722\n",
      "Finished epoch 1089, latest loss 0.7150796055793762\n",
      "Finished epoch 1090, latest loss 0.715454638004303\n",
      "Finished epoch 1091, latest loss 0.7150755524635315\n",
      "Finished epoch 1092, latest loss 0.7150755524635315\n",
      "Finished epoch 1093, latest loss 0.7150755524635315\n",
      "Finished epoch 1094, latest loss 0.7150755524635315\n",
      "Finished epoch 1095, latest loss 0.7152989506721497\n",
      "Finished epoch 1096, latest loss 0.7150755524635315\n",
      "Finished epoch 1097, latest loss 0.7150755524635315\n",
      "Finished epoch 1098, latest loss 0.7150755524635315\n",
      "Finished epoch 1099, latest loss 0.7150755524635315\n",
      "Finished epoch 1100, latest loss 0.7150755524635315\n",
      "Finished epoch 1101, latest loss 0.7150755524635315\n",
      "Finished epoch 1102, latest loss 0.7150755524635315\n",
      "Finished epoch 1103, latest loss 0.7150755524635315\n",
      "Finished epoch 1104, latest loss 0.7150755524635315\n",
      "Finished epoch 1105, latest loss 0.7158346176147461\n",
      "Finished epoch 1106, latest loss 0.7158346176147461\n",
      "Finished epoch 1107, latest loss 0.7158346176147461\n",
      "Finished epoch 1108, latest loss 0.7158346176147461\n",
      "Finished epoch 1109, latest loss 0.7158346176147461\n",
      "Finished epoch 1110, latest loss 0.7157771587371826\n",
      "Finished epoch 1111, latest loss 0.7150755524635315\n",
      "Finished epoch 1112, latest loss 0.7150755524635315\n",
      "Finished epoch 1113, latest loss 0.7150755524635315\n",
      "Finished epoch 1114, latest loss 0.7153372168540955\n",
      "Finished epoch 1115, latest loss 0.7150755524635315\n",
      "Finished epoch 1116, latest loss 0.7150755524635315\n",
      "Finished epoch 1117, latest loss 0.7150755524635315\n",
      "Finished epoch 1118, latest loss 0.7150755524635315\n",
      "Finished epoch 1119, latest loss 0.7150755524635315\n",
      "Finished epoch 1120, latest loss 0.7150755524635315\n",
      "Finished epoch 1121, latest loss 0.7150755524635315\n",
      "Finished epoch 1122, latest loss 0.7150755524635315\n",
      "Finished epoch 1123, latest loss 0.7154079675674438\n",
      "Finished epoch 1124, latest loss 0.7150755524635315\n",
      "Finished epoch 1125, latest loss 0.7150755524635315\n",
      "Finished epoch 1126, latest loss 0.7150755524635315\n",
      "Finished epoch 1127, latest loss 0.7150755524635315\n",
      "Finished epoch 1128, latest loss 0.7150755524635315\n",
      "Finished epoch 1129, latest loss 0.7150755524635315\n",
      "Finished epoch 1130, latest loss 0.7150755524635315\n",
      "Finished epoch 1131, latest loss 0.7150755524635315\n",
      "Finished epoch 1132, latest loss 0.7150755524635315\n",
      "Finished epoch 1133, latest loss 0.7150755524635315\n",
      "Finished epoch 1134, latest loss 0.7150755524635315\n",
      "Finished epoch 1135, latest loss 0.7150755524635315\n",
      "Finished epoch 1136, latest loss 0.7150755524635315\n",
      "Finished epoch 1137, latest loss 0.715075671672821\n",
      "Finished epoch 1138, latest loss 0.7151595950126648\n",
      "Finished epoch 1139, latest loss 0.7173520922660828\n",
      "Finished epoch 1140, latest loss 0.7158346176147461\n",
      "Finished epoch 1141, latest loss 0.7150755524635315\n",
      "Finished epoch 1142, latest loss 0.7158340811729431\n",
      "Finished epoch 1143, latest loss 0.7154827117919922\n",
      "Finished epoch 1144, latest loss 0.7150755524635315\n",
      "Finished epoch 1145, latest loss 0.7150755524635315\n",
      "Finished epoch 1146, latest loss 0.7158346176147461\n",
      "Finished epoch 1147, latest loss 0.7150755524635315\n",
      "Finished epoch 1148, latest loss 0.7157729864120483\n",
      "Finished epoch 1149, latest loss 0.7165019512176514\n",
      "Finished epoch 1150, latest loss 0.7150755524635315\n",
      "Finished epoch 1151, latest loss 0.7150755524635315\n",
      "Finished epoch 1152, latest loss 0.7150755524635315\n",
      "Finished epoch 1153, latest loss 0.7157414555549622\n",
      "Finished epoch 1154, latest loss 0.7150755524635315\n",
      "Finished epoch 1155, latest loss 0.7150755524635315\n",
      "Finished epoch 1156, latest loss 0.7152407765388489\n",
      "Finished epoch 1157, latest loss 0.7157650589942932\n",
      "Finished epoch 1158, latest loss 0.7158346176147461\n",
      "Finished epoch 1159, latest loss 0.7150755524635315\n",
      "Finished epoch 1160, latest loss 0.7158341407775879\n",
      "Finished epoch 1161, latest loss 0.7150755524635315\n",
      "Finished epoch 1162, latest loss 0.7150755524635315\n",
      "Finished epoch 1163, latest loss 0.7150755524635315\n",
      "Finished epoch 1164, latest loss 0.7150755524635315\n",
      "Finished epoch 1165, latest loss 0.7157730460166931\n",
      "Finished epoch 1166, latest loss 0.7150755524635315\n",
      "Finished epoch 1167, latest loss 0.7150755524635315\n",
      "Finished epoch 1168, latest loss 0.7150755524635315\n",
      "Finished epoch 1169, latest loss 0.7150755524635315\n",
      "Finished epoch 1170, latest loss 0.7150755524635315\n",
      "Finished epoch 1171, latest loss 0.7150755524635315\n",
      "Finished epoch 1172, latest loss 0.7150755524635315\n",
      "Finished epoch 1173, latest loss 0.7150755524635315\n",
      "Finished epoch 1174, latest loss 0.7150755524635315\n",
      "Finished epoch 1175, latest loss 0.7150755524635315\n",
      "Finished epoch 1176, latest loss 0.7150755524635315\n",
      "Finished epoch 1177, latest loss 0.7157703638076782\n",
      "Finished epoch 1178, latest loss 0.7150755524635315\n",
      "Finished epoch 1179, latest loss 0.7150755524635315\n",
      "Finished epoch 1180, latest loss 0.7158346176147461\n",
      "Finished epoch 1181, latest loss 0.7150755524635315\n",
      "Finished epoch 1182, latest loss 0.7150755524635315\n",
      "Finished epoch 1183, latest loss 0.7150755524635315\n",
      "Finished epoch 1184, latest loss 0.7150755524635315\n",
      "Finished epoch 1185, latest loss 0.7150755524635315\n",
      "Finished epoch 1186, latest loss 0.7150755524635315\n",
      "Finished epoch 1187, latest loss 0.7159938216209412\n",
      "Finished epoch 1188, latest loss 0.7150755524635315\n",
      "Finished epoch 1189, latest loss 0.7150755524635315\n",
      "Finished epoch 1190, latest loss 0.7150755524635315\n",
      "Finished epoch 1191, latest loss 0.7150755524635315\n",
      "Finished epoch 1192, latest loss 0.7150755524635315\n",
      "Finished epoch 1193, latest loss 0.715075671672821\n",
      "Finished epoch 1194, latest loss 0.7158977389335632\n",
      "Finished epoch 1195, latest loss 0.7150843739509583\n",
      "Finished epoch 1196, latest loss 0.7150755524635315\n",
      "Finished epoch 1197, latest loss 0.7150755524635315\n",
      "Finished epoch 1198, latest loss 0.7150755524635315\n",
      "Finished epoch 1199, latest loss 0.7150755524635315\n",
      "Finished epoch 1200, latest loss 0.7150755524635315\n",
      "Finished epoch 1201, latest loss 0.7143781185150146\n",
      "Saved improved model\n",
      "Finished epoch 1202, latest loss 0.7150755524635315\n",
      "Finished epoch 1203, latest loss 0.7150755524635315\n",
      "Finished epoch 1204, latest loss 0.7154232859611511\n",
      "Finished epoch 1205, latest loss 0.7153106927871704\n",
      "Finished epoch 1206, latest loss 0.7150755524635315\n",
      "Finished epoch 1207, latest loss 0.7150755524635315\n",
      "Finished epoch 1208, latest loss 0.7150755524635315\n",
      "Finished epoch 1209, latest loss 0.7150755524635315\n",
      "Finished epoch 1210, latest loss 0.7150755524635315\n",
      "Finished epoch 1211, latest loss 0.7150755524635315\n",
      "Finished epoch 1212, latest loss 0.7150946259498596\n",
      "Finished epoch 1213, latest loss 0.7150755524635315\n",
      "Finished epoch 1214, latest loss 0.7150755524635315\n",
      "Finished epoch 1215, latest loss 0.7150755524635315\n",
      "Finished epoch 1216, latest loss 0.7150755524635315\n",
      "Finished epoch 1217, latest loss 0.7150755524635315\n",
      "Finished epoch 1218, latest loss 0.7150755524635315\n",
      "Finished epoch 1219, latest loss 0.7150755524635315\n",
      "Finished epoch 1220, latest loss 0.7150755524635315\n",
      "Finished epoch 1221, latest loss 0.7150755524635315\n",
      "Finished epoch 1222, latest loss 0.7150755524635315\n",
      "Finished epoch 1223, latest loss 0.7150755524635315\n",
      "Finished epoch 1224, latest loss 0.7150755524635315\n",
      "Finished epoch 1225, latest loss 0.7150755524635315\n",
      "Finished epoch 1226, latest loss 0.7158346176147461\n",
      "Finished epoch 1227, latest loss 0.7158346176147461\n",
      "Finished epoch 1228, latest loss 0.7158346176147461\n",
      "Finished epoch 1229, latest loss 0.7158346176147461\n",
      "Finished epoch 1230, latest loss 0.7158346176147461\n",
      "Finished epoch 1231, latest loss 0.7158346176147461\n",
      "Finished epoch 1232, latest loss 0.7158346176147461\n",
      "Finished epoch 1233, latest loss 0.7158346176147461\n",
      "Finished epoch 1234, latest loss 0.7158346176147461\n",
      "Finished epoch 1235, latest loss 0.7150755524635315\n",
      "Finished epoch 1236, latest loss 0.7158346176147461\n",
      "Finished epoch 1237, latest loss 0.7158346176147461\n",
      "Finished epoch 1238, latest loss 0.7158346176147461\n",
      "Finished epoch 1239, latest loss 0.7158346176147461\n",
      "Finished epoch 1240, latest loss 0.7158346176147461\n",
      "Finished epoch 1241, latest loss 0.7158346176147461\n",
      "Finished epoch 1242, latest loss 0.7158346176147461\n",
      "Finished epoch 1243, latest loss 0.7158346176147461\n",
      "Finished epoch 1244, latest loss 0.7158346176147461\n",
      "Finished epoch 1245, latest loss 0.7158346176147461\n",
      "Finished epoch 1246, latest loss 0.7158346176147461\n",
      "Finished epoch 1247, latest loss 0.7158346176147461\n",
      "Finished epoch 1248, latest loss 0.7158346176147461\n",
      "Finished epoch 1249, latest loss 0.7158346176147461\n",
      "Finished epoch 1250, latest loss 0.7158346176147461\n",
      "Finished epoch 1251, latest loss 0.7158346176147461\n",
      "Finished epoch 1252, latest loss 0.7158346176147461\n",
      "Finished epoch 1253, latest loss 0.7158346176147461\n",
      "Finished epoch 1254, latest loss 0.7158346176147461\n",
      "Finished epoch 1255, latest loss 0.7158346176147461\n",
      "Finished epoch 1256, latest loss 0.7158346176147461\n",
      "Finished epoch 1257, latest loss 0.7150755524635315\n",
      "Finished epoch 1258, latest loss 0.7158346176147461\n",
      "Finished epoch 1259, latest loss 0.7150755524635315\n",
      "Finished epoch 1260, latest loss 0.7150766253471375\n",
      "Finished epoch 1261, latest loss 0.7157696485519409\n",
      "Finished epoch 1262, latest loss 0.7150755524635315\n",
      "Finished epoch 1263, latest loss 0.7150755524635315\n",
      "Finished epoch 1264, latest loss 0.7150755524635315\n",
      "Finished epoch 1265, latest loss 0.7150755524635315\n",
      "Finished epoch 1266, latest loss 0.7150755524635315\n",
      "Finished epoch 1267, latest loss 0.7157730460166931\n",
      "Finished epoch 1268, latest loss 0.7150755524635315\n",
      "Finished epoch 1269, latest loss 0.7150755524635315\n",
      "Finished epoch 1270, latest loss 0.7150755524635315\n",
      "Finished epoch 1271, latest loss 0.7150755524635315\n",
      "Finished epoch 1272, latest loss 0.7158132791519165\n",
      "Finished epoch 1273, latest loss 0.7150755524635315\n",
      "Finished epoch 1274, latest loss 0.7150817513465881\n",
      "Finished epoch 1275, latest loss 0.7150755524635315\n",
      "Finished epoch 1276, latest loss 0.7150755524635315\n",
      "Finished epoch 1277, latest loss 0.7150755524635315\n",
      "Finished epoch 1278, latest loss 0.715075671672821\n",
      "Finished epoch 1279, latest loss 0.7150755524635315\n",
      "Finished epoch 1280, latest loss 0.7150755524635315\n",
      "Finished epoch 1281, latest loss 0.7150755524635315\n",
      "Finished epoch 1282, latest loss 0.7150755524635315\n",
      "Finished epoch 1283, latest loss 0.7150755524635315\n",
      "Finished epoch 1284, latest loss 0.7150755524635315\n",
      "Finished epoch 1285, latest loss 0.7150755524635315\n",
      "Finished epoch 1286, latest loss 0.7150755524635315\n",
      "Finished epoch 1287, latest loss 0.7150755524635315\n",
      "Finished epoch 1288, latest loss 0.7158346176147461\n",
      "Finished epoch 1289, latest loss 0.7158346176147461\n",
      "Finished epoch 1290, latest loss 0.7150755524635315\n",
      "Finished epoch 1291, latest loss 0.7150755524635315\n",
      "Finished epoch 1292, latest loss 0.7158089876174927\n",
      "Finished epoch 1293, latest loss 0.7150755524635315\n",
      "Finished epoch 1294, latest loss 0.7150755524635315\n",
      "Finished epoch 1295, latest loss 0.7150755524635315\n",
      "Finished epoch 1296, latest loss 0.7150755524635315\n",
      "Finished epoch 1297, latest loss 0.7158273458480835\n",
      "Finished epoch 1298, latest loss 0.7150755524635315\n",
      "Finished epoch 1299, latest loss 0.7150760889053345\n",
      "Finished epoch 1300, latest loss 0.7150755524635315\n",
      "Finished epoch 1301, latest loss 0.7150755524635315\n",
      "Finished epoch 1302, latest loss 0.7150755524635315\n",
      "Finished epoch 1303, latest loss 0.7150755524635315\n",
      "Finished epoch 1304, latest loss 0.7150755524635315\n",
      "Finished epoch 1305, latest loss 0.7150755524635315\n",
      "Finished epoch 1306, latest loss 0.7150755524635315\n",
      "Finished epoch 1307, latest loss 0.7150755524635315\n",
      "Finished epoch 1308, latest loss 0.7150755524635315\n",
      "Finished epoch 1309, latest loss 0.7150755524635315\n",
      "Finished epoch 1310, latest loss 0.7158371806144714\n",
      "Finished epoch 1311, latest loss 0.7150762677192688\n",
      "Finished epoch 1312, latest loss 0.7150755524635315\n",
      "Finished epoch 1313, latest loss 0.7150755524635315\n",
      "Finished epoch 1314, latest loss 0.7150755524635315\n",
      "Finished epoch 1315, latest loss 0.7157730460166931\n",
      "Finished epoch 1316, latest loss 0.715075671672821\n",
      "Finished epoch 1317, latest loss 0.7150755524635315\n",
      "Finished epoch 1318, latest loss 0.7150755524635315\n",
      "Finished epoch 1319, latest loss 0.7150755524635315\n",
      "Finished epoch 1320, latest loss 0.7150755524635315\n",
      "Finished epoch 1321, latest loss 0.7150755524635315\n",
      "Finished epoch 1322, latest loss 0.7150755524635315\n",
      "Finished epoch 1323, latest loss 0.715075671672821\n",
      "Finished epoch 1324, latest loss 0.715075671672821\n",
      "Finished epoch 1325, latest loss 0.7150755524635315\n",
      "Finished epoch 1326, latest loss 0.7150755524635315\n",
      "Finished epoch 1327, latest loss 0.7150755524635315\n",
      "Finished epoch 1328, latest loss 0.7150755524635315\n",
      "Finished epoch 1329, latest loss 0.7150755524635315\n",
      "Finished epoch 1330, latest loss 0.7150755524635315\n",
      "Finished epoch 1331, latest loss 0.7150755524635315\n",
      "Finished epoch 1332, latest loss 0.7150755524635315\n",
      "Finished epoch 1333, latest loss 0.7150755524635315\n",
      "Finished epoch 1334, latest loss 0.7155577540397644\n",
      "Finished epoch 1335, latest loss 0.7150755524635315\n",
      "Finished epoch 1336, latest loss 0.7150755524635315\n",
      "Finished epoch 1337, latest loss 0.7158346176147461\n",
      "Finished epoch 1338, latest loss 0.7158346176147461\n",
      "Finished epoch 1339, latest loss 0.7150755524635315\n",
      "Finished epoch 1340, latest loss 0.7151114344596863\n",
      "Finished epoch 1341, latest loss 0.7150755524635315\n",
      "Finished epoch 1342, latest loss 0.7150755524635315\n",
      "Finished epoch 1343, latest loss 0.7150755524635315\n",
      "Finished epoch 1344, latest loss 0.7150757908821106\n",
      "Finished epoch 1345, latest loss 0.7150755524635315\n",
      "Finished epoch 1346, latest loss 0.7150755524635315\n",
      "Finished epoch 1347, latest loss 0.7150755524635315\n",
      "Finished epoch 1348, latest loss 0.7150755524635315\n",
      "Finished epoch 1349, latest loss 0.7150755524635315\n",
      "Finished epoch 1350, latest loss 0.7150755524635315\n",
      "Finished epoch 1351, latest loss 0.7158346176147461\n",
      "Finished epoch 1352, latest loss 0.7150755524635315\n",
      "Finished epoch 1353, latest loss 0.7150755524635315\n",
      "Finished epoch 1354, latest loss 0.7150755524635315\n",
      "Finished epoch 1355, latest loss 0.7150755524635315\n",
      "Finished epoch 1356, latest loss 0.7150755524635315\n",
      "Finished epoch 1357, latest loss 0.7150755524635315\n",
      "Finished epoch 1358, latest loss 0.7150755524635315\n",
      "Finished epoch 1359, latest loss 0.7150755524635315\n",
      "Finished epoch 1360, latest loss 0.7150755524635315\n",
      "Finished epoch 1361, latest loss 0.7150755524635315\n",
      "Finished epoch 1362, latest loss 0.7150755524635315\n",
      "Finished epoch 1363, latest loss 0.7150755524635315\n",
      "Finished epoch 1364, latest loss 0.7150765657424927\n",
      "Finished epoch 1365, latest loss 0.7150755524635315\n",
      "Finished epoch 1366, latest loss 0.7150755524635315\n",
      "Finished epoch 1367, latest loss 0.7150755524635315\n",
      "Finished epoch 1368, latest loss 0.715075671672821\n",
      "Finished epoch 1369, latest loss 0.7150755524635315\n",
      "Finished epoch 1370, latest loss 0.7150755524635315\n",
      "Finished epoch 1371, latest loss 0.7150755524635315\n",
      "Finished epoch 1372, latest loss 0.7150755524635315\n",
      "Finished epoch 1373, latest loss 0.7150755524635315\n",
      "Finished epoch 1374, latest loss 0.7158346176147461\n",
      "Finished epoch 1375, latest loss 0.7143792510032654\n",
      "Finished epoch 1376, latest loss 0.7143781185150146\n",
      "Finished epoch 1377, latest loss 0.7143781185150146\n",
      "Finished epoch 1378, latest loss 0.7143781185150146\n",
      "Finished epoch 1379, latest loss 0.7143781185150146\n",
      "Finished epoch 1380, latest loss 0.7143781185150146\n",
      "Finished epoch 1381, latest loss 0.7143781185150146\n",
      "Finished epoch 1382, latest loss 0.7143781185150146\n",
      "Finished epoch 1383, latest loss 0.7144945859909058\n",
      "Finished epoch 1384, latest loss 0.7143781185150146\n",
      "Finished epoch 1385, latest loss 0.7143781185150146\n",
      "Finished epoch 1386, latest loss 0.7151370644569397\n",
      "Finished epoch 1387, latest loss 0.7151042819023132\n",
      "Finished epoch 1388, latest loss 0.7143781185150146\n",
      "Finished epoch 1389, latest loss 0.7143781185150146\n",
      "Finished epoch 1390, latest loss 0.7143781185150146\n",
      "Finished epoch 1391, latest loss 0.7143781185150146\n",
      "Finished epoch 1392, latest loss 0.7143781185150146\n",
      "Finished epoch 1393, latest loss 0.7143781185150146\n",
      "Finished epoch 1394, latest loss 0.7143781185150146\n",
      "Finished epoch 1395, latest loss 0.7143784761428833\n",
      "Finished epoch 1396, latest loss 0.7143781185150146\n",
      "Finished epoch 1397, latest loss 0.7143781185150146\n",
      "Finished epoch 1398, latest loss 0.7151370644569397\n",
      "Finished epoch 1399, latest loss 0.7150759696960449\n",
      "Finished epoch 1400, latest loss 0.7143809795379639\n",
      "Finished epoch 1401, latest loss 0.7151371836662292\n",
      "Finished epoch 1402, latest loss 0.7156810760498047\n",
      "Finished epoch 1403, latest loss 0.7143781781196594\n",
      "Finished epoch 1404, latest loss 0.7143781185150146\n",
      "Finished epoch 1405, latest loss 0.7143781185150146\n",
      "Finished epoch 1406, latest loss 0.7143781185150146\n",
      "Finished epoch 1407, latest loss 0.7143781185150146\n",
      "Finished epoch 1408, latest loss 0.7143781185150146\n",
      "Finished epoch 1409, latest loss 0.7143781185150146\n",
      "Finished epoch 1410, latest loss 0.7143781185150146\n",
      "Finished epoch 1411, latest loss 0.7143781185150146\n",
      "Finished epoch 1412, latest loss 0.714405357837677\n",
      "Finished epoch 1413, latest loss 0.7143781185150146\n",
      "Finished epoch 1414, latest loss 0.7151371240615845\n",
      "Finished epoch 1415, latest loss 0.7144022583961487\n",
      "Finished epoch 1416, latest loss 0.7143781185150146\n",
      "Finished epoch 1417, latest loss 0.7143781185150146\n",
      "Finished epoch 1418, latest loss 0.7143781185150146\n",
      "Finished epoch 1419, latest loss 0.7143781185150146\n",
      "Finished epoch 1420, latest loss 0.7143783569335938\n",
      "Finished epoch 1421, latest loss 0.7143781185150146\n",
      "Finished epoch 1422, latest loss 0.7151371836662292\n",
      "Finished epoch 1423, latest loss 0.7143781185150146\n",
      "Finished epoch 1424, latest loss 0.7151016592979431\n",
      "Finished epoch 1425, latest loss 0.7143781185150146\n",
      "Finished epoch 1426, latest loss 0.7143781185150146\n",
      "Finished epoch 1427, latest loss 0.7143781185150146\n",
      "Finished epoch 1428, latest loss 0.7143781185150146\n",
      "Finished epoch 1429, latest loss 0.7143781185150146\n",
      "Finished epoch 1430, latest loss 0.7151371240615845\n",
      "Finished epoch 1431, latest loss 0.7143235206604004\n",
      "Saved improved model\n",
      "Finished epoch 1432, latest loss 0.7151433825492859\n",
      "Finished epoch 1433, latest loss 0.7143781185150146\n",
      "Finished epoch 1434, latest loss 0.7143781185150146\n",
      "Finished epoch 1435, latest loss 0.7141211032867432\n",
      "Saved improved model\n",
      "Finished epoch 1436, latest loss 0.7136808633804321\n",
      "Saved improved model\n",
      "Finished epoch 1437, latest loss 0.7136806845664978\n",
      "Saved improved model\n",
      "Finished epoch 1438, latest loss 0.7144396901130676\n",
      "Finished epoch 1439, latest loss 0.7136806845664978\n",
      "Finished epoch 1440, latest loss 0.7136806845664978\n",
      "Finished epoch 1441, latest loss 0.7136806845664978\n",
      "Finished epoch 1442, latest loss 0.7136806845664978\n",
      "Finished epoch 1443, latest loss 0.7136807441711426\n",
      "Finished epoch 1444, latest loss 0.7136806845664978\n",
      "Finished epoch 1445, latest loss 0.7136806845664978\n",
      "Finished epoch 1446, latest loss 0.7136806845664978\n",
      "Finished epoch 1447, latest loss 0.7136806845664978\n",
      "Finished epoch 1448, latest loss 0.7136806845664978\n",
      "Finished epoch 1449, latest loss 0.7136807441711426\n",
      "Finished epoch 1450, latest loss 0.7136806845664978\n",
      "Finished epoch 1451, latest loss 0.7136795520782471\n",
      "Saved improved model\n",
      "Finished epoch 1452, latest loss 0.7136806845664978\n",
      "Finished epoch 1453, latest loss 0.7136806845664978\n",
      "Finished epoch 1454, latest loss 0.7136806845664978\n",
      "Finished epoch 1455, latest loss 0.7136805653572083\n",
      "Finished epoch 1456, latest loss 0.7136669158935547\n",
      "Saved improved model\n",
      "Finished epoch 1457, latest loss 0.7136804461479187\n",
      "Finished epoch 1458, latest loss 0.7136806845664978\n",
      "Finished epoch 1459, latest loss 0.7136807441711426\n",
      "Finished epoch 1460, latest loss 0.7136808633804321\n",
      "Finished epoch 1461, latest loss 0.7136806845664978\n",
      "Finished epoch 1462, latest loss 0.7136806845664978\n",
      "Finished epoch 1463, latest loss 0.7136814594268799\n",
      "Finished epoch 1464, latest loss 0.7136922478675842\n",
      "Finished epoch 1465, latest loss 0.7136813402175903\n",
      "Finished epoch 1466, latest loss 0.7144396901130676\n",
      "Finished epoch 1467, latest loss 0.7136807441711426\n",
      "Finished epoch 1468, latest loss 0.7151371240615845\n",
      "Finished epoch 1469, latest loss 0.7141996622085571\n",
      "Finished epoch 1470, latest loss 0.7136806845664978\n",
      "Finished epoch 1471, latest loss 0.7136806845664978\n",
      "Finished epoch 1472, latest loss 0.7136887907981873\n",
      "Finished epoch 1473, latest loss 0.7144160866737366\n",
      "Finished epoch 1474, latest loss 0.7136806845664978\n",
      "Finished epoch 1475, latest loss 0.7136806845664978\n",
      "Finished epoch 1476, latest loss 0.7136806845664978\n",
      "Finished epoch 1477, latest loss 0.7136806845664978\n",
      "Finished epoch 1478, latest loss 0.7136806845664978\n",
      "Finished epoch 1479, latest loss 0.7136806845664978\n",
      "Finished epoch 1480, latest loss 0.7136806845664978\n",
      "Finished epoch 1481, latest loss 0.7136806845664978\n",
      "Finished epoch 1482, latest loss 0.7136806845664978\n",
      "Finished epoch 1483, latest loss 0.7136806845664978\n",
      "Finished epoch 1484, latest loss 0.7140486836433411\n",
      "Finished epoch 1485, latest loss 0.7136806845664978\n",
      "Finished epoch 1486, latest loss 0.7136806845664978\n",
      "Finished epoch 1487, latest loss 0.7136806845664978\n",
      "Finished epoch 1488, latest loss 0.7136806845664978\n",
      "Finished epoch 1489, latest loss 0.7136806845664978\n",
      "Finished epoch 1490, latest loss 0.7136806845664978\n",
      "Finished epoch 1491, latest loss 0.7136806845664978\n",
      "Finished epoch 1492, latest loss 0.7136806845664978\n",
      "Finished epoch 1493, latest loss 0.7136806845664978\n",
      "Finished epoch 1494, latest loss 0.7136806845664978\n",
      "Finished epoch 1495, latest loss 0.7136806845664978\n",
      "Finished epoch 1496, latest loss 0.7136806845664978\n",
      "Finished epoch 1497, latest loss 0.7136806845664978\n",
      "Finished epoch 1498, latest loss 0.7136806845664978\n",
      "Finished epoch 1499, latest loss 0.7143781781196594\n",
      "Finished epoch 1500, latest loss 0.7136806845664978\n",
      "Finished epoch 1501, latest loss 0.7137777209281921\n",
      "Finished epoch 1502, latest loss 0.7136806845664978\n",
      "Finished epoch 1503, latest loss 0.7136806845664978\n",
      "Finished epoch 1504, latest loss 0.7136806845664978\n",
      "Finished epoch 1505, latest loss 0.7136806845664978\n",
      "Finished epoch 1506, latest loss 0.7144396901130676\n",
      "Finished epoch 1507, latest loss 0.7136743664741516\n",
      "Finished epoch 1508, latest loss 0.7129831910133362\n",
      "Saved improved model\n",
      "Finished epoch 1509, latest loss 0.7136806845664978\n",
      "Finished epoch 1510, latest loss 0.7136342525482178\n",
      "Finished epoch 1511, latest loss 0.7136806845664978\n",
      "Finished epoch 1512, latest loss 0.7136806845664978\n",
      "Finished epoch 1513, latest loss 0.7136806845664978\n",
      "Finished epoch 1514, latest loss 0.713146448135376\n",
      "Finished epoch 1515, latest loss 0.7129831910133362\n",
      "Finished epoch 1516, latest loss 0.7129831910133362\n",
      "Finished epoch 1517, latest loss 0.7129831910133362\n",
      "Finished epoch 1518, latest loss 0.7129831910133362\n",
      "Finished epoch 1519, latest loss 0.7129831910133362\n",
      "Finished epoch 1520, latest loss 0.7129831910133362\n",
      "Finished epoch 1521, latest loss 0.7129831910133362\n",
      "Finished epoch 1522, latest loss 0.7129884958267212\n",
      "Finished epoch 1523, latest loss 0.7129831910133362\n",
      "Finished epoch 1524, latest loss 0.7129831910133362\n",
      "Finished epoch 1525, latest loss 0.7129831910133362\n",
      "Finished epoch 1526, latest loss 0.7129831910133362\n",
      "Finished epoch 1527, latest loss 0.7129831910133362\n",
      "Finished epoch 1528, latest loss 0.7129831910133362\n",
      "Finished epoch 1529, latest loss 0.7129831910133362\n",
      "Finished epoch 1530, latest loss 0.7129831910133362\n",
      "Finished epoch 1531, latest loss 0.713742196559906\n",
      "Finished epoch 1532, latest loss 0.7129831910133362\n",
      "Finished epoch 1533, latest loss 0.7144396901130676\n",
      "Finished epoch 1534, latest loss 0.7136806845664978\n",
      "Finished epoch 1535, latest loss 0.7130038738250732\n",
      "Finished epoch 1536, latest loss 0.7137336730957031\n",
      "Finished epoch 1537, latest loss 0.7133552432060242\n",
      "Finished epoch 1538, latest loss 0.7136806845664978\n",
      "Finished epoch 1539, latest loss 0.7136806845664978\n",
      "Finished epoch 1540, latest loss 0.7129831910133362\n",
      "Finished epoch 1541, latest loss 0.7129831910133362\n",
      "Finished epoch 1542, latest loss 0.7129831910133362\n",
      "Finished epoch 1543, latest loss 0.7129831910133362\n",
      "Finished epoch 1544, latest loss 0.7129831910133362\n",
      "Finished epoch 1545, latest loss 0.7129831910133362\n",
      "Finished epoch 1546, latest loss 0.7137411832809448\n",
      "Finished epoch 1547, latest loss 0.7129831910133362\n",
      "Finished epoch 1548, latest loss 0.7129831910133362\n",
      "Finished epoch 1549, latest loss 0.7129831910133362\n",
      "Finished epoch 1550, latest loss 0.7129831910133362\n",
      "Finished epoch 1551, latest loss 0.7129831910133362\n",
      "Finished epoch 1552, latest loss 0.7129831910133362\n",
      "Finished epoch 1553, latest loss 0.713742196559906\n",
      "Finished epoch 1554, latest loss 0.7129831910133362\n",
      "Finished epoch 1555, latest loss 0.7129833698272705\n",
      "Finished epoch 1556, latest loss 0.7129831910133362\n",
      "Finished epoch 1557, latest loss 0.7129831910133362\n",
      "Finished epoch 1558, latest loss 0.7129831910133362\n",
      "Finished epoch 1559, latest loss 0.7137446999549866\n",
      "Finished epoch 1560, latest loss 0.713742196559906\n",
      "Finished epoch 1561, latest loss 0.7129831910133362\n",
      "Finished epoch 1562, latest loss 0.7129831910133362\n",
      "Finished epoch 1563, latest loss 0.7130950093269348\n",
      "Finished epoch 1564, latest loss 0.7129831910133362\n",
      "Finished epoch 1565, latest loss 0.7136842608451843\n",
      "Finished epoch 1566, latest loss 0.7129831910133362\n",
      "Finished epoch 1567, latest loss 0.713672935962677\n",
      "Finished epoch 1568, latest loss 0.7129831910133362\n",
      "Finished epoch 1569, latest loss 0.7129831910133362\n",
      "Finished epoch 1570, latest loss 0.7129831910133362\n",
      "Finished epoch 1571, latest loss 0.7129831910133362\n",
      "Finished epoch 1572, latest loss 0.7129831910133362\n",
      "Finished epoch 1573, latest loss 0.7129831910133362\n",
      "Finished epoch 1574, latest loss 0.7129831910133362\n",
      "Finished epoch 1575, latest loss 0.7129831910133362\n",
      "Finished epoch 1576, latest loss 0.7129831910133362\n",
      "Finished epoch 1577, latest loss 0.7129831910133362\n",
      "Finished epoch 1578, latest loss 0.7136807441711426\n",
      "Finished epoch 1579, latest loss 0.7129831910133362\n",
      "Finished epoch 1580, latest loss 0.7145007252693176\n",
      "Finished epoch 1581, latest loss 0.7129831910133362\n",
      "Finished epoch 1582, latest loss 0.7129831910133362\n",
      "Finished epoch 1583, latest loss 0.7129831910133362\n",
      "Finished epoch 1584, latest loss 0.7129831910133362\n",
      "Finished epoch 1585, latest loss 0.7136533856391907\n",
      "Finished epoch 1586, latest loss 0.7129831910133362\n",
      "Finished epoch 1587, latest loss 0.7129831910133362\n",
      "Finished epoch 1588, latest loss 0.7129831910133362\n",
      "Finished epoch 1589, latest loss 0.7129846215248108\n",
      "Finished epoch 1590, latest loss 0.713678777217865\n",
      "Finished epoch 1591, latest loss 0.7149056196212769\n",
      "Finished epoch 1592, latest loss 0.713742196559906\n",
      "Finished epoch 1593, latest loss 0.712983250617981\n",
      "Finished epoch 1594, latest loss 0.7136806845664978\n",
      "Finished epoch 1595, latest loss 0.7136806845664978\n",
      "Finished epoch 1596, latest loss 0.7129831910133362\n",
      "Finished epoch 1597, latest loss 0.7130237817764282\n",
      "Finished epoch 1598, latest loss 0.712983250617981\n",
      "Finished epoch 1599, latest loss 0.7129831910133362\n",
      "Finished epoch 1600, latest loss 0.7129831910133362\n",
      "Finished epoch 1601, latest loss 0.7129831910133362\n",
      "Finished epoch 1602, latest loss 0.712983250617981\n",
      "Finished epoch 1603, latest loss 0.7129831910133362\n",
      "Finished epoch 1604, latest loss 0.7129831910133362\n",
      "Finished epoch 1605, latest loss 0.7129831910133362\n",
      "Finished epoch 1606, latest loss 0.7134752869606018\n",
      "Finished epoch 1607, latest loss 0.7129831910133362\n",
      "Finished epoch 1608, latest loss 0.712983250617981\n",
      "Finished epoch 1609, latest loss 0.7129831910133362\n",
      "Finished epoch 1610, latest loss 0.7129831910133362\n",
      "Finished epoch 1611, latest loss 0.7129831910133362\n",
      "Finished epoch 1612, latest loss 0.712983250617981\n",
      "Finished epoch 1613, latest loss 0.7129884362220764\n",
      "Finished epoch 1614, latest loss 0.7129831910133362\n",
      "Finished epoch 1615, latest loss 0.7129831910133362\n",
      "Finished epoch 1616, latest loss 0.7136806845664978\n",
      "Finished epoch 1617, latest loss 0.713007390499115\n",
      "Finished epoch 1618, latest loss 0.7129831910133362\n",
      "Finished epoch 1619, latest loss 0.7129831910133362\n",
      "Finished epoch 1620, latest loss 0.7136805653572083\n",
      "Finished epoch 1621, latest loss 0.7129831910133362\n",
      "Finished epoch 1622, latest loss 0.7129836678504944\n",
      "Finished epoch 1623, latest loss 0.7130587100982666\n",
      "Finished epoch 1624, latest loss 0.7129831910133362\n",
      "Finished epoch 1625, latest loss 0.7129831910133362\n",
      "Finished epoch 1626, latest loss 0.7129831910133362\n",
      "Finished epoch 1627, latest loss 0.7129831910133362\n",
      "Finished epoch 1628, latest loss 0.7129831910133362\n",
      "Finished epoch 1629, latest loss 0.7129831910133362\n",
      "Finished epoch 1630, latest loss 0.7129831910133362\n",
      "Finished epoch 1631, latest loss 0.7129831910133362\n",
      "Finished epoch 1632, latest loss 0.7129831910133362\n",
      "Finished epoch 1633, latest loss 0.7129831910133362\n",
      "Finished epoch 1634, latest loss 0.7129831910133362\n",
      "Finished epoch 1635, latest loss 0.7129831910133362\n",
      "Finished epoch 1636, latest loss 0.7129831910133362\n",
      "Finished epoch 1637, latest loss 0.7129831910133362\n",
      "Finished epoch 1638, latest loss 0.7129858136177063\n",
      "Finished epoch 1639, latest loss 0.7129831910133362\n",
      "Finished epoch 1640, latest loss 0.7129831910133362\n",
      "Finished epoch 1641, latest loss 0.7129831910133362\n",
      "Finished epoch 1642, latest loss 0.7129831910133362\n",
      "Finished epoch 1643, latest loss 0.7129831910133362\n",
      "Finished epoch 1644, latest loss 0.7129831910133362\n",
      "Finished epoch 1645, latest loss 0.7129831910133362\n",
      "Finished epoch 1646, latest loss 0.7129831910133362\n",
      "Finished epoch 1647, latest loss 0.7129831910133362\n",
      "Finished epoch 1648, latest loss 0.7129831910133362\n",
      "Finished epoch 1649, latest loss 0.7137469053268433\n",
      "Finished epoch 1650, latest loss 0.7129831910133362\n",
      "Finished epoch 1651, latest loss 0.7129831910133362\n",
      "Finished epoch 1652, latest loss 0.7129831910133362\n",
      "Finished epoch 1653, latest loss 0.7129831910133362\n",
      "Finished epoch 1654, latest loss 0.7129831910133362\n",
      "Finished epoch 1655, latest loss 0.7129831910133362\n",
      "Finished epoch 1656, latest loss 0.7129831910133362\n",
      "Finished epoch 1657, latest loss 0.7129831910133362\n",
      "Finished epoch 1658, latest loss 0.7129831910133362\n",
      "Finished epoch 1659, latest loss 0.7129831910133362\n",
      "Finished epoch 1660, latest loss 0.7129831910133362\n",
      "Finished epoch 1661, latest loss 0.7129831910133362\n",
      "Finished epoch 1662, latest loss 0.7129831910133362\n",
      "Finished epoch 1663, latest loss 0.7136806845664978\n",
      "Finished epoch 1664, latest loss 0.7129831910133362\n",
      "Finished epoch 1665, latest loss 0.7129831910133362\n",
      "Finished epoch 1666, latest loss 0.7129831910133362\n",
      "Finished epoch 1667, latest loss 0.7136786580085754\n",
      "Finished epoch 1668, latest loss 0.7129831910133362\n",
      "Finished epoch 1669, latest loss 0.7129831910133362\n",
      "Finished epoch 1670, latest loss 0.7129831910133362\n",
      "Finished epoch 1671, latest loss 0.7130075693130493\n",
      "Finished epoch 1672, latest loss 0.7129831910133362\n",
      "Finished epoch 1673, latest loss 0.7129831910133362\n",
      "Finished epoch 1674, latest loss 0.7129831910133362\n",
      "Finished epoch 1675, latest loss 0.7136806845664978\n",
      "Finished epoch 1676, latest loss 0.7136806845664978\n",
      "Finished epoch 1677, latest loss 0.7130035758018494\n",
      "Finished epoch 1678, latest loss 0.7129831910133362\n",
      "Finished epoch 1679, latest loss 0.7129831910133362\n",
      "Finished epoch 1680, latest loss 0.7129831910133362\n",
      "Finished epoch 1681, latest loss 0.7136806845664978\n",
      "Finished epoch 1682, latest loss 0.7129831910133362\n",
      "Finished epoch 1683, latest loss 0.713742196559906\n",
      "Finished epoch 1684, latest loss 0.7129831910133362\n",
      "Finished epoch 1685, latest loss 0.7129831910133362\n",
      "Finished epoch 1686, latest loss 0.7129831910133362\n",
      "Finished epoch 1687, latest loss 0.7129831910133362\n",
      "Finished epoch 1688, latest loss 0.7129831910133362\n",
      "Finished epoch 1689, latest loss 0.7129831910133362\n",
      "Finished epoch 1690, latest loss 0.7129831910133362\n",
      "Finished epoch 1691, latest loss 0.7129831910133362\n",
      "Finished epoch 1692, latest loss 0.7129831910133362\n",
      "Finished epoch 1693, latest loss 0.7136806845664978\n",
      "Finished epoch 1694, latest loss 0.7136806845664978\n",
      "Finished epoch 1695, latest loss 0.7144396901130676\n",
      "Finished epoch 1696, latest loss 0.7136806845664978\n",
      "Finished epoch 1697, latest loss 0.7136806845664978\n",
      "Finished epoch 1698, latest loss 0.7142185568809509\n",
      "Finished epoch 1699, latest loss 0.7136806845664978\n",
      "Finished epoch 1700, latest loss 0.7143768668174744\n",
      "Finished epoch 1701, latest loss 0.7136922478675842\n",
      "Finished epoch 1702, latest loss 0.7136806845664978\n",
      "Finished epoch 1703, latest loss 0.7136806845664978\n",
      "Finished epoch 1704, latest loss 0.7136806845664978\n",
      "Finished epoch 1705, latest loss 0.7136806845664978\n",
      "Finished epoch 1706, latest loss 0.7144595980644226\n",
      "Finished epoch 1707, latest loss 0.7136806845664978\n",
      "Finished epoch 1708, latest loss 0.7136806845664978\n",
      "Finished epoch 1709, latest loss 0.7136806845664978\n",
      "Finished epoch 1710, latest loss 0.7136806845664978\n",
      "Finished epoch 1711, latest loss 0.7136806845664978\n",
      "Finished epoch 1712, latest loss 0.7144396901130676\n",
      "Finished epoch 1713, latest loss 0.7144396901130676\n",
      "Finished epoch 1714, latest loss 0.7136806845664978\n",
      "Finished epoch 1715, latest loss 0.7136806845664978\n",
      "Finished epoch 1716, latest loss 0.7136806845664978\n",
      "Finished epoch 1717, latest loss 0.7136806845664978\n",
      "Finished epoch 1718, latest loss 0.7129831910133362\n",
      "Finished epoch 1719, latest loss 0.7133914828300476\n",
      "Finished epoch 1720, latest loss 0.7129831910133362\n",
      "Finished epoch 1721, latest loss 0.7129831910133362\n",
      "Finished epoch 1722, latest loss 0.7129831910133362\n",
      "Finished epoch 1723, latest loss 0.7129831910133362\n",
      "Finished epoch 1724, latest loss 0.7129831910133362\n",
      "Finished epoch 1725, latest loss 0.7129831910133362\n",
      "Finished epoch 1726, latest loss 0.7129831910133362\n",
      "Finished epoch 1727, latest loss 0.7129831910133362\n",
      "Finished epoch 1728, latest loss 0.7129831910133362\n",
      "Finished epoch 1729, latest loss 0.7129831910133362\n",
      "Finished epoch 1730, latest loss 0.7129831910133362\n",
      "Finished epoch 1731, latest loss 0.7129831910133362\n",
      "Finished epoch 1732, latest loss 0.7129831910133362\n",
      "Finished epoch 1733, latest loss 0.7129831910133362\n",
      "Finished epoch 1734, latest loss 0.7129831910133362\n",
      "Finished epoch 1735, latest loss 0.7129831910133362\n",
      "Finished epoch 1736, latest loss 0.7129831910133362\n",
      "Finished epoch 1737, latest loss 0.7129831910133362\n",
      "Finished epoch 1738, latest loss 0.7129831910133362\n",
      "Finished epoch 1739, latest loss 0.7129831910133362\n",
      "Finished epoch 1740, latest loss 0.7129831910133362\n",
      "Finished epoch 1741, latest loss 0.7129831910133362\n",
      "Finished epoch 1742, latest loss 0.7129831910133362\n",
      "Finished epoch 1743, latest loss 0.712983250617981\n",
      "Finished epoch 1744, latest loss 0.7136868834495544\n",
      "Finished epoch 1745, latest loss 0.7129831910133362\n",
      "Finished epoch 1746, latest loss 0.7129831910133362\n",
      "Finished epoch 1747, latest loss 0.7129831910133362\n",
      "Finished epoch 1748, latest loss 0.7129831910133362\n",
      "Finished epoch 1749, latest loss 0.7129831910133362\n",
      "Finished epoch 1750, latest loss 0.7129831910133362\n",
      "Finished epoch 1751, latest loss 0.7136805653572083\n",
      "Finished epoch 1752, latest loss 0.7129835486412048\n",
      "Finished epoch 1753, latest loss 0.7136806845664978\n",
      "Finished epoch 1754, latest loss 0.7129842638969421\n",
      "Finished epoch 1755, latest loss 0.7129849791526794\n",
      "Finished epoch 1756, latest loss 0.7137423157691956\n",
      "Finished epoch 1757, latest loss 0.7130028605461121\n",
      "Finished epoch 1758, latest loss 0.712983250617981\n",
      "Finished epoch 1759, latest loss 0.7129831910133362\n",
      "Finished epoch 1760, latest loss 0.712983250617981\n",
      "Finished epoch 1761, latest loss 0.7129831910133362\n",
      "Finished epoch 1762, latest loss 0.7129878401756287\n",
      "Finished epoch 1763, latest loss 0.712983250617981\n",
      "Finished epoch 1764, latest loss 0.7129831910133362\n",
      "Finished epoch 1765, latest loss 0.7129831910133362\n",
      "Finished epoch 1766, latest loss 0.7129831910133362\n",
      "Finished epoch 1767, latest loss 0.7137421369552612\n",
      "Finished epoch 1768, latest loss 0.7129831910133362\n",
      "Finished epoch 1769, latest loss 0.7129831910133362\n",
      "Finished epoch 1770, latest loss 0.7134469151496887\n",
      "Finished epoch 1771, latest loss 0.7134808897972107\n",
      "Finished epoch 1772, latest loss 0.7129831910133362\n",
      "Finished epoch 1773, latest loss 0.7129831910133362\n",
      "Finished epoch 1774, latest loss 0.7129831910133362\n",
      "Finished epoch 1775, latest loss 0.712994396686554\n",
      "Finished epoch 1776, latest loss 0.7129852771759033\n",
      "Finished epoch 1777, latest loss 0.7129831910133362\n",
      "Finished epoch 1778, latest loss 0.7129831910133362\n",
      "Finished epoch 1779, latest loss 0.7129983901977539\n",
      "Finished epoch 1780, latest loss 0.7136797308921814\n",
      "Finished epoch 1781, latest loss 0.7129831910133362\n",
      "Finished epoch 1782, latest loss 0.7137415409088135\n",
      "Finished epoch 1783, latest loss 0.7129831910133362\n",
      "Finished epoch 1784, latest loss 0.7129831910133362\n",
      "Finished epoch 1785, latest loss 0.713742196559906\n",
      "Finished epoch 1786, latest loss 0.7129831910133362\n",
      "Finished epoch 1787, latest loss 0.7129831910133362\n",
      "Finished epoch 1788, latest loss 0.7136780619621277\n",
      "Finished epoch 1789, latest loss 0.7143326997756958\n",
      "Finished epoch 1790, latest loss 0.7129831910133362\n",
      "Finished epoch 1791, latest loss 0.7129831910133362\n",
      "Finished epoch 1792, latest loss 0.7132432460784912\n",
      "Finished epoch 1793, latest loss 0.7129831910133362\n",
      "Finished epoch 1794, latest loss 0.7133251428604126\n",
      "Finished epoch 1795, latest loss 0.7129831910133362\n",
      "Finished epoch 1796, latest loss 0.7129831910133362\n",
      "Finished epoch 1797, latest loss 0.712983250617981\n",
      "Finished epoch 1798, latest loss 0.7129831910133362\n",
      "Finished epoch 1799, latest loss 0.7129831910133362\n",
      "Finished epoch 1800, latest loss 0.7129831910133362\n",
      "Finished epoch 1801, latest loss 0.7129831910133362\n",
      "Finished epoch 1802, latest loss 0.7129831910133362\n",
      "Finished epoch 1803, latest loss 0.7129831910133362\n",
      "Finished epoch 1804, latest loss 0.7131457328796387\n",
      "Finished epoch 1805, latest loss 0.7129831910133362\n",
      "Finished epoch 1806, latest loss 0.7130526900291443\n",
      "Finished epoch 1807, latest loss 0.712983250617981\n",
      "Finished epoch 1808, latest loss 0.7129831910133362\n",
      "Finished epoch 1809, latest loss 0.7131569385528564\n",
      "Finished epoch 1810, latest loss 0.7129831910133362\n",
      "Finished epoch 1811, latest loss 0.7129831910133362\n",
      "Finished epoch 1812, latest loss 0.7129831910133362\n",
      "Finished epoch 1813, latest loss 0.7129831910133362\n",
      "Finished epoch 1814, latest loss 0.7129831910133362\n",
      "Finished epoch 1815, latest loss 0.7129831910133362\n",
      "Finished epoch 1816, latest loss 0.7145012617111206\n",
      "Finished epoch 1817, latest loss 0.7129831910133362\n",
      "Finished epoch 1818, latest loss 0.7129831910133362\n",
      "Finished epoch 1819, latest loss 0.7137444615364075\n",
      "Finished epoch 1820, latest loss 0.7137091159820557\n",
      "Finished epoch 1821, latest loss 0.7129831910133362\n",
      "Finished epoch 1822, latest loss 0.7129831910133362\n",
      "Finished epoch 1823, latest loss 0.7129831910133362\n",
      "Finished epoch 1824, latest loss 0.7129831910133362\n",
      "Finished epoch 1825, latest loss 0.7129831910133362\n",
      "Finished epoch 1826, latest loss 0.7129831910133362\n",
      "Finished epoch 1827, latest loss 0.7129831910133362\n",
      "Finished epoch 1828, latest loss 0.7129831910133362\n",
      "Finished epoch 1829, latest loss 0.7129831910133362\n",
      "Finished epoch 1830, latest loss 0.7129831910133362\n",
      "Finished epoch 1831, latest loss 0.7129831910133362\n",
      "Finished epoch 1832, latest loss 0.7129831910133362\n",
      "Finished epoch 1833, latest loss 0.7129831910133362\n",
      "Finished epoch 1834, latest loss 0.7129831910133362\n",
      "Finished epoch 1835, latest loss 0.7129831910133362\n",
      "Finished epoch 1836, latest loss 0.712983250617981\n",
      "Finished epoch 1837, latest loss 0.7129831910133362\n",
      "Finished epoch 1838, latest loss 0.7129831910133362\n",
      "Finished epoch 1839, latest loss 0.7129837870597839\n",
      "Finished epoch 1840, latest loss 0.7137404680252075\n",
      "Finished epoch 1841, latest loss 0.7129831910133362\n",
      "Finished epoch 1842, latest loss 0.7129831910133362\n",
      "Finished epoch 1843, latest loss 0.7129831910133362\n",
      "Finished epoch 1844, latest loss 0.7129831910133362\n",
      "Finished epoch 1845, latest loss 0.7130942940711975\n",
      "Finished epoch 1846, latest loss 0.7137115001678467\n",
      "Finished epoch 1847, latest loss 0.7129831910133362\n",
      "Finished epoch 1848, latest loss 0.7129831910133362\n",
      "Finished epoch 1849, latest loss 0.7129831910133362\n",
      "Finished epoch 1850, latest loss 0.7129831910133362\n",
      "Finished epoch 1851, latest loss 0.7129831910133362\n",
      "Finished epoch 1852, latest loss 0.7129831910133362\n",
      "Finished epoch 1853, latest loss 0.7136806845664978\n",
      "Finished epoch 1854, latest loss 0.7129831910133362\n",
      "Finished epoch 1855, latest loss 0.712983250617981\n",
      "Finished epoch 1856, latest loss 0.7129899859428406\n",
      "Finished epoch 1857, latest loss 0.7129831910133362\n",
      "Finished epoch 1858, latest loss 0.7129831910133362\n",
      "Finished epoch 1859, latest loss 0.7129831910133362\n",
      "Finished epoch 1860, latest loss 0.713742196559906\n",
      "Finished epoch 1861, latest loss 0.713742196559906\n",
      "Finished epoch 1862, latest loss 0.713742196559906\n",
      "Finished epoch 1863, latest loss 0.7129831910133362\n",
      "Finished epoch 1864, latest loss 0.7129831910133362\n",
      "Finished epoch 1865, latest loss 0.7129831910133362\n",
      "Finished epoch 1866, latest loss 0.7136621475219727\n",
      "Finished epoch 1867, latest loss 0.7145010232925415\n",
      "Finished epoch 1868, latest loss 0.7129831910133362\n",
      "Finished epoch 1869, latest loss 0.7129831910133362\n",
      "Finished epoch 1870, latest loss 0.7129831910133362\n",
      "Finished epoch 1871, latest loss 0.7129831910133362\n",
      "Finished epoch 1872, latest loss 0.7130436301231384\n",
      "Finished epoch 1873, latest loss 0.7136806845664978\n",
      "Finished epoch 1874, latest loss 0.7136806845664978\n",
      "Finished epoch 1875, latest loss 0.7137418985366821\n",
      "Finished epoch 1876, latest loss 0.7143509387969971\n",
      "Finished epoch 1877, latest loss 0.7129953503608704\n",
      "Finished epoch 1878, latest loss 0.7130169868469238\n",
      "Finished epoch 1879, latest loss 0.7129831910133362\n",
      "Finished epoch 1880, latest loss 0.7129854559898376\n",
      "Finished epoch 1881, latest loss 0.7129831910133362\n",
      "Finished epoch 1882, latest loss 0.7129831910133362\n",
      "Finished epoch 1883, latest loss 0.7129831910133362\n",
      "Finished epoch 1884, latest loss 0.7127827405929565\n",
      "Saved improved model\n",
      "Finished epoch 1885, latest loss 0.7122857570648193\n",
      "Saved improved model\n",
      "Finished epoch 1886, latest loss 0.7122857570648193\n",
      "Finished epoch 1887, latest loss 0.7122857570648193\n",
      "Finished epoch 1888, latest loss 0.7122857570648193\n",
      "Finished epoch 1889, latest loss 0.7122857570648193\n",
      "Finished epoch 1890, latest loss 0.7122857570648193\n",
      "Finished epoch 1891, latest loss 0.7122857570648193\n",
      "Finished epoch 1892, latest loss 0.7122857570648193\n",
      "Finished epoch 1893, latest loss 0.7122857570648193\n",
      "Finished epoch 1894, latest loss 0.7122857570648193\n",
      "Finished epoch 1895, latest loss 0.7122857570648193\n",
      "Finished epoch 1896, latest loss 0.7122857570648193\n",
      "Finished epoch 1897, latest loss 0.7130056619644165\n",
      "Finished epoch 1898, latest loss 0.7122857570648193\n",
      "Finished epoch 1899, latest loss 0.7130364775657654\n",
      "Finished epoch 1900, latest loss 0.7130447626113892\n",
      "Finished epoch 1901, latest loss 0.7122857570648193\n",
      "Finished epoch 1902, latest loss 0.7122857570648193\n",
      "Finished epoch 1903, latest loss 0.7122857570648193\n",
      "Finished epoch 1904, latest loss 0.7122947573661804\n",
      "Finished epoch 1905, latest loss 0.7122856378555298\n",
      "Saved improved model\n",
      "Finished epoch 1906, latest loss 0.7131173014640808\n",
      "Finished epoch 1907, latest loss 0.7122929692268372\n",
      "Finished epoch 1908, latest loss 0.712331235408783\n",
      "Finished epoch 1909, latest loss 0.7129116058349609\n",
      "Finished epoch 1910, latest loss 0.7122863531112671\n",
      "Finished epoch 1911, latest loss 0.7122857570648193\n",
      "Finished epoch 1912, latest loss 0.7122857570648193\n",
      "Finished epoch 1913, latest loss 0.7122857570648193\n",
      "Finished epoch 1914, latest loss 0.7129831910133362\n",
      "Finished epoch 1915, latest loss 0.7129831910133362\n",
      "Finished epoch 1916, latest loss 0.7122858762741089\n",
      "Finished epoch 1917, latest loss 0.7122857570648193\n",
      "Finished epoch 1918, latest loss 0.7122857570648193\n",
      "Finished epoch 1919, latest loss 0.7122857570648193\n",
      "Finished epoch 1920, latest loss 0.7121944427490234\n",
      "Saved improved model\n",
      "Finished epoch 1921, latest loss 0.7115882635116577\n",
      "Saved improved model\n",
      "Finished epoch 1922, latest loss 0.7115882635116577\n",
      "Finished epoch 1923, latest loss 0.712286114692688\n",
      "Finished epoch 1924, latest loss 0.7122857570648193\n",
      "Finished epoch 1925, latest loss 0.7116914391517639\n",
      "Finished epoch 1926, latest loss 0.7115882635116577\n",
      "Finished epoch 1927, latest loss 0.7115882635116577\n",
      "Finished epoch 1928, latest loss 0.7115882635116577\n",
      "Finished epoch 1929, latest loss 0.7116265296936035\n",
      "Finished epoch 1930, latest loss 0.7117193937301636\n",
      "Finished epoch 1931, latest loss 0.7117748260498047\n",
      "Finished epoch 1932, latest loss 0.7115882635116577\n",
      "Finished epoch 1933, latest loss 0.7115882635116577\n",
      "Finished epoch 1934, latest loss 0.7115882635116577\n",
      "Finished epoch 1935, latest loss 0.7122205495834351\n",
      "Finished epoch 1936, latest loss 0.7115890383720398\n",
      "Finished epoch 1937, latest loss 0.712347149848938\n",
      "Finished epoch 1938, latest loss 0.7115910649299622\n",
      "Finished epoch 1939, latest loss 0.7115882635116577\n",
      "Finished epoch 1940, latest loss 0.7115882635116577\n",
      "Finished epoch 1941, latest loss 0.7115904688835144\n",
      "Finished epoch 1942, latest loss 0.7116476893424988\n",
      "Finished epoch 1943, latest loss 0.7115882635116577\n",
      "Finished epoch 1944, latest loss 0.7115882635116577\n",
      "Finished epoch 1945, latest loss 0.7115882635116577\n",
      "Finished epoch 1946, latest loss 0.7115914821624756\n",
      "Finished epoch 1947, latest loss 0.7129831910133362\n",
      "Finished epoch 1948, latest loss 0.7115892767906189\n",
      "Finished epoch 1949, latest loss 0.7115882635116577\n",
      "Finished epoch 1950, latest loss 0.7115882635116577\n",
      "Finished epoch 1951, latest loss 0.7115882635116577\n",
      "Finished epoch 1952, latest loss 0.7115882635116577\n",
      "Finished epoch 1953, latest loss 0.7115882635116577\n",
      "Finished epoch 1954, latest loss 0.7117031812667847\n",
      "Finished epoch 1955, latest loss 0.7115882635116577\n",
      "Finished epoch 1956, latest loss 0.7115882635116577\n",
      "Finished epoch 1957, latest loss 0.7115882635116577\n",
      "Finished epoch 1958, latest loss 0.7115882635116577\n",
      "Finished epoch 1959, latest loss 0.7115895748138428\n",
      "Finished epoch 1960, latest loss 0.7115928530693054\n",
      "Finished epoch 1961, latest loss 0.7119330763816833\n",
      "Finished epoch 1962, latest loss 0.7115961313247681\n",
      "Finished epoch 1963, latest loss 0.7115882635116577\n",
      "Finished epoch 1964, latest loss 0.7115882635116577\n",
      "Finished epoch 1965, latest loss 0.7117538452148438\n",
      "Finished epoch 1966, latest loss 0.7115882635116577\n",
      "Finished epoch 1967, latest loss 0.7115882635116577\n",
      "Finished epoch 1968, latest loss 0.7115882635116577\n",
      "Finished epoch 1969, latest loss 0.7115882635116577\n",
      "Finished epoch 1970, latest loss 0.7115882635116577\n",
      "Finished epoch 1971, latest loss 0.7122857570648193\n",
      "Finished epoch 1972, latest loss 0.7115882635116577\n",
      "Finished epoch 1973, latest loss 0.7115882635116577\n",
      "Finished epoch 1974, latest loss 0.7115882635116577\n",
      "Finished epoch 1975, latest loss 0.7115882635116577\n",
      "Finished epoch 1976, latest loss 0.7116179466247559\n",
      "Finished epoch 1977, latest loss 0.7115882635116577\n",
      "Finished epoch 1978, latest loss 0.7115882635116577\n",
      "Finished epoch 1979, latest loss 0.7115882635116577\n",
      "Finished epoch 1980, latest loss 0.7115882635116577\n",
      "Finished epoch 1981, latest loss 0.7115882635116577\n",
      "Finished epoch 1982, latest loss 0.7115882635116577\n",
      "Finished epoch 1983, latest loss 0.7123448252677917\n",
      "Finished epoch 1984, latest loss 0.7115882635116577\n",
      "Finished epoch 1985, latest loss 0.711588978767395\n",
      "Finished epoch 1986, latest loss 0.7122855186462402\n",
      "Finished epoch 1987, latest loss 0.7115882635116577\n",
      "Finished epoch 1988, latest loss 0.7115882635116577\n",
      "Finished epoch 1989, latest loss 0.7115882635116577\n",
      "Finished epoch 1990, latest loss 0.7115882635116577\n",
      "Finished epoch 1991, latest loss 0.7123457789421082\n",
      "Finished epoch 1992, latest loss 0.7115882635116577\n",
      "Finished epoch 1993, latest loss 0.7115882635116577\n",
      "Finished epoch 1994, latest loss 0.7122577428817749\n",
      "Finished epoch 1995, latest loss 0.7116777300834656\n",
      "Finished epoch 1996, latest loss 0.7115882635116577\n",
      "Finished epoch 1997, latest loss 0.7115882635116577\n",
      "Finished epoch 1998, latest loss 0.7115882635116577\n",
      "Finished epoch 1999, latest loss 0.7115882635116577\n",
      "Accuracy 0.9382161498069763\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                8022               15455\n",
      "Actual Negative                 165              229175\n",
      "Positive predictive power:\n",
      "34.17%\n",
      "Positive predictive accuracy:\n",
      "97.98%\n",
      "Confusion Matrix for merged predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                7296               16181\n",
      "Actual Negative                 117              229223\n",
      "Positive predictive power:\n",
      "31.08%\n",
      "Positive predictive accuracy:\n",
      "98.42%\n",
      "Mean change for incorrect predictions: 1.045\n",
      "Mean change for correct predictions: 1.12\n",
      "PimaClassifier(\n",
      "  (hidden1): Linear(in_features=1616, out_features=64, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (hidden2): Linear(in_features=64, out_features=12, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (hidden3): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (act3): ReLU()\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (act_output): Sigmoid()\n",
      ")\n",
      "Finished epoch 0, latest loss 0.7592862248420715\n",
      "Saved improved model\n",
      "Finished epoch 1, latest loss 0.7592453956604004\n",
      "Saved improved model\n",
      "Finished epoch 2, latest loss 0.7591386437416077\n",
      "Saved improved model\n",
      "Finished epoch 3, latest loss 0.7586697936058044\n",
      "Saved improved model\n",
      "Finished epoch 4, latest loss 0.7580983638763428\n",
      "Saved improved model\n",
      "Finished epoch 5, latest loss 0.758375346660614\n",
      "Finished epoch 6, latest loss 0.7579571604728699\n",
      "Saved improved model\n",
      "Finished epoch 7, latest loss 0.7557154297828674\n",
      "Saved improved model\n",
      "Finished epoch 8, latest loss 0.7544816732406616\n",
      "Saved improved model\n",
      "Finished epoch 9, latest loss 0.7547779083251953\n",
      "Finished epoch 10, latest loss 0.7547930479049683\n",
      "Finished epoch 11, latest loss 0.7532849907875061\n",
      "Saved improved model\n",
      "Finished epoch 12, latest loss 0.7514306902885437\n",
      "Saved improved model\n",
      "Finished epoch 13, latest loss 0.7516149878501892\n",
      "Finished epoch 14, latest loss 0.751239538192749\n",
      "Saved improved model\n",
      "Finished epoch 15, latest loss 0.7508477568626404\n",
      "Saved improved model\n",
      "Finished epoch 16, latest loss 0.7508777976036072\n",
      "Finished epoch 17, latest loss 0.750788152217865\n",
      "Saved improved model\n",
      "Finished epoch 18, latest loss 0.7516924738883972\n",
      "Finished epoch 19, latest loss 0.750796377658844\n",
      "Finished epoch 20, latest loss 0.7508090734481812\n",
      "Finished epoch 21, latest loss 0.7514936923980713\n",
      "Finished epoch 22, latest loss 0.7511540651321411\n",
      "Finished epoch 23, latest loss 0.7507701516151428\n",
      "Saved improved model\n",
      "Finished epoch 24, latest loss 0.7508096694946289\n",
      "Finished epoch 25, latest loss 0.7508136630058289\n",
      "Finished epoch 26, latest loss 0.7511531114578247\n",
      "Finished epoch 27, latest loss 0.750531017780304\n",
      "Saved improved model\n",
      "Finished epoch 28, latest loss 0.7501698136329651\n",
      "Saved improved model\n",
      "Finished epoch 29, latest loss 0.7496373653411865\n",
      "Saved improved model\n",
      "Finished epoch 30, latest loss 0.7489345669746399\n",
      "Saved improved model\n",
      "Finished epoch 31, latest loss 0.7485723495483398\n",
      "Saved improved model\n",
      "Finished epoch 32, latest loss 0.7492361664772034\n",
      "Finished epoch 33, latest loss 0.7487845420837402\n",
      "Finished epoch 34, latest loss 0.748617947101593\n",
      "Finished epoch 35, latest loss 0.749514102935791\n",
      "Finished epoch 36, latest loss 0.7487022876739502\n",
      "Finished epoch 37, latest loss 0.74800044298172\n",
      "Saved improved model\n",
      "Finished epoch 38, latest loss 0.7487414479255676\n",
      "Finished epoch 39, latest loss 0.7472176551818848\n",
      "Saved improved model\n",
      "Finished epoch 40, latest loss 0.7470623254776001\n",
      "Saved improved model\n",
      "Finished epoch 41, latest loss 0.7464650273323059\n",
      "Saved improved model\n",
      "Finished epoch 42, latest loss 0.7461856603622437\n",
      "Saved improved model\n",
      "Finished epoch 43, latest loss 0.7461563944816589\n",
      "Saved improved model\n",
      "Finished epoch 44, latest loss 0.746921956539154\n",
      "Finished epoch 45, latest loss 0.7464366555213928\n",
      "Finished epoch 46, latest loss 0.7464903593063354\n",
      "Finished epoch 47, latest loss 0.7463800311088562\n",
      "Finished epoch 48, latest loss 0.7470589876174927\n",
      "Finished epoch 49, latest loss 0.7467615604400635\n",
      "Finished epoch 50, latest loss 0.7453243136405945\n",
      "Saved improved model\n",
      "Finished epoch 51, latest loss 0.7468234896659851\n",
      "Finished epoch 52, latest loss 0.7464424967765808\n",
      "Finished epoch 53, latest loss 0.74666428565979\n",
      "Finished epoch 54, latest loss 0.7452976107597351\n",
      "Saved improved model\n",
      "Finished epoch 55, latest loss 0.7462615370750427\n",
      "Finished epoch 56, latest loss 0.7446520924568176\n",
      "Saved improved model\n",
      "Finished epoch 57, latest loss 0.7442727088928223\n",
      "Saved improved model\n",
      "Finished epoch 58, latest loss 0.7442755699157715\n",
      "Finished epoch 59, latest loss 0.7444929480552673\n",
      "Finished epoch 60, latest loss 0.7442811727523804\n",
      "Finished epoch 61, latest loss 0.7451940774917603\n",
      "Finished epoch 62, latest loss 0.744275689125061\n",
      "Finished epoch 63, latest loss 0.7443413138389587\n",
      "Finished epoch 64, latest loss 0.7464097738265991\n",
      "Finished epoch 65, latest loss 0.7444106936454773\n",
      "Finished epoch 66, latest loss 0.7450321316719055\n",
      "Finished epoch 67, latest loss 0.744274377822876\n",
      "Finished epoch 68, latest loss 0.7442808151245117\n",
      "Finished epoch 69, latest loss 0.7442731857299805\n",
      "Finished epoch 70, latest loss 0.7442848086357117\n",
      "Finished epoch 71, latest loss 0.7459672093391418\n",
      "Finished epoch 72, latest loss 0.7467305660247803\n",
      "Finished epoch 73, latest loss 0.74514240026474\n",
      "Finished epoch 74, latest loss 0.7442745566368103\n",
      "Finished epoch 75, latest loss 0.7451722621917725\n",
      "Finished epoch 76, latest loss 0.7442827224731445\n",
      "Finished epoch 77, latest loss 0.7445700764656067\n",
      "Finished epoch 78, latest loss 0.7444894909858704\n",
      "Finished epoch 79, latest loss 0.7442728877067566\n",
      "Finished epoch 80, latest loss 0.7443099021911621\n",
      "Finished epoch 81, latest loss 0.7450066208839417\n",
      "Finished epoch 82, latest loss 0.7451881170272827\n",
      "Finished epoch 83, latest loss 0.7442753314971924\n",
      "Finished epoch 84, latest loss 0.7443097829818726\n",
      "Finished epoch 85, latest loss 0.7454161643981934\n",
      "Finished epoch 86, latest loss 0.7459370493888855\n",
      "Finished epoch 87, latest loss 0.7457877397537231\n",
      "Finished epoch 88, latest loss 0.7442744374275208\n",
      "Finished epoch 89, latest loss 0.7455823421478271\n",
      "Finished epoch 90, latest loss 0.7443408966064453\n",
      "Finished epoch 91, latest loss 0.7443430423736572\n",
      "Finished epoch 92, latest loss 0.7451940178871155\n",
      "Finished epoch 93, latest loss 0.7450554966926575\n",
      "Finished epoch 94, latest loss 0.7451001405715942\n",
      "Finished epoch 95, latest loss 0.7450101971626282\n",
      "Finished epoch 96, latest loss 0.7449054718017578\n",
      "Finished epoch 97, latest loss 0.7449314594268799\n",
      "Finished epoch 98, latest loss 0.7450380325317383\n",
      "Finished epoch 99, latest loss 0.7455226182937622\n",
      "Finished epoch 100, latest loss 0.7459586262702942\n",
      "Finished epoch 101, latest loss 0.7452109456062317\n",
      "Finished epoch 102, latest loss 0.7452163100242615\n",
      "Finished epoch 103, latest loss 0.7458727955818176\n",
      "Finished epoch 104, latest loss 0.7443299293518066\n",
      "Finished epoch 105, latest loss 0.744274914264679\n",
      "Finished epoch 106, latest loss 0.7446330785751343\n",
      "Finished epoch 107, latest loss 0.744440495967865\n",
      "Finished epoch 108, latest loss 0.7445513606071472\n",
      "Finished epoch 109, latest loss 0.7436480522155762\n",
      "Saved improved model\n",
      "Finished epoch 110, latest loss 0.7433459162712097\n",
      "Saved improved model\n",
      "Finished epoch 111, latest loss 0.743342936038971\n",
      "Saved improved model\n",
      "Finished epoch 112, latest loss 0.7437340021133423\n",
      "Finished epoch 113, latest loss 0.7443113923072815\n",
      "Finished epoch 114, latest loss 0.743582010269165\n",
      "Finished epoch 115, latest loss 0.7433428764343262\n",
      "Saved improved model\n",
      "Finished epoch 116, latest loss 0.7433448433876038\n",
      "Finished epoch 117, latest loss 0.7434261441230774\n",
      "Finished epoch 118, latest loss 0.7438796758651733\n",
      "Finished epoch 119, latest loss 0.7433471083641052\n",
      "Finished epoch 120, latest loss 0.7441809177398682\n",
      "Finished epoch 121, latest loss 0.7433428764343262\n",
      "Finished epoch 122, latest loss 0.7433439493179321\n"
     ]
    }
   ],
   "source": [
    "# Ensure reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "X = torch.tensor(np.array(train_df.T), dtype=torch.float32)\n",
    "y = torch.tensor(np.array(train_negoutput), dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Check for CUDA and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move data to the chosen device\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(train_df.shape[0], 64)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(64, 12)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.hidden3 = nn.Linear(12, 8)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act3(self.hidden3(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    " \n",
    "negmodel = PimaClassifier().to(device)\n",
    "print(negmodel)\n",
    "\n",
    "pos_weight = torch.tensor([2.5], device=device)  # Set your_pos_weight based on your needs\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(negmodel.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 2000\n",
    "batch_size = 2000\n",
    "best_loss = float('inf')\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = negmodel(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        # Save model checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': negmodel.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }, 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_negmodel.pth')\n",
    "        print(\"Saved improved model\")\n",
    "\n",
    "test_model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_negmodel.pth')\n",
    "test_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = test_model(X)\n",
    " \n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")\n",
    "\n",
    "# make class predictions with the negmodel\n",
    "neg_predictions = (test_model(X) > 0.5).int().to('cpu')\n",
    "neg_predictions = neg_predictions.numpy()\n",
    "test_pred = pd.DataFrame(neg_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "actual_values = train_negoutput\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for negative predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "neg_predictions = 1 - neg_predictions\n",
    "\n",
    "X = torch.tensor(np.array(train_df.T), dtype=torch.float32)\n",
    "y = torch.tensor(np.array(train9up10d_output), dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Move data to the chosen device\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "model9up10d = PimaClassifier().to(device)\n",
    "print(model9up10d)\n",
    "\n",
    "pos_weight = torch.tensor([1.5], device=device)  # Set your_pos_weight based on your needs\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model9up10d.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 2000\n",
    "batch_size = 2000\n",
    "best_loss = float('inf')\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = model9up10d(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        # Save model checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model9up10d.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }, 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model9up10d.pth')\n",
    "        print(\"Saved improved model\")\n",
    "\n",
    "test_model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model9up10d.pth')\n",
    "test_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = test_model(X)\n",
    " \n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")\n",
    "\n",
    "# make class predictions with the model\n",
    "predictions = (test_model(X) > 0.5).int().to('cpu')\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "###\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "actual_values = train9up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "merge_predictions = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "merge_predictions.index = range(1, len(merge_predictions) + 1)\n",
    "actual_values = train9up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(merge_predictions)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct predictions:\", mean_value)\n",
    "\n",
    "X = torch.tensor(np.array(train_df.T), dtype=torch.float32)\n",
    "y = torch.tensor(np.array(train9up10d_output), dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Move data to the chosen device\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "model7up10d = PimaClassifier().to(device)\n",
    "print(model7up10d)\n",
    "\n",
    "pos_weight = torch.tensor([2], device=device)  # Set your_pos_weight based on your needs\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model7up10d.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 2000\n",
    "batch_size = 2000\n",
    "best_loss = float('inf')\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = model7up10d(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        # Save model checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model7up10d.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }, 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model7up10d.pth')\n",
    "        print(\"Saved improved model\")\n",
    "\n",
    "test_model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model7up10d.pth')\n",
    "test_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = test_model(X)\n",
    " \n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")\n",
    "\n",
    "# make class predictions with the model\n",
    "predictions = (test_model(X) > 0.5).int().to('cpu')\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "###\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "actual_values = train7up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "merge_predictions = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "merge_predictions.index = range(1, len(merge_predictions) + 1)\n",
    "actual_values = train7up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(merge_predictions)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct predictions:\", mean_value)\n",
    "\n",
    "X = torch.tensor(np.array(train_df.T), dtype=torch.float32)\n",
    "y = torch.tensor(np.array(train9up10d_output), dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Move data to the chosen device\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "model5up10d = PimaClassifier().to(device)\n",
    "print(model5up10d)\n",
    "\n",
    "pos_weight = torch.tensor([2.5], device=device)  # Set your_pos_weight based on your needs\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model5up10d.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 2000\n",
    "batch_size = 2000\n",
    "best_loss = float('inf')\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = model5up10d(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        # Save model checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model5up10d.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }, 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model5up10d.pth')\n",
    "        print(\"Saved improved model\")\n",
    "\n",
    "test_model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model5up10d.pth')\n",
    "test_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "test_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = test_model(X)\n",
    " \n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")\n",
    "\n",
    "# make class predictions with the model\n",
    "predictions = (test_model(X) > 0.5).int().to('cpu')\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "###\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "actual_values = train5up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "merge_predictions = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "merge_predictions.index = range(1, len(merge_predictions) + 1)\n",
    "actual_values = train5up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(merge_predictions)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct predictions:\", mean_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eb21fa4-a084-4bc0-8c06-7b939ca43ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63205\n",
      "63205\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1558                4367\n",
      "Actual Negative                 410               56870\n",
      "Positive predictive power:\n",
      "26.3%\n",
      "Positive predictive accuracy:\n",
      "79.17%\n",
      "Confusion Matrix for merged 9up10d predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1343                4582\n",
      "Actual Negative                 285               56995\n",
      "Positive predictive power for 9up10d:\n",
      "22.67%\n",
      "Positive predictive accuracy for 9up10d:\n",
      "82.49%\n",
      "Mean change for incorrect 9up10d predictions: 1.032\n",
      "Mean change for correct 9up10d predictions: 1.128\n",
      "63205\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                2082                8039\n",
      "Actual Negative                 293               52791\n",
      "Positive predictive power:\n",
      "20.57%\n",
      "Positive predictive accuracy:\n",
      "87.66%\n",
      "Confusion Matrix for merged 7up10d predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1779                8342\n",
      "Actual Negative                 174               52910\n",
      "Positive predictive power for 7up10d:\n",
      "17.58%\n",
      "Positive predictive accuracy for 7up10d:\n",
      "91.09%\n",
      "Mean change for incorrect 7up10d predictions: 1.015\n",
      "Mean change for correct 7up10d predictions: 1.12\n",
      "63205\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                2415               14959\n",
      "Actual Negative                 202               45629\n",
      "Positive predictive power:\n",
      "13.9%\n",
      "Positive predictive accuracy:\n",
      "92.28%\n",
      "Confusion Matrix for merged 5up10d predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                2065               15309\n",
      "Actual Negative                 118               45713\n",
      "Positive predictive power for 5up10d:\n",
      "11.89%\n",
      "Positive predictive accuracy for 5up10d:\n",
      "94.59%\n",
      "Mean change for incorrect 5up10d predictions: 0.98\n",
      "Mean change for correct 5up10d predictions: 1.112\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Move your model and input data to the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "negmodel = PimaClassifier().to(device)\n",
    "negcheckpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_negmodel.pth')\n",
    "negmodel.load_state_dict(negcheckpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(negcheckpoint['optimizer_state_dict'])\n",
    "epoch = negcheckpoint['epoch']\n",
    "loss = negcheckpoint['loss']\n",
    "negmodel.eval()\n",
    "negmodel = negmodel.to(device)\n",
    "\n",
    "# Step 2: Prepare your input data (assuming new_input is your raw data)\n",
    "# For example, if your model expects input size of (1, C, H, W)\n",
    "input_tensor = torch.tensor(np.array(test_df.T), dtype=torch.float32)\n",
    "input_tensor = input_tensor.to(device)\n",
    "neg_predictions = (negmodel(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(neg_predictions))\n",
    "neg_predictions = neg_predictions.numpy()\n",
    "neg_predictions = 1 - neg_predictions\n",
    "\n",
    "model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model9up10d.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "input_tensor = torch.tensor(np.array(test_df.T), dtype=torch.float32)\n",
    "input_tensor = input_tensor.to(device)\n",
    "predictions = (model(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(predictions))\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test9up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "test_pred = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test9up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged 9up10d predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power for 9up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy for 9up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect 9up10d predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct 9up10d predictions:\", mean_value)\n",
    "\n",
    "###\n",
    "\n",
    "model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model7up10d.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "input_tensor = torch.tensor(np.array(test_df.T), dtype=torch.float32)\n",
    "input_tensor = input_tensor.to(device)\n",
    "predictions = (model(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(predictions))\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test7up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "test_pred = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test7up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged 7up10d predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power for 7up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy for 7up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect 7up10d predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct 7up10d predictions:\", mean_value)\n",
    "\n",
    "###\n",
    "\n",
    "model = PimaClassifier().to(device)\n",
    "checkpoint = torch.load('E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_best_model5up10d.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "input_tensor = torch.tensor(np.array(test_df.T), dtype=torch.float32)\n",
    "input_tensor = input_tensor.to(device)\n",
    "predictions = (model(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(predictions))\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test5up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "test_pred = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test5up10d_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged 5up10d predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power for 5up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy for 5up10d:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect 5up10d predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct 5up10d predictions:\", mean_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9aa606-c4b5-4206-8868-e66b1375ede3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c1258c0-3f3f-4818-93a8-e74cfdc70dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PimaClassifier(\n",
      "  (hidden1): Linear(in_features=1616, out_features=64, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (hidden2): Linear(in_features=64, out_features=12, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (hidden3): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (act3): ReLU()\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (act_output): Sigmoid()\n",
      ")\n",
      "Finished epoch 0, latest loss 0.9709123969078064\n",
      "Finished epoch 1, latest loss 0.959958553314209\n",
      "Finished epoch 2, latest loss 0.9461503028869629\n",
      "Finished epoch 3, latest loss 0.9359431862831116\n",
      "Finished epoch 4, latest loss 0.9327227473258972\n",
      "Finished epoch 5, latest loss 0.922701895236969\n",
      "Finished epoch 6, latest loss 0.9164071083068848\n",
      "Finished epoch 7, latest loss 0.9102634787559509\n",
      "Finished epoch 8, latest loss 0.9003651142120361\n",
      "Finished epoch 9, latest loss 0.8953574895858765\n",
      "Finished epoch 10, latest loss 0.9102886915206909\n",
      "Finished epoch 11, latest loss 0.8989652395248413\n",
      "Finished epoch 12, latest loss 0.8933894038200378\n",
      "Finished epoch 13, latest loss 0.8964558839797974\n",
      "Finished epoch 14, latest loss 0.891559362411499\n",
      "Finished epoch 15, latest loss 0.8963116407394409\n",
      "Finished epoch 16, latest loss 0.8827286958694458\n",
      "Finished epoch 17, latest loss 0.8841604590415955\n",
      "Finished epoch 18, latest loss 0.8831980228424072\n",
      "Finished epoch 19, latest loss 0.881640613079071\n",
      "Finished epoch 20, latest loss 0.8756496906280518\n",
      "Finished epoch 21, latest loss 0.8760429620742798\n",
      "Finished epoch 22, latest loss 0.8760552406311035\n",
      "Finished epoch 23, latest loss 0.8785009980201721\n",
      "Finished epoch 24, latest loss 0.8791466355323792\n",
      "Finished epoch 25, latest loss 0.8762941956520081\n",
      "Finished epoch 26, latest loss 0.8733170032501221\n",
      "Finished epoch 27, latest loss 0.8737958073616028\n",
      "Finished epoch 28, latest loss 0.8721607327461243\n",
      "Finished epoch 29, latest loss 0.8716892004013062\n",
      "Finished epoch 30, latest loss 0.8699405789375305\n",
      "Finished epoch 31, latest loss 0.8747430443763733\n",
      "Finished epoch 32, latest loss 0.8736231923103333\n",
      "Finished epoch 33, latest loss 0.8748226761817932\n",
      "Finished epoch 34, latest loss 0.8700977563858032\n",
      "Finished epoch 35, latest loss 0.8733459115028381\n",
      "Finished epoch 36, latest loss 0.870094895362854\n",
      "Finished epoch 37, latest loss 0.8722060322761536\n",
      "Finished epoch 38, latest loss 0.8739586472511292\n",
      "Finished epoch 39, latest loss 0.8768329620361328\n",
      "Finished epoch 40, latest loss 0.8741050958633423\n",
      "Finished epoch 41, latest loss 0.8694067001342773\n",
      "Finished epoch 42, latest loss 0.8665526509284973\n",
      "Finished epoch 43, latest loss 0.8704248666763306\n",
      "Finished epoch 44, latest loss 0.8676503896713257\n",
      "Finished epoch 45, latest loss 0.8702866435050964\n",
      "Finished epoch 46, latest loss 0.8733204007148743\n",
      "Finished epoch 47, latest loss 0.8667195439338684\n",
      "Finished epoch 48, latest loss 0.8660386800765991\n",
      "Finished epoch 49, latest loss 0.8665107488632202\n",
      "Finished epoch 50, latest loss 0.8654048442840576\n",
      "Finished epoch 51, latest loss 0.8627528548240662\n",
      "Finished epoch 52, latest loss 0.8629735112190247\n",
      "Finished epoch 53, latest loss 0.870855987071991\n",
      "Finished epoch 54, latest loss 0.8617167472839355\n",
      "Finished epoch 55, latest loss 0.8627155423164368\n",
      "Finished epoch 56, latest loss 0.8606384992599487\n",
      "Finished epoch 57, latest loss 0.8650370240211487\n",
      "Finished epoch 58, latest loss 0.8621782660484314\n",
      "Finished epoch 59, latest loss 0.864676296710968\n",
      "Finished epoch 60, latest loss 0.8589894771575928\n",
      "Finished epoch 61, latest loss 0.8636762499809265\n",
      "Finished epoch 62, latest loss 0.8588061928749084\n",
      "Finished epoch 63, latest loss 0.854671835899353\n",
      "Finished epoch 64, latest loss 0.8634796142578125\n",
      "Finished epoch 65, latest loss 0.8588449358940125\n",
      "Finished epoch 66, latest loss 0.8572849631309509\n",
      "Finished epoch 67, latest loss 0.8587656617164612\n",
      "Finished epoch 68, latest loss 0.8664069175720215\n",
      "Finished epoch 69, latest loss 0.8617787957191467\n",
      "Finished epoch 70, latest loss 0.860742449760437\n",
      "Finished epoch 71, latest loss 0.8556802272796631\n",
      "Finished epoch 72, latest loss 0.8558149337768555\n",
      "Finished epoch 73, latest loss 0.8578251600265503\n",
      "Finished epoch 74, latest loss 0.8582732677459717\n",
      "Finished epoch 75, latest loss 0.8571744561195374\n",
      "Finished epoch 76, latest loss 0.8622742295265198\n",
      "Finished epoch 77, latest loss 0.858347475528717\n",
      "Finished epoch 78, latest loss 0.8521270751953125\n",
      "Finished epoch 79, latest loss 0.8554804921150208\n",
      "Finished epoch 80, latest loss 0.8573498725891113\n",
      "Finished epoch 81, latest loss 0.8545690774917603\n",
      "Finished epoch 82, latest loss 0.8519980907440186\n",
      "Finished epoch 83, latest loss 0.8516297340393066\n",
      "Finished epoch 84, latest loss 0.8515192866325378\n",
      "Finished epoch 85, latest loss 0.8485076427459717\n",
      "Finished epoch 86, latest loss 0.8532629013061523\n",
      "Finished epoch 87, latest loss 0.848918080329895\n",
      "Finished epoch 88, latest loss 0.8489283323287964\n",
      "Finished epoch 89, latest loss 0.8600982427597046\n",
      "Finished epoch 90, latest loss 0.8463184833526611\n",
      "Finished epoch 91, latest loss 0.8604433536529541\n",
      "Finished epoch 92, latest loss 0.8520397543907166\n",
      "Finished epoch 93, latest loss 0.8513018488883972\n",
      "Finished epoch 94, latest loss 0.8522081971168518\n",
      "Finished epoch 95, latest loss 0.8522616028785706\n",
      "Finished epoch 96, latest loss 0.8578948378562927\n",
      "Finished epoch 97, latest loss 0.8509938716888428\n",
      "Finished epoch 98, latest loss 0.8581672310829163\n",
      "Finished epoch 99, latest loss 0.8558616638183594\n",
      "Finished epoch 100, latest loss 0.8475341796875\n",
      "Finished epoch 101, latest loss 0.8548972606658936\n",
      "Finished epoch 102, latest loss 0.8553658127784729\n",
      "Finished epoch 103, latest loss 0.8611295819282532\n",
      "Finished epoch 104, latest loss 0.8561303019523621\n",
      "Finished epoch 105, latest loss 0.8494819402694702\n",
      "Finished epoch 106, latest loss 0.8509270548820496\n",
      "Finished epoch 107, latest loss 0.8523752093315125\n",
      "Finished epoch 108, latest loss 0.8467671275138855\n",
      "Finished epoch 109, latest loss 0.8556126356124878\n",
      "Finished epoch 110, latest loss 0.8574919700622559\n",
      "Finished epoch 111, latest loss 0.853399932384491\n",
      "Finished epoch 112, latest loss 0.8492499589920044\n",
      "Finished epoch 113, latest loss 0.8521375060081482\n",
      "Finished epoch 114, latest loss 0.8507534265518188\n",
      "Finished epoch 115, latest loss 0.8596461415290833\n",
      "Finished epoch 116, latest loss 0.8534042239189148\n",
      "Finished epoch 117, latest loss 0.848142147064209\n",
      "Finished epoch 118, latest loss 0.8489590287208557\n",
      "Finished epoch 119, latest loss 0.8496900200843811\n",
      "Finished epoch 120, latest loss 0.85174560546875\n",
      "Finished epoch 121, latest loss 0.8542914390563965\n",
      "Finished epoch 122, latest loss 0.8493244051933289\n",
      "Finished epoch 123, latest loss 0.852387547492981\n",
      "Finished epoch 124, latest loss 0.8556776642799377\n",
      "Finished epoch 125, latest loss 0.8505853414535522\n",
      "Finished epoch 126, latest loss 0.849648118019104\n",
      "Finished epoch 127, latest loss 0.8422441482543945\n",
      "Finished epoch 128, latest loss 0.8547195792198181\n",
      "Finished epoch 129, latest loss 0.8496055006980896\n",
      "Finished epoch 130, latest loss 0.8463085889816284\n",
      "Finished epoch 131, latest loss 0.857821524143219\n",
      "Finished epoch 132, latest loss 0.8459029793739319\n",
      "Finished epoch 133, latest loss 0.8521700501441956\n",
      "Finished epoch 134, latest loss 0.8514416217803955\n",
      "Finished epoch 135, latest loss 0.847698450088501\n",
      "Finished epoch 136, latest loss 0.8510007262229919\n",
      "Finished epoch 137, latest loss 0.8535781502723694\n",
      "Finished epoch 138, latest loss 0.8485466241836548\n",
      "Finished epoch 139, latest loss 0.8517096638679504\n",
      "Finished epoch 140, latest loss 0.8456049561500549\n",
      "Finished epoch 141, latest loss 0.8463292121887207\n",
      "Finished epoch 142, latest loss 0.8450645208358765\n",
      "Finished epoch 143, latest loss 0.8504583835601807\n",
      "Finished epoch 144, latest loss 0.8532701730728149\n",
      "Finished epoch 145, latest loss 0.8479034900665283\n",
      "Finished epoch 146, latest loss 0.8463752269744873\n",
      "Finished epoch 147, latest loss 0.8572549819946289\n",
      "Finished epoch 148, latest loss 0.8433634638786316\n",
      "Finished epoch 149, latest loss 0.8453982472419739\n",
      "Finished epoch 150, latest loss 0.8573904037475586\n",
      "Finished epoch 151, latest loss 0.8587216138839722\n",
      "Finished epoch 152, latest loss 0.854512631893158\n",
      "Finished epoch 153, latest loss 0.8498214483261108\n",
      "Finished epoch 154, latest loss 0.8518309593200684\n",
      "Finished epoch 155, latest loss 0.8461446166038513\n",
      "Finished epoch 156, latest loss 0.8490805625915527\n",
      "Finished epoch 157, latest loss 0.8402974009513855\n",
      "Finished epoch 158, latest loss 0.8416075110435486\n",
      "Finished epoch 159, latest loss 0.8470944166183472\n",
      "Finished epoch 160, latest loss 0.8414229154586792\n",
      "Finished epoch 161, latest loss 0.8470556735992432\n",
      "Finished epoch 162, latest loss 0.8460688591003418\n",
      "Finished epoch 163, latest loss 0.8471612334251404\n",
      "Finished epoch 164, latest loss 0.8455640077590942\n",
      "Finished epoch 165, latest loss 0.8474141955375671\n",
      "Finished epoch 166, latest loss 0.8494056463241577\n",
      "Finished epoch 167, latest loss 0.8477177619934082\n",
      "Finished epoch 168, latest loss 0.8572458624839783\n",
      "Finished epoch 169, latest loss 0.8524196147918701\n",
      "Finished epoch 170, latest loss 0.8500112295150757\n",
      "Finished epoch 171, latest loss 0.8466944098472595\n",
      "Finished epoch 172, latest loss 0.8472082018852234\n",
      "Finished epoch 173, latest loss 0.8458936810493469\n",
      "Finished epoch 174, latest loss 0.8423096537590027\n",
      "Finished epoch 175, latest loss 0.8459190130233765\n",
      "Finished epoch 176, latest loss 0.8447017073631287\n",
      "Finished epoch 177, latest loss 0.8484809994697571\n",
      "Finished epoch 178, latest loss 0.8458168506622314\n",
      "Finished epoch 179, latest loss 0.8453351259231567\n",
      "Finished epoch 180, latest loss 0.8409529328346252\n",
      "Finished epoch 181, latest loss 0.8412861227989197\n",
      "Finished epoch 182, latest loss 0.8441782593727112\n",
      "Finished epoch 183, latest loss 0.8449782729148865\n",
      "Finished epoch 184, latest loss 0.8469526171684265\n",
      "Finished epoch 185, latest loss 0.8407219648361206\n",
      "Finished epoch 186, latest loss 0.8449850678443909\n",
      "Finished epoch 187, latest loss 0.8454098105430603\n",
      "Finished epoch 188, latest loss 0.8453466892242432\n",
      "Finished epoch 189, latest loss 0.8452221155166626\n",
      "Finished epoch 190, latest loss 0.8407732248306274\n",
      "Finished epoch 191, latest loss 0.844975471496582\n",
      "Finished epoch 192, latest loss 0.8450832962989807\n",
      "Finished epoch 193, latest loss 0.8483107089996338\n",
      "Finished epoch 194, latest loss 0.8407588005065918\n",
      "Finished epoch 195, latest loss 0.8452965021133423\n",
      "Finished epoch 196, latest loss 0.8420074582099915\n",
      "Finished epoch 197, latest loss 0.8498626947402954\n",
      "Finished epoch 198, latest loss 0.8431093096733093\n",
      "Finished epoch 199, latest loss 0.8417583703994751\n",
      "Finished epoch 200, latest loss 0.8443474173545837\n",
      "Finished epoch 201, latest loss 0.8407619595527649\n",
      "Finished epoch 202, latest loss 0.8402503728866577\n",
      "Finished epoch 203, latest loss 0.8387306928634644\n",
      "Finished epoch 204, latest loss 0.8451880812644958\n",
      "Finished epoch 205, latest loss 0.8366438150405884\n",
      "Finished epoch 206, latest loss 0.841101884841919\n",
      "Finished epoch 207, latest loss 0.8411903381347656\n",
      "Finished epoch 208, latest loss 0.8443695902824402\n",
      "Finished epoch 209, latest loss 0.8401643633842468\n",
      "Finished epoch 210, latest loss 0.8377143144607544\n",
      "Finished epoch 211, latest loss 0.836598813533783\n",
      "Finished epoch 212, latest loss 0.8381202220916748\n",
      "Finished epoch 213, latest loss 0.8395825028419495\n",
      "Finished epoch 214, latest loss 0.8416944146156311\n",
      "Finished epoch 215, latest loss 0.8356056213378906\n",
      "Finished epoch 216, latest loss 0.8389718532562256\n",
      "Finished epoch 217, latest loss 0.8357664346694946\n",
      "Finished epoch 218, latest loss 0.8333595991134644\n",
      "Finished epoch 219, latest loss 0.8427766561508179\n",
      "Finished epoch 220, latest loss 0.8332995772361755\n",
      "Finished epoch 221, latest loss 0.8376796245574951\n",
      "Finished epoch 222, latest loss 0.8340137004852295\n",
      "Finished epoch 223, latest loss 0.8415806293487549\n",
      "Finished epoch 224, latest loss 0.8378534913063049\n",
      "Finished epoch 225, latest loss 0.8408913016319275\n",
      "Finished epoch 226, latest loss 0.8372067213058472\n",
      "Finished epoch 227, latest loss 0.8514107465744019\n",
      "Finished epoch 228, latest loss 0.8402888178825378\n",
      "Finished epoch 229, latest loss 0.8378952145576477\n",
      "Finished epoch 230, latest loss 0.8433957695960999\n",
      "Finished epoch 231, latest loss 0.8388400077819824\n",
      "Finished epoch 232, latest loss 0.8375716209411621\n",
      "Finished epoch 233, latest loss 0.8337610363960266\n",
      "Finished epoch 234, latest loss 0.8348155617713928\n",
      "Finished epoch 235, latest loss 0.8297587037086487\n",
      "Finished epoch 236, latest loss 0.8372973799705505\n",
      "Finished epoch 237, latest loss 0.8367469906806946\n",
      "Finished epoch 238, latest loss 0.8310763239860535\n",
      "Finished epoch 239, latest loss 0.8393234014511108\n",
      "Finished epoch 240, latest loss 0.8327175974845886\n",
      "Finished epoch 241, latest loss 0.8356113433837891\n",
      "Finished epoch 242, latest loss 0.8334271311759949\n",
      "Finished epoch 243, latest loss 0.8300756812095642\n",
      "Finished epoch 244, latest loss 0.8377084136009216\n",
      "Finished epoch 245, latest loss 0.8323968648910522\n",
      "Finished epoch 246, latest loss 0.833217978477478\n",
      "Finished epoch 247, latest loss 0.8400038480758667\n",
      "Finished epoch 248, latest loss 0.8319441080093384\n",
      "Finished epoch 249, latest loss 0.841381311416626\n",
      "Finished epoch 250, latest loss 0.83734530210495\n",
      "Finished epoch 251, latest loss 0.8370864987373352\n",
      "Finished epoch 252, latest loss 0.8314806222915649\n",
      "Finished epoch 253, latest loss 0.8427618145942688\n",
      "Finished epoch 254, latest loss 0.8375717997550964\n",
      "Finished epoch 255, latest loss 0.8295974135398865\n",
      "Finished epoch 256, latest loss 0.8295924663543701\n",
      "Finished epoch 257, latest loss 0.8323339819908142\n",
      "Finished epoch 258, latest loss 0.8353663682937622\n",
      "Finished epoch 259, latest loss 0.8323138356208801\n",
      "Finished epoch 260, latest loss 0.8287204504013062\n",
      "Finished epoch 261, latest loss 0.8294048309326172\n",
      "Finished epoch 262, latest loss 0.8320931792259216\n",
      "Finished epoch 263, latest loss 0.833512008190155\n",
      "Finished epoch 264, latest loss 0.834739089012146\n",
      "Finished epoch 265, latest loss 0.8318672180175781\n",
      "Finished epoch 266, latest loss 0.8316842913627625\n",
      "Finished epoch 267, latest loss 0.8282944560050964\n",
      "Finished epoch 268, latest loss 0.834498941898346\n",
      "Finished epoch 269, latest loss 0.8332157135009766\n",
      "Finished epoch 270, latest loss 0.841322124004364\n",
      "Finished epoch 271, latest loss 0.8354442715644836\n",
      "Finished epoch 272, latest loss 0.8381108641624451\n",
      "Finished epoch 273, latest loss 0.834247350692749\n",
      "Finished epoch 274, latest loss 0.8350716233253479\n",
      "Finished epoch 275, latest loss 0.8314905762672424\n",
      "Finished epoch 276, latest loss 0.834770679473877\n",
      "Finished epoch 277, latest loss 0.8258034586906433\n",
      "Finished epoch 278, latest loss 0.8298126459121704\n",
      "Finished epoch 279, latest loss 0.8304606676101685\n",
      "Finished epoch 280, latest loss 0.8273329734802246\n",
      "Finished epoch 281, latest loss 0.8307719230651855\n",
      "Finished epoch 282, latest loss 0.8333401679992676\n",
      "Finished epoch 283, latest loss 0.835402250289917\n",
      "Finished epoch 284, latest loss 0.8329077363014221\n",
      "Finished epoch 285, latest loss 0.8375793099403381\n",
      "Finished epoch 286, latest loss 0.8321805000305176\n",
      "Finished epoch 287, latest loss 0.8332871794700623\n",
      "Finished epoch 288, latest loss 0.8298191428184509\n",
      "Finished epoch 289, latest loss 0.8324963450431824\n",
      "Finished epoch 290, latest loss 0.8431776762008667\n",
      "Finished epoch 291, latest loss 0.8347423672676086\n",
      "Finished epoch 292, latest loss 0.8300141096115112\n",
      "Finished epoch 293, latest loss 0.8356872200965881\n",
      "Finished epoch 294, latest loss 0.8323498368263245\n",
      "Finished epoch 295, latest loss 0.8336591720581055\n",
      "Finished epoch 296, latest loss 0.8343555927276611\n",
      "Finished epoch 297, latest loss 0.8342617154121399\n",
      "Finished epoch 298, latest loss 0.8315902948379517\n",
      "Finished epoch 299, latest loss 0.8323390483856201\n",
      "Finished epoch 300, latest loss 0.8266458511352539\n",
      "Finished epoch 301, latest loss 0.829335629940033\n",
      "Finished epoch 302, latest loss 0.8320615291595459\n",
      "Finished epoch 303, latest loss 0.8339980244636536\n",
      "Finished epoch 304, latest loss 0.8269492387771606\n",
      "Finished epoch 305, latest loss 0.8297650814056396\n",
      "Finished epoch 306, latest loss 0.8284717798233032\n",
      "Finished epoch 307, latest loss 0.8286579847335815\n",
      "Finished epoch 308, latest loss 0.8336941003799438\n",
      "Finished epoch 309, latest loss 0.827272891998291\n",
      "Finished epoch 310, latest loss 0.827947735786438\n",
      "Finished epoch 311, latest loss 0.8320568203926086\n",
      "Finished epoch 312, latest loss 0.8315141201019287\n",
      "Finished epoch 313, latest loss 0.8380371928215027\n",
      "Finished epoch 314, latest loss 0.8249794840812683\n",
      "Finished epoch 315, latest loss 0.8340393304824829\n",
      "Finished epoch 316, latest loss 0.8308987021446228\n",
      "Finished epoch 317, latest loss 0.827847957611084\n",
      "Finished epoch 318, latest loss 0.8324154615402222\n",
      "Finished epoch 319, latest loss 0.8294848799705505\n",
      "Finished epoch 320, latest loss 0.8277955651283264\n",
      "Finished epoch 321, latest loss 0.8310210704803467\n",
      "Finished epoch 322, latest loss 0.8358311653137207\n",
      "Finished epoch 323, latest loss 0.8318809866905212\n",
      "Finished epoch 324, latest loss 0.8320624232292175\n",
      "Finished epoch 325, latest loss 0.8303776979446411\n",
      "Finished epoch 326, latest loss 0.8293554782867432\n",
      "Finished epoch 327, latest loss 0.8267862200737\n",
      "Finished epoch 328, latest loss 0.8276203870773315\n",
      "Finished epoch 329, latest loss 0.8316368460655212\n",
      "Finished epoch 330, latest loss 0.8257891535758972\n",
      "Finished epoch 331, latest loss 0.8317835330963135\n",
      "Finished epoch 332, latest loss 0.8286174535751343\n",
      "Finished epoch 333, latest loss 0.8272297978401184\n",
      "Finished epoch 334, latest loss 0.8320696353912354\n",
      "Finished epoch 335, latest loss 0.8293217420578003\n",
      "Finished epoch 336, latest loss 0.8423269987106323\n",
      "Finished epoch 337, latest loss 0.8304977416992188\n",
      "Finished epoch 338, latest loss 0.8292627930641174\n",
      "Finished epoch 339, latest loss 0.8315969109535217\n",
      "Finished epoch 340, latest loss 0.8332023024559021\n",
      "Finished epoch 341, latest loss 0.8304400444030762\n",
      "Finished epoch 342, latest loss 0.8275817632675171\n",
      "Finished epoch 343, latest loss 0.827864944934845\n",
      "Finished epoch 344, latest loss 0.836562991142273\n",
      "Finished epoch 345, latest loss 0.8351212739944458\n",
      "Finished epoch 346, latest loss 0.8331518173217773\n",
      "Finished epoch 347, latest loss 0.8317121863365173\n",
      "Finished epoch 348, latest loss 0.8276780843734741\n",
      "Finished epoch 349, latest loss 0.8311007022857666\n",
      "Finished epoch 350, latest loss 0.8269779682159424\n",
      "Finished epoch 351, latest loss 0.8287410736083984\n",
      "Finished epoch 352, latest loss 0.82534259557724\n",
      "Finished epoch 353, latest loss 0.8365919589996338\n",
      "Finished epoch 354, latest loss 0.8308360576629639\n",
      "Finished epoch 355, latest loss 0.83526611328125\n",
      "Finished epoch 356, latest loss 0.8265780210494995\n",
      "Finished epoch 357, latest loss 0.8296598196029663\n",
      "Finished epoch 358, latest loss 0.8281707763671875\n",
      "Finished epoch 359, latest loss 0.8310365676879883\n",
      "Finished epoch 360, latest loss 0.8317992091178894\n",
      "Finished epoch 361, latest loss 0.8282788395881653\n",
      "Finished epoch 362, latest loss 0.8281106352806091\n",
      "Finished epoch 363, latest loss 0.8245640397071838\n",
      "Finished epoch 364, latest loss 0.8290107846260071\n",
      "Finished epoch 365, latest loss 0.8230478167533875\n",
      "Finished epoch 366, latest loss 0.8274205923080444\n",
      "Finished epoch 367, latest loss 0.8303421139717102\n",
      "Finished epoch 368, latest loss 0.8341376185417175\n",
      "Finished epoch 369, latest loss 0.8358608484268188\n",
      "Finished epoch 370, latest loss 0.8258838653564453\n",
      "Finished epoch 371, latest loss 0.8265281319618225\n",
      "Finished epoch 372, latest loss 0.8240014314651489\n",
      "Finished epoch 373, latest loss 0.8253287672996521\n",
      "Finished epoch 374, latest loss 0.8305837512016296\n",
      "Finished epoch 375, latest loss 0.8267351388931274\n",
      "Finished epoch 376, latest loss 0.8238987326622009\n",
      "Finished epoch 377, latest loss 0.8238345980644226\n",
      "Finished epoch 378, latest loss 0.8233357667922974\n",
      "Finished epoch 379, latest loss 0.8238384127616882\n",
      "Finished epoch 380, latest loss 0.8300592303276062\n",
      "Finished epoch 381, latest loss 0.8250974416732788\n",
      "Finished epoch 382, latest loss 0.8316987752914429\n",
      "Finished epoch 383, latest loss 0.8385262489318848\n",
      "Finished epoch 384, latest loss 0.8234896063804626\n",
      "Finished epoch 385, latest loss 0.8248023986816406\n",
      "Finished epoch 386, latest loss 0.8226929903030396\n",
      "Finished epoch 387, latest loss 0.8259209394454956\n",
      "Finished epoch 388, latest loss 0.8248879909515381\n",
      "Finished epoch 389, latest loss 0.8270941972732544\n",
      "Finished epoch 390, latest loss 0.824236273765564\n",
      "Finished epoch 391, latest loss 0.8242198824882507\n",
      "Finished epoch 392, latest loss 0.8297906517982483\n",
      "Finished epoch 393, latest loss 0.8298118710517883\n",
      "Finished epoch 394, latest loss 0.825342059135437\n",
      "Finished epoch 395, latest loss 0.8342546224594116\n",
      "Finished epoch 396, latest loss 0.8241723775863647\n",
      "Finished epoch 397, latest loss 0.8278831839561462\n",
      "Finished epoch 398, latest loss 0.8312170505523682\n",
      "Finished epoch 399, latest loss 0.8342803120613098\n",
      "Finished epoch 400, latest loss 0.825439453125\n",
      "Finished epoch 401, latest loss 0.8237104415893555\n",
      "Finished epoch 402, latest loss 0.8258681297302246\n",
      "Finished epoch 403, latest loss 0.8235516548156738\n",
      "Finished epoch 404, latest loss 0.8278762102127075\n",
      "Finished epoch 405, latest loss 0.825334906578064\n",
      "Finished epoch 406, latest loss 0.8282276391983032\n",
      "Finished epoch 407, latest loss 0.8259549736976624\n",
      "Finished epoch 408, latest loss 0.822374165058136\n",
      "Finished epoch 409, latest loss 0.8242926001548767\n",
      "Finished epoch 410, latest loss 0.8245713710784912\n",
      "Finished epoch 411, latest loss 0.8283753991127014\n",
      "Finished epoch 412, latest loss 0.8247873783111572\n",
      "Finished epoch 413, latest loss 0.8214987516403198\n",
      "Finished epoch 414, latest loss 0.8224257230758667\n",
      "Finished epoch 415, latest loss 0.8255406618118286\n",
      "Finished epoch 416, latest loss 0.8207679390907288\n",
      "Finished epoch 417, latest loss 0.8209984302520752\n",
      "Finished epoch 418, latest loss 0.8276313543319702\n",
      "Finished epoch 419, latest loss 0.8337627649307251\n",
      "Finished epoch 420, latest loss 0.82328861951828\n",
      "Finished epoch 421, latest loss 0.8229452967643738\n",
      "Finished epoch 422, latest loss 0.822141170501709\n",
      "Finished epoch 423, latest loss 0.8213586807250977\n",
      "Finished epoch 424, latest loss 0.8234226703643799\n",
      "Finished epoch 425, latest loss 0.8312092423439026\n",
      "Finished epoch 426, latest loss 0.8180734515190125\n",
      "Finished epoch 427, latest loss 0.8224518895149231\n",
      "Finished epoch 428, latest loss 0.825064480304718\n",
      "Finished epoch 429, latest loss 0.8209090232849121\n",
      "Finished epoch 430, latest loss 0.8268538117408752\n",
      "Finished epoch 431, latest loss 0.8233232498168945\n",
      "Finished epoch 432, latest loss 0.8259739279747009\n",
      "Finished epoch 433, latest loss 0.8237224221229553\n",
      "Finished epoch 434, latest loss 0.8216932415962219\n",
      "Finished epoch 435, latest loss 0.8240742087364197\n",
      "Finished epoch 436, latest loss 0.8241819739341736\n",
      "Finished epoch 437, latest loss 0.8282938599586487\n",
      "Finished epoch 438, latest loss 0.823469340801239\n",
      "Finished epoch 439, latest loss 0.8254783749580383\n",
      "Finished epoch 440, latest loss 0.8255095481872559\n",
      "Finished epoch 441, latest loss 0.8191037774085999\n",
      "Finished epoch 442, latest loss 0.8209962248802185\n",
      "Finished epoch 443, latest loss 0.8243039846420288\n",
      "Finished epoch 444, latest loss 0.8209495544433594\n",
      "Finished epoch 445, latest loss 0.8319369554519653\n",
      "Finished epoch 446, latest loss 0.8255441784858704\n",
      "Finished epoch 447, latest loss 0.8217417001724243\n",
      "Finished epoch 448, latest loss 0.8296524286270142\n",
      "Finished epoch 449, latest loss 0.8196150064468384\n",
      "Finished epoch 450, latest loss 0.8252048492431641\n",
      "Finished epoch 451, latest loss 0.8256551027297974\n",
      "Finished epoch 452, latest loss 0.824983537197113\n",
      "Finished epoch 453, latest loss 0.8258791565895081\n",
      "Finished epoch 454, latest loss 0.8245989680290222\n",
      "Finished epoch 455, latest loss 0.8223325610160828\n",
      "Finished epoch 456, latest loss 0.8217390179634094\n",
      "Finished epoch 457, latest loss 0.8269990086555481\n",
      "Finished epoch 458, latest loss 0.8236192464828491\n",
      "Finished epoch 459, latest loss 0.8286569118499756\n",
      "Finished epoch 460, latest loss 0.8211344480514526\n",
      "Finished epoch 461, latest loss 0.8221930265426636\n",
      "Finished epoch 462, latest loss 0.8231250047683716\n",
      "Finished epoch 463, latest loss 0.8247458934783936\n",
      "Finished epoch 464, latest loss 0.824112594127655\n",
      "Finished epoch 465, latest loss 0.8247302174568176\n",
      "Finished epoch 466, latest loss 0.8199635744094849\n",
      "Finished epoch 467, latest loss 0.8305188417434692\n",
      "Finished epoch 468, latest loss 0.8223316073417664\n",
      "Finished epoch 469, latest loss 0.8231072425842285\n",
      "Finished epoch 470, latest loss 0.8225669264793396\n",
      "Finished epoch 471, latest loss 0.8248900175094604\n",
      "Finished epoch 472, latest loss 0.8222727179527283\n",
      "Finished epoch 473, latest loss 0.8247610330581665\n",
      "Finished epoch 474, latest loss 0.8245208263397217\n",
      "Finished epoch 475, latest loss 0.8299465775489807\n",
      "Finished epoch 476, latest loss 0.8215736150741577\n",
      "Finished epoch 477, latest loss 0.8222936987876892\n",
      "Finished epoch 478, latest loss 0.8196316957473755\n",
      "Finished epoch 479, latest loss 0.8189949989318848\n",
      "Finished epoch 480, latest loss 0.8257747888565063\n",
      "Finished epoch 481, latest loss 0.8236271739006042\n",
      "Finished epoch 482, latest loss 0.8221470713615417\n",
      "Finished epoch 483, latest loss 0.8206250667572021\n",
      "Finished epoch 484, latest loss 0.8220965266227722\n",
      "Finished epoch 485, latest loss 0.8196065425872803\n",
      "Finished epoch 486, latest loss 0.8202705979347229\n",
      "Finished epoch 487, latest loss 0.8254937529563904\n",
      "Finished epoch 488, latest loss 0.8206285238265991\n",
      "Finished epoch 489, latest loss 0.8221676349639893\n",
      "Finished epoch 490, latest loss 0.8245376348495483\n",
      "Finished epoch 491, latest loss 0.8236119151115417\n",
      "Finished epoch 492, latest loss 0.8182653784751892\n",
      "Finished epoch 493, latest loss 0.8233306407928467\n",
      "Finished epoch 494, latest loss 0.8221460580825806\n",
      "Finished epoch 495, latest loss 0.8201417922973633\n",
      "Finished epoch 496, latest loss 0.8196994662284851\n",
      "Finished epoch 497, latest loss 0.8251915574073792\n",
      "Finished epoch 498, latest loss 0.8276342153549194\n",
      "Finished epoch 499, latest loss 0.8214505910873413\n",
      "Finished epoch 500, latest loss 0.8265703916549683\n",
      "Finished epoch 501, latest loss 0.8252903819084167\n",
      "Finished epoch 502, latest loss 0.8257831931114197\n",
      "Finished epoch 503, latest loss 0.8237529993057251\n",
      "Finished epoch 504, latest loss 0.8210904598236084\n",
      "Finished epoch 505, latest loss 0.8223874568939209\n",
      "Finished epoch 506, latest loss 0.823249876499176\n",
      "Finished epoch 507, latest loss 0.8231526613235474\n",
      "Finished epoch 508, latest loss 0.8212363123893738\n",
      "Finished epoch 509, latest loss 0.8196312785148621\n",
      "Finished epoch 510, latest loss 0.8227170705795288\n",
      "Finished epoch 511, latest loss 0.8199549317359924\n",
      "Finished epoch 512, latest loss 0.8221530318260193\n",
      "Finished epoch 513, latest loss 0.8196083903312683\n",
      "Finished epoch 514, latest loss 0.824520468711853\n",
      "Finished epoch 515, latest loss 0.8204237818717957\n",
      "Finished epoch 516, latest loss 0.820637047290802\n",
      "Finished epoch 517, latest loss 0.8208272457122803\n",
      "Finished epoch 518, latest loss 0.8200296759605408\n",
      "Finished epoch 519, latest loss 0.8257732391357422\n",
      "Finished epoch 520, latest loss 0.8208818435668945\n",
      "Finished epoch 521, latest loss 0.8199920654296875\n",
      "Finished epoch 522, latest loss 0.8213621377944946\n",
      "Finished epoch 523, latest loss 0.82010817527771\n",
      "Finished epoch 524, latest loss 0.8225268125534058\n",
      "Finished epoch 525, latest loss 0.8229978680610657\n",
      "Finished epoch 526, latest loss 0.8230154514312744\n",
      "Finished epoch 527, latest loss 0.8205367922782898\n",
      "Finished epoch 528, latest loss 0.8226661682128906\n",
      "Finished epoch 529, latest loss 0.8252000212669373\n",
      "Finished epoch 530, latest loss 0.8184471726417542\n",
      "Finished epoch 531, latest loss 0.8183531761169434\n",
      "Finished epoch 532, latest loss 0.8227787613868713\n",
      "Finished epoch 533, latest loss 0.823524534702301\n",
      "Finished epoch 534, latest loss 0.8201238512992859\n",
      "Finished epoch 535, latest loss 0.8221794962882996\n",
      "Finished epoch 536, latest loss 0.8246395587921143\n",
      "Finished epoch 537, latest loss 0.8200550079345703\n",
      "Finished epoch 538, latest loss 0.8322920203208923\n",
      "Finished epoch 539, latest loss 0.820904016494751\n",
      "Finished epoch 540, latest loss 0.8224426507949829\n",
      "Finished epoch 541, latest loss 0.8180809020996094\n",
      "Finished epoch 542, latest loss 0.8208881616592407\n",
      "Finished epoch 543, latest loss 0.8238022923469543\n",
      "Finished epoch 544, latest loss 0.818453311920166\n",
      "Finished epoch 545, latest loss 0.8254834413528442\n",
      "Finished epoch 546, latest loss 0.8206712007522583\n",
      "Finished epoch 547, latest loss 0.8197779059410095\n",
      "Finished epoch 548, latest loss 0.8200787305831909\n",
      "Finished epoch 549, latest loss 0.8211095929145813\n",
      "Finished epoch 550, latest loss 0.8286881446838379\n",
      "Finished epoch 551, latest loss 0.8191800117492676\n",
      "Finished epoch 552, latest loss 0.8226478695869446\n",
      "Finished epoch 553, latest loss 0.8214330673217773\n",
      "Finished epoch 554, latest loss 0.8240739107131958\n",
      "Finished epoch 555, latest loss 0.8207523822784424\n",
      "Finished epoch 556, latest loss 0.8204118609428406\n",
      "Finished epoch 557, latest loss 0.8261935710906982\n",
      "Finished epoch 558, latest loss 0.8216049075126648\n",
      "Finished epoch 559, latest loss 0.8196972608566284\n",
      "Finished epoch 560, latest loss 0.820084273815155\n",
      "Finished epoch 561, latest loss 0.8251094818115234\n",
      "Finished epoch 562, latest loss 0.8250800967216492\n",
      "Finished epoch 563, latest loss 0.819772481918335\n",
      "Finished epoch 564, latest loss 0.818965494632721\n",
      "Finished epoch 565, latest loss 0.819161593914032\n",
      "Finished epoch 566, latest loss 0.8165841102600098\n",
      "Finished epoch 567, latest loss 0.8191146850585938\n",
      "Finished epoch 568, latest loss 0.8193603157997131\n",
      "Finished epoch 569, latest loss 0.817260205745697\n",
      "Finished epoch 570, latest loss 0.8198815584182739\n",
      "Finished epoch 571, latest loss 0.818058431148529\n",
      "Finished epoch 572, latest loss 0.8210882544517517\n",
      "Finished epoch 573, latest loss 0.8199489712715149\n",
      "Finished epoch 574, latest loss 0.8211631178855896\n",
      "Finished epoch 575, latest loss 0.8179964423179626\n",
      "Finished epoch 576, latest loss 0.8206571340560913\n",
      "Finished epoch 577, latest loss 0.8182687759399414\n",
      "Finished epoch 578, latest loss 0.8180619478225708\n",
      "Finished epoch 579, latest loss 0.8177758455276489\n",
      "Finished epoch 580, latest loss 0.8198752403259277\n",
      "Finished epoch 581, latest loss 0.819615364074707\n",
      "Finished epoch 582, latest loss 0.8221718668937683\n",
      "Finished epoch 583, latest loss 0.8189883828163147\n",
      "Finished epoch 584, latest loss 0.8222401738166809\n",
      "Finished epoch 585, latest loss 0.8184933662414551\n",
      "Finished epoch 586, latest loss 0.8197369575500488\n",
      "Finished epoch 587, latest loss 0.8223844170570374\n",
      "Finished epoch 588, latest loss 0.8245100975036621\n",
      "Finished epoch 589, latest loss 0.8226927518844604\n",
      "Finished epoch 590, latest loss 0.8218923807144165\n",
      "Finished epoch 591, latest loss 0.8225600719451904\n",
      "Finished epoch 592, latest loss 0.8259155750274658\n",
      "Finished epoch 593, latest loss 0.8218330144882202\n",
      "Finished epoch 594, latest loss 0.8183327913284302\n",
      "Finished epoch 595, latest loss 0.8238814473152161\n",
      "Finished epoch 596, latest loss 0.8181915879249573\n",
      "Finished epoch 597, latest loss 0.8224635720252991\n",
      "Finished epoch 598, latest loss 0.8191583752632141\n",
      "Finished epoch 599, latest loss 0.8179773688316345\n",
      "Finished epoch 600, latest loss 0.8198131918907166\n",
      "Finished epoch 601, latest loss 0.8206188082695007\n",
      "Finished epoch 602, latest loss 0.8215148448944092\n",
      "Finished epoch 603, latest loss 0.8165985941886902\n",
      "Finished epoch 604, latest loss 0.8179008960723877\n",
      "Finished epoch 605, latest loss 0.8182814121246338\n",
      "Finished epoch 606, latest loss 0.8245188593864441\n",
      "Finished epoch 607, latest loss 0.8216413855552673\n",
      "Finished epoch 608, latest loss 0.8221089839935303\n",
      "Finished epoch 609, latest loss 0.8227945566177368\n",
      "Finished epoch 610, latest loss 0.821546733379364\n",
      "Finished epoch 611, latest loss 0.8180084824562073\n",
      "Finished epoch 612, latest loss 0.8178346753120422\n",
      "Finished epoch 613, latest loss 0.8204175233840942\n",
      "Finished epoch 614, latest loss 0.8191379308700562\n",
      "Finished epoch 615, latest loss 0.823110044002533\n",
      "Finished epoch 616, latest loss 0.8223005533218384\n",
      "Finished epoch 617, latest loss 0.8212801814079285\n",
      "Finished epoch 618, latest loss 0.8185853958129883\n",
      "Finished epoch 619, latest loss 0.8215389251708984\n",
      "Finished epoch 620, latest loss 0.8196243643760681\n",
      "Finished epoch 621, latest loss 0.8210094571113586\n",
      "Finished epoch 622, latest loss 0.8282045722007751\n",
      "Finished epoch 623, latest loss 0.8214312195777893\n",
      "Finished epoch 624, latest loss 0.8237863183021545\n",
      "Finished epoch 625, latest loss 0.8185998201370239\n",
      "Finished epoch 626, latest loss 0.8190730214118958\n",
      "Finished epoch 627, latest loss 0.8170780539512634\n",
      "Finished epoch 628, latest loss 0.8171355128288269\n",
      "Finished epoch 629, latest loss 0.8166594505310059\n",
      "Finished epoch 630, latest loss 0.8250539898872375\n",
      "Finished epoch 631, latest loss 0.8221786618232727\n",
      "Finished epoch 632, latest loss 0.8244448304176331\n",
      "Finished epoch 633, latest loss 0.8202164769172668\n",
      "Finished epoch 634, latest loss 0.8221453428268433\n",
      "Finished epoch 635, latest loss 0.8165442943572998\n",
      "Finished epoch 636, latest loss 0.8236122727394104\n",
      "Finished epoch 637, latest loss 0.8195890188217163\n",
      "Finished epoch 638, latest loss 0.8173582553863525\n",
      "Finished epoch 639, latest loss 0.8211521506309509\n",
      "Finished epoch 640, latest loss 0.8245940208435059\n",
      "Finished epoch 641, latest loss 0.8217307329177856\n",
      "Finished epoch 642, latest loss 0.8216270208358765\n",
      "Finished epoch 643, latest loss 0.8233287334442139\n",
      "Finished epoch 644, latest loss 0.8236347436904907\n",
      "Finished epoch 645, latest loss 0.8211549520492554\n",
      "Finished epoch 646, latest loss 0.8247814774513245\n",
      "Finished epoch 647, latest loss 0.8217529058456421\n",
      "Finished epoch 648, latest loss 0.8195443153381348\n",
      "Finished epoch 649, latest loss 0.8196946382522583\n",
      "Finished epoch 650, latest loss 0.8282714486122131\n",
      "Finished epoch 651, latest loss 0.8170590400695801\n",
      "Finished epoch 652, latest loss 0.8232496380805969\n",
      "Finished epoch 653, latest loss 0.8216209411621094\n",
      "Finished epoch 654, latest loss 0.8164904117584229\n",
      "Finished epoch 655, latest loss 0.8191177248954773\n",
      "Finished epoch 656, latest loss 0.8155139684677124\n",
      "Finished epoch 657, latest loss 0.8175143599510193\n",
      "Finished epoch 658, latest loss 0.8197711110115051\n",
      "Finished epoch 659, latest loss 0.821322500705719\n",
      "Finished epoch 660, latest loss 0.8159101605415344\n",
      "Finished epoch 661, latest loss 0.8171826601028442\n",
      "Finished epoch 662, latest loss 0.8194724321365356\n",
      "Finished epoch 663, latest loss 0.8217616677284241\n",
      "Finished epoch 664, latest loss 0.8214602470397949\n",
      "Finished epoch 665, latest loss 0.8192171454429626\n",
      "Finished epoch 666, latest loss 0.8206032514572144\n",
      "Finished epoch 667, latest loss 0.8151928186416626\n",
      "Finished epoch 668, latest loss 0.817059338092804\n",
      "Finished epoch 669, latest loss 0.8185559511184692\n",
      "Finished epoch 670, latest loss 0.817527711391449\n",
      "Finished epoch 671, latest loss 0.8235361576080322\n",
      "Finished epoch 672, latest loss 0.8188271522521973\n",
      "Finished epoch 673, latest loss 0.8220776915550232\n",
      "Finished epoch 674, latest loss 0.8201501369476318\n",
      "Finished epoch 675, latest loss 0.8234579563140869\n",
      "Finished epoch 676, latest loss 0.8312101364135742\n",
      "Finished epoch 677, latest loss 0.8202964067459106\n",
      "Finished epoch 678, latest loss 0.8186033368110657\n",
      "Finished epoch 679, latest loss 0.8187344074249268\n",
      "Finished epoch 680, latest loss 0.8196961879730225\n",
      "Finished epoch 681, latest loss 0.8168811798095703\n",
      "Finished epoch 682, latest loss 0.825787365436554\n",
      "Finished epoch 683, latest loss 0.8200634121894836\n",
      "Finished epoch 684, latest loss 0.8181087970733643\n",
      "Finished epoch 685, latest loss 0.8234105706214905\n",
      "Finished epoch 686, latest loss 0.8244461417198181\n",
      "Finished epoch 687, latest loss 0.8206223249435425\n",
      "Finished epoch 688, latest loss 0.8204469084739685\n",
      "Finished epoch 689, latest loss 0.8161768317222595\n",
      "Finished epoch 690, latest loss 0.8164613842964172\n",
      "Finished epoch 691, latest loss 0.8157035708427429\n",
      "Finished epoch 692, latest loss 0.8148661851882935\n",
      "Finished epoch 693, latest loss 0.8174063563346863\n",
      "Finished epoch 694, latest loss 0.8206478357315063\n",
      "Finished epoch 695, latest loss 0.8168169856071472\n",
      "Finished epoch 696, latest loss 0.8190880417823792\n",
      "Finished epoch 697, latest loss 0.8185520172119141\n",
      "Finished epoch 698, latest loss 0.8202840685844421\n",
      "Finished epoch 699, latest loss 0.8203849792480469\n",
      "Finished epoch 700, latest loss 0.8174952268600464\n",
      "Finished epoch 701, latest loss 0.8170755505561829\n",
      "Finished epoch 702, latest loss 0.8178228139877319\n",
      "Finished epoch 703, latest loss 0.8188971281051636\n",
      "Finished epoch 704, latest loss 0.8215459585189819\n",
      "Finished epoch 705, latest loss 0.8188561797142029\n",
      "Finished epoch 706, latest loss 0.8206173777580261\n",
      "Finished epoch 707, latest loss 0.8235905170440674\n",
      "Finished epoch 708, latest loss 0.8234230279922485\n",
      "Finished epoch 709, latest loss 0.8192797899246216\n",
      "Finished epoch 710, latest loss 0.8210945129394531\n",
      "Finished epoch 711, latest loss 0.8194608092308044\n",
      "Finished epoch 712, latest loss 0.817446768283844\n",
      "Finished epoch 713, latest loss 0.821923553943634\n",
      "Finished epoch 714, latest loss 0.8192075490951538\n",
      "Finished epoch 715, latest loss 0.8166104555130005\n",
      "Finished epoch 716, latest loss 0.8185384273529053\n",
      "Finished epoch 717, latest loss 0.8170177936553955\n",
      "Finished epoch 718, latest loss 0.8168206810951233\n",
      "Finished epoch 719, latest loss 0.8153103590011597\n",
      "Finished epoch 720, latest loss 0.8129596710205078\n",
      "Finished epoch 721, latest loss 0.8201465606689453\n",
      "Finished epoch 722, latest loss 0.8174901604652405\n",
      "Finished epoch 723, latest loss 0.8256554007530212\n",
      "Finished epoch 724, latest loss 0.8164663910865784\n",
      "Finished epoch 725, latest loss 0.8174322843551636\n",
      "Finished epoch 726, latest loss 0.8169203996658325\n",
      "Finished epoch 727, latest loss 0.8155050277709961\n",
      "Finished epoch 728, latest loss 0.8170568346977234\n",
      "Finished epoch 729, latest loss 0.8180893659591675\n",
      "Finished epoch 730, latest loss 0.8206983804702759\n",
      "Finished epoch 731, latest loss 0.8173750638961792\n",
      "Finished epoch 732, latest loss 0.815021276473999\n",
      "Finished epoch 733, latest loss 0.8173379898071289\n",
      "Finished epoch 734, latest loss 0.8144354224205017\n",
      "Finished epoch 735, latest loss 0.8150688409805298\n",
      "Finished epoch 736, latest loss 0.8210551142692566\n",
      "Finished epoch 737, latest loss 0.8205695152282715\n",
      "Finished epoch 738, latest loss 0.816121518611908\n",
      "Finished epoch 739, latest loss 0.817363977432251\n",
      "Finished epoch 740, latest loss 0.817670464515686\n",
      "Finished epoch 741, latest loss 0.8267138600349426\n",
      "Finished epoch 742, latest loss 0.8194327354431152\n",
      "Finished epoch 743, latest loss 0.8186044096946716\n",
      "Finished epoch 744, latest loss 0.8172768950462341\n",
      "Finished epoch 745, latest loss 0.821281909942627\n",
      "Finished epoch 746, latest loss 0.8171826004981995\n",
      "Finished epoch 747, latest loss 0.8200044631958008\n",
      "Finished epoch 748, latest loss 0.8209785223007202\n",
      "Finished epoch 749, latest loss 0.8157932162284851\n",
      "Finished epoch 750, latest loss 0.8149786591529846\n",
      "Finished epoch 751, latest loss 0.8177968263626099\n",
      "Finished epoch 752, latest loss 0.8173933029174805\n",
      "Finished epoch 753, latest loss 0.8155989646911621\n",
      "Finished epoch 754, latest loss 0.8177765607833862\n",
      "Finished epoch 755, latest loss 0.8155065178871155\n",
      "Finished epoch 756, latest loss 0.8167576193809509\n",
      "Finished epoch 757, latest loss 0.8201578259468079\n",
      "Finished epoch 758, latest loss 0.8167312741279602\n",
      "Finished epoch 759, latest loss 0.8155704140663147\n",
      "Finished epoch 760, latest loss 0.8156844973564148\n",
      "Finished epoch 761, latest loss 0.8176510334014893\n",
      "Finished epoch 762, latest loss 0.8142490386962891\n",
      "Finished epoch 763, latest loss 0.819150984287262\n",
      "Finished epoch 764, latest loss 0.8172621130943298\n",
      "Finished epoch 765, latest loss 0.8156310319900513\n",
      "Finished epoch 766, latest loss 0.8198922276496887\n",
      "Finished epoch 767, latest loss 0.819110631942749\n",
      "Finished epoch 768, latest loss 0.8157056570053101\n",
      "Finished epoch 769, latest loss 0.8137033581733704\n",
      "Finished epoch 770, latest loss 0.8141716718673706\n",
      "Finished epoch 771, latest loss 0.8168816566467285\n",
      "Finished epoch 772, latest loss 0.8142288327217102\n",
      "Finished epoch 773, latest loss 0.8165342807769775\n",
      "Finished epoch 774, latest loss 0.8145701885223389\n",
      "Finished epoch 775, latest loss 0.8191182613372803\n",
      "Finished epoch 776, latest loss 0.8113901019096375\n",
      "Finished epoch 777, latest loss 0.8160302042961121\n",
      "Finished epoch 778, latest loss 0.8164191246032715\n",
      "Finished epoch 779, latest loss 0.8195472359657288\n",
      "Finished epoch 780, latest loss 0.8138300776481628\n",
      "Finished epoch 781, latest loss 0.8196074962615967\n",
      "Finished epoch 782, latest loss 0.8150313496589661\n",
      "Finished epoch 783, latest loss 0.813250720500946\n",
      "Finished epoch 784, latest loss 0.8128175139427185\n",
      "Finished epoch 785, latest loss 0.8180510997772217\n",
      "Finished epoch 786, latest loss 0.8180670738220215\n",
      "Finished epoch 787, latest loss 0.8177551031112671\n",
      "Finished epoch 788, latest loss 0.816547155380249\n",
      "Finished epoch 789, latest loss 0.8134174346923828\n",
      "Finished epoch 790, latest loss 0.8211947679519653\n",
      "Finished epoch 791, latest loss 0.8127505779266357\n",
      "Finished epoch 792, latest loss 0.8191509246826172\n",
      "Finished epoch 793, latest loss 0.8134115934371948\n",
      "Finished epoch 794, latest loss 0.8175802826881409\n",
      "Finished epoch 795, latest loss 0.8140490055084229\n",
      "Finished epoch 796, latest loss 0.8114680647850037\n",
      "Finished epoch 797, latest loss 0.8139567971229553\n",
      "Finished epoch 798, latest loss 0.8140478730201721\n",
      "Finished epoch 799, latest loss 0.8161129355430603\n",
      "Finished epoch 800, latest loss 0.8182085752487183\n",
      "Finished epoch 801, latest loss 0.8161659836769104\n",
      "Finished epoch 802, latest loss 0.8221468925476074\n",
      "Finished epoch 803, latest loss 0.8139514327049255\n",
      "Finished epoch 804, latest loss 0.816253125667572\n",
      "Finished epoch 805, latest loss 0.8129000067710876\n",
      "Finished epoch 806, latest loss 0.8193556666374207\n",
      "Finished epoch 807, latest loss 0.8131086826324463\n",
      "Finished epoch 808, latest loss 0.8164287805557251\n",
      "Finished epoch 809, latest loss 0.8141523599624634\n",
      "Finished epoch 810, latest loss 0.8170828223228455\n",
      "Finished epoch 811, latest loss 0.8165090680122375\n",
      "Finished epoch 812, latest loss 0.825156569480896\n",
      "Finished epoch 813, latest loss 0.8169359564781189\n",
      "Finished epoch 814, latest loss 0.815874457359314\n",
      "Finished epoch 815, latest loss 0.8159617185592651\n",
      "Finished epoch 816, latest loss 0.8147250413894653\n",
      "Finished epoch 817, latest loss 0.8155054450035095\n",
      "Finished epoch 818, latest loss 0.8174154758453369\n",
      "Finished epoch 819, latest loss 0.8115075826644897\n",
      "Finished epoch 820, latest loss 0.8121070265769958\n",
      "Finished epoch 821, latest loss 0.814995288848877\n",
      "Finished epoch 822, latest loss 0.8134909272193909\n",
      "Finished epoch 823, latest loss 0.8150427341461182\n",
      "Finished epoch 824, latest loss 0.8167026042938232\n",
      "Finished epoch 825, latest loss 0.8151438236236572\n",
      "Finished epoch 826, latest loss 0.8111738562583923\n",
      "Finished epoch 827, latest loss 0.8159638047218323\n",
      "Finished epoch 828, latest loss 0.8152146339416504\n",
      "Finished epoch 829, latest loss 0.8174353837966919\n",
      "Finished epoch 830, latest loss 0.8193755745887756\n",
      "Finished epoch 831, latest loss 0.8140400648117065\n",
      "Finished epoch 832, latest loss 0.8098562359809875\n",
      "Finished epoch 833, latest loss 0.8153654336929321\n",
      "Finished epoch 834, latest loss 0.8162779211997986\n",
      "Finished epoch 835, latest loss 0.8125839233398438\n",
      "Finished epoch 836, latest loss 0.8164691925048828\n",
      "Finished epoch 837, latest loss 0.8113448023796082\n",
      "Finished epoch 838, latest loss 0.8195200562477112\n",
      "Finished epoch 839, latest loss 0.8138922452926636\n",
      "Finished epoch 840, latest loss 0.8214817047119141\n",
      "Finished epoch 841, latest loss 0.8167445063591003\n",
      "Finished epoch 842, latest loss 0.8130069971084595\n",
      "Finished epoch 843, latest loss 0.8158057928085327\n",
      "Finished epoch 844, latest loss 0.8161078691482544\n",
      "Finished epoch 845, latest loss 0.8139393329620361\n",
      "Finished epoch 846, latest loss 0.8176688551902771\n",
      "Finished epoch 847, latest loss 0.8136906623840332\n",
      "Finished epoch 848, latest loss 0.8195539712905884\n",
      "Finished epoch 849, latest loss 0.8133766055107117\n",
      "Finished epoch 850, latest loss 0.8140419125556946\n",
      "Finished epoch 851, latest loss 0.816987156867981\n",
      "Finished epoch 852, latest loss 0.8129532337188721\n",
      "Finished epoch 853, latest loss 0.8157461285591125\n",
      "Finished epoch 854, latest loss 0.813668429851532\n",
      "Finished epoch 855, latest loss 0.81253981590271\n",
      "Finished epoch 856, latest loss 0.8164097666740417\n",
      "Finished epoch 857, latest loss 0.8140174150466919\n",
      "Finished epoch 858, latest loss 0.813580334186554\n",
      "Finished epoch 859, latest loss 0.8234954476356506\n",
      "Finished epoch 860, latest loss 0.8140762448310852\n",
      "Finished epoch 861, latest loss 0.8129307627677917\n",
      "Finished epoch 862, latest loss 0.8119035959243774\n",
      "Finished epoch 863, latest loss 0.8134180903434753\n",
      "Finished epoch 864, latest loss 0.8124545812606812\n",
      "Finished epoch 865, latest loss 0.8108574151992798\n",
      "Finished epoch 866, latest loss 0.8192043900489807\n",
      "Finished epoch 867, latest loss 0.8119085431098938\n",
      "Finished epoch 868, latest loss 0.8149352669715881\n",
      "Finished epoch 869, latest loss 0.8193261623382568\n",
      "Finished epoch 870, latest loss 0.8193564414978027\n",
      "Finished epoch 871, latest loss 0.8154271841049194\n",
      "Finished epoch 872, latest loss 0.8163089752197266\n",
      "Finished epoch 873, latest loss 0.8124093413352966\n",
      "Finished epoch 874, latest loss 0.8159619569778442\n",
      "Finished epoch 875, latest loss 0.81301349401474\n",
      "Finished epoch 876, latest loss 0.8119444251060486\n",
      "Finished epoch 877, latest loss 0.8159940242767334\n",
      "Finished epoch 878, latest loss 0.8123263716697693\n",
      "Finished epoch 879, latest loss 0.8179103136062622\n",
      "Finished epoch 880, latest loss 0.8148474097251892\n",
      "Finished epoch 881, latest loss 0.8213279843330383\n",
      "Finished epoch 882, latest loss 0.8218005299568176\n",
      "Finished epoch 883, latest loss 0.8147860169410706\n",
      "Finished epoch 884, latest loss 0.8145137429237366\n",
      "Finished epoch 885, latest loss 0.8129127621650696\n",
      "Finished epoch 886, latest loss 0.8139572143554688\n",
      "Finished epoch 887, latest loss 0.8208706974983215\n",
      "Finished epoch 888, latest loss 0.8208619952201843\n",
      "Finished epoch 889, latest loss 0.8149680495262146\n",
      "Finished epoch 890, latest loss 0.815271258354187\n",
      "Finished epoch 891, latest loss 0.8179433941841125\n",
      "Finished epoch 892, latest loss 0.8156924247741699\n",
      "Finished epoch 893, latest loss 0.8134759068489075\n",
      "Finished epoch 894, latest loss 0.8158933520317078\n",
      "Finished epoch 895, latest loss 0.8163804411888123\n",
      "Finished epoch 896, latest loss 0.8140801191329956\n",
      "Finished epoch 897, latest loss 0.8127861618995667\n",
      "Finished epoch 898, latest loss 0.8249694108963013\n",
      "Finished epoch 899, latest loss 0.8136224150657654\n",
      "Finished epoch 900, latest loss 0.8117494583129883\n",
      "Finished epoch 901, latest loss 0.818120539188385\n",
      "Finished epoch 902, latest loss 0.8325880169868469\n",
      "Finished epoch 903, latest loss 0.8172340393066406\n",
      "Finished epoch 904, latest loss 0.8158901929855347\n",
      "Finished epoch 905, latest loss 0.8151476383209229\n",
      "Finished epoch 906, latest loss 0.816582202911377\n",
      "Finished epoch 907, latest loss 0.8119221925735474\n",
      "Finished epoch 908, latest loss 0.8118665218353271\n",
      "Finished epoch 909, latest loss 0.8151012063026428\n",
      "Finished epoch 910, latest loss 0.8127250671386719\n",
      "Finished epoch 911, latest loss 0.8106518983840942\n",
      "Finished epoch 912, latest loss 0.8119959831237793\n",
      "Finished epoch 913, latest loss 0.8138051629066467\n",
      "Finished epoch 914, latest loss 0.8179075717926025\n",
      "Finished epoch 915, latest loss 0.8121057748794556\n",
      "Finished epoch 916, latest loss 0.8104431629180908\n",
      "Finished epoch 917, latest loss 0.8136237263679504\n",
      "Finished epoch 918, latest loss 0.814958393573761\n",
      "Finished epoch 919, latest loss 0.811920702457428\n",
      "Finished epoch 920, latest loss 0.8217528462409973\n",
      "Finished epoch 921, latest loss 0.8164939284324646\n",
      "Finished epoch 922, latest loss 0.8162587881088257\n",
      "Finished epoch 923, latest loss 0.815504252910614\n",
      "Finished epoch 924, latest loss 0.8109378814697266\n",
      "Finished epoch 925, latest loss 0.8148454427719116\n",
      "Finished epoch 926, latest loss 0.8193775415420532\n",
      "Finished epoch 927, latest loss 0.8199125528335571\n",
      "Finished epoch 928, latest loss 0.8137919902801514\n",
      "Finished epoch 929, latest loss 0.8169533014297485\n",
      "Finished epoch 930, latest loss 0.8197959661483765\n",
      "Finished epoch 931, latest loss 0.8096936345100403\n",
      "Finished epoch 932, latest loss 0.8167662024497986\n",
      "Finished epoch 933, latest loss 0.8124902248382568\n",
      "Finished epoch 934, latest loss 0.8143046498298645\n",
      "Finished epoch 935, latest loss 0.8098722100257874\n",
      "Finished epoch 936, latest loss 0.8166601657867432\n",
      "Finished epoch 937, latest loss 0.8119497895240784\n",
      "Finished epoch 938, latest loss 0.8125231266021729\n",
      "Finished epoch 939, latest loss 0.8099799156188965\n",
      "Finished epoch 940, latest loss 0.813198983669281\n",
      "Finished epoch 941, latest loss 0.8169200420379639\n",
      "Finished epoch 942, latest loss 0.8164739608764648\n",
      "Finished epoch 943, latest loss 0.8151293992996216\n",
      "Finished epoch 944, latest loss 0.8127709031105042\n",
      "Finished epoch 945, latest loss 0.8133305311203003\n",
      "Finished epoch 946, latest loss 0.8173081874847412\n",
      "Finished epoch 947, latest loss 0.8113338947296143\n",
      "Finished epoch 948, latest loss 0.8127604722976685\n",
      "Finished epoch 949, latest loss 0.8124346137046814\n",
      "Finished epoch 950, latest loss 0.8123477697372437\n",
      "Finished epoch 951, latest loss 0.815700113773346\n",
      "Finished epoch 952, latest loss 0.8154945969581604\n",
      "Finished epoch 953, latest loss 0.8143102526664734\n",
      "Finished epoch 954, latest loss 0.8106953501701355\n",
      "Finished epoch 955, latest loss 0.8113695383071899\n",
      "Finished epoch 956, latest loss 0.8163366913795471\n",
      "Finished epoch 957, latest loss 0.823054313659668\n",
      "Finished epoch 958, latest loss 0.8169233202934265\n",
      "Finished epoch 959, latest loss 0.8146244883537292\n",
      "Finished epoch 960, latest loss 0.814063310623169\n",
      "Finished epoch 961, latest loss 0.8121895790100098\n",
      "Finished epoch 962, latest loss 0.8127416968345642\n",
      "Finished epoch 963, latest loss 0.8138087391853333\n",
      "Finished epoch 964, latest loss 0.8084751963615417\n",
      "Finished epoch 965, latest loss 0.8089033961296082\n",
      "Finished epoch 966, latest loss 0.8112821578979492\n",
      "Finished epoch 967, latest loss 0.8130105137825012\n",
      "Finished epoch 968, latest loss 0.815629243850708\n",
      "Finished epoch 969, latest loss 0.815316915512085\n",
      "Finished epoch 970, latest loss 0.8108040690422058\n",
      "Finished epoch 971, latest loss 0.8134902119636536\n",
      "Finished epoch 972, latest loss 0.8103832602500916\n",
      "Finished epoch 973, latest loss 0.8154382705688477\n",
      "Finished epoch 974, latest loss 0.8107172250747681\n",
      "Finished epoch 975, latest loss 0.8137671947479248\n",
      "Finished epoch 976, latest loss 0.8201583623886108\n",
      "Finished epoch 977, latest loss 0.8134860992431641\n",
      "Finished epoch 978, latest loss 0.8180427551269531\n",
      "Finished epoch 979, latest loss 0.8103968501091003\n",
      "Finished epoch 980, latest loss 0.8103222250938416\n",
      "Finished epoch 981, latest loss 0.8132098913192749\n",
      "Finished epoch 982, latest loss 0.8161364793777466\n",
      "Finished epoch 983, latest loss 0.8111900091171265\n",
      "Finished epoch 984, latest loss 0.8168261647224426\n",
      "Finished epoch 985, latest loss 0.8124135732650757\n",
      "Finished epoch 986, latest loss 0.8119186162948608\n",
      "Finished epoch 987, latest loss 0.8139391541481018\n",
      "Finished epoch 988, latest loss 0.8157830834388733\n",
      "Finished epoch 989, latest loss 0.814537763595581\n",
      "Finished epoch 990, latest loss 0.8143501281738281\n",
      "Finished epoch 991, latest loss 0.8149263858795166\n",
      "Finished epoch 992, latest loss 0.8100736737251282\n",
      "Finished epoch 993, latest loss 0.8172287344932556\n",
      "Finished epoch 994, latest loss 0.8129667043685913\n",
      "Finished epoch 995, latest loss 0.819892942905426\n",
      "Finished epoch 996, latest loss 0.8160383105278015\n",
      "Finished epoch 997, latest loss 0.8124074339866638\n",
      "Finished epoch 998, latest loss 0.8121032118797302\n",
      "Finished epoch 999, latest loss 0.8157554864883423\n",
      "Finished epoch 1000, latest loss 0.8198046088218689\n",
      "Finished epoch 1001, latest loss 0.8144336938858032\n",
      "Finished epoch 1002, latest loss 0.8158901929855347\n",
      "Finished epoch 1003, latest loss 0.8111689686775208\n",
      "Finished epoch 1004, latest loss 0.8134250044822693\n",
      "Finished epoch 1005, latest loss 0.8160064816474915\n",
      "Finished epoch 1006, latest loss 0.8160533905029297\n",
      "Finished epoch 1007, latest loss 0.8145175576210022\n",
      "Finished epoch 1008, latest loss 0.8137228488922119\n",
      "Finished epoch 1009, latest loss 0.8153432607650757\n",
      "Finished epoch 1010, latest loss 0.8179490566253662\n",
      "Finished epoch 1011, latest loss 0.8170136213302612\n",
      "Finished epoch 1012, latest loss 0.8141286969184875\n",
      "Finished epoch 1013, latest loss 0.812943160533905\n",
      "Finished epoch 1014, latest loss 0.82304847240448\n",
      "Finished epoch 1015, latest loss 0.8164620995521545\n",
      "Finished epoch 1016, latest loss 0.8129035830497742\n",
      "Finished epoch 1017, latest loss 0.810743510723114\n",
      "Finished epoch 1018, latest loss 0.8163636326789856\n",
      "Finished epoch 1019, latest loss 0.8119218349456787\n",
      "Finished epoch 1020, latest loss 0.8117369413375854\n",
      "Finished epoch 1021, latest loss 0.8171961903572083\n",
      "Finished epoch 1022, latest loss 0.8119400143623352\n",
      "Finished epoch 1023, latest loss 0.8091669678688049\n",
      "Finished epoch 1024, latest loss 0.8129400610923767\n",
      "Finished epoch 1025, latest loss 0.8095758557319641\n",
      "Finished epoch 1026, latest loss 0.8140568733215332\n",
      "Finished epoch 1027, latest loss 0.8176004886627197\n",
      "Finished epoch 1028, latest loss 0.820789635181427\n",
      "Finished epoch 1029, latest loss 0.8131265640258789\n",
      "Finished epoch 1030, latest loss 0.8144734501838684\n",
      "Finished epoch 1031, latest loss 0.8178173899650574\n",
      "Finished epoch 1032, latest loss 0.8122996091842651\n",
      "Finished epoch 1033, latest loss 0.8088341355323792\n",
      "Finished epoch 1034, latest loss 0.8143784403800964\n",
      "Finished epoch 1035, latest loss 0.8103712201118469\n",
      "Finished epoch 1036, latest loss 0.808395266532898\n",
      "Finished epoch 1037, latest loss 0.8133453130722046\n",
      "Finished epoch 1038, latest loss 0.815096378326416\n",
      "Finished epoch 1039, latest loss 0.8163719773292542\n",
      "Finished epoch 1040, latest loss 0.8155916333198547\n",
      "Finished epoch 1041, latest loss 0.8173787593841553\n",
      "Finished epoch 1042, latest loss 0.8133977055549622\n",
      "Finished epoch 1043, latest loss 0.8123552203178406\n",
      "Finished epoch 1044, latest loss 0.8097466230392456\n",
      "Finished epoch 1045, latest loss 0.8139557838439941\n",
      "Finished epoch 1046, latest loss 0.8156377673149109\n",
      "Finished epoch 1047, latest loss 0.8097934722900391\n",
      "Finished epoch 1048, latest loss 0.8150204420089722\n",
      "Finished epoch 1049, latest loss 0.8113246560096741\n",
      "Finished epoch 1050, latest loss 0.8103176951408386\n",
      "Finished epoch 1051, latest loss 0.8121839761734009\n",
      "Finished epoch 1052, latest loss 0.8134673237800598\n",
      "Finished epoch 1053, latest loss 0.8123195767402649\n",
      "Finished epoch 1054, latest loss 0.811532199382782\n",
      "Finished epoch 1055, latest loss 0.808917224407196\n",
      "Finished epoch 1056, latest loss 0.8120774626731873\n",
      "Finished epoch 1057, latest loss 0.8088374733924866\n",
      "Finished epoch 1058, latest loss 0.8143435120582581\n",
      "Finished epoch 1059, latest loss 0.8109084963798523\n",
      "Finished epoch 1060, latest loss 0.8142213821411133\n",
      "Finished epoch 1061, latest loss 0.8142430782318115\n",
      "Finished epoch 1062, latest loss 0.8118579983711243\n",
      "Finished epoch 1063, latest loss 0.8112987875938416\n",
      "Finished epoch 1064, latest loss 0.8128576278686523\n",
      "Finished epoch 1065, latest loss 0.8120524287223816\n",
      "Finished epoch 1066, latest loss 0.8112470507621765\n",
      "Finished epoch 1067, latest loss 0.8098506927490234\n",
      "Finished epoch 1068, latest loss 0.810124933719635\n",
      "Finished epoch 1069, latest loss 0.8094231486320496\n",
      "Finished epoch 1070, latest loss 0.8114601969718933\n",
      "Finished epoch 1071, latest loss 0.8174180388450623\n",
      "Finished epoch 1072, latest loss 0.8136323690414429\n",
      "Finished epoch 1073, latest loss 0.8131099343299866\n",
      "Finished epoch 1074, latest loss 0.8126780390739441\n",
      "Finished epoch 1075, latest loss 0.8116825819015503\n",
      "Finished epoch 1076, latest loss 0.8094801902770996\n",
      "Finished epoch 1077, latest loss 0.8138781189918518\n",
      "Finished epoch 1078, latest loss 0.8131164312362671\n",
      "Finished epoch 1079, latest loss 0.8083157539367676\n",
      "Finished epoch 1080, latest loss 0.8082990646362305\n",
      "Finished epoch 1081, latest loss 0.809286892414093\n",
      "Finished epoch 1082, latest loss 0.8110167384147644\n",
      "Finished epoch 1083, latest loss 0.8093568682670593\n",
      "Finished epoch 1084, latest loss 0.8107801675796509\n",
      "Finished epoch 1085, latest loss 0.8090981841087341\n",
      "Finished epoch 1086, latest loss 0.8142449259757996\n",
      "Finished epoch 1087, latest loss 0.8134647011756897\n",
      "Finished epoch 1088, latest loss 0.8148464560508728\n",
      "Finished epoch 1089, latest loss 0.8119701147079468\n",
      "Finished epoch 1090, latest loss 0.8093042373657227\n",
      "Finished epoch 1091, latest loss 0.8147997260093689\n",
      "Finished epoch 1092, latest loss 0.815593957901001\n",
      "Finished epoch 1093, latest loss 0.809014618396759\n",
      "Finished epoch 1094, latest loss 0.8095653057098389\n",
      "Finished epoch 1095, latest loss 0.8100326061248779\n",
      "Finished epoch 1096, latest loss 0.8108699917793274\n",
      "Finished epoch 1097, latest loss 0.8082608580589294\n",
      "Finished epoch 1098, latest loss 0.8112390041351318\n",
      "Finished epoch 1099, latest loss 0.8108600378036499\n",
      "Finished epoch 1100, latest loss 0.8080354928970337\n",
      "Finished epoch 1101, latest loss 0.8116212487220764\n",
      "Finished epoch 1102, latest loss 0.8126088380813599\n",
      "Finished epoch 1103, latest loss 0.8107751607894897\n",
      "Finished epoch 1104, latest loss 0.8144307732582092\n",
      "Finished epoch 1105, latest loss 0.807951033115387\n",
      "Finished epoch 1106, latest loss 0.8129225969314575\n",
      "Finished epoch 1107, latest loss 0.812910795211792\n",
      "Finished epoch 1108, latest loss 0.8136019110679626\n",
      "Finished epoch 1109, latest loss 0.8099735975265503\n",
      "Finished epoch 1110, latest loss 0.8129457235336304\n",
      "Finished epoch 1111, latest loss 0.8142926692962646\n",
      "Finished epoch 1112, latest loss 0.8199049830436707\n",
      "Finished epoch 1113, latest loss 0.8073177933692932\n",
      "Finished epoch 1114, latest loss 0.8163456916809082\n",
      "Finished epoch 1115, latest loss 0.8127197623252869\n",
      "Finished epoch 1116, latest loss 0.8104392290115356\n",
      "Finished epoch 1117, latest loss 0.8113444447517395\n",
      "Finished epoch 1118, latest loss 0.8094722628593445\n",
      "Finished epoch 1119, latest loss 0.8129757642745972\n",
      "Finished epoch 1120, latest loss 0.8080684542655945\n",
      "Finished epoch 1121, latest loss 0.8088281154632568\n",
      "Finished epoch 1122, latest loss 0.8112781047821045\n",
      "Finished epoch 1123, latest loss 0.811214804649353\n",
      "Finished epoch 1124, latest loss 0.8136369585990906\n",
      "Finished epoch 1125, latest loss 0.8088234066963196\n",
      "Finished epoch 1126, latest loss 0.811866044998169\n",
      "Finished epoch 1127, latest loss 0.8150289058685303\n",
      "Finished epoch 1128, latest loss 0.8114455938339233\n",
      "Finished epoch 1129, latest loss 0.8098471164703369\n",
      "Finished epoch 1130, latest loss 0.8169677257537842\n",
      "Finished epoch 1131, latest loss 0.8119282722473145\n",
      "Finished epoch 1132, latest loss 0.8141844868659973\n",
      "Finished epoch 1133, latest loss 0.8109173774719238\n",
      "Finished epoch 1134, latest loss 0.817945122718811\n",
      "Finished epoch 1135, latest loss 0.8133571147918701\n",
      "Finished epoch 1136, latest loss 0.8111603260040283\n",
      "Finished epoch 1137, latest loss 0.8125581741333008\n",
      "Finished epoch 1138, latest loss 0.8113477826118469\n",
      "Finished epoch 1139, latest loss 0.8099589347839355\n",
      "Finished epoch 1140, latest loss 0.8107660412788391\n",
      "Finished epoch 1141, latest loss 0.8088773488998413\n",
      "Finished epoch 1142, latest loss 0.8142548203468323\n",
      "Finished epoch 1143, latest loss 0.8123374581336975\n",
      "Finished epoch 1144, latest loss 0.8137219548225403\n",
      "Finished epoch 1145, latest loss 0.8104042410850525\n",
      "Finished epoch 1146, latest loss 0.8098373413085938\n",
      "Finished epoch 1147, latest loss 0.8124709129333496\n",
      "Finished epoch 1148, latest loss 0.8101701736450195\n",
      "Finished epoch 1149, latest loss 0.808296799659729\n",
      "Finished epoch 1150, latest loss 0.8083023428916931\n",
      "Finished epoch 1151, latest loss 0.8112199902534485\n",
      "Finished epoch 1152, latest loss 0.8145418763160706\n",
      "Finished epoch 1153, latest loss 0.8134447932243347\n",
      "Finished epoch 1154, latest loss 0.808840811252594\n",
      "Finished epoch 1155, latest loss 0.809845507144928\n",
      "Finished epoch 1156, latest loss 0.8156793117523193\n",
      "Finished epoch 1157, latest loss 0.8130368590354919\n",
      "Finished epoch 1158, latest loss 0.8138310313224792\n",
      "Finished epoch 1159, latest loss 0.8114224076271057\n",
      "Finished epoch 1160, latest loss 0.8084409832954407\n",
      "Finished epoch 1161, latest loss 0.8103821873664856\n",
      "Finished epoch 1162, latest loss 0.8093990683555603\n",
      "Finished epoch 1163, latest loss 0.8135488629341125\n",
      "Finished epoch 1164, latest loss 0.8112072944641113\n",
      "Finished epoch 1165, latest loss 0.8108010292053223\n",
      "Finished epoch 1166, latest loss 0.8106544613838196\n",
      "Finished epoch 1167, latest loss 0.8187200427055359\n",
      "Finished epoch 1168, latest loss 0.8090170621871948\n",
      "Finished epoch 1169, latest loss 0.8076234459877014\n",
      "Finished epoch 1170, latest loss 0.8112964034080505\n",
      "Finished epoch 1171, latest loss 0.8073914647102356\n",
      "Finished epoch 1172, latest loss 0.8119747638702393\n",
      "Finished epoch 1173, latest loss 0.8128002882003784\n",
      "Finished epoch 1174, latest loss 0.810390293598175\n",
      "Finished epoch 1175, latest loss 0.8099130392074585\n",
      "Finished epoch 1176, latest loss 0.8078317046165466\n",
      "Finished epoch 1177, latest loss 0.8073634505271912\n",
      "Finished epoch 1178, latest loss 0.8096149563789368\n",
      "Finished epoch 1179, latest loss 0.8118936419487\n",
      "Finished epoch 1180, latest loss 0.8134178519248962\n",
      "Finished epoch 1181, latest loss 0.8175742030143738\n",
      "Finished epoch 1182, latest loss 0.8168224692344666\n",
      "Finished epoch 1183, latest loss 0.8104724287986755\n",
      "Finished epoch 1184, latest loss 0.8121351599693298\n",
      "Finished epoch 1185, latest loss 0.8119357824325562\n",
      "Finished epoch 1186, latest loss 0.8156768083572388\n",
      "Finished epoch 1187, latest loss 0.8103195428848267\n",
      "Finished epoch 1188, latest loss 0.8106094598770142\n",
      "Finished epoch 1189, latest loss 0.8128488659858704\n",
      "Finished epoch 1190, latest loss 0.8064535856246948\n",
      "Finished epoch 1191, latest loss 0.8094107508659363\n",
      "Finished epoch 1192, latest loss 0.8107385635375977\n",
      "Finished epoch 1193, latest loss 0.8092916011810303\n",
      "Finished epoch 1194, latest loss 0.806388258934021\n",
      "Finished epoch 1195, latest loss 0.8081937432289124\n",
      "Finished epoch 1196, latest loss 0.8101796507835388\n",
      "Finished epoch 1197, latest loss 0.8112788796424866\n",
      "Finished epoch 1198, latest loss 0.8074790239334106\n",
      "Finished epoch 1199, latest loss 0.8135097026824951\n",
      "Finished epoch 1200, latest loss 0.8160472512245178\n",
      "Finished epoch 1201, latest loss 0.8127552270889282\n",
      "Finished epoch 1202, latest loss 0.8125278353691101\n",
      "Finished epoch 1203, latest loss 0.8138487339019775\n",
      "Finished epoch 1204, latest loss 0.809563398361206\n",
      "Finished epoch 1205, latest loss 0.8093298673629761\n",
      "Finished epoch 1206, latest loss 0.8090423941612244\n",
      "Finished epoch 1207, latest loss 0.8073069453239441\n",
      "Finished epoch 1208, latest loss 0.8105430603027344\n",
      "Finished epoch 1209, latest loss 0.8100647926330566\n",
      "Finished epoch 1210, latest loss 0.8105661273002625\n",
      "Finished epoch 1211, latest loss 0.8080859780311584\n",
      "Finished epoch 1212, latest loss 0.8072865605354309\n",
      "Finished epoch 1213, latest loss 0.8093087673187256\n",
      "Finished epoch 1214, latest loss 0.8102105855941772\n",
      "Finished epoch 1215, latest loss 0.8114625811576843\n",
      "Finished epoch 1216, latest loss 0.8106964826583862\n",
      "Finished epoch 1217, latest loss 0.8103840947151184\n",
      "Finished epoch 1218, latest loss 0.8109716176986694\n",
      "Finished epoch 1219, latest loss 0.8100710511207581\n",
      "Finished epoch 1220, latest loss 0.8088326454162598\n",
      "Finished epoch 1221, latest loss 0.8080071806907654\n",
      "Finished epoch 1222, latest loss 0.8092961311340332\n",
      "Finished epoch 1223, latest loss 0.8073033690452576\n",
      "Finished epoch 1224, latest loss 0.8079230189323425\n",
      "Finished epoch 1225, latest loss 0.812667727470398\n",
      "Finished epoch 1226, latest loss 0.8082974553108215\n",
      "Finished epoch 1227, latest loss 0.8147832155227661\n",
      "Finished epoch 1228, latest loss 0.8116837739944458\n",
      "Finished epoch 1229, latest loss 0.8095875382423401\n",
      "Finished epoch 1230, latest loss 0.8074511885643005\n",
      "Finished epoch 1231, latest loss 0.8111968040466309\n",
      "Finished epoch 1232, latest loss 0.8088353276252747\n",
      "Finished epoch 1233, latest loss 0.8079623579978943\n",
      "Finished epoch 1234, latest loss 0.8088350892066956\n",
      "Finished epoch 1235, latest loss 0.8106294274330139\n",
      "Finished epoch 1236, latest loss 0.8125553727149963\n",
      "Finished epoch 1237, latest loss 0.8072847127914429\n",
      "Finished epoch 1238, latest loss 0.8103832602500916\n",
      "Finished epoch 1239, latest loss 0.8097522258758545\n",
      "Finished epoch 1240, latest loss 0.808796763420105\n",
      "Finished epoch 1241, latest loss 0.8124060034751892\n",
      "Finished epoch 1242, latest loss 0.8085426688194275\n",
      "Finished epoch 1243, latest loss 0.8092414140701294\n",
      "Finished epoch 1244, latest loss 0.8090771436691284\n",
      "Finished epoch 1245, latest loss 0.8111173510551453\n",
      "Finished epoch 1246, latest loss 0.8083110451698303\n",
      "Finished epoch 1247, latest loss 0.8082961440086365\n",
      "Finished epoch 1248, latest loss 0.8140358328819275\n",
      "Finished epoch 1249, latest loss 0.8093119859695435\n",
      "Finished epoch 1250, latest loss 0.8094010949134827\n",
      "Finished epoch 1251, latest loss 0.809607744216919\n",
      "Finished epoch 1252, latest loss 0.8120623230934143\n",
      "Finished epoch 1253, latest loss 0.8146626949310303\n",
      "Finished epoch 1254, latest loss 0.8088232278823853\n",
      "Finished epoch 1255, latest loss 0.8072847127914429\n",
      "Finished epoch 1256, latest loss 0.8105291724205017\n",
      "Finished epoch 1257, latest loss 0.8103734850883484\n",
      "Finished epoch 1258, latest loss 0.8082972764968872\n",
      "Finished epoch 1259, latest loss 0.810504674911499\n",
      "Finished epoch 1260, latest loss 0.8124207258224487\n",
      "Finished epoch 1261, latest loss 0.8107791543006897\n",
      "Finished epoch 1262, latest loss 0.8094194531440735\n",
      "Finished epoch 1263, latest loss 0.8068218231201172\n",
      "Finished epoch 1264, latest loss 0.8134976029396057\n",
      "Finished epoch 1265, latest loss 0.8082713484764099\n",
      "Finished epoch 1266, latest loss 0.8088434934616089\n",
      "Finished epoch 1267, latest loss 0.8098470568656921\n",
      "Finished epoch 1268, latest loss 0.8088410496711731\n",
      "Finished epoch 1269, latest loss 0.8073054552078247\n",
      "Finished epoch 1270, latest loss 0.8098502159118652\n",
      "Finished epoch 1271, latest loss 0.8088503479957581\n",
      "Finished epoch 1272, latest loss 0.8140727281570435\n",
      "Finished epoch 1273, latest loss 0.8102356195449829\n",
      "Finished epoch 1274, latest loss 0.8085575103759766\n",
      "Finished epoch 1275, latest loss 0.8117725849151611\n",
      "Finished epoch 1276, latest loss 0.8121922016143799\n",
      "Finished epoch 1277, latest loss 0.811399519443512\n",
      "Finished epoch 1278, latest loss 0.8129405379295349\n",
      "Finished epoch 1279, latest loss 0.8098814487457275\n",
      "Finished epoch 1280, latest loss 0.8128654956817627\n",
      "Finished epoch 1281, latest loss 0.8129392862319946\n",
      "Finished epoch 1282, latest loss 0.811067521572113\n",
      "Finished epoch 1283, latest loss 0.8126415014266968\n",
      "Finished epoch 1284, latest loss 0.8103604912757874\n",
      "Finished epoch 1285, latest loss 0.8118681311607361\n",
      "Finished epoch 1286, latest loss 0.8128709197044373\n",
      "Finished epoch 1287, latest loss 0.8097693920135498\n",
      "Finished epoch 1288, latest loss 0.8072848916053772\n",
      "Finished epoch 1289, latest loss 0.808296799659729\n",
      "Finished epoch 1290, latest loss 0.8074315786361694\n",
      "Finished epoch 1291, latest loss 0.8136582374572754\n",
      "Finished epoch 1292, latest loss 0.8123297691345215\n",
      "Finished epoch 1293, latest loss 0.8087814450263977\n",
      "Finished epoch 1294, latest loss 0.8119033575057983\n",
      "Finished epoch 1295, latest loss 0.808914065361023\n",
      "Finished epoch 1296, latest loss 0.8103429079055786\n",
      "Finished epoch 1297, latest loss 0.8098412156105042\n",
      "Finished epoch 1298, latest loss 0.8153135776519775\n",
      "Finished epoch 1299, latest loss 0.8080120086669922\n",
      "Finished epoch 1300, latest loss 0.8134300112724304\n",
      "Finished epoch 1301, latest loss 0.8115713596343994\n",
      "Finished epoch 1302, latest loss 0.8089299201965332\n",
      "Finished epoch 1303, latest loss 0.8091831803321838\n",
      "Finished epoch 1304, latest loss 0.8098061680793762\n",
      "Finished epoch 1305, latest loss 0.8088544607162476\n",
      "Finished epoch 1306, latest loss 0.810854971408844\n",
      "Finished epoch 1307, latest loss 0.8101679682731628\n",
      "Finished epoch 1308, latest loss 0.813737690448761\n",
      "Finished epoch 1309, latest loss 0.8132320046424866\n",
      "Finished epoch 1310, latest loss 0.8134424686431885\n",
      "Finished epoch 1311, latest loss 0.8116719722747803\n",
      "Finished epoch 1312, latest loss 0.8073157668113708\n",
      "Finished epoch 1313, latest loss 0.8097345232963562\n",
      "Finished epoch 1314, latest loss 0.8088802099227905\n",
      "Finished epoch 1315, latest loss 0.8162633776664734\n",
      "Finished epoch 1316, latest loss 0.8109142184257507\n",
      "Finished epoch 1317, latest loss 0.8103415966033936\n",
      "Finished epoch 1318, latest loss 0.8118705153465271\n",
      "Finished epoch 1319, latest loss 0.8103929758071899\n",
      "Finished epoch 1320, latest loss 0.8147484660148621\n",
      "Finished epoch 1321, latest loss 0.8178325891494751\n",
      "Finished epoch 1322, latest loss 0.8141965270042419\n",
      "Finished epoch 1323, latest loss 0.8098121881484985\n",
      "Finished epoch 1324, latest loss 0.8118724822998047\n",
      "Finished epoch 1325, latest loss 0.8074129223823547\n",
      "Finished epoch 1326, latest loss 0.8100730776786804\n",
      "Finished epoch 1327, latest loss 0.8107284903526306\n",
      "Finished epoch 1328, latest loss 0.8099937438964844\n",
      "Finished epoch 1329, latest loss 0.8095139861106873\n",
      "Finished epoch 1330, latest loss 0.8099678158760071\n",
      "Finished epoch 1331, latest loss 0.8082999587059021\n",
      "Finished epoch 1332, latest loss 0.8107084035873413\n",
      "Finished epoch 1333, latest loss 0.8072850704193115\n",
      "Finished epoch 1334, latest loss 0.8082436323165894\n",
      "Finished epoch 1335, latest loss 0.8102462291717529\n",
      "Finished epoch 1336, latest loss 0.8085353374481201\n",
      "Finished epoch 1337, latest loss 0.8103232383728027\n",
      "Finished epoch 1338, latest loss 0.8103684782981873\n",
      "Finished epoch 1339, latest loss 0.8113601207733154\n",
      "Finished epoch 1340, latest loss 0.8120059370994568\n",
      "Finished epoch 1341, latest loss 0.809839129447937\n",
      "Finished epoch 1342, latest loss 0.8217540979385376\n",
      "Finished epoch 1343, latest loss 0.809381902217865\n",
      "Finished epoch 1344, latest loss 0.8118056058883667\n",
      "Finished epoch 1345, latest loss 0.8123305439949036\n",
      "Finished epoch 1346, latest loss 0.815303385257721\n",
      "Finished epoch 1347, latest loss 0.8145465850830078\n",
      "Finished epoch 1348, latest loss 0.8129441738128662\n",
      "Finished epoch 1349, latest loss 0.8076999187469482\n",
      "Finished epoch 1350, latest loss 0.8063823580741882\n",
      "Finished epoch 1351, latest loss 0.8150498270988464\n",
      "Finished epoch 1352, latest loss 0.8106851577758789\n",
      "Finished epoch 1353, latest loss 0.8081997632980347\n",
      "Finished epoch 1354, latest loss 0.8155553936958313\n",
      "Finished epoch 1355, latest loss 0.8072851300239563\n",
      "Finished epoch 1356, latest loss 0.8149427175521851\n",
      "Finished epoch 1357, latest loss 0.81193608045578\n",
      "Finished epoch 1358, latest loss 0.8072850108146667\n",
      "Finished epoch 1359, latest loss 0.8108287453651428\n",
      "Finished epoch 1360, latest loss 0.808999240398407\n",
      "Finished epoch 1361, latest loss 0.8127765655517578\n",
      "Finished epoch 1362, latest loss 0.809914767742157\n",
      "Finished epoch 1363, latest loss 0.8115655183792114\n",
      "Finished epoch 1364, latest loss 0.8119437098503113\n",
      "Finished epoch 1365, latest loss 0.8058944344520569\n",
      "Finished epoch 1366, latest loss 0.807611346244812\n",
      "Finished epoch 1367, latest loss 0.8075945973396301\n",
      "Finished epoch 1368, latest loss 0.808280348777771\n",
      "Finished epoch 1369, latest loss 0.8135077357292175\n",
      "Finished epoch 1370, latest loss 0.8119325637817383\n",
      "Finished epoch 1371, latest loss 0.8121469616889954\n",
      "Finished epoch 1372, latest loss 0.8082963824272156\n",
      "Finished epoch 1373, latest loss 0.8074339628219604\n",
      "Finished epoch 1374, latest loss 0.8118495345115662\n",
      "Finished epoch 1375, latest loss 0.8135012984275818\n",
      "Finished epoch 1376, latest loss 0.8093177676200867\n",
      "Finished epoch 1377, latest loss 0.809861421585083\n",
      "Finished epoch 1378, latest loss 0.8132663369178772\n",
      "Finished epoch 1379, latest loss 0.813700795173645\n",
      "Finished epoch 1380, latest loss 0.8108508586883545\n",
      "Finished epoch 1381, latest loss 0.808016300201416\n",
      "Finished epoch 1382, latest loss 0.8104481101036072\n",
      "Finished epoch 1383, latest loss 0.8108663558959961\n",
      "Finished epoch 1384, latest loss 0.8095968961715698\n",
      "Finished epoch 1385, latest loss 0.808432400226593\n",
      "Finished epoch 1386, latest loss 0.8113136291503906\n",
      "Finished epoch 1387, latest loss 0.8057357668876648\n",
      "Finished epoch 1388, latest loss 0.8129022121429443\n",
      "Finished epoch 1389, latest loss 0.8088386058807373\n",
      "Finished epoch 1390, latest loss 0.8108103275299072\n",
      "Finished epoch 1391, latest loss 0.8142266869544983\n",
      "Finished epoch 1392, latest loss 0.8102306723594666\n",
      "Finished epoch 1393, latest loss 0.8097186088562012\n",
      "Finished epoch 1394, latest loss 0.8103833198547363\n",
      "Finished epoch 1395, latest loss 0.8092788457870483\n",
      "Finished epoch 1396, latest loss 0.8072848320007324\n",
      "Finished epoch 1397, latest loss 0.8118933439254761\n",
      "Finished epoch 1398, latest loss 0.8159741759300232\n",
      "Finished epoch 1399, latest loss 0.8139570355415344\n",
      "Finished epoch 1400, latest loss 0.8103833198547363\n",
      "Finished epoch 1401, latest loss 0.8073803186416626\n",
      "Finished epoch 1402, latest loss 0.809844434261322\n",
      "Finished epoch 1403, latest loss 0.8088328242301941\n",
      "Finished epoch 1404, latest loss 0.8074538111686707\n",
      "Finished epoch 1405, latest loss 0.811187744140625\n",
      "Finished epoch 1406, latest loss 0.8119054436683655\n",
      "Finished epoch 1407, latest loss 0.8072850108146667\n",
      "Finished epoch 1408, latest loss 0.8093119859695435\n",
      "Finished epoch 1409, latest loss 0.8108589053153992\n",
      "Finished epoch 1410, latest loss 0.8089269399642944\n",
      "Finished epoch 1411, latest loss 0.8098512887954712\n",
      "Finished epoch 1412, latest loss 0.8061960339546204\n",
      "Finished epoch 1413, latest loss 0.8102788329124451\n",
      "Finished epoch 1414, latest loss 0.8106104731559753\n",
      "Finished epoch 1415, latest loss 0.8077319264411926\n",
      "Finished epoch 1416, latest loss 0.8079132437705994\n",
      "Finished epoch 1417, latest loss 0.8095025420188904\n",
      "Finished epoch 1418, latest loss 0.8077833652496338\n",
      "Finished epoch 1419, latest loss 0.8059008717536926\n",
      "Finished epoch 1420, latest loss 0.8077993392944336\n",
      "Finished epoch 1421, latest loss 0.8091779351234436\n",
      "Finished epoch 1422, latest loss 0.805704653263092\n",
      "Finished epoch 1423, latest loss 0.8057416081428528\n",
      "Finished epoch 1424, latest loss 0.8210811018943787\n",
      "Finished epoch 1425, latest loss 0.8100227117538452\n",
      "Finished epoch 1426, latest loss 0.8100382685661316\n",
      "Finished epoch 1427, latest loss 0.8088234066963196\n",
      "Finished epoch 1428, latest loss 0.8123239874839783\n",
      "Finished epoch 1429, latest loss 0.8130168914794922\n",
      "Finished epoch 1430, latest loss 0.8096571564674377\n",
      "Finished epoch 1431, latest loss 0.808980405330658\n",
      "Finished epoch 1432, latest loss 0.8116508722305298\n",
      "Finished epoch 1433, latest loss 0.8106076121330261\n",
      "Finished epoch 1434, latest loss 0.8116946816444397\n",
      "Finished epoch 1435, latest loss 0.8061537742614746\n",
      "Finished epoch 1436, latest loss 0.8108994364738464\n",
      "Finished epoch 1437, latest loss 0.8078001737594604\n",
      "Finished epoch 1438, latest loss 0.8113901019096375\n",
      "Finished epoch 1439, latest loss 0.8151624798774719\n",
      "Finished epoch 1440, latest loss 0.8095493316650391\n",
      "Finished epoch 1441, latest loss 0.8103601932525635\n",
      "Finished epoch 1442, latest loss 0.8061038851737976\n",
      "Finished epoch 1443, latest loss 0.8128385543823242\n",
      "Finished epoch 1444, latest loss 0.807094395160675\n",
      "Finished epoch 1445, latest loss 0.807284951210022\n",
      "Finished epoch 1446, latest loss 0.8095521330833435\n",
      "Finished epoch 1447, latest loss 0.8084225058555603\n",
      "Finished epoch 1448, latest loss 0.8098565340042114\n",
      "Finished epoch 1449, latest loss 0.8107516169548035\n",
      "Finished epoch 1450, latest loss 0.8124482035636902\n",
      "Finished epoch 1451, latest loss 0.8100915551185608\n",
      "Finished epoch 1452, latest loss 0.8098185658454895\n",
      "Finished epoch 1453, latest loss 0.806107223033905\n",
      "Finished epoch 1454, latest loss 0.808842658996582\n",
      "Finished epoch 1455, latest loss 0.8113966584205627\n",
      "Finished epoch 1456, latest loss 0.8093084096908569\n",
      "Finished epoch 1457, latest loss 0.806567907333374\n",
      "Finished epoch 1458, latest loss 0.8113986849784851\n",
      "Finished epoch 1459, latest loss 0.8130917549133301\n",
      "Finished epoch 1460, latest loss 0.8115423321723938\n",
      "Finished epoch 1461, latest loss 0.8121817708015442\n",
      "Finished epoch 1462, latest loss 0.8078139424324036\n",
      "Finished epoch 1463, latest loss 0.8120614290237427\n",
      "Finished epoch 1464, latest loss 0.8093155026435852\n",
      "Finished epoch 1465, latest loss 0.8132765293121338\n",
      "Finished epoch 1466, latest loss 0.8061065673828125\n",
      "Finished epoch 1467, latest loss 0.8074844479560852\n",
      "Finished epoch 1468, latest loss 0.8100152611732483\n",
      "Finished epoch 1469, latest loss 0.8086187243461609\n",
      "Finished epoch 1470, latest loss 0.8118712306022644\n",
      "Finished epoch 1471, latest loss 0.8062659502029419\n",
      "Finished epoch 1472, latest loss 0.8065240383148193\n",
      "Finished epoch 1473, latest loss 0.8087304830551147\n",
      "Finished epoch 1474, latest loss 0.8100336790084839\n",
      "Finished epoch 1475, latest loss 0.8102372288703918\n",
      "Finished epoch 1476, latest loss 0.8078544735908508\n",
      "Finished epoch 1477, latest loss 0.8099255561828613\n",
      "Finished epoch 1478, latest loss 0.8093074560165405\n",
      "Finished epoch 1479, latest loss 0.8118999600410461\n",
      "Finished epoch 1480, latest loss 0.807044506072998\n",
      "Finished epoch 1481, latest loss 0.8106458783149719\n",
      "Finished epoch 1482, latest loss 0.8096116185188293\n",
      "Finished epoch 1483, latest loss 0.8081017136573792\n",
      "Finished epoch 1484, latest loss 0.8042629957199097\n",
      "Finished epoch 1485, latest loss 0.8067482709884644\n",
      "Finished epoch 1486, latest loss 0.8147340416908264\n",
      "Finished epoch 1487, latest loss 0.808769166469574\n",
      "Finished epoch 1488, latest loss 0.8094185590744019\n",
      "Finished epoch 1489, latest loss 0.8062093257904053\n",
      "Finished epoch 1490, latest loss 0.8057509660720825\n",
      "Finished epoch 1491, latest loss 0.8062106966972351\n",
      "Finished epoch 1492, latest loss 0.8060916066169739\n",
      "Finished epoch 1493, latest loss 0.8043901324272156\n",
      "Finished epoch 1494, latest loss 0.8103665113449097\n",
      "Finished epoch 1495, latest loss 0.8074535131454468\n",
      "Finished epoch 1496, latest loss 0.8057354092597961\n",
      "Finished epoch 1497, latest loss 0.8057354092597961\n",
      "Finished epoch 1498, latest loss 0.8046495318412781\n",
      "Finished epoch 1499, latest loss 0.8057275414466858\n",
      "Finished epoch 1500, latest loss 0.8041864037513733\n",
      "Finished epoch 1501, latest loss 0.8085736632347107\n",
      "Finished epoch 1502, latest loss 0.8109803199768066\n",
      "Finished epoch 1503, latest loss 0.8080074787139893\n",
      "Finished epoch 1504, latest loss 0.8136675953865051\n",
      "Finished epoch 1505, latest loss 0.8108795285224915\n",
      "Finished epoch 1506, latest loss 0.8155121803283691\n",
      "Finished epoch 1507, latest loss 0.8073616027832031\n",
      "Finished epoch 1508, latest loss 0.8050244450569153\n",
      "Finished epoch 1509, latest loss 0.8102381825447083\n",
      "Finished epoch 1510, latest loss 0.8066378235816956\n",
      "Finished epoch 1511, latest loss 0.8077604174613953\n",
      "Finished epoch 1512, latest loss 0.808573842048645\n",
      "Finished epoch 1513, latest loss 0.8063311576843262\n",
      "Finished epoch 1514, latest loss 0.8052151799201965\n",
      "Finished epoch 1515, latest loss 0.81026291847229\n",
      "Finished epoch 1516, latest loss 0.8041938543319702\n",
      "Finished epoch 1517, latest loss 0.8067914843559265\n",
      "Finished epoch 1518, latest loss 0.8063011765480042\n",
      "Finished epoch 1519, latest loss 0.8062041997909546\n",
      "Finished epoch 1520, latest loss 0.8108729720115662\n",
      "Finished epoch 1521, latest loss 0.8090730905532837\n",
      "Finished epoch 1522, latest loss 0.8068316578865051\n",
      "Finished epoch 1523, latest loss 0.8066794872283936\n",
      "Finished epoch 1524, latest loss 0.8072515726089478\n",
      "Finished epoch 1525, latest loss 0.8072852492332458\n",
      "Finished epoch 1526, latest loss 0.8083327412605286\n",
      "Finished epoch 1527, latest loss 0.8057133555412292\n",
      "Finished epoch 1528, latest loss 0.8049080967903137\n",
      "Finished epoch 1529, latest loss 0.8082957863807678\n",
      "Finished epoch 1530, latest loss 0.8092957139015198\n",
      "Finished epoch 1531, latest loss 0.815267026424408\n",
      "Finished epoch 1532, latest loss 0.8041275143623352\n",
      "Finished epoch 1533, latest loss 0.8067790269851685\n",
      "Finished epoch 1534, latest loss 0.8082928657531738\n",
      "Finished epoch 1535, latest loss 0.8133828639984131\n",
      "Finished epoch 1536, latest loss 0.8062334060668945\n",
      "Finished epoch 1537, latest loss 0.8057456016540527\n",
      "Finished epoch 1538, latest loss 0.8076654076576233\n",
      "Finished epoch 1539, latest loss 0.8082963824272156\n",
      "Finished epoch 1540, latest loss 0.8104680180549622\n",
      "Finished epoch 1541, latest loss 0.8088393211364746\n",
      "Finished epoch 1542, latest loss 0.8041722774505615\n",
      "Finished epoch 1543, latest loss 0.8067358136177063\n",
      "Finished epoch 1544, latest loss 0.8159254789352417\n",
      "Finished epoch 1545, latest loss 0.8072458505630493\n",
      "Finished epoch 1546, latest loss 0.8067570924758911\n",
      "Finished epoch 1547, latest loss 0.8078042268753052\n",
      "Finished epoch 1548, latest loss 0.8066470623016357\n",
      "Finished epoch 1549, latest loss 0.8109286427497864\n",
      "Finished epoch 1550, latest loss 0.804747998714447\n",
      "Finished epoch 1551, latest loss 0.8081681728363037\n",
      "Finished epoch 1552, latest loss 0.8075760006904602\n",
      "Finished epoch 1553, latest loss 0.8113282918930054\n",
      "Finished epoch 1554, latest loss 0.810325562953949\n",
      "Finished epoch 1555, latest loss 0.8068109154701233\n",
      "Finished epoch 1556, latest loss 0.8043689727783203\n",
      "Finished epoch 1557, latest loss 0.8122691512107849\n",
      "Finished epoch 1558, latest loss 0.8073323369026184\n",
      "Finished epoch 1559, latest loss 0.8041861057281494\n",
      "Finished epoch 1560, latest loss 0.8051983118057251\n",
      "Finished epoch 1561, latest loss 0.8090776801109314\n",
      "Finished epoch 1562, latest loss 0.8050978183746338\n",
      "Finished epoch 1563, latest loss 0.8063174486160278\n",
      "Finished epoch 1564, latest loss 0.8059022426605225\n",
      "Finished epoch 1565, latest loss 0.8052638173103333\n",
      "Finished epoch 1566, latest loss 0.8031885027885437\n",
      "Finished epoch 1567, latest loss 0.8042474389076233\n",
      "Finished epoch 1568, latest loss 0.8042964339256287\n",
      "Finished epoch 1569, latest loss 0.8113023042678833\n",
      "Finished epoch 1570, latest loss 0.8082910180091858\n",
      "Finished epoch 1571, latest loss 0.80620276927948\n",
      "Finished epoch 1572, latest loss 0.8108519911766052\n",
      "Finished epoch 1573, latest loss 0.8042536973953247\n",
      "Finished epoch 1574, latest loss 0.8057357668876648\n",
      "Finished epoch 1575, latest loss 0.8100318312644958\n",
      "Finished epoch 1576, latest loss 0.8087202906608582\n",
      "Finished epoch 1577, latest loss 0.8041530251502991\n",
      "Finished epoch 1578, latest loss 0.8132760524749756\n",
      "Finished epoch 1579, latest loss 0.808217465877533\n",
      "Finished epoch 1580, latest loss 0.8051989078521729\n",
      "Finished epoch 1581, latest loss 0.8089354038238525\n",
      "Finished epoch 1582, latest loss 0.8064305782318115\n",
      "Finished epoch 1583, latest loss 0.8100718259811401\n",
      "Finished epoch 1584, latest loss 0.8108481168746948\n",
      "Finished epoch 1585, latest loss 0.8088040947914124\n",
      "Finished epoch 1586, latest loss 0.8090403079986572\n",
      "Finished epoch 1587, latest loss 0.8085790276527405\n",
      "Finished epoch 1588, latest loss 0.8032459616661072\n",
      "Finished epoch 1589, latest loss 0.8076509833335876\n",
      "Finished epoch 1590, latest loss 0.8051941394805908\n",
      "Finished epoch 1591, latest loss 0.804631769657135\n",
      "Finished epoch 1592, latest loss 0.805935800075531\n",
      "Finished epoch 1593, latest loss 0.8077126145362854\n",
      "Finished epoch 1594, latest loss 0.8077412247657776\n",
      "Finished epoch 1595, latest loss 0.8071209192276001\n",
      "Finished epoch 1596, latest loss 0.8098699450492859\n",
      "Finished epoch 1597, latest loss 0.8116520643234253\n",
      "Finished epoch 1598, latest loss 0.8074407577514648\n",
      "Finished epoch 1599, latest loss 0.806294858455658\n",
      "Finished epoch 1600, latest loss 0.8047237396240234\n",
      "Finished epoch 1601, latest loss 0.8077901005744934\n",
      "Finished epoch 1602, latest loss 0.8065569400787354\n",
      "Finished epoch 1603, latest loss 0.8032280206680298\n",
      "Finished epoch 1604, latest loss 0.8061299920082092\n",
      "Finished epoch 1605, latest loss 0.8053281307220459\n",
      "Finished epoch 1606, latest loss 0.8057096004486084\n",
      "Finished epoch 1607, latest loss 0.8093044757843018\n",
      "Finished epoch 1608, latest loss 0.8093216419219971\n",
      "Finished epoch 1609, latest loss 0.8093005418777466\n",
      "Finished epoch 1610, latest loss 0.8094197511672974\n",
      "Finished epoch 1611, latest loss 0.8047237992286682\n",
      "Finished epoch 1612, latest loss 0.8119811415672302\n",
      "Finished epoch 1613, latest loss 0.8088357448577881\n",
      "Finished epoch 1614, latest loss 0.8076433539390564\n",
      "Finished epoch 1615, latest loss 0.80621337890625\n",
      "Finished epoch 1616, latest loss 0.8058071732521057\n",
      "Finished epoch 1617, latest loss 0.8027723431587219\n",
      "Finished epoch 1618, latest loss 0.8068284392356873\n",
      "Finished epoch 1619, latest loss 0.8079658150672913\n",
      "Finished epoch 1620, latest loss 0.8062494397163391\n",
      "Finished epoch 1621, latest loss 0.8097777962684631\n",
      "Finished epoch 1622, latest loss 0.8067487478256226\n",
      "Finished epoch 1623, latest loss 0.8054951429367065\n",
      "Finished epoch 1624, latest loss 0.8081505298614502\n",
      "Finished epoch 1625, latest loss 0.8072841167449951\n",
      "Finished epoch 1626, latest loss 0.8128474950790405\n",
      "Finished epoch 1627, latest loss 0.8046039938926697\n",
      "Finished epoch 1628, latest loss 0.8082966804504395\n",
      "Finished epoch 1629, latest loss 0.8069130778312683\n",
      "Finished epoch 1630, latest loss 0.8127546310424805\n",
      "Finished epoch 1631, latest loss 0.8098455667495728\n",
      "Finished epoch 1632, latest loss 0.8067481517791748\n",
      "Finished epoch 1633, latest loss 0.805237889289856\n",
      "Finished epoch 1634, latest loss 0.8051977753639221\n",
      "Finished epoch 1635, latest loss 0.8131217360496521\n",
      "Finished epoch 1636, latest loss 0.8076896667480469\n",
      "Finished epoch 1637, latest loss 0.8066490888595581\n",
      "Finished epoch 1638, latest loss 0.8077862858772278\n",
      "Finished epoch 1639, latest loss 0.8051372170448303\n",
      "Finished epoch 1640, latest loss 0.8045997023582458\n",
      "Finished epoch 1641, latest loss 0.8031745553016663\n",
      "Finished epoch 1642, latest loss 0.8041861057281494\n",
      "Finished epoch 1643, latest loss 0.8010876178741455\n",
      "Finished epoch 1644, latest loss 0.805607795715332\n",
      "Finished epoch 1645, latest loss 0.8087670207023621\n",
      "Finished epoch 1646, latest loss 0.8068999648094177\n",
      "Finished epoch 1647, latest loss 0.807974636554718\n",
      "Finished epoch 1648, latest loss 0.8080338835716248\n",
      "Finished epoch 1649, latest loss 0.8108574151992798\n",
      "Finished epoch 1650, latest loss 0.8067490458488464\n",
      "Finished epoch 1651, latest loss 0.8079191446304321\n",
      "Finished epoch 1652, latest loss 0.8057353496551514\n",
      "Finished epoch 1653, latest loss 0.8052980303764343\n",
      "Finished epoch 1654, latest loss 0.801151692867279\n",
      "Finished epoch 1655, latest loss 0.802625298500061\n",
      "Finished epoch 1656, latest loss 0.8000759482383728\n",
      "Finished epoch 1657, latest loss 0.8003064393997192\n",
      "Finished epoch 1658, latest loss 0.8053409457206726\n",
      "Finished epoch 1659, latest loss 0.8054368495941162\n",
      "Finished epoch 1660, latest loss 0.8047232627868652\n",
      "Finished epoch 1661, latest loss 0.8095434308052063\n",
      "Finished epoch 1662, latest loss 0.8000776767730713\n",
      "Finished epoch 1663, latest loss 0.808539867401123\n",
      "Finished epoch 1664, latest loss 0.8050224184989929\n",
      "Finished epoch 1665, latest loss 0.8051272034645081\n",
      "Finished epoch 1666, latest loss 0.8000764846801758\n",
      "Finished epoch 1667, latest loss 0.8029149174690247\n",
      "Finished epoch 1668, latest loss 0.8011519908905029\n",
      "Finished epoch 1669, latest loss 0.8042672276496887\n",
      "Finished epoch 1670, latest loss 0.8113618493080139\n",
      "Finished epoch 1671, latest loss 0.808788537979126\n",
      "Finished epoch 1672, latest loss 0.8041961193084717\n",
      "Finished epoch 1673, latest loss 0.8077017068862915\n",
      "Finished epoch 1674, latest loss 0.8097414970397949\n",
      "Finished epoch 1675, latest loss 0.8029718399047852\n",
      "Finished epoch 1676, latest loss 0.8033007383346558\n",
      "Finished epoch 1677, latest loss 0.8026368618011475\n",
      "Finished epoch 1678, latest loss 0.8020996451377869\n",
      "Finished epoch 1679, latest loss 0.8087388873100281\n",
      "Finished epoch 1680, latest loss 0.8066246509552002\n",
      "Finished epoch 1681, latest loss 0.8051652908325195\n",
      "Finished epoch 1682, latest loss 0.8046358227729797\n",
      "Finished epoch 1683, latest loss 0.8051942586898804\n",
      "Finished epoch 1684, latest loss 0.8049870133399963\n",
      "Finished epoch 1685, latest loss 0.8042786717414856\n",
      "Finished epoch 1686, latest loss 0.8005028367042542\n",
      "Finished epoch 1687, latest loss 0.8076515197753906\n",
      "Finished epoch 1688, latest loss 0.8032925724983215\n",
      "Finished epoch 1689, latest loss 0.8061110377311707\n",
      "Finished epoch 1690, latest loss 0.8087741136550903\n",
      "Finished epoch 1691, latest loss 0.8118346929550171\n",
      "Finished epoch 1692, latest loss 0.8025690913200378\n",
      "Finished epoch 1693, latest loss 0.8034188747406006\n",
      "Finished epoch 1694, latest loss 0.8051983118057251\n",
      "Finished epoch 1695, latest loss 0.8082305192947388\n",
      "Finished epoch 1696, latest loss 0.8011394739151001\n",
      "Finished epoch 1697, latest loss 0.8076778054237366\n",
      "Finished epoch 1698, latest loss 0.8011301159858704\n",
      "Finished epoch 1699, latest loss 0.8060596585273743\n",
      "Finished epoch 1700, latest loss 0.8087788820266724\n",
      "Finished epoch 1701, latest loss 0.8058141469955444\n",
      "Finished epoch 1702, latest loss 0.8026369214057922\n",
      "Finished epoch 1703, latest loss 0.8145352005958557\n",
      "Finished epoch 1704, latest loss 0.8020992875099182\n",
      "Finished epoch 1705, latest loss 0.8026368618011475\n",
      "Finished epoch 1706, latest loss 0.8054590821266174\n",
      "Finished epoch 1707, latest loss 0.803107738494873\n",
      "Finished epoch 1708, latest loss 0.8041794896125793\n",
      "Finished epoch 1709, latest loss 0.8020995855331421\n",
      "Finished epoch 1710, latest loss 0.8061954379081726\n",
      "Finished epoch 1711, latest loss 0.8085006475448608\n",
      "Finished epoch 1712, latest loss 0.8052272796630859\n",
      "Finished epoch 1713, latest loss 0.8058235049247742\n",
      "Finished epoch 1714, latest loss 0.8056913018226624\n",
      "Finished epoch 1715, latest loss 0.8021206259727478\n",
      "Finished epoch 1716, latest loss 0.8044617772102356\n",
      "Finished epoch 1717, latest loss 0.8021160364151001\n",
      "Finished epoch 1718, latest loss 0.8066104650497437\n",
      "Finished epoch 1719, latest loss 0.8074803948402405\n",
      "Finished epoch 1720, latest loss 0.8043153285980225\n",
      "Finished epoch 1721, latest loss 0.8061511516571045\n",
      "Finished epoch 1722, latest loss 0.8046725988388062\n",
      "Finished epoch 1723, latest loss 0.8056478500366211\n",
      "Finished epoch 1724, latest loss 0.8020948767662048\n",
      "Finished epoch 1725, latest loss 0.8057211637496948\n",
      "Finished epoch 1726, latest loss 0.8038501143455505\n",
      "Finished epoch 1727, latest loss 0.8066840767860413\n",
      "Finished epoch 1728, latest loss 0.8073188662528992\n",
      "Finished epoch 1729, latest loss 0.8097809553146362\n",
      "Finished epoch 1730, latest loss 0.8041200041770935\n",
      "Finished epoch 1731, latest loss 0.808689534664154\n",
      "Finished epoch 1732, latest loss 0.803175687789917\n",
      "Finished epoch 1733, latest loss 0.8082311153411865\n",
      "Finished epoch 1734, latest loss 0.8023760914802551\n",
      "Finished epoch 1735, latest loss 0.803107500076294\n",
      "Finished epoch 1736, latest loss 0.8097615242004395\n",
      "Finished epoch 1737, latest loss 0.8062731027603149\n",
      "Finished epoch 1738, latest loss 0.8039734959602356\n",
      "Finished epoch 1739, latest loss 0.8020346760749817\n",
      "Finished epoch 1740, latest loss 0.8016756176948547\n",
      "Finished epoch 1741, latest loss 0.8031185269355774\n",
      "Finished epoch 1742, latest loss 0.8051424622535706\n",
      "Finished epoch 1743, latest loss 0.8056870698928833\n",
      "Finished epoch 1744, latest loss 0.8064348697662354\n",
      "Finished epoch 1745, latest loss 0.8081296682357788\n",
      "Finished epoch 1746, latest loss 0.8057342171669006\n",
      "Finished epoch 1747, latest loss 0.8064647912979126\n",
      "Finished epoch 1748, latest loss 0.8038725852966309\n",
      "Finished epoch 1749, latest loss 0.8026164174079895\n",
      "Finished epoch 1750, latest loss 0.8047674894332886\n",
      "Finished epoch 1751, latest loss 0.8072234988212585\n",
      "Finished epoch 1752, latest loss 0.806200385093689\n",
      "Finished epoch 1753, latest loss 0.8046961426734924\n",
      "Finished epoch 1754, latest loss 0.8026382923126221\n",
      "Finished epoch 1755, latest loss 0.8147337436676025\n",
      "Finished epoch 1756, latest loss 0.8058329820632935\n",
      "Finished epoch 1757, latest loss 0.8058376312255859\n",
      "Finished epoch 1758, latest loss 0.8082142472267151\n",
      "Finished epoch 1759, latest loss 0.8086795806884766\n",
      "Finished epoch 1760, latest loss 0.8017764687538147\n",
      "Finished epoch 1761, latest loss 0.8070212006568909\n",
      "Finished epoch 1762, latest loss 0.8066717386245728\n",
      "Finished epoch 1763, latest loss 0.8026379942893982\n",
      "Finished epoch 1764, latest loss 0.802873432636261\n",
      "Finished epoch 1765, latest loss 0.8031107783317566\n",
      "Finished epoch 1766, latest loss 0.8084630370140076\n",
      "Finished epoch 1767, latest loss 0.8010733127593994\n",
      "Finished epoch 1768, latest loss 0.8000906109809875\n",
      "Finished epoch 1769, latest loss 0.8020997643470764\n",
      "Finished epoch 1770, latest loss 0.8057237863540649\n",
      "Finished epoch 1771, latest loss 0.8026376962661743\n",
      "Finished epoch 1772, latest loss 0.8027025461196899\n",
      "Finished epoch 1773, latest loss 0.8028297424316406\n",
      "Finished epoch 1774, latest loss 0.802299439907074\n",
      "Finished epoch 1775, latest loss 0.8026654124259949\n",
      "Finished epoch 1776, latest loss 0.8037253022193909\n",
      "Finished epoch 1777, latest loss 0.8055316209793091\n",
      "Finished epoch 1778, latest loss 0.8078765869140625\n",
      "Finished epoch 1779, latest loss 0.8085890412330627\n",
      "Finished epoch 1780, latest loss 0.8037809133529663\n",
      "Finished epoch 1781, latest loss 0.8067467212677002\n",
      "Finished epoch 1782, latest loss 0.8093737959861755\n",
      "Finished epoch 1783, latest loss 0.8026390671730042\n",
      "Finished epoch 1784, latest loss 0.804186224937439\n",
      "Finished epoch 1785, latest loss 0.8048514723777771\n",
      "Finished epoch 1786, latest loss 0.8031258583068848\n",
      "Finished epoch 1787, latest loss 0.8076900243759155\n",
      "Finished epoch 1788, latest loss 0.8056125640869141\n",
      "Finished epoch 1789, latest loss 0.8082325458526611\n",
      "Finished epoch 1790, latest loss 0.8053950667381287\n",
      "Finished epoch 1791, latest loss 0.8031080961227417\n",
      "Finished epoch 1792, latest loss 0.8022741675376892\n",
      "Finished epoch 1793, latest loss 0.8041284084320068\n",
      "Finished epoch 1794, latest loss 0.80113685131073\n",
      "Finished epoch 1795, latest loss 0.8041563034057617\n",
      "Finished epoch 1796, latest loss 0.8020991683006287\n",
      "Finished epoch 1797, latest loss 0.8061361312866211\n",
      "Finished epoch 1798, latest loss 0.8089479804039001\n",
      "Finished epoch 1799, latest loss 0.8037147521972656\n",
      "Finished epoch 1800, latest loss 0.8073148131370544\n",
      "Finished epoch 1801, latest loss 0.8051303625106812\n",
      "Finished epoch 1802, latest loss 0.8048251867294312\n",
      "Finished epoch 1803, latest loss 0.8051282167434692\n",
      "Finished epoch 1804, latest loss 0.8089752793312073\n",
      "Finished epoch 1805, latest loss 0.8046556711196899\n",
      "Finished epoch 1806, latest loss 0.8066529035568237\n",
      "Finished epoch 1807, latest loss 0.8044155836105347\n",
      "Finished epoch 1808, latest loss 0.8044773936271667\n",
      "Finished epoch 1809, latest loss 0.8100304007530212\n",
      "Finished epoch 1810, latest loss 0.802756667137146\n",
      "Finished epoch 1811, latest loss 0.8032609224319458\n",
      "Finished epoch 1812, latest loss 0.8063867092132568\n",
      "Finished epoch 1813, latest loss 0.8036482930183411\n",
      "Finished epoch 1814, latest loss 0.8048794269561768\n",
      "Finished epoch 1815, latest loss 0.805232048034668\n",
      "Finished epoch 1816, latest loss 0.8011409044265747\n",
      "Finished epoch 1817, latest loss 0.804554283618927\n",
      "Finished epoch 1818, latest loss 0.80556321144104\n",
      "Finished epoch 1819, latest loss 0.8072859048843384\n",
      "Finished epoch 1820, latest loss 0.8010700941085815\n",
      "Finished epoch 1821, latest loss 0.8026297092437744\n",
      "Finished epoch 1822, latest loss 0.804711103439331\n",
      "Finished epoch 1823, latest loss 0.8037896752357483\n",
      "Finished epoch 1824, latest loss 0.8056142926216125\n",
      "Finished epoch 1825, latest loss 0.8073154091835022\n",
      "Finished epoch 1826, latest loss 0.8021594882011414\n",
      "Finished epoch 1827, latest loss 0.8010875582695007\n",
      "Finished epoch 1828, latest loss 0.8037227988243103\n",
      "Finished epoch 1829, latest loss 0.8027070760726929\n",
      "Finished epoch 1830, latest loss 0.8041850328445435\n",
      "Finished epoch 1831, latest loss 0.8024067282676697\n",
      "Finished epoch 1832, latest loss 0.8010454773902893\n",
      "Finished epoch 1833, latest loss 0.8036646246910095\n",
      "Finished epoch 1834, latest loss 0.8064166307449341\n",
      "Finished epoch 1835, latest loss 0.801504909992218\n",
      "Finished epoch 1836, latest loss 0.8026360869407654\n",
      "Finished epoch 1837, latest loss 0.8031744956970215\n",
      "Finished epoch 1838, latest loss 0.8036494851112366\n",
      "Finished epoch 1839, latest loss 0.8051224946975708\n",
      "Finished epoch 1840, latest loss 0.8020987510681152\n",
      "Finished epoch 1841, latest loss 0.8033533692359924\n",
      "Finished epoch 1842, latest loss 0.8053010702133179\n",
      "Finished epoch 1843, latest loss 0.8038375973701477\n",
      "Finished epoch 1844, latest loss 0.8036487698554993\n",
      "Finished epoch 1845, latest loss 0.8102371692657471\n",
      "Finished epoch 1846, latest loss 0.8098848462104797\n",
      "Finished epoch 1847, latest loss 0.8031127452850342\n",
      "Finished epoch 1848, latest loss 0.8055446147918701\n",
      "Finished epoch 1849, latest loss 0.8060135245323181\n",
      "Finished epoch 1850, latest loss 0.8036470413208008\n",
      "Finished epoch 1851, latest loss 0.8080341815948486\n",
      "Finished epoch 1852, latest loss 0.8046292662620544\n",
      "Finished epoch 1853, latest loss 0.8040082454681396\n",
      "Finished epoch 1854, latest loss 0.8036127686500549\n",
      "Finished epoch 1855, latest loss 0.8014432787895203\n",
      "Finished epoch 1856, latest loss 0.801154375076294\n",
      "Finished epoch 1857, latest loss 0.8031805753707886\n",
      "Finished epoch 1858, latest loss 0.8010875582695007\n",
      "Finished epoch 1859, latest loss 0.8061105608940125\n",
      "Finished epoch 1860, latest loss 0.8073562383651733\n",
      "Finished epoch 1861, latest loss 0.8076995611190796\n",
      "Finished epoch 1862, latest loss 0.8053208589553833\n",
      "Finished epoch 1863, latest loss 0.8016252517700195\n",
      "Finished epoch 1864, latest loss 0.805185854434967\n",
      "Finished epoch 1865, latest loss 0.8057354688644409\n",
      "Finished epoch 1866, latest loss 0.8037489056587219\n",
      "Finished epoch 1867, latest loss 0.8058614730834961\n",
      "Finished epoch 1868, latest loss 0.8029195666313171\n",
      "Finished epoch 1869, latest loss 0.8036405444145203\n",
      "Finished epoch 1870, latest loss 0.8047007918357849\n",
      "Finished epoch 1871, latest loss 0.8057748675346375\n",
      "Finished epoch 1872, latest loss 0.8011787533760071\n",
      "Finished epoch 1873, latest loss 0.8036593198776245\n",
      "Finished epoch 1874, latest loss 0.8033109307289124\n",
      "Finished epoch 1875, latest loss 0.8082352876663208\n",
      "Finished epoch 1876, latest loss 0.805738627910614\n",
      "Finished epoch 1877, latest loss 0.8042051792144775\n",
      "Finished epoch 1878, latest loss 0.8041109442710876\n",
      "Finished epoch 1879, latest loss 0.8069857358932495\n",
      "Finished epoch 1880, latest loss 0.8087704181671143\n",
      "Finished epoch 1881, latest loss 0.8026196360588074\n",
      "Finished epoch 1882, latest loss 0.80520099401474\n",
      "Finished epoch 1883, latest loss 0.8028632998466492\n",
      "Finished epoch 1884, latest loss 0.8016371726989746\n",
      "Finished epoch 1885, latest loss 0.8046581745147705\n",
      "Finished epoch 1886, latest loss 0.8034160733222961\n",
      "Finished epoch 1887, latest loss 0.8052093386650085\n",
      "Finished epoch 1888, latest loss 0.8037506937980652\n",
      "Finished epoch 1889, latest loss 0.8047012090682983\n",
      "Finished epoch 1890, latest loss 0.8029689192771912\n",
      "Finished epoch 1891, latest loss 0.8031744956970215\n",
      "Finished epoch 1892, latest loss 0.8026368618011475\n",
      "Finished epoch 1893, latest loss 0.8010875582695007\n",
      "Finished epoch 1894, latest loss 0.8052392601966858\n",
      "Finished epoch 1895, latest loss 0.8016252517700195\n",
      "Finished epoch 1896, latest loss 0.8055536150932312\n",
      "Finished epoch 1897, latest loss 0.8021346926689148\n",
      "Finished epoch 1898, latest loss 0.8034113049507141\n",
      "Finished epoch 1899, latest loss 0.8059561252593994\n",
      "Finished epoch 1900, latest loss 0.8054853677749634\n",
      "Finished epoch 1901, latest loss 0.8041973114013672\n",
      "Finished epoch 1902, latest loss 0.8062801361083984\n",
      "Finished epoch 1903, latest loss 0.8028165102005005\n",
      "Finished epoch 1904, latest loss 0.8020648956298828\n",
      "Finished epoch 1905, latest loss 0.8101986050605774\n",
      "Finished epoch 1906, latest loss 0.8010875582695007\n",
      "Finished epoch 1907, latest loss 0.8022744655609131\n",
      "Finished epoch 1908, latest loss 0.8012561202049255\n",
      "Finished epoch 1909, latest loss 0.8085870146751404\n",
      "Finished epoch 1910, latest loss 0.8043215870857239\n",
      "Finished epoch 1911, latest loss 0.8023354411125183\n",
      "Finished epoch 1912, latest loss 0.8010889291763306\n",
      "Finished epoch 1913, latest loss 0.8043116927146912\n",
      "Finished epoch 1914, latest loss 0.8076234459877014\n",
      "Finished epoch 1915, latest loss 0.8035957217216492\n",
      "Finished epoch 1916, latest loss 0.8048028945922852\n",
      "Finished epoch 1917, latest loss 0.8014646768569946\n",
      "Finished epoch 1918, latest loss 0.8024869561195374\n",
      "Finished epoch 1919, latest loss 0.8031874299049377\n",
      "Finished epoch 1920, latest loss 0.8010873794555664\n",
      "Finished epoch 1921, latest loss 0.8015345931053162\n",
      "Finished epoch 1922, latest loss 0.8073258996009827\n",
      "Finished epoch 1923, latest loss 0.8000759482383728\n",
      "Finished epoch 1924, latest loss 0.8029975891113281\n",
      "Finished epoch 1925, latest loss 0.8056681752204895\n",
      "Finished epoch 1926, latest loss 0.8019900321960449\n",
      "Finished epoch 1927, latest loss 0.8050994277000427\n",
      "Finished epoch 1928, latest loss 0.8051279187202454\n",
      "Finished epoch 1929, latest loss 0.802401602268219\n",
      "Finished epoch 1930, latest loss 0.8024487495422363\n",
      "Finished epoch 1931, latest loss 0.8035587072372437\n",
      "Finished epoch 1932, latest loss 0.8026370406150818\n",
      "Finished epoch 1933, latest loss 0.806865930557251\n",
      "Finished epoch 1934, latest loss 0.8063803911209106\n",
      "Finished epoch 1935, latest loss 0.803979754447937\n",
      "Finished epoch 1936, latest loss 0.8010860085487366\n",
      "Finished epoch 1937, latest loss 0.8012216687202454\n",
      "Finished epoch 1938, latest loss 0.8042571544647217\n",
      "Finished epoch 1939, latest loss 0.8027675747871399\n",
      "Finished epoch 1940, latest loss 0.8042094707489014\n",
      "Finished epoch 1941, latest loss 0.8024997711181641\n",
      "Finished epoch 1942, latest loss 0.8016253709793091\n",
      "Finished epoch 1943, latest loss 0.8010876178741455\n",
      "Finished epoch 1944, latest loss 0.8000759482383728\n",
      "Finished epoch 1945, latest loss 0.801770806312561\n",
      "Finished epoch 1946, latest loss 0.8064690828323364\n",
      "Finished epoch 1947, latest loss 0.806708812713623\n",
      "Finished epoch 1948, latest loss 0.805190920829773\n",
      "Finished epoch 1949, latest loss 0.8147032856941223\n",
      "Finished epoch 1950, latest loss 0.8064042329788208\n",
      "Finished epoch 1951, latest loss 0.805625855922699\n",
      "Finished epoch 1952, latest loss 0.8081271052360535\n",
      "Finished epoch 1953, latest loss 0.8040855526924133\n",
      "Finished epoch 1954, latest loss 0.8010972142219543\n",
      "Finished epoch 1955, latest loss 0.8041215538978577\n",
      "Finished epoch 1956, latest loss 0.8066301345825195\n",
      "Finished epoch 1957, latest loss 0.8046643733978271\n",
      "Finished epoch 1958, latest loss 0.8021477460861206\n",
      "Finished epoch 1959, latest loss 0.8096717596054077\n",
      "Finished epoch 1960, latest loss 0.8016252517700195\n",
      "Finished epoch 1961, latest loss 0.8027343153953552\n",
      "Finished epoch 1962, latest loss 0.8016252517700195\n",
      "Finished epoch 1963, latest loss 0.8026373982429504\n",
      "Finished epoch 1964, latest loss 0.803543746471405\n",
      "Finished epoch 1965, latest loss 0.8041861653327942\n",
      "Finished epoch 1966, latest loss 0.8036412596702576\n",
      "Finished epoch 1967, latest loss 0.8020898103713989\n",
      "Finished epoch 1968, latest loss 0.802100419998169\n",
      "Finished epoch 1969, latest loss 0.8057268261909485\n",
      "Finished epoch 1970, latest loss 0.8051539063453674\n",
      "Finished epoch 1971, latest loss 0.8010963201522827\n",
      "Finished epoch 1972, latest loss 0.8010902404785156\n",
      "Finished epoch 1973, latest loss 0.8027052283287048\n",
      "Finished epoch 1974, latest loss 0.8030337691307068\n",
      "Finished epoch 1975, latest loss 0.8047053813934326\n",
      "Finished epoch 1976, latest loss 0.8022413849830627\n",
      "Finished epoch 1977, latest loss 0.8044031858444214\n",
      "Finished epoch 1978, latest loss 0.8054947257041931\n",
      "Finished epoch 1979, latest loss 0.8020750284194946\n",
      "Finished epoch 1980, latest loss 0.8046169877052307\n",
      "Finished epoch 1981, latest loss 0.8041830062866211\n",
      "Finished epoch 1982, latest loss 0.8051690459251404\n",
      "Finished epoch 1983, latest loss 0.8049164414405823\n",
      "Finished epoch 1984, latest loss 0.8054830431938171\n",
      "Finished epoch 1985, latest loss 0.8089338541030884\n",
      "Finished epoch 1986, latest loss 0.806142270565033\n",
      "Finished epoch 1987, latest loss 0.8049227595329285\n",
      "Finished epoch 1988, latest loss 0.8041102290153503\n",
      "Finished epoch 1989, latest loss 0.8021442890167236\n",
      "Finished epoch 1990, latest loss 0.8074817657470703\n",
      "Finished epoch 1991, latest loss 0.8014927506446838\n",
      "Finished epoch 1992, latest loss 0.800076425075531\n",
      "Finished epoch 1993, latest loss 0.8016800284385681\n",
      "Finished epoch 1994, latest loss 0.8030075430870056\n",
      "Finished epoch 1995, latest loss 0.8020349144935608\n",
      "Finished epoch 1996, latest loss 0.8050516247749329\n",
      "Finished epoch 1997, latest loss 0.8041542172431946\n",
      "Finished epoch 1998, latest loss 0.802602231502533\n",
      "Finished epoch 1999, latest loss 0.8018674850463867\n",
      "Accuracy 0.9194464683532715\n",
      "Confusion Matrix for negative predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive               36863               12094\n",
      "Actual Negative                3180              137476\n",
      "Positive predictive power:\n",
      "75.3%\n",
      "Positive predictive accuracy:\n",
      "92.06%\n",
      "Using device: cuda\n",
      "PimaClassifier(\n",
      "  (hidden1): Linear(in_features=1616, out_features=64, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (hidden2): Linear(in_features=64, out_features=12, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (hidden3): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (act3): ReLU()\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (act_output): Sigmoid()\n",
      ")\n",
      "Finished epoch 0, latest loss 0.7237534523010254\n",
      "Finished epoch 1, latest loss 0.7236954569816589\n",
      "Finished epoch 2, latest loss 0.7236855626106262\n",
      "Finished epoch 3, latest loss 0.7236822247505188\n",
      "Finished epoch 4, latest loss 0.7236807942390442\n",
      "Finished epoch 5, latest loss 0.7236807346343994\n",
      "Finished epoch 6, latest loss 0.7236810326576233\n",
      "Finished epoch 7, latest loss 0.7236945629119873\n",
      "Finished epoch 8, latest loss 0.7239779233932495\n",
      "Finished epoch 9, latest loss 0.7237119078636169\n",
      "Finished epoch 10, latest loss 0.7236164212226868\n",
      "Finished epoch 11, latest loss 0.7230170965194702\n",
      "Finished epoch 12, latest loss 0.7236776351928711\n",
      "Finished epoch 13, latest loss 0.7236860990524292\n",
      "Finished epoch 14, latest loss 0.7236799597740173\n",
      "Finished epoch 15, latest loss 0.7227927446365356\n",
      "Finished epoch 16, latest loss 0.7232427597045898\n",
      "Finished epoch 17, latest loss 0.7227501273155212\n",
      "Finished epoch 18, latest loss 0.7227481603622437\n",
      "Finished epoch 19, latest loss 0.7227855324745178\n",
      "Finished epoch 20, latest loss 0.7227532863616943\n",
      "Finished epoch 21, latest loss 0.7227646708488464\n",
      "Finished epoch 22, latest loss 0.7227811813354492\n",
      "Finished epoch 23, latest loss 0.7232762575149536\n",
      "Finished epoch 24, latest loss 0.722751259803772\n",
      "Finished epoch 25, latest loss 0.7225766777992249\n",
      "Finished epoch 26, latest loss 0.7219407558441162\n",
      "Finished epoch 27, latest loss 0.7218188047409058\n",
      "Finished epoch 28, latest loss 0.7220131754875183\n",
      "Finished epoch 29, latest loss 0.7218193411827087\n",
      "Finished epoch 30, latest loss 0.7218226194381714\n",
      "Finished epoch 31, latest loss 0.7219856381416321\n",
      "Finished epoch 32, latest loss 0.7218188643455505\n",
      "Finished epoch 33, latest loss 0.7218173742294312\n",
      "Finished epoch 34, latest loss 0.721819281578064\n",
      "Finished epoch 35, latest loss 0.7218300700187683\n",
      "Finished epoch 36, latest loss 0.7234581708908081\n",
      "Finished epoch 37, latest loss 0.7218203544616699\n",
      "Finished epoch 38, latest loss 0.7218047380447388\n",
      "Finished epoch 39, latest loss 0.7228891849517822\n",
      "Finished epoch 40, latest loss 0.722646951675415\n",
      "Finished epoch 41, latest loss 0.7231149077415466\n",
      "Finished epoch 42, latest loss 0.7230750322341919\n",
      "Finished epoch 43, latest loss 0.7231630682945251\n",
      "Finished epoch 44, latest loss 0.7230556607246399\n",
      "Finished epoch 45, latest loss 0.7229496240615845\n",
      "Finished epoch 46, latest loss 0.7229152321815491\n",
      "Finished epoch 47, latest loss 0.7217273116111755\n",
      "Finished epoch 48, latest loss 0.7219712138175964\n",
      "Finished epoch 49, latest loss 0.7212446331977844\n",
      "Finished epoch 50, latest loss 0.7213925123214722\n",
      "Finished epoch 51, latest loss 0.7208875417709351\n",
      "Finished epoch 52, latest loss 0.7195051312446594\n",
      "Finished epoch 53, latest loss 0.7205231189727783\n",
      "Finished epoch 54, latest loss 0.7196255326271057\n",
      "Finished epoch 55, latest loss 0.7199221253395081\n",
      "Finished epoch 56, latest loss 0.7181188464164734\n",
      "Finished epoch 57, latest loss 0.7191010117530823\n",
      "Finished epoch 58, latest loss 0.7181087732315063\n",
      "Finished epoch 59, latest loss 0.7182211875915527\n",
      "Finished epoch 60, latest loss 0.718278169631958\n",
      "Finished epoch 61, latest loss 0.7181414365768433\n",
      "Finished epoch 62, latest loss 0.7212144136428833\n",
      "Finished epoch 63, latest loss 0.7181032299995422\n",
      "Finished epoch 64, latest loss 0.7199092507362366\n",
      "Finished epoch 65, latest loss 0.7181379199028015\n",
      "Finished epoch 66, latest loss 0.7187601923942566\n",
      "Finished epoch 67, latest loss 0.7181020379066467\n",
      "Finished epoch 68, latest loss 0.7190483212471008\n",
      "Finished epoch 69, latest loss 0.7182669043540955\n",
      "Finished epoch 70, latest loss 0.7181081771850586\n",
      "Finished epoch 71, latest loss 0.718315064907074\n",
      "Finished epoch 72, latest loss 0.718108057975769\n",
      "Finished epoch 73, latest loss 0.7181001305580139\n",
      "Finished epoch 74, latest loss 0.7181147933006287\n",
      "Finished epoch 75, latest loss 0.7182807326316833\n",
      "Finished epoch 76, latest loss 0.7183483242988586\n",
      "Finished epoch 77, latest loss 0.7181110382080078\n",
      "Finished epoch 78, latest loss 0.718510091304779\n",
      "Finished epoch 79, latest loss 0.7181000709533691\n",
      "Finished epoch 80, latest loss 0.718100905418396\n",
      "Finished epoch 81, latest loss 0.7181020975112915\n",
      "Finished epoch 82, latest loss 0.7181046009063721\n",
      "Finished epoch 83, latest loss 0.7181016206741333\n",
      "Finished epoch 84, latest loss 0.718103289604187\n",
      "Finished epoch 85, latest loss 0.7181008458137512\n",
      "Finished epoch 86, latest loss 0.718101441860199\n",
      "Finished epoch 87, latest loss 0.7181005477905273\n",
      "Finished epoch 88, latest loss 0.7181005477905273\n",
      "Finished epoch 89, latest loss 0.7181020379066467\n",
      "Finished epoch 90, latest loss 0.7181004285812378\n",
      "Finished epoch 91, latest loss 0.7181006073951721\n",
      "Finished epoch 92, latest loss 0.7181005477905273\n",
      "Finished epoch 93, latest loss 0.7181010246276855\n",
      "Finished epoch 94, latest loss 0.7181214690208435\n",
      "Finished epoch 95, latest loss 0.7181211113929749\n",
      "Finished epoch 96, latest loss 0.7182609438896179\n",
      "Finished epoch 97, latest loss 0.718112587928772\n",
      "Finished epoch 98, latest loss 0.7180999517440796\n",
      "Finished epoch 99, latest loss 0.7181000113487244\n",
      "Finished epoch 100, latest loss 0.7181001305580139\n",
      "Finished epoch 101, latest loss 0.7174490690231323\n",
      "Finished epoch 102, latest loss 0.7171705365180969\n",
      "Finished epoch 103, latest loss 0.7171704173088074\n",
      "Finished epoch 104, latest loss 0.718099057674408\n",
      "Finished epoch 105, latest loss 0.7171772718429565\n",
      "Finished epoch 106, latest loss 0.7180188894271851\n",
      "Finished epoch 107, latest loss 0.7171784043312073\n",
      "Finished epoch 108, latest loss 0.717188835144043\n",
      "Finished epoch 109, latest loss 0.7181000113487244\n",
      "Finished epoch 110, latest loss 0.7171708941459656\n",
      "Finished epoch 111, latest loss 0.7180863618850708\n",
      "Finished epoch 112, latest loss 0.7171770334243774\n",
      "Finished epoch 113, latest loss 0.7173757553100586\n",
      "Finished epoch 114, latest loss 0.7171717286109924\n",
      "Finished epoch 115, latest loss 0.7171715497970581\n",
      "Finished epoch 116, latest loss 0.7172098159790039\n",
      "Finished epoch 117, latest loss 0.718100368976593\n",
      "Finished epoch 118, latest loss 0.7172094583511353\n",
      "Finished epoch 119, latest loss 0.7180999517440796\n",
      "Finished epoch 120, latest loss 0.7172154784202576\n",
      "Finished epoch 121, latest loss 0.7180420756340027\n",
      "Finished epoch 122, latest loss 0.7171714305877686\n",
      "Finished epoch 123, latest loss 0.7171709537506104\n",
      "Finished epoch 124, latest loss 0.7173944115638733\n",
      "Finished epoch 125, latest loss 0.7171708345413208\n",
      "Finished epoch 126, latest loss 0.7171986103057861\n",
      "Finished epoch 127, latest loss 0.717170774936676\n",
      "Finished epoch 128, latest loss 0.7171893119812012\n",
      "Finished epoch 129, latest loss 0.7171704769134521\n",
      "Finished epoch 130, latest loss 0.7171703577041626\n",
      "Finished epoch 131, latest loss 0.7171703577041626\n",
      "Finished epoch 132, latest loss 0.7171754240989685\n",
      "Finished epoch 133, latest loss 0.7171704769134521\n",
      "Finished epoch 134, latest loss 0.7171705365180969\n",
      "Finished epoch 135, latest loss 0.7171708345413208\n",
      "Finished epoch 136, latest loss 0.717157781124115\n",
      "Finished epoch 137, latest loss 0.7162739038467407\n",
      "Finished epoch 138, latest loss 0.7170752882957458\n",
      "Finished epoch 139, latest loss 0.7162415981292725\n",
      "Finished epoch 140, latest loss 0.7162410020828247\n",
      "Finished epoch 141, latest loss 0.7162414193153381\n",
      "Finished epoch 142, latest loss 0.7162817716598511\n",
      "Finished epoch 143, latest loss 0.7162410020828247\n",
      "Finished epoch 144, latest loss 0.7162410020828247\n",
      "Finished epoch 145, latest loss 0.7162410020828247\n",
      "Finished epoch 146, latest loss 0.7162410020828247\n",
      "Finished epoch 147, latest loss 0.7180511951446533\n",
      "Finished epoch 148, latest loss 0.7162408232688904\n",
      "Finished epoch 149, latest loss 0.7153116464614868\n",
      "Finished epoch 150, latest loss 0.715313196182251\n",
      "Finished epoch 151, latest loss 0.7162420153617859\n",
      "Finished epoch 152, latest loss 0.7163835167884827\n",
      "Finished epoch 153, latest loss 0.7162411212921143\n",
      "Finished epoch 154, latest loss 0.7154960036277771\n",
      "Finished epoch 155, latest loss 0.7163228392601013\n",
      "Finished epoch 156, latest loss 0.7153210043907166\n",
      "Finished epoch 157, latest loss 0.7153119444847107\n",
      "Finished epoch 158, latest loss 0.716238796710968\n",
      "Finished epoch 159, latest loss 0.7153114080429077\n",
      "Finished epoch 160, latest loss 0.7158209681510925\n",
      "Finished epoch 161, latest loss 0.715316891670227\n",
      "Finished epoch 162, latest loss 0.7153249382972717\n",
      "Finished epoch 163, latest loss 0.7153111696243286\n",
      "Finished epoch 164, latest loss 0.7153119444847107\n",
      "Finished epoch 165, latest loss 0.7153111696243286\n",
      "Finished epoch 166, latest loss 0.7153112292289734\n",
      "Finished epoch 167, latest loss 0.7153111696243286\n",
      "Finished epoch 168, latest loss 0.7158628106117249\n",
      "Finished epoch 169, latest loss 0.7153112292289734\n",
      "Finished epoch 170, latest loss 0.7153111696243286\n",
      "Finished epoch 171, latest loss 0.7153111696243286\n",
      "Finished epoch 172, latest loss 0.7161804437637329\n",
      "Finished epoch 173, latest loss 0.7153113484382629\n",
      "Finished epoch 174, latest loss 0.7163147926330566\n",
      "Finished epoch 175, latest loss 0.7153114080429077\n",
      "Finished epoch 176, latest loss 0.7153124213218689\n",
      "Finished epoch 177, latest loss 0.7153111696243286\n",
      "Finished epoch 178, latest loss 0.7153388857841492\n",
      "Finished epoch 179, latest loss 0.7153143882751465\n",
      "Finished epoch 180, latest loss 0.7153112292289734\n",
      "Finished epoch 181, latest loss 0.7153126001358032\n",
      "Finished epoch 182, latest loss 0.7153334617614746\n",
      "Finished epoch 183, latest loss 0.7153113484382629\n",
      "Finished epoch 184, latest loss 0.7162046432495117\n",
      "Finished epoch 185, latest loss 0.7173488736152649\n",
      "Finished epoch 186, latest loss 0.7153112292289734\n",
      "Finished epoch 187, latest loss 0.7153111696243286\n",
      "Finished epoch 188, latest loss 0.7153112888336182\n",
      "Finished epoch 189, latest loss 0.7153112292289734\n",
      "Finished epoch 190, latest loss 0.7153112292289734\n",
      "Finished epoch 191, latest loss 0.7153113484382629\n",
      "Finished epoch 192, latest loss 0.7162408232688904\n",
      "Finished epoch 193, latest loss 0.7153732776641846\n",
      "Finished epoch 194, latest loss 0.7153112292289734\n",
      "Finished epoch 195, latest loss 0.7153112292289734\n",
      "Finished epoch 196, latest loss 0.7153112292289734\n",
      "Finished epoch 197, latest loss 0.7154212594032288\n",
      "Finished epoch 198, latest loss 0.715313196182251\n",
      "Finished epoch 199, latest loss 0.7153113484382629\n",
      "Finished epoch 200, latest loss 0.7153115272521973\n",
      "Finished epoch 201, latest loss 0.7153112292289734\n",
      "Finished epoch 202, latest loss 0.7163195610046387\n",
      "Finished epoch 203, latest loss 0.715315580368042\n",
      "Finished epoch 204, latest loss 0.7143824100494385\n",
      "Finished epoch 205, latest loss 0.7162408232688904\n",
      "Finished epoch 206, latest loss 0.7144650220870972\n",
      "Finished epoch 207, latest loss 0.7153117656707764\n",
      "Finished epoch 208, latest loss 0.7143822312355042\n",
      "Finished epoch 209, latest loss 0.7143819332122803\n",
      "Finished epoch 210, latest loss 0.714532196521759\n",
      "Finished epoch 211, latest loss 0.7143818736076355\n",
      "Finished epoch 212, latest loss 0.7144821286201477\n",
      "Finished epoch 213, latest loss 0.7153932452201843\n",
      "Finished epoch 214, latest loss 0.7160561680793762\n",
      "Finished epoch 215, latest loss 0.7143816351890564\n",
      "Finished epoch 216, latest loss 0.7151349186897278\n",
      "Finished epoch 217, latest loss 0.7153146862983704\n",
      "Finished epoch 218, latest loss 0.7144328355789185\n",
      "Finished epoch 219, latest loss 0.7143822908401489\n",
      "Finished epoch 220, latest loss 0.714381754398346\n",
      "Finished epoch 221, latest loss 0.7143816351890564\n",
      "Finished epoch 222, latest loss 0.7143816351890564\n",
      "Finished epoch 223, latest loss 0.7143821716308594\n",
      "Finished epoch 224, latest loss 0.7143816351890564\n",
      "Finished epoch 225, latest loss 0.7143816351890564\n",
      "Finished epoch 226, latest loss 0.7153111100196838\n",
      "Finished epoch 227, latest loss 0.7143816351890564\n",
      "Finished epoch 228, latest loss 0.714381754398346\n",
      "Finished epoch 229, latest loss 0.7143816351890564\n",
      "Finished epoch 230, latest loss 0.7145768404006958\n",
      "Finished epoch 231, latest loss 0.714381754398346\n",
      "Finished epoch 232, latest loss 0.7143816351890564\n",
      "Finished epoch 233, latest loss 0.7143836617469788\n",
      "Finished epoch 234, latest loss 0.714381754398346\n",
      "Finished epoch 235, latest loss 0.7143816351890564\n",
      "Finished epoch 236, latest loss 0.7137323617935181\n",
      "Finished epoch 237, latest loss 0.7134595513343811\n",
      "Finished epoch 238, latest loss 0.7134521007537842\n",
      "Finished epoch 239, latest loss 0.7143740653991699\n",
      "Finished epoch 240, latest loss 0.7143816351890564\n",
      "Finished epoch 241, latest loss 0.7143783569335938\n",
      "Finished epoch 242, latest loss 0.7142487168312073\n",
      "Finished epoch 243, latest loss 0.7143816351890564\n",
      "Finished epoch 244, latest loss 0.7143816351890564\n",
      "Finished epoch 245, latest loss 0.7143819332122803\n",
      "Finished epoch 246, latest loss 0.7144466638565063\n",
      "Finished epoch 247, latest loss 0.7143774032592773\n",
      "Finished epoch 248, latest loss 0.7153913974761963\n",
      "Finished epoch 249, latest loss 0.7143816947937012\n",
      "Finished epoch 250, latest loss 0.7143814563751221\n",
      "Finished epoch 251, latest loss 0.7143816351890564\n",
      "Finished epoch 252, latest loss 0.7143816351890564\n",
      "Finished epoch 253, latest loss 0.7143816351890564\n",
      "Finished epoch 254, latest loss 0.7143846750259399\n",
      "Finished epoch 255, latest loss 0.7143816351890564\n",
      "Finished epoch 256, latest loss 0.714381754398346\n",
      "Finished epoch 257, latest loss 0.7134672999382019\n",
      "Finished epoch 258, latest loss 0.7143816351890564\n",
      "Finished epoch 259, latest loss 0.7143816351890564\n",
      "Finished epoch 260, latest loss 0.7143888473510742\n",
      "Finished epoch 261, latest loss 0.7143816351890564\n",
      "Finished epoch 262, latest loss 0.7153066396713257\n",
      "Finished epoch 263, latest loss 0.7143816351890564\n",
      "Finished epoch 264, latest loss 0.7145127654075623\n",
      "Finished epoch 265, latest loss 0.7143816351890564\n",
      "Finished epoch 266, latest loss 0.7143816351890564\n",
      "Finished epoch 267, latest loss 0.7143816351890564\n",
      "Finished epoch 268, latest loss 0.7153112292289734\n",
      "Finished epoch 269, latest loss 0.7143816351890564\n",
      "Finished epoch 270, latest loss 0.7153112292289734\n",
      "Finished epoch 271, latest loss 0.7144085168838501\n",
      "Finished epoch 272, latest loss 0.7152552008628845\n",
      "Finished epoch 273, latest loss 0.7152776718139648\n",
      "Finished epoch 274, latest loss 0.7144261598587036\n",
      "Finished epoch 275, latest loss 0.7143828272819519\n",
      "Finished epoch 276, latest loss 0.7143816351890564\n",
      "Finished epoch 277, latest loss 0.7143816351890564\n",
      "Finished epoch 278, latest loss 0.7143816351890564\n",
      "Finished epoch 279, latest loss 0.7153115272521973\n",
      "Finished epoch 280, latest loss 0.7143816351890564\n",
      "Finished epoch 281, latest loss 0.7153111100196838\n",
      "Finished epoch 282, latest loss 0.7162408232688904\n",
      "Finished epoch 283, latest loss 0.7170817255973816\n",
      "Finished epoch 284, latest loss 0.7143816351890564\n",
      "Finished epoch 285, latest loss 0.7153112292289734\n",
      "Finished epoch 286, latest loss 0.7143816351890564\n",
      "Finished epoch 287, latest loss 0.7143816351890564\n",
      "Finished epoch 288, latest loss 0.7143816351890564\n",
      "Finished epoch 289, latest loss 0.7143816351890564\n",
      "Finished epoch 290, latest loss 0.7153104543685913\n",
      "Finished epoch 291, latest loss 0.7143816351890564\n",
      "Finished epoch 292, latest loss 0.7153968811035156\n",
      "Finished epoch 293, latest loss 0.71539306640625\n",
      "Finished epoch 294, latest loss 0.7143816351890564\n",
      "Finished epoch 295, latest loss 0.7146007418632507\n",
      "Finished epoch 296, latest loss 0.7153868675231934\n",
      "Finished epoch 297, latest loss 0.7143816351890564\n",
      "Finished epoch 298, latest loss 0.7143819332122803\n",
      "Finished epoch 299, latest loss 0.7143816351890564\n",
      "Finished epoch 300, latest loss 0.7157024145126343\n",
      "Finished epoch 301, latest loss 0.7143816351890564\n",
      "Finished epoch 302, latest loss 0.7173169255256653\n",
      "Finished epoch 303, latest loss 0.7143824100494385\n",
      "Finished epoch 304, latest loss 0.7144585847854614\n",
      "Finished epoch 305, latest loss 0.7143855690956116\n",
      "Finished epoch 306, latest loss 0.7143824696540833\n",
      "Finished epoch 307, latest loss 0.7151457667350769\n",
      "Finished epoch 308, latest loss 0.7143816351890564\n",
      "Finished epoch 309, latest loss 0.7143816351890564\n",
      "Finished epoch 310, latest loss 0.7143816947937012\n",
      "Finished epoch 311, latest loss 0.7148475646972656\n",
      "Finished epoch 312, latest loss 0.7143816351890564\n",
      "Finished epoch 313, latest loss 0.7143840789794922\n",
      "Finished epoch 314, latest loss 0.714381754398346\n",
      "Finished epoch 315, latest loss 0.7153104543685913\n",
      "Finished epoch 316, latest loss 0.7143819332122803\n",
      "Finished epoch 317, latest loss 0.7143816947937012\n",
      "Finished epoch 318, latest loss 0.7153112292289734\n",
      "Finished epoch 319, latest loss 0.7143816351890564\n",
      "Finished epoch 320, latest loss 0.7143816351890564\n",
      "Finished epoch 321, latest loss 0.714382529258728\n",
      "Finished epoch 322, latest loss 0.715393602848053\n",
      "Finished epoch 323, latest loss 0.7153953909873962\n",
      "Finished epoch 324, latest loss 0.7143819332122803\n",
      "Finished epoch 325, latest loss 0.7143839597702026\n",
      "Finished epoch 326, latest loss 0.7153929471969604\n",
      "Finished epoch 327, latest loss 0.7153115272521973\n",
      "Finished epoch 328, latest loss 0.7153112292289734\n",
      "Finished epoch 329, latest loss 0.7153934836387634\n",
      "Finished epoch 330, latest loss 0.715313196182251\n",
      "Finished epoch 331, latest loss 0.7144160866737366\n",
      "Finished epoch 332, latest loss 0.715307891368866\n",
      "Finished epoch 333, latest loss 0.714388906955719\n",
      "Finished epoch 334, latest loss 0.7143820524215698\n",
      "Finished epoch 335, latest loss 0.7153111100196838\n",
      "Finished epoch 336, latest loss 0.7143816351890564\n",
      "Finished epoch 337, latest loss 0.7153127193450928\n",
      "Finished epoch 338, latest loss 0.7143831849098206\n",
      "Finished epoch 339, latest loss 0.7143816351890564\n",
      "Finished epoch 340, latest loss 0.7143898010253906\n",
      "Finished epoch 341, latest loss 0.7143836617469788\n",
      "Finished epoch 342, latest loss 0.714991569519043\n",
      "Finished epoch 343, latest loss 0.7143816351890564\n",
      "Finished epoch 344, latest loss 0.7143816351890564\n",
      "Finished epoch 345, latest loss 0.7143816351890564\n",
      "Finished epoch 346, latest loss 0.7143816351890564\n",
      "Finished epoch 347, latest loss 0.7153961658477783\n",
      "Finished epoch 348, latest loss 0.7143816351890564\n",
      "Finished epoch 349, latest loss 0.7143816351890564\n",
      "Finished epoch 350, latest loss 0.7143824696540833\n",
      "Finished epoch 351, latest loss 0.7143813371658325\n",
      "Finished epoch 352, latest loss 0.7153932452201843\n",
      "Finished epoch 353, latest loss 0.7153932452201843\n",
      "Finished epoch 354, latest loss 0.7153945565223694\n",
      "Finished epoch 355, latest loss 0.7153675556182861\n",
      "Finished epoch 356, latest loss 0.7143816351890564\n",
      "Finished epoch 357, latest loss 0.7143816351890564\n",
      "Finished epoch 358, latest loss 0.7153111696243286\n",
      "Finished epoch 359, latest loss 0.7153932452201843\n",
      "Finished epoch 360, latest loss 0.7163228392601013\n",
      "Finished epoch 361, latest loss 0.7153932452201843\n",
      "Finished epoch 362, latest loss 0.715394139289856\n",
      "Finished epoch 363, latest loss 0.7143816351890564\n",
      "Finished epoch 364, latest loss 0.7143967747688293\n",
      "Finished epoch 365, latest loss 0.7164047360420227\n",
      "Finished epoch 366, latest loss 0.7153932452201843\n",
      "Finished epoch 367, latest loss 0.7143821716308594\n",
      "Finished epoch 368, latest loss 0.71539306640625\n",
      "Finished epoch 369, latest loss 0.7143816351890564\n",
      "Finished epoch 370, latest loss 0.7162126898765564\n",
      "Finished epoch 371, latest loss 0.7143843770027161\n",
      "Finished epoch 372, latest loss 0.7143816351890564\n",
      "Finished epoch 373, latest loss 0.7143816351890564\n",
      "Finished epoch 374, latest loss 0.7159196138381958\n",
      "Finished epoch 375, latest loss 0.7143816351890564\n",
      "Finished epoch 376, latest loss 0.7163950204849243\n",
      "Finished epoch 377, latest loss 0.7143816351890564\n",
      "Finished epoch 378, latest loss 0.7152577638626099\n",
      "Finished epoch 379, latest loss 0.7143816351890564\n",
      "Finished epoch 380, latest loss 0.7164047956466675\n",
      "Finished epoch 381, latest loss 0.7143816351890564\n",
      "Finished epoch 382, latest loss 0.7143816351890564\n",
      "Finished epoch 383, latest loss 0.7164348363876343\n",
      "Finished epoch 384, latest loss 0.7143816351890564\n",
      "Finished epoch 385, latest loss 0.7143816351890564\n",
      "Finished epoch 386, latest loss 0.7153935432434082\n",
      "Finished epoch 387, latest loss 0.7143816351890564\n",
      "Finished epoch 388, latest loss 0.7152758240699768\n",
      "Finished epoch 389, latest loss 0.7143816351890564\n",
      "Finished epoch 390, latest loss 0.7143816351890564\n",
      "Finished epoch 391, latest loss 0.7143816351890564\n",
      "Finished epoch 392, latest loss 0.7143834829330444\n",
      "Finished epoch 393, latest loss 0.7143852710723877\n",
      "Finished epoch 394, latest loss 0.7143816351890564\n",
      "Finished epoch 395, latest loss 0.7153112292289734\n",
      "Finished epoch 396, latest loss 0.7143816351890564\n",
      "Finished epoch 397, latest loss 0.714381754398346\n",
      "Finished epoch 398, latest loss 0.7143816351890564\n",
      "Finished epoch 399, latest loss 0.7153142094612122\n",
      "Finished epoch 400, latest loss 0.7143816351890564\n",
      "Finished epoch 401, latest loss 0.7153932452201843\n",
      "Finished epoch 402, latest loss 0.7153118252754211\n",
      "Finished epoch 403, latest loss 0.717170238494873\n",
      "Finished epoch 404, latest loss 0.7153101563453674\n",
      "Finished epoch 405, latest loss 0.7143842577934265\n",
      "Finished epoch 406, latest loss 0.7153111100196838\n",
      "Finished epoch 407, latest loss 0.7153111696243286\n",
      "Finished epoch 408, latest loss 0.7143816351890564\n",
      "Finished epoch 409, latest loss 0.7163227796554565\n",
      "Finished epoch 410, latest loss 0.7153111696243286\n",
      "Finished epoch 411, latest loss 0.7153112292289734\n",
      "Finished epoch 412, latest loss 0.7143816351890564\n",
      "Finished epoch 413, latest loss 0.7143816351890564\n",
      "Finished epoch 414, latest loss 0.7143816351890564\n",
      "Finished epoch 415, latest loss 0.7143816351890564\n",
      "Finished epoch 416, latest loss 0.7163211703300476\n",
      "Finished epoch 417, latest loss 0.7153988480567932\n",
      "Finished epoch 418, latest loss 0.7160248160362244\n",
      "Finished epoch 419, latest loss 0.714445173740387\n",
      "Finished epoch 420, latest loss 0.7143816351890564\n",
      "Finished epoch 421, latest loss 0.7143816351890564\n",
      "Finished epoch 422, latest loss 0.7143816351890564\n",
      "Finished epoch 423, latest loss 0.7143816351890564\n",
      "Finished epoch 424, latest loss 0.7143816351890564\n",
      "Finished epoch 425, latest loss 0.7164047956466675\n",
      "Finished epoch 426, latest loss 0.7143816351890564\n",
      "Finished epoch 427, latest loss 0.7143816351890564\n",
      "Finished epoch 428, latest loss 0.7149657011032104\n",
      "Finished epoch 429, latest loss 0.7144028544425964\n",
      "Finished epoch 430, latest loss 0.7143816351890564\n",
      "Finished epoch 431, latest loss 0.7143816351890564\n",
      "Finished epoch 432, latest loss 0.7144056558609009\n",
      "Finished epoch 433, latest loss 0.714381754398346\n",
      "Finished epoch 434, latest loss 0.7144542932510376\n",
      "Finished epoch 435, latest loss 0.7143816351890564\n",
      "Finished epoch 436, latest loss 0.7143816351890564\n",
      "Finished epoch 437, latest loss 0.7143816351890564\n",
      "Finished epoch 438, latest loss 0.7143816351890564\n",
      "Finished epoch 439, latest loss 0.7143816351890564\n",
      "Finished epoch 440, latest loss 0.7143822312355042\n",
      "Finished epoch 441, latest loss 0.7153112292289734\n",
      "Finished epoch 442, latest loss 0.7143816351890564\n",
      "Finished epoch 443, latest loss 0.7143816351890564\n",
      "Finished epoch 444, latest loss 0.7147390246391296\n",
      "Finished epoch 445, latest loss 0.7143816351890564\n",
      "Finished epoch 446, latest loss 0.7143819332122803\n",
      "Finished epoch 447, latest loss 0.7143816351890564\n",
      "Finished epoch 448, latest loss 0.7143816351890564\n",
      "Finished epoch 449, latest loss 0.7143816351890564\n",
      "Finished epoch 450, latest loss 0.7143816351890564\n",
      "Finished epoch 451, latest loss 0.7153109312057495\n",
      "Finished epoch 452, latest loss 0.7153932452201843\n",
      "Finished epoch 453, latest loss 0.7153932452201843\n",
      "Finished epoch 454, latest loss 0.71539306640625\n",
      "Finished epoch 455, latest loss 0.7143886685371399\n",
      "Finished epoch 456, latest loss 0.7143816351890564\n",
      "Finished epoch 457, latest loss 0.7153931856155396\n",
      "Finished epoch 458, latest loss 0.7143816351890564\n",
      "Finished epoch 459, latest loss 0.714381754398346\n",
      "Finished epoch 460, latest loss 0.7143816351890564\n",
      "Finished epoch 461, latest loss 0.7153925895690918\n",
      "Finished epoch 462, latest loss 0.7143816351890564\n",
      "Finished epoch 463, latest loss 0.7143816351890564\n",
      "Finished epoch 464, latest loss 0.7143816351890564\n",
      "Finished epoch 465, latest loss 0.7143816351890564\n",
      "Finished epoch 466, latest loss 0.7143816351890564\n",
      "Finished epoch 467, latest loss 0.7143816351890564\n",
      "Finished epoch 468, latest loss 0.7143816351890564\n",
      "Finished epoch 469, latest loss 0.7143815755844116\n",
      "Finished epoch 470, latest loss 0.7143816351890564\n",
      "Finished epoch 471, latest loss 0.7143816351890564\n",
      "Finished epoch 472, latest loss 0.7143816351890564\n",
      "Finished epoch 473, latest loss 0.7153593897819519\n",
      "Finished epoch 474, latest loss 0.713455080986023\n",
      "Finished epoch 475, latest loss 0.7143818140029907\n",
      "Finished epoch 476, latest loss 0.7143851518630981\n",
      "Finished epoch 477, latest loss 0.7134523987770081\n",
      "Finished epoch 478, latest loss 0.7143816351890564\n",
      "Finished epoch 479, latest loss 0.7143816351890564\n",
      "Finished epoch 480, latest loss 0.7143816351890564\n",
      "Finished epoch 481, latest loss 0.7144964933395386\n",
      "Finished epoch 482, latest loss 0.7134580612182617\n",
      "Finished epoch 483, latest loss 0.7143816351890564\n",
      "Finished epoch 484, latest loss 0.7143816351890564\n",
      "Finished epoch 485, latest loss 0.714380145072937\n",
      "Finished epoch 486, latest loss 0.7153111100196838\n",
      "Finished epoch 487, latest loss 0.7143816351890564\n",
      "Finished epoch 488, latest loss 0.7143816351890564\n",
      "Finished epoch 489, latest loss 0.7143816351890564\n",
      "Finished epoch 490, latest loss 0.7154529094696045\n",
      "Finished epoch 491, latest loss 0.715304434299469\n",
      "Finished epoch 492, latest loss 0.7143816351890564\n",
      "Finished epoch 493, latest loss 0.715356707572937\n",
      "Finished epoch 494, latest loss 0.7143816351890564\n",
      "Finished epoch 495, latest loss 0.7143816351890564\n",
      "Finished epoch 496, latest loss 0.7143816351890564\n",
      "Finished epoch 497, latest loss 0.7143816351890564\n",
      "Finished epoch 498, latest loss 0.7144166827201843\n",
      "Finished epoch 499, latest loss 0.715151309967041\n",
      "Finished epoch 500, latest loss 0.7143816351890564\n",
      "Finished epoch 501, latest loss 0.7143816351890564\n",
      "Finished epoch 502, latest loss 0.7143816351890564\n",
      "Finished epoch 503, latest loss 0.7143816351890564\n",
      "Finished epoch 504, latest loss 0.7143933176994324\n",
      "Finished epoch 505, latest loss 0.7143816351890564\n",
      "Finished epoch 506, latest loss 0.7143837809562683\n",
      "Finished epoch 507, latest loss 0.7143816351890564\n",
      "Finished epoch 508, latest loss 0.7143816351890564\n",
      "Finished epoch 509, latest loss 0.7143816351890564\n",
      "Finished epoch 510, latest loss 0.7143816351890564\n",
      "Finished epoch 511, latest loss 0.7143816351890564\n",
      "Finished epoch 512, latest loss 0.7143816351890564\n",
      "Finished epoch 513, latest loss 0.7143824696540833\n",
      "Finished epoch 514, latest loss 0.7143816351890564\n",
      "Finished epoch 515, latest loss 0.7143816351890564\n",
      "Finished epoch 516, latest loss 0.7153932452201843\n",
      "Finished epoch 517, latest loss 0.7143816351890564\n",
      "Finished epoch 518, latest loss 0.7157581448554993\n",
      "Finished epoch 519, latest loss 0.7153887152671814\n",
      "Finished epoch 520, latest loss 0.7145146131515503\n",
      "Finished epoch 521, latest loss 0.714388370513916\n",
      "Finished epoch 522, latest loss 0.7143816351890564\n",
      "Finished epoch 523, latest loss 0.7143816351890564\n",
      "Finished epoch 524, latest loss 0.7143808603286743\n",
      "Finished epoch 525, latest loss 0.7143816351890564\n",
      "Finished epoch 526, latest loss 0.7143747210502625\n",
      "Finished epoch 527, latest loss 0.7143816351890564\n",
      "Finished epoch 528, latest loss 0.7162495851516724\n",
      "Finished epoch 529, latest loss 0.7143816351890564\n",
      "Finished epoch 530, latest loss 0.7134908437728882\n",
      "Finished epoch 531, latest loss 0.7144638299942017\n",
      "Finished epoch 532, latest loss 0.7143816351890564\n",
      "Finished epoch 533, latest loss 0.7143712043762207\n",
      "Finished epoch 534, latest loss 0.7143804430961609\n",
      "Finished epoch 535, latest loss 0.7134519815444946\n",
      "Finished epoch 536, latest loss 0.7145487666130066\n",
      "Finished epoch 537, latest loss 0.7143816351890564\n",
      "Finished epoch 538, latest loss 0.7143816351890564\n",
      "Finished epoch 539, latest loss 0.7143816351890564\n",
      "Finished epoch 540, latest loss 0.7142645716667175\n",
      "Finished epoch 541, latest loss 0.7151033282279968\n",
      "Finished epoch 542, latest loss 0.7143816351890564\n",
      "Finished epoch 543, latest loss 0.7143980860710144\n",
      "Finished epoch 544, latest loss 0.7143816351890564\n",
      "Finished epoch 545, latest loss 0.7143816351890564\n",
      "Finished epoch 546, latest loss 0.7143816351890564\n",
      "Finished epoch 547, latest loss 0.7143816351890564\n",
      "Finished epoch 548, latest loss 0.7143816351890564\n",
      "Finished epoch 549, latest loss 0.7143816351890564\n",
      "Finished epoch 550, latest loss 0.7143816351890564\n",
      "Finished epoch 551, latest loss 0.7143816351890564\n",
      "Finished epoch 552, latest loss 0.7143816351890564\n",
      "Finished epoch 553, latest loss 0.7153745293617249\n",
      "Finished epoch 554, latest loss 0.7143816351890564\n",
      "Finished epoch 555, latest loss 0.7143816351890564\n",
      "Finished epoch 556, latest loss 0.7143816351890564\n",
      "Finished epoch 557, latest loss 0.7143816351890564\n",
      "Finished epoch 558, latest loss 0.7134522199630737\n",
      "Finished epoch 559, latest loss 0.7153932452201843\n",
      "Finished epoch 560, latest loss 0.7143816351890564\n",
      "Finished epoch 561, latest loss 0.7134736776351929\n",
      "Finished epoch 562, latest loss 0.7153930068016052\n",
      "Finished epoch 563, latest loss 0.7143816351890564\n",
      "Finished epoch 564, latest loss 0.7143952250480652\n",
      "Finished epoch 565, latest loss 0.7143816351890564\n",
      "Finished epoch 566, latest loss 0.714188277721405\n",
      "Finished epoch 567, latest loss 0.7134519815444946\n",
      "Finished epoch 568, latest loss 0.714397668838501\n",
      "Finished epoch 569, latest loss 0.7134522199630737\n",
      "Finished epoch 570, latest loss 0.7134519815444946\n",
      "Finished epoch 571, latest loss 0.7134519815444946\n",
      "Finished epoch 572, latest loss 0.7134519815444946\n",
      "Finished epoch 573, latest loss 0.7143816351890564\n",
      "Finished epoch 574, latest loss 0.7143815755844116\n",
      "Finished epoch 575, latest loss 0.7134519815444946\n",
      "Finished epoch 576, latest loss 0.7134519815444946\n",
      "Finished epoch 577, latest loss 0.7144635915756226\n",
      "Finished epoch 578, latest loss 0.7134519815444946\n",
      "Finished epoch 579, latest loss 0.714386522769928\n",
      "Finished epoch 580, latest loss 0.7143815755844116\n",
      "Finished epoch 581, latest loss 0.7143814563751221\n",
      "Finished epoch 582, latest loss 0.7134519815444946\n",
      "Finished epoch 583, latest loss 0.7143815755844116\n",
      "Finished epoch 584, latest loss 0.713301420211792\n",
      "Finished epoch 585, latest loss 0.7134519815444946\n",
      "Finished epoch 586, latest loss 0.7134532332420349\n",
      "Finished epoch 587, latest loss 0.7144635915756226\n",
      "Finished epoch 588, latest loss 0.7135135531425476\n",
      "Finished epoch 589, latest loss 0.7134521007537842\n",
      "Finished epoch 590, latest loss 0.7144635915756226\n",
      "Finished epoch 591, latest loss 0.7142281532287598\n",
      "Finished epoch 592, latest loss 0.7143816351890564\n",
      "Finished epoch 593, latest loss 0.7134519815444946\n",
      "Finished epoch 594, latest loss 0.7134519815444946\n",
      "Finished epoch 595, latest loss 0.7134519815444946\n",
      "Finished epoch 596, latest loss 0.7134519815444946\n",
      "Finished epoch 597, latest loss 0.7134519815444946\n",
      "Finished epoch 598, latest loss 0.7144641876220703\n",
      "Finished epoch 599, latest loss 0.7134519815444946\n",
      "Finished epoch 600, latest loss 0.7134521007537842\n",
      "Finished epoch 601, latest loss 0.7125228047370911\n",
      "Finished epoch 602, latest loss 0.7132769823074341\n",
      "Finished epoch 603, latest loss 0.7142438888549805\n",
      "Finished epoch 604, latest loss 0.7134497761726379\n",
      "Finished epoch 605, latest loss 0.7125224471092224\n",
      "Finished epoch 606, latest loss 0.7125214338302612\n",
      "Finished epoch 607, latest loss 0.7143812775611877\n",
      "Finished epoch 608, latest loss 0.7131537795066833\n",
      "Finished epoch 609, latest loss 0.7125224471092224\n",
      "Finished epoch 610, latest loss 0.7125224471092224\n",
      "Finished epoch 611, latest loss 0.7135410308837891\n",
      "Finished epoch 612, latest loss 0.712523341178894\n",
      "Finished epoch 613, latest loss 0.7133187055587769\n",
      "Finished epoch 614, latest loss 0.7125225067138672\n",
      "Finished epoch 615, latest loss 0.7125225067138672\n",
      "Finished epoch 616, latest loss 0.7135342359542847\n",
      "Finished epoch 617, latest loss 0.7125219106674194\n",
      "Finished epoch 618, latest loss 0.7126327753067017\n",
      "Finished epoch 619, latest loss 0.7125225067138672\n",
      "Finished epoch 620, latest loss 0.7125224471092224\n",
      "Finished epoch 621, latest loss 0.7125224471092224\n",
      "Finished epoch 622, latest loss 0.7125224471092224\n",
      "Finished epoch 623, latest loss 0.7134519815444946\n",
      "Finished epoch 624, latest loss 0.7134519815444946\n",
      "Finished epoch 625, latest loss 0.713445246219635\n",
      "Finished epoch 626, latest loss 0.7125224471092224\n",
      "Finished epoch 627, latest loss 0.7125224471092224\n",
      "Finished epoch 628, latest loss 0.7125224471092224\n",
      "Finished epoch 629, latest loss 0.7123794555664062\n",
      "Finished epoch 630, latest loss 0.7115928530693054\n",
      "Finished epoch 631, latest loss 0.7115928530693054\n",
      "Finished epoch 632, latest loss 0.7115936875343323\n",
      "Finished epoch 633, latest loss 0.711596667766571\n",
      "Finished epoch 634, latest loss 0.7116369009017944\n",
      "Finished epoch 635, latest loss 0.7115928530693054\n",
      "Finished epoch 636, latest loss 0.7121179103851318\n",
      "Finished epoch 637, latest loss 0.7125224471092224\n",
      "Finished epoch 638, latest loss 0.7134309411048889\n",
      "Finished epoch 639, latest loss 0.7125225067138672\n",
      "Finished epoch 640, latest loss 0.7128170728683472\n",
      "Finished epoch 641, latest loss 0.7115930914878845\n",
      "Finished epoch 642, latest loss 0.7115928530693054\n",
      "Finished epoch 643, latest loss 0.7133519053459167\n",
      "Finished epoch 644, latest loss 0.7125224471092224\n",
      "Finished epoch 645, latest loss 0.7115936875343323\n",
      "Finished epoch 646, latest loss 0.7125225067138672\n",
      "Finished epoch 647, latest loss 0.7126036882400513\n",
      "Finished epoch 648, latest loss 0.7125224471092224\n",
      "Finished epoch 649, latest loss 0.7115932703018188\n",
      "Finished epoch 650, latest loss 0.712522029876709\n",
      "Finished epoch 651, latest loss 0.7134501934051514\n",
      "Finished epoch 652, latest loss 0.7143490314483643\n",
      "Finished epoch 653, latest loss 0.711592972278595\n",
      "Finished epoch 654, latest loss 0.7115930914878845\n",
      "Finished epoch 655, latest loss 0.7125224471092224\n",
      "Finished epoch 656, latest loss 0.7125224471092224\n",
      "Finished epoch 657, latest loss 0.713444709777832\n",
      "Finished epoch 658, latest loss 0.7125225067138672\n",
      "Finished epoch 659, latest loss 0.715453028678894\n",
      "Finished epoch 660, latest loss 0.7134519815444946\n",
      "Finished epoch 661, latest loss 0.7125244140625\n",
      "Finished epoch 662, latest loss 0.7125224471092224\n",
      "Finished epoch 663, latest loss 0.7115930914878845\n",
      "Finished epoch 664, latest loss 0.7115928530693054\n",
      "Finished epoch 665, latest loss 0.712522566318512\n",
      "Finished epoch 666, latest loss 0.7130884528160095\n",
      "Finished epoch 667, latest loss 0.7125753164291382\n",
      "Finished epoch 668, latest loss 0.7125221490859985\n",
      "Finished epoch 669, latest loss 0.7115929126739502\n",
      "Finished epoch 670, latest loss 0.7115928530693054\n",
      "Finished epoch 671, latest loss 0.7126044631004333\n",
      "Finished epoch 672, latest loss 0.7115928530693054\n",
      "Finished epoch 673, latest loss 0.7134124636650085\n",
      "Finished epoch 674, latest loss 0.7115929126739502\n",
      "Finished epoch 675, latest loss 0.7135340571403503\n",
      "Finished epoch 676, latest loss 0.7135340571403503\n",
      "Finished epoch 677, latest loss 0.7135340571403503\n",
      "Finished epoch 678, latest loss 0.714461624622345\n",
      "Finished epoch 679, latest loss 0.7144626379013062\n",
      "Finished epoch 680, latest loss 0.7134519815444946\n",
      "Finished epoch 681, latest loss 0.7125225067138672\n",
      "Finished epoch 682, latest loss 0.7125224471092224\n",
      "Finished epoch 683, latest loss 0.7125224471092224\n",
      "Finished epoch 684, latest loss 0.7125488519668579\n",
      "Finished epoch 685, latest loss 0.7134519815444946\n",
      "Finished epoch 686, latest loss 0.7125224471092224\n",
      "Finished epoch 687, latest loss 0.7134615778923035\n",
      "Finished epoch 688, latest loss 0.7134522795677185\n",
      "Finished epoch 689, latest loss 0.715304970741272\n",
      "Finished epoch 690, latest loss 0.7125224471092224\n",
      "Finished epoch 691, latest loss 0.7125224471092224\n",
      "Finished epoch 692, latest loss 0.7125738859176636\n",
      "Finished epoch 693, latest loss 0.7126315236091614\n",
      "Finished epoch 694, latest loss 0.7125225067138672\n",
      "Finished epoch 695, latest loss 0.7135443091392517\n",
      "Finished epoch 696, latest loss 0.7125224471092224\n",
      "Finished epoch 697, latest loss 0.7116846442222595\n",
      "Finished epoch 698, latest loss 0.7115928530693054\n",
      "Finished epoch 699, latest loss 0.7116003036499023\n",
      "Finished epoch 700, latest loss 0.7115928530693054\n",
      "Finished epoch 701, latest loss 0.7129748463630676\n",
      "Finished epoch 702, latest loss 0.7125224471092224\n",
      "Finished epoch 703, latest loss 0.7131026387214661\n",
      "Finished epoch 704, latest loss 0.7125224471092224\n",
      "Finished epoch 705, latest loss 0.7144635915756226\n",
      "Finished epoch 706, latest loss 0.7134581804275513\n",
      "Finished epoch 707, latest loss 0.7115989327430725\n",
      "Finished epoch 708, latest loss 0.7133322358131409\n",
      "Finished epoch 709, latest loss 0.7126045823097229\n",
      "Finished epoch 710, latest loss 0.7115928530693054\n",
      "Finished epoch 711, latest loss 0.7115928530693054\n",
      "Finished epoch 712, latest loss 0.7125224471092224\n",
      "Finished epoch 713, latest loss 0.7133398652076721\n",
      "Finished epoch 714, latest loss 0.7118338942527771\n",
      "Finished epoch 715, latest loss 0.7115928530693054\n",
      "Finished epoch 716, latest loss 0.7115928530693054\n",
      "Finished epoch 717, latest loss 0.7115928530693054\n",
      "Finished epoch 718, latest loss 0.7125224471092224\n",
      "Finished epoch 719, latest loss 0.7125224471092224\n",
      "Finished epoch 720, latest loss 0.7129061222076416\n",
      "Finished epoch 721, latest loss 0.7125224471092224\n",
      "Finished epoch 722, latest loss 0.7125224471092224\n",
      "Finished epoch 723, latest loss 0.7125224471092224\n",
      "Finished epoch 724, latest loss 0.7125224471092224\n",
      "Finished epoch 725, latest loss 0.7125224471092224\n",
      "Finished epoch 726, latest loss 0.7135311365127563\n",
      "Finished epoch 727, latest loss 0.7125374674797058\n",
      "Finished epoch 728, latest loss 0.7125224471092224\n",
      "Finished epoch 729, latest loss 0.7125224471092224\n",
      "Finished epoch 730, latest loss 0.7125652432441711\n",
      "Finished epoch 731, latest loss 0.7125224471092224\n",
      "Finished epoch 732, latest loss 0.7125224471092224\n",
      "Finished epoch 733, latest loss 0.7125224471092224\n",
      "Finished epoch 734, latest loss 0.7135340571403503\n",
      "Finished epoch 735, latest loss 0.7125221490859985\n",
      "Finished epoch 736, latest loss 0.7120246887207031\n",
      "Finished epoch 737, latest loss 0.7115928530693054\n",
      "Finished epoch 738, latest loss 0.711613118648529\n",
      "Finished epoch 739, latest loss 0.7115928530693054\n",
      "Finished epoch 740, latest loss 0.7115928530693054\n",
      "Finished epoch 741, latest loss 0.7134009003639221\n",
      "Finished epoch 742, latest loss 0.7125228047370911\n",
      "Finished epoch 743, latest loss 0.7115928530693054\n",
      "Finished epoch 744, latest loss 0.712211012840271\n",
      "Finished epoch 745, latest loss 0.7115922570228577\n",
      "Finished epoch 746, latest loss 0.7115928530693054\n",
      "Finished epoch 747, latest loss 0.7126044631004333\n",
      "Finished epoch 748, latest loss 0.7133996486663818\n",
      "Finished epoch 749, latest loss 0.7115928530693054\n",
      "Finished epoch 750, latest loss 0.7115930318832397\n",
      "Finished epoch 751, latest loss 0.7115928530693054\n",
      "Finished epoch 752, latest loss 0.7115928530693054\n",
      "Finished epoch 753, latest loss 0.7115929126739502\n",
      "Finished epoch 754, latest loss 0.7115928530693054\n",
      "Finished epoch 755, latest loss 0.7115928530693054\n",
      "Finished epoch 756, latest loss 0.7115928530693054\n",
      "Finished epoch 757, latest loss 0.7125224471092224\n",
      "Finished epoch 758, latest loss 0.7115975618362427\n",
      "Finished epoch 759, latest loss 0.7125225067138672\n",
      "Finished epoch 760, latest loss 0.7115928530693054\n",
      "Finished epoch 761, latest loss 0.7126044631004333\n",
      "Finished epoch 762, latest loss 0.7116214632987976\n",
      "Finished epoch 763, latest loss 0.7115928530693054\n",
      "Finished epoch 764, latest loss 0.7121188640594482\n",
      "Finished epoch 765, latest loss 0.7125225067138672\n",
      "Finished epoch 766, latest loss 0.7115928530693054\n",
      "Finished epoch 767, latest loss 0.7135341167449951\n",
      "Finished epoch 768, latest loss 0.7125224471092224\n",
      "Finished epoch 769, latest loss 0.7125224471092224\n",
      "Finished epoch 770, latest loss 0.7125224471092224\n",
      "Finished epoch 771, latest loss 0.7125224471092224\n",
      "Finished epoch 772, latest loss 0.7125224471092224\n",
      "Finished epoch 773, latest loss 0.7134518027305603\n",
      "Finished epoch 774, latest loss 0.7135340571403503\n",
      "Finished epoch 775, latest loss 0.7125228047370911\n",
      "Finished epoch 776, latest loss 0.7125224471092224\n",
      "Finished epoch 777, latest loss 0.7134202122688293\n",
      "Finished epoch 778, latest loss 0.7125224471092224\n",
      "Finished epoch 779, latest loss 0.7125224471092224\n",
      "Finished epoch 780, latest loss 0.7125224471092224\n",
      "Finished epoch 781, latest loss 0.7122940421104431\n",
      "Finished epoch 782, latest loss 0.7115928530693054\n",
      "Finished epoch 783, latest loss 0.7115928530693054\n",
      "Finished epoch 784, latest loss 0.7123558521270752\n",
      "Finished epoch 785, latest loss 0.7115928530693054\n",
      "Finished epoch 786, latest loss 0.7115928530693054\n",
      "Finished epoch 787, latest loss 0.7115928530693054\n",
      "Finished epoch 788, latest loss 0.7115928530693054\n",
      "Finished epoch 789, latest loss 0.7116054892539978\n",
      "Finished epoch 790, latest loss 0.7115928530693054\n",
      "Finished epoch 791, latest loss 0.7115928530693054\n",
      "Finished epoch 792, latest loss 0.7115928530693054\n",
      "Finished epoch 793, latest loss 0.7115928530693054\n",
      "Finished epoch 794, latest loss 0.7115928530693054\n",
      "Finished epoch 795, latest loss 0.7118775844573975\n",
      "Finished epoch 796, latest loss 0.7115928530693054\n",
      "Finished epoch 797, latest loss 0.7125224471092224\n",
      "Finished epoch 798, latest loss 0.7115928530693054\n",
      "Finished epoch 799, latest loss 0.7115928530693054\n",
      "Finished epoch 800, latest loss 0.7116642594337463\n",
      "Finished epoch 801, latest loss 0.7115959525108337\n",
      "Finished epoch 802, latest loss 0.7115225791931152\n",
      "Finished epoch 803, latest loss 0.7106633186340332\n",
      "Finished epoch 804, latest loss 0.7115928530693054\n",
      "Finished epoch 805, latest loss 0.7115930318832397\n",
      "Finished epoch 806, latest loss 0.7125223278999329\n",
      "Finished epoch 807, latest loss 0.7124882936477661\n",
      "Finished epoch 808, latest loss 0.7106642723083496\n",
      "Finished epoch 809, latest loss 0.7115929126739502\n",
      "Finished epoch 810, latest loss 0.712300717830658\n",
      "Finished epoch 811, latest loss 0.7132657170295715\n",
      "Finished epoch 812, latest loss 0.7115928530693054\n",
      "Finished epoch 813, latest loss 0.7115928530693054\n",
      "Finished epoch 814, latest loss 0.7125161290168762\n",
      "Finished epoch 815, latest loss 0.7115928530693054\n",
      "Finished epoch 816, latest loss 0.7115928530693054\n",
      "Finished epoch 817, latest loss 0.7115928530693054\n",
      "Finished epoch 818, latest loss 0.7115928530693054\n",
      "Finished epoch 819, latest loss 0.7115928530693054\n",
      "Finished epoch 820, latest loss 0.7115928530693054\n",
      "Finished epoch 821, latest loss 0.7115928530693054\n",
      "Finished epoch 822, latest loss 0.7125224471092224\n",
      "Finished epoch 823, latest loss 0.7115928530693054\n",
      "Finished epoch 824, latest loss 0.7115928530693054\n",
      "Finished epoch 825, latest loss 0.7115928530693054\n",
      "Finished epoch 826, latest loss 0.7116100788116455\n",
      "Finished epoch 827, latest loss 0.7126044631004333\n",
      "Finished epoch 828, latest loss 0.7122260928153992\n",
      "Finished epoch 829, latest loss 0.7116021513938904\n",
      "Finished epoch 830, latest loss 0.7115928530693054\n",
      "Finished epoch 831, latest loss 0.7115946412086487\n",
      "Finished epoch 832, latest loss 0.7115928530693054\n",
      "Finished epoch 833, latest loss 0.7126044631004333\n",
      "Finished epoch 834, latest loss 0.7125224471092224\n",
      "Finished epoch 835, latest loss 0.7115928530693054\n",
      "Finished epoch 836, latest loss 0.7125329375267029\n",
      "Finished epoch 837, latest loss 0.7115928530693054\n",
      "Finished epoch 838, latest loss 0.7115928530693054\n",
      "Finished epoch 839, latest loss 0.7125224471092224\n",
      "Finished epoch 840, latest loss 0.7125663161277771\n",
      "Finished epoch 841, latest loss 0.7106679677963257\n",
      "Finished epoch 842, latest loss 0.7115928530693054\n",
      "Finished epoch 843, latest loss 0.7115929126739502\n",
      "Finished epoch 844, latest loss 0.7125224471092224\n",
      "Finished epoch 845, latest loss 0.7125449180603027\n",
      "Finished epoch 846, latest loss 0.712522029876709\n",
      "Finished epoch 847, latest loss 0.7115936279296875\n",
      "Finished epoch 848, latest loss 0.7113268971443176\n",
      "Finished epoch 849, latest loss 0.7116742134094238\n",
      "Finished epoch 850, latest loss 0.711767315864563\n",
      "Finished epoch 851, latest loss 0.7106633186340332\n",
      "Finished epoch 852, latest loss 0.7106633186340332\n",
      "Finished epoch 853, latest loss 0.7116749286651611\n",
      "Finished epoch 854, latest loss 0.7115928530693054\n",
      "Finished epoch 855, latest loss 0.7106805443763733\n",
      "Finished epoch 856, latest loss 0.7112913727760315\n",
      "Finished epoch 857, latest loss 0.7106633186340332\n",
      "Finished epoch 858, latest loss 0.7106633186340332\n",
      "Finished epoch 859, latest loss 0.7106633186340332\n",
      "Finished epoch 860, latest loss 0.7106648683547974\n",
      "Finished epoch 861, latest loss 0.7117090821266174\n",
      "Finished epoch 862, latest loss 0.7113499045372009\n",
      "Finished epoch 863, latest loss 0.7106633186340332\n",
      "Finished epoch 864, latest loss 0.7106633186340332\n",
      "Finished epoch 865, latest loss 0.7115929126739502\n",
      "Finished epoch 866, latest loss 0.7106633186340332\n",
      "Finished epoch 867, latest loss 0.7106633186340332\n",
      "Finished epoch 868, latest loss 0.7106633186340332\n",
      "Finished epoch 869, latest loss 0.7116749286651611\n",
      "Finished epoch 870, latest loss 0.7109046578407288\n",
      "Finished epoch 871, latest loss 0.7125225067138672\n",
      "Finished epoch 872, latest loss 0.7123066186904907\n",
      "Finished epoch 873, latest loss 0.7115929126739502\n",
      "Finished epoch 874, latest loss 0.710664689540863\n",
      "Finished epoch 875, latest loss 0.7107059955596924\n",
      "Finished epoch 876, latest loss 0.7106633186340332\n",
      "Finished epoch 877, latest loss 0.7106633186340332\n",
      "Finished epoch 878, latest loss 0.7107195854187012\n",
      "Finished epoch 879, latest loss 0.7107846140861511\n",
      "Finished epoch 880, latest loss 0.7106633186340332\n",
      "Finished epoch 881, latest loss 0.7114346623420715\n",
      "Finished epoch 882, latest loss 0.7106633186340332\n",
      "Finished epoch 883, latest loss 0.7115929126739502\n",
      "Finished epoch 884, latest loss 0.7106635570526123\n",
      "Finished epoch 885, latest loss 0.7115928530693054\n",
      "Finished epoch 886, latest loss 0.7106633186340332\n",
      "Finished epoch 887, latest loss 0.7106745839118958\n",
      "Finished epoch 888, latest loss 0.7107222676277161\n",
      "Finished epoch 889, latest loss 0.7106633186340332\n",
      "Finished epoch 890, latest loss 0.7106633186340332\n",
      "Finished epoch 891, latest loss 0.7106633186340332\n",
      "Finished epoch 892, latest loss 0.7106633186340332\n",
      "Finished epoch 893, latest loss 0.7106633186340332\n",
      "Finished epoch 894, latest loss 0.7106633186340332\n",
      "Finished epoch 895, latest loss 0.7106633186340332\n",
      "Finished epoch 896, latest loss 0.7115930914878845\n",
      "Finished epoch 897, latest loss 0.7116912007331848\n",
      "Finished epoch 898, latest loss 0.7114595174789429\n",
      "Finished epoch 899, latest loss 0.7115928530693054\n",
      "Finished epoch 900, latest loss 0.7106633186340332\n",
      "Finished epoch 901, latest loss 0.7106633186340332\n",
      "Finished epoch 902, latest loss 0.7106634974479675\n",
      "Finished epoch 903, latest loss 0.7115929126739502\n",
      "Finished epoch 904, latest loss 0.7116749286651611\n",
      "Finished epoch 905, latest loss 0.7106633186340332\n",
      "Finished epoch 906, latest loss 0.7106633186340332\n",
      "Finished epoch 907, latest loss 0.7106633186340332\n",
      "Finished epoch 908, latest loss 0.7106633186340332\n",
      "Finished epoch 909, latest loss 0.7106633186340332\n",
      "Finished epoch 910, latest loss 0.7114487886428833\n",
      "Finished epoch 911, latest loss 0.7106633186340332\n",
      "Finished epoch 912, latest loss 0.7106633186340332\n",
      "Finished epoch 913, latest loss 0.7106633186340332\n",
      "Finished epoch 914, latest loss 0.7106633186340332\n",
      "Finished epoch 915, latest loss 0.710663378238678\n",
      "Finished epoch 916, latest loss 0.7108773589134216\n",
      "Finished epoch 917, latest loss 0.7116749286651611\n",
      "Finished epoch 918, latest loss 0.7106638550758362\n",
      "Finished epoch 919, latest loss 0.7115894556045532\n",
      "Finished epoch 920, latest loss 0.7106633186340332\n",
      "Finished epoch 921, latest loss 0.7106633186340332\n",
      "Finished epoch 922, latest loss 0.710663378238678\n",
      "Finished epoch 923, latest loss 0.7106633186340332\n",
      "Finished epoch 924, latest loss 0.7115928530693054\n",
      "Finished epoch 925, latest loss 0.7166505455970764\n",
      "Finished epoch 926, latest loss 0.7115928530693054\n",
      "Finished epoch 927, latest loss 0.7106648087501526\n",
      "Finished epoch 928, latest loss 0.7115928530693054\n",
      "Finished epoch 929, latest loss 0.7125146985054016\n",
      "Finished epoch 930, latest loss 0.7115928530693054\n",
      "Finished epoch 931, latest loss 0.7116749882698059\n",
      "Finished epoch 932, latest loss 0.7136086225509644\n",
      "Finished epoch 933, latest loss 0.7116749882698059\n",
      "Finished epoch 934, latest loss 0.7115928530693054\n",
      "Finished epoch 935, latest loss 0.710663378238678\n",
      "Finished epoch 936, latest loss 0.7116228342056274\n",
      "Finished epoch 937, latest loss 0.7106633186340332\n",
      "Finished epoch 938, latest loss 0.7106667757034302\n",
      "Finished epoch 939, latest loss 0.7115928530693054\n",
      "Finished epoch 940, latest loss 0.7120850086212158\n",
      "Finished epoch 941, latest loss 0.7107992768287659\n",
      "Finished epoch 942, latest loss 0.7106633186340332\n",
      "Finished epoch 943, latest loss 0.7106633186340332\n",
      "Finished epoch 944, latest loss 0.7116749286651611\n",
      "Finished epoch 945, latest loss 0.7116749286651611\n",
      "Finished epoch 946, latest loss 0.7116749286651611\n",
      "Finished epoch 947, latest loss 0.7106633186340332\n",
      "Finished epoch 948, latest loss 0.7126044631004333\n",
      "Finished epoch 949, latest loss 0.7115931510925293\n",
      "Finished epoch 950, latest loss 0.7106633186340332\n",
      "Finished epoch 951, latest loss 0.7106635570526123\n",
      "Finished epoch 952, latest loss 0.7106633186340332\n",
      "Finished epoch 953, latest loss 0.7106633186340332\n",
      "Finished epoch 954, latest loss 0.7106633186340332\n",
      "Finished epoch 955, latest loss 0.7106633186340332\n",
      "Finished epoch 956, latest loss 0.7106637954711914\n",
      "Finished epoch 957, latest loss 0.7106633186340332\n",
      "Finished epoch 958, latest loss 0.712522029876709\n",
      "Finished epoch 959, latest loss 0.7107693552970886\n",
      "Finished epoch 960, latest loss 0.7106633186340332\n",
      "Finished epoch 961, latest loss 0.7115929126739502\n",
      "Finished epoch 962, latest loss 0.7114477753639221\n",
      "Finished epoch 963, latest loss 0.7106633186340332\n",
      "Finished epoch 964, latest loss 0.7106633186340332\n",
      "Finished epoch 965, latest loss 0.7106633186340332\n",
      "Finished epoch 966, latest loss 0.7106633186340332\n",
      "Finished epoch 967, latest loss 0.7115928530693054\n",
      "Finished epoch 968, latest loss 0.7126865386962891\n",
      "Finished epoch 969, latest loss 0.7116749286651611\n",
      "Finished epoch 970, latest loss 0.7116749286651611\n",
      "Finished epoch 971, latest loss 0.7126054763793945\n",
      "Finished epoch 972, latest loss 0.7126045227050781\n",
      "Finished epoch 973, latest loss 0.7121288180351257\n",
      "Finished epoch 974, latest loss 0.7116749286651611\n",
      "Finished epoch 975, latest loss 0.7106633186340332\n",
      "Finished epoch 976, latest loss 0.7106633186340332\n",
      "Finished epoch 977, latest loss 0.7106633186340332\n",
      "Finished epoch 978, latest loss 0.7116749286651611\n",
      "Finished epoch 979, latest loss 0.7106633186340332\n",
      "Finished epoch 980, latest loss 0.7106633186340332\n",
      "Finished epoch 981, latest loss 0.7116749286651611\n",
      "Finished epoch 982, latest loss 0.7116749286651611\n",
      "Finished epoch 983, latest loss 0.7116749286651611\n",
      "Finished epoch 984, latest loss 0.7106633186340332\n",
      "Finished epoch 985, latest loss 0.7106633186340332\n",
      "Finished epoch 986, latest loss 0.7106633186340332\n",
      "Finished epoch 987, latest loss 0.7106633186340332\n",
      "Finished epoch 988, latest loss 0.7115926742553711\n",
      "Finished epoch 989, latest loss 0.7126044631004333\n",
      "Finished epoch 990, latest loss 0.7115928530693054\n",
      "Finished epoch 991, latest loss 0.7106633186340332\n",
      "Finished epoch 992, latest loss 0.7106633186340332\n",
      "Finished epoch 993, latest loss 0.7106633186340332\n",
      "Finished epoch 994, latest loss 0.712604820728302\n",
      "Finished epoch 995, latest loss 0.7115928530693054\n",
      "Finished epoch 996, latest loss 0.7126044631004333\n",
      "Finished epoch 997, latest loss 0.7116795778274536\n",
      "Finished epoch 998, latest loss 0.7106633186340332\n",
      "Finished epoch 999, latest loss 0.7116749286651611\n",
      "Finished epoch 1000, latest loss 0.7124118208885193\n",
      "Finished epoch 1001, latest loss 0.7115928530693054\n",
      "Finished epoch 1002, latest loss 0.7106633186340332\n",
      "Finished epoch 1003, latest loss 0.7106633186340332\n",
      "Finished epoch 1004, latest loss 0.7106633186340332\n",
      "Finished epoch 1005, latest loss 0.7106633186340332\n",
      "Finished epoch 1006, latest loss 0.7106633186340332\n",
      "Finished epoch 1007, latest loss 0.7106633186340332\n",
      "Finished epoch 1008, latest loss 0.7111862301826477\n",
      "Finished epoch 1009, latest loss 0.7106633186340332\n",
      "Finished epoch 1010, latest loss 0.7106633186340332\n",
      "Finished epoch 1011, latest loss 0.7106633186340332\n",
      "Finished epoch 1012, latest loss 0.7106633186340332\n",
      "Finished epoch 1013, latest loss 0.7106633186340332\n",
      "Finished epoch 1014, latest loss 0.7106633186340332\n",
      "Finished epoch 1015, latest loss 0.7147097587585449\n",
      "Finished epoch 1016, latest loss 0.7106633186340332\n",
      "Finished epoch 1017, latest loss 0.7106633186340332\n",
      "Finished epoch 1018, latest loss 0.7106633186340332\n",
      "Finished epoch 1019, latest loss 0.7115929126739502\n",
      "Finished epoch 1020, latest loss 0.7116749286651611\n",
      "Finished epoch 1021, latest loss 0.7116458415985107\n",
      "Finished epoch 1022, latest loss 0.7106633186340332\n",
      "Finished epoch 1023, latest loss 0.7126044631004333\n",
      "Finished epoch 1024, latest loss 0.7106633186340332\n",
      "Finished epoch 1025, latest loss 0.7126044631004333\n",
      "Finished epoch 1026, latest loss 0.7106633186340332\n",
      "Finished epoch 1027, latest loss 0.7106633186340332\n",
      "Finished epoch 1028, latest loss 0.7115918397903442\n",
      "Finished epoch 1029, latest loss 0.7106633186340332\n",
      "Finished epoch 1030, latest loss 0.7106633186340332\n",
      "Finished epoch 1031, latest loss 0.7106633186340332\n",
      "Finished epoch 1032, latest loss 0.7106633186340332\n",
      "Finished epoch 1033, latest loss 0.7106755375862122\n",
      "Finished epoch 1034, latest loss 0.7106633186340332\n",
      "Finished epoch 1035, latest loss 0.7110437750816345\n",
      "Finished epoch 1036, latest loss 0.7106633186340332\n",
      "Finished epoch 1037, latest loss 0.7106633186340332\n",
      "Finished epoch 1038, latest loss 0.7106633186340332\n",
      "Finished epoch 1039, latest loss 0.7106633186340332\n",
      "Finished epoch 1040, latest loss 0.7106633186340332\n",
      "Finished epoch 1041, latest loss 0.7106633186340332\n",
      "Finished epoch 1042, latest loss 0.7115271687507629\n",
      "Finished epoch 1043, latest loss 0.7106675505638123\n",
      "Finished epoch 1044, latest loss 0.7106633186340332\n",
      "Finished epoch 1045, latest loss 0.7115928530693054\n",
      "Finished epoch 1046, latest loss 0.7116749286651611\n",
      "Finished epoch 1047, latest loss 0.7106633186340332\n",
      "Finished epoch 1048, latest loss 0.7106633186340332\n",
      "Finished epoch 1049, latest loss 0.7106633186340332\n",
      "Finished epoch 1050, latest loss 0.7106633186340332\n",
      "Finished epoch 1051, latest loss 0.7106633186340332\n",
      "Finished epoch 1052, latest loss 0.7116748094558716\n",
      "Finished epoch 1053, latest loss 0.7116749286651611\n",
      "Finished epoch 1054, latest loss 0.7116749286651611\n",
      "Finished epoch 1055, latest loss 0.7106633186340332\n",
      "Finished epoch 1056, latest loss 0.7106633186340332\n",
      "Finished epoch 1057, latest loss 0.7116749286651611\n",
      "Finished epoch 1058, latest loss 0.7106633186340332\n",
      "Finished epoch 1059, latest loss 0.7120752930641174\n",
      "Finished epoch 1060, latest loss 0.7116749286651611\n",
      "Finished epoch 1061, latest loss 0.7106633186340332\n",
      "Finished epoch 1062, latest loss 0.7106633186340332\n",
      "Finished epoch 1063, latest loss 0.7116749286651611\n",
      "Finished epoch 1064, latest loss 0.7126883268356323\n",
      "Finished epoch 1065, latest loss 0.7106633186340332\n",
      "Finished epoch 1066, latest loss 0.7106633186340332\n",
      "Finished epoch 1067, latest loss 0.7116751074790955\n",
      "Finished epoch 1068, latest loss 0.7116749286651611\n",
      "Finished epoch 1069, latest loss 0.7116749286651611\n",
      "Finished epoch 1070, latest loss 0.7106633186340332\n",
      "Finished epoch 1071, latest loss 0.7106633186340332\n",
      "Finished epoch 1072, latest loss 0.7106633186340332\n",
      "Finished epoch 1073, latest loss 0.7106633186340332\n",
      "Finished epoch 1074, latest loss 0.7106633186340332\n",
      "Finished epoch 1075, latest loss 0.7106633186340332\n",
      "Finished epoch 1076, latest loss 0.7106633186340332\n",
      "Finished epoch 1077, latest loss 0.7106633186340332\n",
      "Finished epoch 1078, latest loss 0.7106790542602539\n",
      "Finished epoch 1079, latest loss 0.7106633186340332\n",
      "Finished epoch 1080, latest loss 0.7106667757034302\n",
      "Finished epoch 1081, latest loss 0.7106645703315735\n",
      "Finished epoch 1082, latest loss 0.7106633186340332\n",
      "Finished epoch 1083, latest loss 0.7115928530693054\n",
      "Finished epoch 1084, latest loss 0.7106633186340332\n",
      "Finished epoch 1085, latest loss 0.7106633186340332\n",
      "Finished epoch 1086, latest loss 0.7106633186340332\n",
      "Finished epoch 1087, latest loss 0.7115928530693054\n",
      "Finished epoch 1088, latest loss 0.7126044631004333\n",
      "Finished epoch 1089, latest loss 0.7116748094558716\n",
      "Finished epoch 1090, latest loss 0.7106633186340332\n",
      "Finished epoch 1091, latest loss 0.7116749286651611\n",
      "Finished epoch 1092, latest loss 0.7106633186340332\n",
      "Finished epoch 1093, latest loss 0.7116749286651611\n",
      "Finished epoch 1094, latest loss 0.7106633186340332\n",
      "Finished epoch 1095, latest loss 0.7106633186340332\n",
      "Finished epoch 1096, latest loss 0.7116749286651611\n",
      "Finished epoch 1097, latest loss 0.7116749286651611\n",
      "Finished epoch 1098, latest loss 0.7106633186340332\n",
      "Finished epoch 1099, latest loss 0.7116749286651611\n",
      "Finished epoch 1100, latest loss 0.7106633186340332\n",
      "Finished epoch 1101, latest loss 0.7115928530693054\n",
      "Finished epoch 1102, latest loss 0.7106633186340332\n",
      "Finished epoch 1103, latest loss 0.7106633186340332\n",
      "Finished epoch 1104, latest loss 0.7106633186340332\n",
      "Finished epoch 1105, latest loss 0.7106633186340332\n",
      "Finished epoch 1106, latest loss 0.7106633186340332\n",
      "Finished epoch 1107, latest loss 0.7106633186340332\n",
      "Finished epoch 1108, latest loss 0.7106633186340332\n",
      "Finished epoch 1109, latest loss 0.7106633186340332\n",
      "Finished epoch 1110, latest loss 0.7106633186340332\n",
      "Finished epoch 1111, latest loss 0.7106633186340332\n",
      "Finished epoch 1112, latest loss 0.7106633186340332\n",
      "Finished epoch 1113, latest loss 0.7106633186340332\n",
      "Finished epoch 1114, latest loss 0.7114610075950623\n",
      "Finished epoch 1115, latest loss 0.7106633186340332\n",
      "Finished epoch 1116, latest loss 0.711675226688385\n",
      "Finished epoch 1117, latest loss 0.7116749286651611\n",
      "Finished epoch 1118, latest loss 0.7116749286651611\n",
      "Finished epoch 1119, latest loss 0.7116749286651611\n",
      "Finished epoch 1120, latest loss 0.7106633186340332\n",
      "Finished epoch 1121, latest loss 0.7116749286651611\n",
      "Finished epoch 1122, latest loss 0.7106633186340332\n",
      "Finished epoch 1123, latest loss 0.7116749286651611\n",
      "Finished epoch 1124, latest loss 0.7116749286651611\n",
      "Finished epoch 1125, latest loss 0.7106633186340332\n",
      "Finished epoch 1126, latest loss 0.7106633186340332\n",
      "Finished epoch 1127, latest loss 0.7106633186340332\n",
      "Finished epoch 1128, latest loss 0.7106633186340332\n",
      "Finished epoch 1129, latest loss 0.7106633186340332\n",
      "Finished epoch 1130, latest loss 0.7106633186340332\n",
      "Finished epoch 1131, latest loss 0.7106633186340332\n",
      "Finished epoch 1132, latest loss 0.7116749286651611\n",
      "Finished epoch 1133, latest loss 0.7126030325889587\n",
      "Finished epoch 1134, latest loss 0.7116749286651611\n",
      "Finished epoch 1135, latest loss 0.7116749286651611\n",
      "Finished epoch 1136, latest loss 0.7116749286651611\n",
      "Finished epoch 1137, latest loss 0.7106633186340332\n",
      "Finished epoch 1138, latest loss 0.7116749286651611\n",
      "Finished epoch 1139, latest loss 0.7106633186340332\n",
      "Finished epoch 1140, latest loss 0.7118405103683472\n",
      "Finished epoch 1141, latest loss 0.7126044631004333\n",
      "Finished epoch 1142, latest loss 0.7115928530693054\n",
      "Finished epoch 1143, latest loss 0.7126873135566711\n",
      "Finished epoch 1144, latest loss 0.7116751074790955\n",
      "Finished epoch 1145, latest loss 0.7115928530693054\n",
      "Finished epoch 1146, latest loss 0.7106633186340332\n",
      "Finished epoch 1147, latest loss 0.7116749286651611\n",
      "Finished epoch 1148, latest loss 0.7117270827293396\n",
      "Finished epoch 1149, latest loss 0.7116749286651611\n",
      "Finished epoch 1150, latest loss 0.7116749286651611\n",
      "Finished epoch 1151, latest loss 0.7106719613075256\n",
      "Finished epoch 1152, latest loss 0.7106633186340332\n",
      "Finished epoch 1153, latest loss 0.7116749286651611\n",
      "Finished epoch 1154, latest loss 0.7125571966171265\n",
      "Finished epoch 1155, latest loss 0.7116749286651611\n",
      "Finished epoch 1156, latest loss 0.7106633186340332\n",
      "Finished epoch 1157, latest loss 0.7116749286651611\n",
      "Finished epoch 1158, latest loss 0.7126044631004333\n",
      "Finished epoch 1159, latest loss 0.7106633186340332\n",
      "Finished epoch 1160, latest loss 0.7106633186340332\n",
      "Finished epoch 1161, latest loss 0.7115922570228577\n",
      "Finished epoch 1162, latest loss 0.7110738158226013\n",
      "Finished epoch 1163, latest loss 0.710663378238678\n",
      "Finished epoch 1164, latest loss 0.7106633186340332\n",
      "Finished epoch 1165, latest loss 0.7106633186340332\n",
      "Finished epoch 1166, latest loss 0.7106633186340332\n",
      "Finished epoch 1167, latest loss 0.7106633186340332\n",
      "Finished epoch 1168, latest loss 0.7106633186340332\n",
      "Finished epoch 1169, latest loss 0.7106633186340332\n",
      "Finished epoch 1170, latest loss 0.7106633186340332\n",
      "Finished epoch 1171, latest loss 0.7106633186340332\n",
      "Finished epoch 1172, latest loss 0.7106633186340332\n",
      "Finished epoch 1173, latest loss 0.7106633186340332\n",
      "Finished epoch 1174, latest loss 0.7106633186340332\n",
      "Finished epoch 1175, latest loss 0.7106633186340332\n",
      "Finished epoch 1176, latest loss 0.7125224471092224\n",
      "Finished epoch 1177, latest loss 0.7115928530693054\n",
      "Finished epoch 1178, latest loss 0.7106633186340332\n",
      "Finished epoch 1179, latest loss 0.7106633186340332\n",
      "Finished epoch 1180, latest loss 0.712685227394104\n",
      "Finished epoch 1181, latest loss 0.7106645703315735\n",
      "Finished epoch 1182, latest loss 0.7116749286651611\n",
      "Finished epoch 1183, latest loss 0.7106633186340332\n",
      "Finished epoch 1184, latest loss 0.7130875587463379\n",
      "Finished epoch 1185, latest loss 0.7116749286651611\n",
      "Finished epoch 1186, latest loss 0.710663378238678\n",
      "Finished epoch 1187, latest loss 0.7106633186340332\n",
      "Finished epoch 1188, latest loss 0.7115928530693054\n",
      "Finished epoch 1189, latest loss 0.7106636762619019\n",
      "Finished epoch 1190, latest loss 0.7115928530693054\n",
      "Finished epoch 1191, latest loss 0.7106633186340332\n",
      "Finished epoch 1192, latest loss 0.7106633186340332\n",
      "Finished epoch 1193, latest loss 0.7106633186340332\n",
      "Finished epoch 1194, latest loss 0.7106633186340332\n",
      "Finished epoch 1195, latest loss 0.7106633186340332\n",
      "Finished epoch 1196, latest loss 0.7106633186340332\n",
      "Finished epoch 1197, latest loss 0.710663378238678\n",
      "Finished epoch 1198, latest loss 0.7106635570526123\n",
      "Finished epoch 1199, latest loss 0.7115929126739502\n",
      "Finished epoch 1200, latest loss 0.7106633186340332\n",
      "Finished epoch 1201, latest loss 0.7106633186340332\n",
      "Finished epoch 1202, latest loss 0.7106633186340332\n",
      "Finished epoch 1203, latest loss 0.7106633186340332\n",
      "Finished epoch 1204, latest loss 0.7135340571403503\n",
      "Finished epoch 1205, latest loss 0.711574375629425\n",
      "Finished epoch 1206, latest loss 0.7106633186340332\n",
      "Finished epoch 1207, latest loss 0.7106633186340332\n",
      "Finished epoch 1208, latest loss 0.7106633186340332\n",
      "Finished epoch 1209, latest loss 0.7106633186340332\n",
      "Finished epoch 1210, latest loss 0.7106633186340332\n",
      "Finished epoch 1211, latest loss 0.7106633186340332\n",
      "Finished epoch 1212, latest loss 0.7106635570526123\n",
      "Finished epoch 1213, latest loss 0.710667610168457\n",
      "Finished epoch 1214, latest loss 0.7106633186340332\n",
      "Finished epoch 1215, latest loss 0.7115928530693054\n",
      "Finished epoch 1216, latest loss 0.7123732566833496\n",
      "Finished epoch 1217, latest loss 0.7106633186340332\n",
      "Finished epoch 1218, latest loss 0.7106633186340332\n",
      "Finished epoch 1219, latest loss 0.7106633186340332\n",
      "Finished epoch 1220, latest loss 0.7106633186340332\n",
      "Finished epoch 1221, latest loss 0.7106637954711914\n",
      "Finished epoch 1222, latest loss 0.7106633186340332\n",
      "Finished epoch 1223, latest loss 0.7116749286651611\n",
      "Finished epoch 1224, latest loss 0.7106633186340332\n",
      "Finished epoch 1225, latest loss 0.7106633186340332\n",
      "Finished epoch 1226, latest loss 0.7106633186340332\n",
      "Finished epoch 1227, latest loss 0.7106633186340332\n",
      "Finished epoch 1228, latest loss 0.7106633186340332\n",
      "Finished epoch 1229, latest loss 0.7115927934646606\n",
      "Finished epoch 1230, latest loss 0.711575448513031\n",
      "Finished epoch 1231, latest loss 0.7115936875343323\n",
      "Finished epoch 1232, latest loss 0.7106633186340332\n",
      "Finished epoch 1233, latest loss 0.7106633186340332\n",
      "Finished epoch 1234, latest loss 0.7106633186340332\n",
      "Finished epoch 1235, latest loss 0.710663378238678\n",
      "Finished epoch 1236, latest loss 0.7124200463294983\n",
      "Finished epoch 1237, latest loss 0.7115925550460815\n",
      "Finished epoch 1238, latest loss 0.711301863193512\n",
      "Finished epoch 1239, latest loss 0.7106633186340332\n",
      "Finished epoch 1240, latest loss 0.7106633186340332\n",
      "Finished epoch 1241, latest loss 0.7106633186340332\n",
      "Finished epoch 1242, latest loss 0.7106633186340332\n",
      "Finished epoch 1243, latest loss 0.7106633186340332\n",
      "Finished epoch 1244, latest loss 0.7116749286651611\n",
      "Finished epoch 1245, latest loss 0.7112784385681152\n",
      "Finished epoch 1246, latest loss 0.7106633186340332\n",
      "Finished epoch 1247, latest loss 0.7106633186340332\n",
      "Finished epoch 1248, latest loss 0.7115586400032043\n",
      "Finished epoch 1249, latest loss 0.7106633186340332\n",
      "Finished epoch 1250, latest loss 0.7106654047966003\n",
      "Finished epoch 1251, latest loss 0.7106633186340332\n",
      "Finished epoch 1252, latest loss 0.7106633186340332\n",
      "Finished epoch 1253, latest loss 0.7106633186340332\n",
      "Finished epoch 1254, latest loss 0.7106633186340332\n",
      "Finished epoch 1255, latest loss 0.7106633186340332\n",
      "Finished epoch 1256, latest loss 0.7106633186340332\n",
      "Finished epoch 1257, latest loss 0.7106633186340332\n",
      "Finished epoch 1258, latest loss 0.7116748690605164\n",
      "Finished epoch 1259, latest loss 0.7116749286651611\n",
      "Finished epoch 1260, latest loss 0.7106633186340332\n",
      "Finished epoch 1261, latest loss 0.7106633186340332\n",
      "Finished epoch 1262, latest loss 0.7106633186340332\n",
      "Finished epoch 1263, latest loss 0.7106633186340332\n",
      "Finished epoch 1264, latest loss 0.7116749286651611\n",
      "Finished epoch 1265, latest loss 0.7106633186340332\n",
      "Finished epoch 1266, latest loss 0.7106633186340332\n",
      "Finished epoch 1267, latest loss 0.711592972278595\n",
      "Finished epoch 1268, latest loss 0.7115928530693054\n",
      "Finished epoch 1269, latest loss 0.7116749286651611\n",
      "Finished epoch 1270, latest loss 0.7116749286651611\n",
      "Finished epoch 1271, latest loss 0.7106633186340332\n",
      "Finished epoch 1272, latest loss 0.7106633186340332\n",
      "Finished epoch 1273, latest loss 0.7106633186340332\n",
      "Finished epoch 1274, latest loss 0.7106633186340332\n",
      "Finished epoch 1275, latest loss 0.7106633186340332\n",
      "Finished epoch 1276, latest loss 0.7106633186340332\n",
      "Finished epoch 1277, latest loss 0.7106633186340332\n",
      "Finished epoch 1278, latest loss 0.7106636762619019\n",
      "Finished epoch 1279, latest loss 0.7106633186340332\n",
      "Finished epoch 1280, latest loss 0.7115892767906189\n",
      "Finished epoch 1281, latest loss 0.7106633186340332\n",
      "Finished epoch 1282, latest loss 0.7106633186340332\n",
      "Finished epoch 1283, latest loss 0.7115929126739502\n",
      "Finished epoch 1284, latest loss 0.7106633186340332\n",
      "Finished epoch 1285, latest loss 0.7115996479988098\n",
      "Finished epoch 1286, latest loss 0.7106633186340332\n",
      "Finished epoch 1287, latest loss 0.7106633186340332\n",
      "Finished epoch 1288, latest loss 0.7106633186340332\n",
      "Finished epoch 1289, latest loss 0.7106633186340332\n",
      "Finished epoch 1290, latest loss 0.7106633186340332\n",
      "Finished epoch 1291, latest loss 0.7106633186340332\n",
      "Finished epoch 1292, latest loss 0.7106633186340332\n",
      "Finished epoch 1293, latest loss 0.7106633186340332\n",
      "Finished epoch 1294, latest loss 0.710665762424469\n",
      "Finished epoch 1295, latest loss 0.7115921378135681\n",
      "Finished epoch 1296, latest loss 0.7115920782089233\n",
      "Finished epoch 1297, latest loss 0.7106633186340332\n",
      "Finished epoch 1298, latest loss 0.7106633186340332\n",
      "Finished epoch 1299, latest loss 0.7115929126739502\n",
      "Finished epoch 1300, latest loss 0.7106633186340332\n",
      "Finished epoch 1301, latest loss 0.7106633186340332\n",
      "Finished epoch 1302, latest loss 0.7108463048934937\n",
      "Finished epoch 1303, latest loss 0.7106752991676331\n",
      "Finished epoch 1304, latest loss 0.7125223875045776\n",
      "Finished epoch 1305, latest loss 0.710663378238678\n",
      "Finished epoch 1306, latest loss 0.7126044034957886\n",
      "Finished epoch 1307, latest loss 0.7106633186340332\n",
      "Finished epoch 1308, latest loss 0.7116749286651611\n",
      "Finished epoch 1309, latest loss 0.7126255035400391\n",
      "Finished epoch 1310, latest loss 0.7106633186340332\n",
      "Finished epoch 1311, latest loss 0.710663378238678\n",
      "Finished epoch 1312, latest loss 0.7106633186340332\n",
      "Finished epoch 1313, latest loss 0.7106633186340332\n",
      "Finished epoch 1314, latest loss 0.7106633186340332\n",
      "Finished epoch 1315, latest loss 0.7115929126739502\n",
      "Finished epoch 1316, latest loss 0.7106633186340332\n",
      "Finished epoch 1317, latest loss 0.7106633186340332\n",
      "Finished epoch 1318, latest loss 0.7106633186340332\n",
      "Finished epoch 1319, latest loss 0.7106633186340332\n",
      "Finished epoch 1320, latest loss 0.7116749286651611\n",
      "Finished epoch 1321, latest loss 0.7116749286651611\n",
      "Finished epoch 1322, latest loss 0.7106633186340332\n",
      "Finished epoch 1323, latest loss 0.7116149663925171\n",
      "Finished epoch 1324, latest loss 0.711584210395813\n",
      "Finished epoch 1325, latest loss 0.7106633186340332\n",
      "Finished epoch 1326, latest loss 0.7106633186340332\n",
      "Finished epoch 1327, latest loss 0.7106633186340332\n",
      "Finished epoch 1328, latest loss 0.7106633186340332\n",
      "Finished epoch 1329, latest loss 0.7115927338600159\n",
      "Finished epoch 1330, latest loss 0.7106633186340332\n",
      "Finished epoch 1331, latest loss 0.7106633186340332\n",
      "Finished epoch 1332, latest loss 0.7106633186340332\n",
      "Finished epoch 1333, latest loss 0.7106633186340332\n",
      "Finished epoch 1334, latest loss 0.7106633186340332\n",
      "Finished epoch 1335, latest loss 0.7115929126739502\n",
      "Finished epoch 1336, latest loss 0.7106633186340332\n",
      "Finished epoch 1337, latest loss 0.710675060749054\n",
      "Finished epoch 1338, latest loss 0.7106771469116211\n",
      "Finished epoch 1339, latest loss 0.7115929126739502\n",
      "Finished epoch 1340, latest loss 0.7106636166572571\n",
      "Finished epoch 1341, latest loss 0.7106637954711914\n",
      "Finished epoch 1342, latest loss 0.7106633186340332\n",
      "Finished epoch 1343, latest loss 0.7106633186340332\n",
      "Finished epoch 1344, latest loss 0.7106633186340332\n",
      "Finished epoch 1345, latest loss 0.7115928530693054\n",
      "Finished epoch 1346, latest loss 0.7126044631004333\n",
      "Finished epoch 1347, latest loss 0.7106633186340332\n",
      "Finished epoch 1348, latest loss 0.7106633186340332\n",
      "Finished epoch 1349, latest loss 0.7106633186340332\n",
      "Finished epoch 1350, latest loss 0.7106633186340332\n",
      "Finished epoch 1351, latest loss 0.7114973068237305\n",
      "Finished epoch 1352, latest loss 0.7106633186340332\n",
      "Finished epoch 1353, latest loss 0.7106633186340332\n",
      "Finished epoch 1354, latest loss 0.7106633186340332\n",
      "Finished epoch 1355, latest loss 0.7106636166572571\n",
      "Finished epoch 1356, latest loss 0.7107197642326355\n",
      "Finished epoch 1357, latest loss 0.7106633186340332\n",
      "Finished epoch 1358, latest loss 0.7115926146507263\n",
      "Finished epoch 1359, latest loss 0.7106633186340332\n",
      "Finished epoch 1360, latest loss 0.7106633186340332\n",
      "Finished epoch 1361, latest loss 0.7106633186340332\n",
      "Finished epoch 1362, latest loss 0.7106633186340332\n",
      "Finished epoch 1363, latest loss 0.7106633186340332\n",
      "Finished epoch 1364, latest loss 0.7116749286651611\n",
      "Finished epoch 1365, latest loss 0.7115929126739502\n",
      "Finished epoch 1366, latest loss 0.7106633186340332\n",
      "Finished epoch 1367, latest loss 0.7106633186340332\n",
      "Finished epoch 1368, latest loss 0.7106633186340332\n",
      "Finished epoch 1369, latest loss 0.7116749286651611\n",
      "Finished epoch 1370, latest loss 0.7116749286651611\n",
      "Finished epoch 1371, latest loss 0.7123919725418091\n",
      "Finished epoch 1372, latest loss 0.7116773128509521\n",
      "Finished epoch 1373, latest loss 0.7126865386962891\n",
      "Finished epoch 1374, latest loss 0.7126865386962891\n",
      "Finished epoch 1375, latest loss 0.7136160731315613\n",
      "Finished epoch 1376, latest loss 0.7116749286651611\n",
      "Finished epoch 1377, latest loss 0.7106633186340332\n",
      "Finished epoch 1378, latest loss 0.7106633186340332\n",
      "Finished epoch 1379, latest loss 0.711649477481842\n",
      "Finished epoch 1380, latest loss 0.7106633186340332\n",
      "Finished epoch 1381, latest loss 0.7106633186340332\n",
      "Finished epoch 1382, latest loss 0.7106633186340332\n",
      "Finished epoch 1383, latest loss 0.7106633186340332\n",
      "Finished epoch 1384, latest loss 0.7106633186340332\n",
      "Finished epoch 1385, latest loss 0.7106633186340332\n",
      "Finished epoch 1386, latest loss 0.7123382091522217\n",
      "Finished epoch 1387, latest loss 0.7116749286651611\n",
      "Finished epoch 1388, latest loss 0.7106633186340332\n",
      "Finished epoch 1389, latest loss 0.7106633186340332\n",
      "Finished epoch 1390, latest loss 0.7106637358665466\n",
      "Finished epoch 1391, latest loss 0.7115929126739502\n",
      "Finished epoch 1392, latest loss 0.7106633186340332\n",
      "Finished epoch 1393, latest loss 0.7116865515708923\n",
      "Finished epoch 1394, latest loss 0.7116749286651611\n",
      "Finished epoch 1395, latest loss 0.7116749286651611\n",
      "Finished epoch 1396, latest loss 0.7116749286651611\n",
      "Finished epoch 1397, latest loss 0.7122886180877686\n",
      "Finished epoch 1398, latest loss 0.7116749286651611\n",
      "Finished epoch 1399, latest loss 0.7116749286651611\n",
      "Finished epoch 1400, latest loss 0.7116749286651611\n",
      "Finished epoch 1401, latest loss 0.7116749286651611\n",
      "Finished epoch 1402, latest loss 0.7116749286651611\n",
      "Finished epoch 1403, latest loss 0.7116068005561829\n",
      "Finished epoch 1404, latest loss 0.7114782333374023\n",
      "Finished epoch 1405, latest loss 0.7116749286651611\n",
      "Finished epoch 1406, latest loss 0.7106633186340332\n",
      "Finished epoch 1407, latest loss 0.7106641530990601\n",
      "Finished epoch 1408, latest loss 0.7116749286651611\n",
      "Finished epoch 1409, latest loss 0.7106633186340332\n",
      "Finished epoch 1410, latest loss 0.7106633186340332\n",
      "Finished epoch 1411, latest loss 0.7136979103088379\n",
      "Finished epoch 1412, latest loss 0.7116749286651611\n",
      "Finished epoch 1413, latest loss 0.7116749286651611\n",
      "Finished epoch 1414, latest loss 0.711675226688385\n",
      "Finished epoch 1415, latest loss 0.7116749286651611\n",
      "Finished epoch 1416, latest loss 0.7116749286651611\n",
      "Finished epoch 1417, latest loss 0.7131468653678894\n",
      "Finished epoch 1418, latest loss 0.7116749286651611\n",
      "Finished epoch 1419, latest loss 0.7126044631004333\n",
      "Finished epoch 1420, latest loss 0.7126044631004333\n",
      "Finished epoch 1421, latest loss 0.7125952839851379\n",
      "Finished epoch 1422, latest loss 0.7116749286651611\n",
      "Finished epoch 1423, latest loss 0.7136985063552856\n",
      "Finished epoch 1424, latest loss 0.7116785645484924\n",
      "Finished epoch 1425, latest loss 0.7106633186340332\n",
      "Finished epoch 1426, latest loss 0.7126865386962891\n",
      "Finished epoch 1427, latest loss 0.7116749286651611\n",
      "Finished epoch 1428, latest loss 0.7106633186340332\n",
      "Finished epoch 1429, latest loss 0.7120213508605957\n",
      "Finished epoch 1430, latest loss 0.7116749286651611\n",
      "Finished epoch 1431, latest loss 0.7116749882698059\n",
      "Finished epoch 1432, latest loss 0.7116749286651611\n",
      "Finished epoch 1433, latest loss 0.7116749286651611\n",
      "Finished epoch 1434, latest loss 0.7120906114578247\n",
      "Finished epoch 1435, latest loss 0.7116845846176147\n",
      "Finished epoch 1436, latest loss 0.7106640934944153\n",
      "Finished epoch 1437, latest loss 0.7106633186340332\n",
      "Finished epoch 1438, latest loss 0.7116749286651611\n",
      "Finished epoch 1439, latest loss 0.7126004695892334\n",
      "Finished epoch 1440, latest loss 0.7106633186340332\n",
      "Finished epoch 1441, latest loss 0.710663378238678\n",
      "Finished epoch 1442, latest loss 0.7106633186340332\n",
      "Finished epoch 1443, latest loss 0.7106633186340332\n",
      "Finished epoch 1444, latest loss 0.7106633186340332\n",
      "Finished epoch 1445, latest loss 0.7106633186340332\n",
      "Finished epoch 1446, latest loss 0.7116749286651611\n",
      "Finished epoch 1447, latest loss 0.7126044631004333\n",
      "Finished epoch 1448, latest loss 0.7134991884231567\n",
      "Finished epoch 1449, latest loss 0.7126044631004333\n",
      "Finished epoch 1450, latest loss 0.7135340571403503\n",
      "Finished epoch 1451, latest loss 0.7106636166572571\n",
      "Finished epoch 1452, latest loss 0.7128946185112\n",
      "Finished epoch 1453, latest loss 0.7116749286651611\n",
      "Finished epoch 1454, latest loss 0.7126044631004333\n",
      "Finished epoch 1455, latest loss 0.7126039266586304\n",
      "Finished epoch 1456, latest loss 0.7106633186340332\n",
      "Finished epoch 1457, latest loss 0.7106633186340332\n",
      "Finished epoch 1458, latest loss 0.7116749286651611\n",
      "Finished epoch 1459, latest loss 0.7116749286651611\n",
      "Finished epoch 1460, latest loss 0.7116749286651611\n",
      "Finished epoch 1461, latest loss 0.7116749286651611\n",
      "Finished epoch 1462, latest loss 0.7135340571403503\n",
      "Finished epoch 1463, latest loss 0.7126044631004333\n",
      "Finished epoch 1464, latest loss 0.7116749286651611\n",
      "Finished epoch 1465, latest loss 0.7116749286651611\n",
      "Finished epoch 1466, latest loss 0.7116749286651611\n",
      "Finished epoch 1467, latest loss 0.7116749286651611\n",
      "Finished epoch 1468, latest loss 0.7116749286651611\n",
      "Finished epoch 1469, latest loss 0.7116749286651611\n",
      "Finished epoch 1470, latest loss 0.7116749286651611\n",
      "Finished epoch 1471, latest loss 0.7126044631004333\n",
      "Finished epoch 1472, latest loss 0.7126044631004333\n",
      "Finished epoch 1473, latest loss 0.7126033902168274\n",
      "Finished epoch 1474, latest loss 0.7126044034957886\n",
      "Finished epoch 1475, latest loss 0.7106980085372925\n",
      "Finished epoch 1476, latest loss 0.7106872200965881\n",
      "Finished epoch 1477, latest loss 0.7113270163536072\n",
      "Finished epoch 1478, latest loss 0.7106633186340332\n",
      "Finished epoch 1479, latest loss 0.7106633186340332\n",
      "Finished epoch 1480, latest loss 0.7116749286651611\n",
      "Finished epoch 1481, latest loss 0.7116749286651611\n",
      "Finished epoch 1482, latest loss 0.7106633186340332\n",
      "Finished epoch 1483, latest loss 0.7116749286651611\n",
      "Finished epoch 1484, latest loss 0.7126643657684326\n",
      "Finished epoch 1485, latest loss 0.7116749286651611\n",
      "Finished epoch 1486, latest loss 0.7116749286651611\n",
      "Finished epoch 1487, latest loss 0.7116754055023193\n",
      "Finished epoch 1488, latest loss 0.7115928530693054\n",
      "Finished epoch 1489, latest loss 0.7118001580238342\n",
      "Finished epoch 1490, latest loss 0.7126044631004333\n",
      "Finished epoch 1491, latest loss 0.7116755843162537\n",
      "Finished epoch 1492, latest loss 0.7126044034957886\n",
      "Finished epoch 1493, latest loss 0.7106633186340332\n",
      "Finished epoch 1494, latest loss 0.7106633186340332\n",
      "Finished epoch 1495, latest loss 0.7115929126739502\n",
      "Finished epoch 1496, latest loss 0.7116749286651611\n",
      "Finished epoch 1497, latest loss 0.7115929126739502\n",
      "Finished epoch 1498, latest loss 0.7135341167449951\n",
      "Finished epoch 1499, latest loss 0.7116751074790955\n",
      "Finished epoch 1500, latest loss 0.712604284286499\n",
      "Finished epoch 1501, latest loss 0.7115930318832397\n",
      "Finished epoch 1502, latest loss 0.7106633186340332\n",
      "Finished epoch 1503, latest loss 0.7106633186340332\n",
      "Finished epoch 1504, latest loss 0.7116749286651611\n",
      "Finished epoch 1505, latest loss 0.7116749286651611\n",
      "Finished epoch 1506, latest loss 0.7106633186340332\n",
      "Finished epoch 1507, latest loss 0.7116749286651611\n",
      "Finished epoch 1508, latest loss 0.7124266624450684\n",
      "Finished epoch 1509, latest loss 0.7106633186340332\n",
      "Finished epoch 1510, latest loss 0.7116749286651611\n",
      "Finished epoch 1511, latest loss 0.7126044034957886\n",
      "Finished epoch 1512, latest loss 0.7106643915176392\n",
      "Finished epoch 1513, latest loss 0.7116749286651611\n",
      "Finished epoch 1514, latest loss 0.712671160697937\n",
      "Finished epoch 1515, latest loss 0.7126865386962891\n",
      "Finished epoch 1516, latest loss 0.7116756439208984\n",
      "Finished epoch 1517, latest loss 0.7106725573539734\n",
      "Finished epoch 1518, latest loss 0.7116749882698059\n",
      "Finished epoch 1519, latest loss 0.7116752862930298\n",
      "Finished epoch 1520, latest loss 0.7116749882698059\n",
      "Finished epoch 1521, latest loss 0.7126853466033936\n",
      "Finished epoch 1522, latest loss 0.7116749286651611\n",
      "Finished epoch 1523, latest loss 0.7116749286651611\n",
      "Finished epoch 1524, latest loss 0.7116749286651611\n",
      "Finished epoch 1525, latest loss 0.7116749286651611\n",
      "Finished epoch 1526, latest loss 0.7116335034370422\n",
      "Finished epoch 1527, latest loss 0.7116749286651611\n",
      "Finished epoch 1528, latest loss 0.7106633186340332\n",
      "Finished epoch 1529, latest loss 0.7116612792015076\n",
      "Finished epoch 1530, latest loss 0.7106633186340332\n",
      "Finished epoch 1531, latest loss 0.7106633186340332\n",
      "Finished epoch 1532, latest loss 0.7113175392150879\n",
      "Finished epoch 1533, latest loss 0.7106633186340332\n",
      "Finished epoch 1534, latest loss 0.7106633186340332\n",
      "Finished epoch 1535, latest loss 0.7106633186340332\n",
      "Finished epoch 1536, latest loss 0.7106703519821167\n",
      "Finished epoch 1537, latest loss 0.7116749286651611\n",
      "Finished epoch 1538, latest loss 0.7126859426498413\n",
      "Finished epoch 1539, latest loss 0.7116749286651611\n",
      "Finished epoch 1540, latest loss 0.7116749286651611\n",
      "Finished epoch 1541, latest loss 0.7126044034957886\n",
      "Finished epoch 1542, latest loss 0.7116749286651611\n",
      "Finished epoch 1543, latest loss 0.7106633186340332\n",
      "Finished epoch 1544, latest loss 0.7106633186340332\n",
      "Finished epoch 1545, latest loss 0.7106633186340332\n",
      "Finished epoch 1546, latest loss 0.7106633186340332\n",
      "Finished epoch 1547, latest loss 0.7106633186340332\n",
      "Finished epoch 1548, latest loss 0.7106633186340332\n",
      "Finished epoch 1549, latest loss 0.7106633186340332\n",
      "Finished epoch 1550, latest loss 0.7106633186340332\n",
      "Finished epoch 1551, latest loss 0.7106633186340332\n",
      "Finished epoch 1552, latest loss 0.7106633186340332\n",
      "Finished epoch 1553, latest loss 0.7116749286651611\n",
      "Finished epoch 1554, latest loss 0.7106633186340332\n",
      "Finished epoch 1555, latest loss 0.7126044631004333\n",
      "Finished epoch 1556, latest loss 0.7106633186340332\n",
      "Finished epoch 1557, latest loss 0.7106633186340332\n",
      "Finished epoch 1558, latest loss 0.7107036709785461\n",
      "Finished epoch 1559, latest loss 0.7106633186340332\n",
      "Finished epoch 1560, latest loss 0.7106633186340332\n",
      "Finished epoch 1561, latest loss 0.7106633186340332\n",
      "Finished epoch 1562, latest loss 0.7106633186340332\n",
      "Finished epoch 1563, latest loss 0.7106633186340332\n",
      "Finished epoch 1564, latest loss 0.7106633186340332\n",
      "Finished epoch 1565, latest loss 0.7116749286651611\n",
      "Finished epoch 1566, latest loss 0.7106633186340332\n",
      "Finished epoch 1567, latest loss 0.7106633186340332\n",
      "Finished epoch 1568, latest loss 0.7106654047966003\n",
      "Finished epoch 1569, latest loss 0.7106633186340332\n",
      "Finished epoch 1570, latest loss 0.7106841802597046\n",
      "Finished epoch 1571, latest loss 0.7106633186340332\n",
      "Finished epoch 1572, latest loss 0.7106633186340332\n",
      "Finished epoch 1573, latest loss 0.7106633186340332\n",
      "Finished epoch 1574, latest loss 0.7106633186340332\n",
      "Finished epoch 1575, latest loss 0.7116749286651611\n",
      "Finished epoch 1576, latest loss 0.7106633186340332\n",
      "Finished epoch 1577, latest loss 0.7107179760932922\n",
      "Finished epoch 1578, latest loss 0.7106633186340332\n",
      "Finished epoch 1579, latest loss 0.7106633186340332\n",
      "Finished epoch 1580, latest loss 0.7106633186340332\n",
      "Finished epoch 1581, latest loss 0.710663378238678\n",
      "Finished epoch 1582, latest loss 0.710663914680481\n",
      "Finished epoch 1583, latest loss 0.7115928530693054\n",
      "Finished epoch 1584, latest loss 0.7115928530693054\n",
      "Finished epoch 1585, latest loss 0.7106633186340332\n",
      "Finished epoch 1586, latest loss 0.7125224471092224\n",
      "Finished epoch 1587, latest loss 0.7115928530693054\n",
      "Finished epoch 1588, latest loss 0.7116591930389404\n",
      "Finished epoch 1589, latest loss 0.7106633186340332\n",
      "Finished epoch 1590, latest loss 0.7106633186340332\n",
      "Finished epoch 1591, latest loss 0.7106633186340332\n",
      "Finished epoch 1592, latest loss 0.7115928530693054\n",
      "Finished epoch 1593, latest loss 0.7126044631004333\n",
      "Finished epoch 1594, latest loss 0.7115928530693054\n",
      "Finished epoch 1595, latest loss 0.7114904522895813\n",
      "Finished epoch 1596, latest loss 0.7106633186340332\n",
      "Finished epoch 1597, latest loss 0.7106714844703674\n",
      "Finished epoch 1598, latest loss 0.7116749286651611\n",
      "Finished epoch 1599, latest loss 0.7106633186340332\n",
      "Finished epoch 1600, latest loss 0.7116749286651611\n",
      "Finished epoch 1601, latest loss 0.7126861214637756\n",
      "Finished epoch 1602, latest loss 0.7106634378433228\n",
      "Finished epoch 1603, latest loss 0.7106633186340332\n",
      "Finished epoch 1604, latest loss 0.7106633186340332\n",
      "Finished epoch 1605, latest loss 0.7106636166572571\n",
      "Finished epoch 1606, latest loss 0.7106633186340332\n",
      "Finished epoch 1607, latest loss 0.710805356502533\n",
      "Finished epoch 1608, latest loss 0.7106633186340332\n",
      "Finished epoch 1609, latest loss 0.7106633186340332\n",
      "Finished epoch 1610, latest loss 0.7106801867485046\n",
      "Finished epoch 1611, latest loss 0.710669994354248\n",
      "Finished epoch 1612, latest loss 0.7106633186340332\n",
      "Finished epoch 1613, latest loss 0.7106633186340332\n",
      "Finished epoch 1614, latest loss 0.7106633186340332\n",
      "Finished epoch 1615, latest loss 0.7106633186340332\n",
      "Finished epoch 1616, latest loss 0.7106633186340332\n",
      "Finished epoch 1617, latest loss 0.7106633186340332\n",
      "Finished epoch 1618, latest loss 0.7106633186340332\n",
      "Finished epoch 1619, latest loss 0.7106633186340332\n",
      "Finished epoch 1620, latest loss 0.7117199897766113\n",
      "Finished epoch 1621, latest loss 0.7106633186340332\n",
      "Finished epoch 1622, latest loss 0.7116749286651611\n",
      "Finished epoch 1623, latest loss 0.7116749286651611\n",
      "Finished epoch 1624, latest loss 0.7115929126739502\n",
      "Finished epoch 1625, latest loss 0.7106633186340332\n",
      "Finished epoch 1626, latest loss 0.7106633186340332\n",
      "Finished epoch 1627, latest loss 0.7106633186340332\n",
      "Finished epoch 1628, latest loss 0.7115928530693054\n",
      "Finished epoch 1629, latest loss 0.7106633186340332\n",
      "Finished epoch 1630, latest loss 0.7116668224334717\n",
      "Finished epoch 1631, latest loss 0.7116749286651611\n",
      "Finished epoch 1632, latest loss 0.7116749286651611\n",
      "Finished epoch 1633, latest loss 0.7116749286651611\n",
      "Finished epoch 1634, latest loss 0.7106636166572571\n",
      "Finished epoch 1635, latest loss 0.7106640934944153\n",
      "Finished epoch 1636, latest loss 0.7136160731315613\n",
      "Finished epoch 1637, latest loss 0.7106633186340332\n",
      "Finished epoch 1638, latest loss 0.7106633186340332\n",
      "Finished epoch 1639, latest loss 0.7106633186340332\n",
      "Finished epoch 1640, latest loss 0.7116749286651611\n",
      "Finished epoch 1641, latest loss 0.7106633186340332\n",
      "Finished epoch 1642, latest loss 0.7116742134094238\n",
      "Finished epoch 1643, latest loss 0.7106633186340332\n",
      "Finished epoch 1644, latest loss 0.7116749286651611\n",
      "Finished epoch 1645, latest loss 0.7126865983009338\n",
      "Finished epoch 1646, latest loss 0.7116746306419373\n",
      "Finished epoch 1647, latest loss 0.7116749286651611\n",
      "Finished epoch 1648, latest loss 0.7106633186340332\n",
      "Finished epoch 1649, latest loss 0.7116749286651611\n",
      "Finished epoch 1650, latest loss 0.7116956114768982\n",
      "Finished epoch 1651, latest loss 0.7106960415840149\n",
      "Finished epoch 1652, latest loss 0.7106633186340332\n",
      "Finished epoch 1653, latest loss 0.711797297000885\n",
      "Finished epoch 1654, latest loss 0.7106633186340332\n",
      "Finished epoch 1655, latest loss 0.7106633186340332\n",
      "Finished epoch 1656, latest loss 0.7106633186340332\n",
      "Finished epoch 1657, latest loss 0.7115923762321472\n",
      "Finished epoch 1658, latest loss 0.7108813524246216\n",
      "Finished epoch 1659, latest loss 0.7106636166572571\n",
      "Finished epoch 1660, latest loss 0.7106633186340332\n",
      "Finished epoch 1661, latest loss 0.7106633186340332\n",
      "Finished epoch 1662, latest loss 0.7106633186340332\n",
      "Finished epoch 1663, latest loss 0.7106633186340332\n",
      "Finished epoch 1664, latest loss 0.7110446691513062\n",
      "Finished epoch 1665, latest loss 0.7106633186340332\n",
      "Finished epoch 1666, latest loss 0.7106633186340332\n",
      "Finished epoch 1667, latest loss 0.7106633186340332\n",
      "Finished epoch 1668, latest loss 0.7106633186340332\n",
      "Finished epoch 1669, latest loss 0.7116371989250183\n",
      "Finished epoch 1670, latest loss 0.7106633186340332\n",
      "Finished epoch 1671, latest loss 0.7106633186340332\n",
      "Finished epoch 1672, latest loss 0.7106633186340332\n",
      "Finished epoch 1673, latest loss 0.711586594581604\n",
      "Finished epoch 1674, latest loss 0.7106633186340332\n",
      "Finished epoch 1675, latest loss 0.7110123038291931\n",
      "Finished epoch 1676, latest loss 0.7106633186340332\n",
      "Finished epoch 1677, latest loss 0.7106633186340332\n",
      "Finished epoch 1678, latest loss 0.7106633186340332\n",
      "Finished epoch 1679, latest loss 0.7106633186340332\n",
      "Finished epoch 1680, latest loss 0.7106633186340332\n",
      "Finished epoch 1681, latest loss 0.7106633186340332\n",
      "Finished epoch 1682, latest loss 0.7106633186340332\n",
      "Finished epoch 1683, latest loss 0.7106633186340332\n",
      "Finished epoch 1684, latest loss 0.7106633186340332\n",
      "Finished epoch 1685, latest loss 0.7106633186340332\n",
      "Finished epoch 1686, latest loss 0.7106633186340332\n",
      "Finished epoch 1687, latest loss 0.7106633186340332\n",
      "Finished epoch 1688, latest loss 0.7106633186340332\n",
      "Finished epoch 1689, latest loss 0.7106633186340332\n",
      "Finished epoch 1690, latest loss 0.7106633186340332\n",
      "Finished epoch 1691, latest loss 0.7106633186340332\n",
      "Finished epoch 1692, latest loss 0.7116749286651611\n",
      "Finished epoch 1693, latest loss 0.7106633186340332\n",
      "Finished epoch 1694, latest loss 0.7125664949417114\n",
      "Finished epoch 1695, latest loss 0.7106633186340332\n",
      "Finished epoch 1696, latest loss 0.7106633186340332\n",
      "Finished epoch 1697, latest loss 0.7106633186340332\n",
      "Finished epoch 1698, latest loss 0.7106633186340332\n",
      "Finished epoch 1699, latest loss 0.7116748094558716\n",
      "Finished epoch 1700, latest loss 0.7106633186340332\n",
      "Finished epoch 1701, latest loss 0.7106633186340332\n",
      "Finished epoch 1702, latest loss 0.7116748094558716\n",
      "Finished epoch 1703, latest loss 0.7115222811698914\n",
      "Finished epoch 1704, latest loss 0.7106633186340332\n",
      "Finished epoch 1705, latest loss 0.7106633186340332\n",
      "Finished epoch 1706, latest loss 0.7116749286651611\n",
      "Finished epoch 1707, latest loss 0.7106633186340332\n",
      "Finished epoch 1708, latest loss 0.7106633186340332\n",
      "Finished epoch 1709, latest loss 0.7106633186340332\n",
      "Finished epoch 1710, latest loss 0.7106633186340332\n",
      "Finished epoch 1711, latest loss 0.7116749286651611\n",
      "Finished epoch 1712, latest loss 0.711592972278595\n",
      "Finished epoch 1713, latest loss 0.7116749286651611\n",
      "Finished epoch 1714, latest loss 0.7116749286651611\n",
      "Finished epoch 1715, latest loss 0.7116749286651611\n",
      "Finished epoch 1716, latest loss 0.7106633186340332\n",
      "Finished epoch 1717, latest loss 0.711675226688385\n",
      "Finished epoch 1718, latest loss 0.7126044631004333\n",
      "Finished epoch 1719, latest loss 0.7106633186340332\n",
      "Finished epoch 1720, latest loss 0.7106633186340332\n",
      "Finished epoch 1721, latest loss 0.7106633186340332\n",
      "Finished epoch 1722, latest loss 0.7106633186340332\n",
      "Finished epoch 1723, latest loss 0.7106633186340332\n",
      "Finished epoch 1724, latest loss 0.7118350863456726\n",
      "Finished epoch 1725, latest loss 0.7116751074790955\n",
      "Finished epoch 1726, latest loss 0.7145436406135559\n",
      "Finished epoch 1727, latest loss 0.713532030582428\n",
      "Finished epoch 1728, latest loss 0.7116749286651611\n",
      "Finished epoch 1729, latest loss 0.71067214012146\n",
      "Finished epoch 1730, latest loss 0.7106633186340332\n",
      "Finished epoch 1731, latest loss 0.7116749286651611\n",
      "Finished epoch 1732, latest loss 0.7106633186340332\n",
      "Finished epoch 1733, latest loss 0.7106633186340332\n",
      "Finished epoch 1734, latest loss 0.7106633186340332\n",
      "Finished epoch 1735, latest loss 0.7116754651069641\n",
      "Finished epoch 1736, latest loss 0.7107237577438354\n",
      "Finished epoch 1737, latest loss 0.7126039862632751\n",
      "Finished epoch 1738, latest loss 0.7106633186340332\n",
      "Finished epoch 1739, latest loss 0.7106633186340332\n",
      "Finished epoch 1740, latest loss 0.7106633186340332\n",
      "Finished epoch 1741, latest loss 0.7115928530693054\n",
      "Finished epoch 1742, latest loss 0.7106634378433228\n",
      "Finished epoch 1743, latest loss 0.7106633186340332\n",
      "Finished epoch 1744, latest loss 0.7106633186340332\n",
      "Finished epoch 1745, latest loss 0.7106700539588928\n",
      "Finished epoch 1746, latest loss 0.7106633186340332\n",
      "Finished epoch 1747, latest loss 0.7115928530693054\n",
      "Finished epoch 1748, latest loss 0.7106633186340332\n",
      "Finished epoch 1749, latest loss 0.7106633186340332\n",
      "Finished epoch 1750, latest loss 0.7106633186340332\n",
      "Finished epoch 1751, latest loss 0.7115928530693054\n",
      "Finished epoch 1752, latest loss 0.7106648087501526\n",
      "Finished epoch 1753, latest loss 0.7126893997192383\n",
      "Finished epoch 1754, latest loss 0.7115811109542847\n",
      "Finished epoch 1755, latest loss 0.710674524307251\n",
      "Finished epoch 1756, latest loss 0.7115940451622009\n",
      "Finished epoch 1757, latest loss 0.7106633186340332\n",
      "Finished epoch 1758, latest loss 0.710663378238678\n",
      "Finished epoch 1759, latest loss 0.7115762233734131\n",
      "Finished epoch 1760, latest loss 0.7115928530693054\n",
      "Finished epoch 1761, latest loss 0.7106633186340332\n",
      "Finished epoch 1762, latest loss 0.7115928530693054\n",
      "Finished epoch 1763, latest loss 0.7115921378135681\n",
      "Finished epoch 1764, latest loss 0.7106634378433228\n",
      "Finished epoch 1765, latest loss 0.711578905582428\n",
      "Finished epoch 1766, latest loss 0.7106633186340332\n",
      "Finished epoch 1767, latest loss 0.7106633186340332\n",
      "Finished epoch 1768, latest loss 0.7106633186340332\n",
      "Finished epoch 1769, latest loss 0.7115928530693054\n",
      "Finished epoch 1770, latest loss 0.7106634378433228\n",
      "Finished epoch 1771, latest loss 0.7097337245941162\n",
      "Finished epoch 1772, latest loss 0.710663378238678\n",
      "Finished epoch 1773, latest loss 0.7115928530693054\n",
      "Finished epoch 1774, latest loss 0.7106888890266418\n",
      "Finished epoch 1775, latest loss 0.7106633186340332\n",
      "Finished epoch 1776, latest loss 0.7097337245941162\n",
      "Finished epoch 1777, latest loss 0.709740400314331\n",
      "Finished epoch 1778, latest loss 0.7097337245941162\n",
      "Finished epoch 1779, latest loss 0.7097337245941162\n",
      "Finished epoch 1780, latest loss 0.7106046080589294\n",
      "Finished epoch 1781, latest loss 0.7097337245941162\n",
      "Finished epoch 1782, latest loss 0.7097338438034058\n",
      "Finished epoch 1783, latest loss 0.7097337245941162\n",
      "Finished epoch 1784, latest loss 0.7097352743148804\n",
      "Finished epoch 1785, latest loss 0.7097337245941162\n",
      "Finished epoch 1786, latest loss 0.7097337245941162\n",
      "Finished epoch 1787, latest loss 0.7106640934944153\n",
      "Finished epoch 1788, latest loss 0.7115928530693054\n",
      "Finished epoch 1789, latest loss 0.711674690246582\n",
      "Finished epoch 1790, latest loss 0.7099435925483704\n",
      "Finished epoch 1791, latest loss 0.7097337245941162\n",
      "Finished epoch 1792, latest loss 0.7097337245941162\n",
      "Finished epoch 1793, latest loss 0.7097337245941162\n",
      "Finished epoch 1794, latest loss 0.7097337245941162\n",
      "Finished epoch 1795, latest loss 0.7107452750205994\n",
      "Finished epoch 1796, latest loss 0.7098881602287292\n",
      "Finished epoch 1797, latest loss 0.7097337245941162\n",
      "Finished epoch 1798, latest loss 0.7097337245941162\n",
      "Finished epoch 1799, latest loss 0.7097337245941162\n",
      "Finished epoch 1800, latest loss 0.7097341418266296\n",
      "Finished epoch 1801, latest loss 0.7097337245941162\n",
      "Finished epoch 1802, latest loss 0.7097337245941162\n",
      "Finished epoch 1803, latest loss 0.7107461094856262\n",
      "Finished epoch 1804, latest loss 0.7097337245941162\n",
      "Finished epoch 1805, latest loss 0.7097337245941162\n",
      "Finished epoch 1806, latest loss 0.7106633186340332\n",
      "Finished epoch 1807, latest loss 0.7106633186340332\n",
      "Finished epoch 1808, latest loss 0.7118640542030334\n",
      "Finished epoch 1809, latest loss 0.7107434272766113\n",
      "Finished epoch 1810, latest loss 0.7097337245941162\n",
      "Finished epoch 1811, latest loss 0.7097339034080505\n",
      "Finished epoch 1812, latest loss 0.7114888429641724\n",
      "Finished epoch 1813, latest loss 0.7097340226173401\n",
      "Finished epoch 1814, latest loss 0.7114025950431824\n",
      "Finished epoch 1815, latest loss 0.7097643613815308\n",
      "Finished epoch 1816, latest loss 0.7097337245941162\n",
      "Finished epoch 1817, latest loss 0.7107447385787964\n",
      "Finished epoch 1818, latest loss 0.7097337245941162\n",
      "Finished epoch 1819, latest loss 0.7117569446563721\n",
      "Finished epoch 1820, latest loss 0.7100738286972046\n",
      "Finished epoch 1821, latest loss 0.7107453346252441\n",
      "Finished epoch 1822, latest loss 0.7097337245941162\n",
      "Finished epoch 1823, latest loss 0.7097337245941162\n",
      "Finished epoch 1824, latest loss 0.7107468843460083\n",
      "Finished epoch 1825, latest loss 0.7115333080291748\n",
      "Finished epoch 1826, latest loss 0.7097337245941162\n",
      "Finished epoch 1827, latest loss 0.7097337245941162\n",
      "Finished epoch 1828, latest loss 0.7102158665657043\n",
      "Finished epoch 1829, latest loss 0.7097337245941162\n",
      "Finished epoch 1830, latest loss 0.7105426788330078\n",
      "Finished epoch 1831, latest loss 0.7097337245941162\n",
      "Finished epoch 1832, latest loss 0.7097337245941162\n",
      "Finished epoch 1833, latest loss 0.7097351551055908\n",
      "Finished epoch 1834, latest loss 0.7097337245941162\n",
      "Finished epoch 1835, latest loss 0.7106633186340332\n",
      "Finished epoch 1836, latest loss 0.7097337245941162\n",
      "Finished epoch 1837, latest loss 0.7097337245941162\n",
      "Finished epoch 1838, latest loss 0.7106633186340332\n",
      "Finished epoch 1839, latest loss 0.7115928530693054\n",
      "Finished epoch 1840, latest loss 0.7106633186340332\n",
      "Finished epoch 1841, latest loss 0.7106630206108093\n",
      "Finished epoch 1842, latest loss 0.7106582522392273\n",
      "Finished epoch 1843, latest loss 0.7104315757751465\n",
      "Finished epoch 1844, latest loss 0.7097337245941162\n",
      "Finished epoch 1845, latest loss 0.7097337245941162\n",
      "Finished epoch 1846, latest loss 0.7097337245941162\n",
      "Finished epoch 1847, latest loss 0.7107454538345337\n",
      "Finished epoch 1848, latest loss 0.7097337245941162\n",
      "Finished epoch 1849, latest loss 0.7097518444061279\n",
      "Finished epoch 1850, latest loss 0.7097337245941162\n",
      "Finished epoch 1851, latest loss 0.7097337245941162\n",
      "Finished epoch 1852, latest loss 0.7097337245941162\n",
      "Finished epoch 1853, latest loss 0.7107453346252441\n",
      "Finished epoch 1854, latest loss 0.7097337245941162\n",
      "Finished epoch 1855, latest loss 0.7097337245941162\n",
      "Finished epoch 1856, latest loss 0.7097340226173401\n",
      "Finished epoch 1857, latest loss 0.7097337245941162\n",
      "Finished epoch 1858, latest loss 0.7107453942298889\n",
      "Finished epoch 1859, latest loss 0.7097337245941162\n",
      "Finished epoch 1860, latest loss 0.7097411751747131\n",
      "Finished epoch 1861, latest loss 0.7097582817077637\n",
      "Finished epoch 1862, latest loss 0.7097337245941162\n",
      "Finished epoch 1863, latest loss 0.7107453346252441\n",
      "Finished epoch 1864, latest loss 0.7097337245941162\n",
      "Finished epoch 1865, latest loss 0.7097337245941162\n",
      "Finished epoch 1866, latest loss 0.7097337245941162\n",
      "Finished epoch 1867, latest loss 0.7097337245941162\n",
      "Finished epoch 1868, latest loss 0.7097337245941162\n",
      "Finished epoch 1869, latest loss 0.7115928530693054\n",
      "Finished epoch 1870, latest loss 0.7097337245941162\n",
      "Finished epoch 1871, latest loss 0.7097337245941162\n",
      "Finished epoch 1872, latest loss 0.7097337245941162\n",
      "Finished epoch 1873, latest loss 0.7097337245941162\n",
      "Finished epoch 1874, latest loss 0.7097337245941162\n",
      "Finished epoch 1875, latest loss 0.7097337245941162\n",
      "Finished epoch 1876, latest loss 0.7097966074943542\n",
      "Finished epoch 1877, latest loss 0.7097337245941162\n",
      "Finished epoch 1878, latest loss 0.7097337245941162\n",
      "Finished epoch 1879, latest loss 0.7106633186340332\n",
      "Finished epoch 1880, latest loss 0.7097337245941162\n",
      "Finished epoch 1881, latest loss 0.7107453346252441\n",
      "Finished epoch 1882, latest loss 0.7107453346252441\n",
      "Finished epoch 1883, latest loss 0.7097342014312744\n",
      "Finished epoch 1884, latest loss 0.7107453346252441\n",
      "Finished epoch 1885, latest loss 0.7097337245941162\n",
      "Finished epoch 1886, latest loss 0.7098550796508789\n",
      "Finished epoch 1887, latest loss 0.7106633186340332\n",
      "Finished epoch 1888, latest loss 0.7103476524353027\n",
      "Finished epoch 1889, latest loss 0.7097337245941162\n",
      "Finished epoch 1890, latest loss 0.7097337245941162\n",
      "Finished epoch 1891, latest loss 0.7097337245941162\n",
      "Finished epoch 1892, latest loss 0.7097431421279907\n",
      "Finished epoch 1893, latest loss 0.7097337245941162\n",
      "Finished epoch 1894, latest loss 0.7097337245941162\n",
      "Finished epoch 1895, latest loss 0.7106633186340332\n",
      "Finished epoch 1896, latest loss 0.7105661034584045\n",
      "Finished epoch 1897, latest loss 0.7107453346252441\n",
      "Finished epoch 1898, latest loss 0.7097337245941162\n",
      "Finished epoch 1899, latest loss 0.7097337245941162\n",
      "Finished epoch 1900, latest loss 0.7097337245941162\n",
      "Finished epoch 1901, latest loss 0.7097337245941162\n",
      "Finished epoch 1902, latest loss 0.7097337245941162\n",
      "Finished epoch 1903, latest loss 0.7097337245941162\n",
      "Finished epoch 1904, latest loss 0.7117547392845154\n",
      "Finished epoch 1905, latest loss 0.7107453346252441\n",
      "Finished epoch 1906, latest loss 0.7107475399971008\n",
      "Finished epoch 1907, latest loss 0.7097337245941162\n",
      "Finished epoch 1908, latest loss 0.7097337245941162\n",
      "Finished epoch 1909, latest loss 0.7097337245941162\n",
      "Finished epoch 1910, latest loss 0.7106682062149048\n",
      "Finished epoch 1911, latest loss 0.7097337245941162\n",
      "Finished epoch 1912, latest loss 0.7097339034080505\n",
      "Finished epoch 1913, latest loss 0.7097337245941162\n",
      "Finished epoch 1914, latest loss 0.709733784198761\n",
      "Finished epoch 1915, latest loss 0.7106633186340332\n",
      "Finished epoch 1916, latest loss 0.7106636166572571\n",
      "Finished epoch 1917, latest loss 0.7117569446563721\n",
      "Finished epoch 1918, latest loss 0.7106634378433228\n",
      "Finished epoch 1919, latest loss 0.7097337245941162\n",
      "Finished epoch 1920, latest loss 0.7106633186340332\n",
      "Finished epoch 1921, latest loss 0.7106633186340332\n",
      "Finished epoch 1922, latest loss 0.7099218368530273\n",
      "Finished epoch 1923, latest loss 0.7097337245941162\n",
      "Finished epoch 1924, latest loss 0.7097337245941162\n",
      "Finished epoch 1925, latest loss 0.7097337245941162\n",
      "Finished epoch 1926, latest loss 0.7097337245941162\n",
      "Finished epoch 1927, latest loss 0.7097337245941162\n",
      "Finished epoch 1928, latest loss 0.7112910747528076\n",
      "Finished epoch 1929, latest loss 0.7097337245941162\n",
      "Finished epoch 1930, latest loss 0.7097337245941162\n",
      "Finished epoch 1931, latest loss 0.7097337245941162\n",
      "Finished epoch 1932, latest loss 0.7097337245941162\n",
      "Finished epoch 1933, latest loss 0.7117511630058289\n",
      "Finished epoch 1934, latest loss 0.7097339034080505\n",
      "Finished epoch 1935, latest loss 0.7097337245941162\n",
      "Finished epoch 1936, latest loss 0.7097337245941162\n",
      "Finished epoch 1937, latest loss 0.7097337245941162\n",
      "Finished epoch 1938, latest loss 0.7097337245941162\n",
      "Finished epoch 1939, latest loss 0.7097337245941162\n",
      "Finished epoch 1940, latest loss 0.7107456922531128\n",
      "Finished epoch 1941, latest loss 0.7097402811050415\n",
      "Finished epoch 1942, latest loss 0.7097337245941162\n",
      "Finished epoch 1943, latest loss 0.7097339630126953\n",
      "Finished epoch 1944, latest loss 0.7097337245941162\n",
      "Finished epoch 1945, latest loss 0.7097337245941162\n",
      "Finished epoch 1946, latest loss 0.7097337245941162\n",
      "Finished epoch 1947, latest loss 0.7097337245941162\n",
      "Finished epoch 1948, latest loss 0.7097337245941162\n",
      "Finished epoch 1949, latest loss 0.7097337245941162\n",
      "Finished epoch 1950, latest loss 0.7097337245941162\n",
      "Finished epoch 1951, latest loss 0.7097337245941162\n",
      "Finished epoch 1952, latest loss 0.7097337245941162\n",
      "Finished epoch 1953, latest loss 0.7097337245941162\n",
      "Finished epoch 1954, latest loss 0.7107453346252441\n",
      "Finished epoch 1955, latest loss 0.7097337245941162\n",
      "Finished epoch 1956, latest loss 0.7097337245941162\n",
      "Finished epoch 1957, latest loss 0.7097337245941162\n",
      "Finished epoch 1958, latest loss 0.7097337245941162\n",
      "Finished epoch 1959, latest loss 0.7097337245941162\n",
      "Finished epoch 1960, latest loss 0.7097337245941162\n",
      "Finished epoch 1961, latest loss 0.7097337245941162\n",
      "Finished epoch 1962, latest loss 0.7105835676193237\n",
      "Finished epoch 1963, latest loss 0.7097337245941162\n",
      "Finished epoch 1964, latest loss 0.7097337245941162\n",
      "Finished epoch 1965, latest loss 0.7097511291503906\n",
      "Finished epoch 1966, latest loss 0.7102676033973694\n",
      "Finished epoch 1967, latest loss 0.7097337245941162\n",
      "Finished epoch 1968, latest loss 0.7097337245941162\n",
      "Finished epoch 1969, latest loss 0.7097337245941162\n",
      "Finished epoch 1970, latest loss 0.710270881652832\n",
      "Finished epoch 1971, latest loss 0.7107453346252441\n",
      "Finished epoch 1972, latest loss 0.7107453346252441\n",
      "Finished epoch 1973, latest loss 0.7098727226257324\n",
      "Finished epoch 1974, latest loss 0.7097337245941162\n",
      "Finished epoch 1975, latest loss 0.7101179361343384\n",
      "Finished epoch 1976, latest loss 0.7097337245941162\n",
      "Finished epoch 1977, latest loss 0.7097337245941162\n",
      "Finished epoch 1978, latest loss 0.7097337245941162\n",
      "Finished epoch 1979, latest loss 0.7107453346252441\n",
      "Finished epoch 1980, latest loss 0.7107453346252441\n",
      "Finished epoch 1981, latest loss 0.7107453346252441\n",
      "Finished epoch 1982, latest loss 0.7107453346252441\n",
      "Finished epoch 1983, latest loss 0.7107453346252441\n",
      "Finished epoch 1984, latest loss 0.7107453346252441\n",
      "Finished epoch 1985, latest loss 0.7097337245941162\n",
      "Finished epoch 1986, latest loss 0.7097337245941162\n",
      "Finished epoch 1987, latest loss 0.7097337245941162\n",
      "Finished epoch 1988, latest loss 0.7107453346252441\n",
      "Finished epoch 1989, latest loss 0.7097337245941162\n",
      "Finished epoch 1990, latest loss 0.7107453346252441\n",
      "Finished epoch 1991, latest loss 0.7107453346252441\n",
      "Finished epoch 1992, latest loss 0.7107453346252441\n",
      "Finished epoch 1993, latest loss 0.7107453346252441\n",
      "Finished epoch 1994, latest loss 0.7097337245941162\n",
      "Finished epoch 1995, latest loss 0.7107453346252441\n",
      "Finished epoch 1996, latest loss 0.7097337245941162\n",
      "Finished epoch 1997, latest loss 0.7107453346252441\n",
      "Finished epoch 1998, latest loss 0.7107453346252441\n",
      "Finished epoch 1999, latest loss 0.7097337245941162\n",
      "Accuracy 0.9426252841949463\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                6855               10808\n",
      "Actual Negative                  71              171879\n",
      "Positive predictive power:\n",
      "38.81%\n",
      "Positive predictive accuracy:\n",
      "98.97%\n",
      "Confusion Matrix for merged predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                6185               11478\n",
      "Actual Negative                  48              171902\n",
      "Positive predictive power:\n",
      "35.02%\n",
      "Positive predictive accuracy:\n",
      "99.23%\n",
      "Mean change for incorrect predictions: 1.048\n",
      "Mean change for correct predictions: 1.121\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(np.array(train_df.T), dtype=torch.float32)\n",
    "y = torch.tensor(np.array(train_negoutput), dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Check for CUDA and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move data to the chosen device\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(train_df.shape[0], 64)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(64, 12)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.hidden3 = nn.Linear(12, 8)\n",
    "        self.act3 = nn.ReLU()\n",
    "        #self.hidden4 = nn.Linear(12, 4)\n",
    "        #self.act4 = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act3(self.hidden3(x))\n",
    "        #x = self.act4(self.hidden4(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    " \n",
    "negmodel = PimaClassifier().to(device)\n",
    "print(negmodel)\n",
    "\n",
    "pos_weight = torch.tensor([2.5], device=device)  # Set your_pos_weight based on your needs\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "#loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "optimizer = optim.Adam(negmodel.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 2000\n",
    "batch_size = 1000\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = negmodel(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "    \n",
    "# compute accuracy (no_grad is optional)\n",
    "with torch.no_grad():\n",
    "    y_pred = negmodel(X)\n",
    " \n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")\n",
    "\n",
    "# make class predictions with the negmodel\n",
    "neg_predictions = (negmodel(X) > 0.5).int().to('cpu')\n",
    "neg_predictions = neg_predictions.numpy()\n",
    "test_pred = pd.DataFrame(neg_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "actual_values = train_negoutput\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for negative predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "neg_predictions = 1 - neg_predictions\n",
    "#print(neg_predictions)\n",
    "\n",
    "X = torch.tensor(np.array(train_df.T), dtype=torch.float32)\n",
    "y = torch.tensor(np.array(train_output), dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Check for CUDA and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move data to the chosen device\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(train_df.shape[0], 64)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(64, 12)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.hidden3 = nn.Linear(12, 8)\n",
    "        self.act3 = nn.ReLU()\n",
    "        #self.hidden4 = nn.Linear(12, 4)\n",
    "        #self.act4 = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act3(self.hidden3(x))\n",
    "        #x = self.act4(self.hidden4(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    " \n",
    "model = PimaClassifier().to(device)\n",
    "print(model)\n",
    "\n",
    "pos_weight = torch.tensor([1.5], device=device)  # Set your_pos_weight based on your needs\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "#loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 2000\n",
    "batch_size = 1000\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "    \n",
    "# compute accuracy (no_grad is optional)\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    " \n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")\n",
    "\n",
    "# make class predictions with the model\n",
    "predictions = (model(X) > 0.5).int().to('cpu')\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "###\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "actual_values = train_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "#print(predictions)\n",
    "\n",
    "###\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "merge_predictions = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "merge_predictions.index = range(1, len(merge_predictions) + 1)\n",
    "actual_values = train_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(merge_predictions)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct predictions:\", mean_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04103b33-5984-45d4-b8c8-509cc08bae86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63204\n",
      "63204\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1605                4209\n",
      "Actual Negative                 519               56871\n",
      "Positive predictive power:\n",
      "27.61%\n",
      "Positive predictive accuracy:\n",
      "75.56%\n",
      "Confusion Matrix for merged predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1379                4435\n",
      "Actual Negative                 378               57012\n",
      "Positive predictive power:\n",
      "23.72%\n",
      "Positive predictive accuracy:\n",
      "78.49%\n",
      "Mean change for incorrect predictions: 1.036\n",
      "Mean change for correct predictions: 1.128\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Set the model to evaluation mode\n",
    "negmodel.eval()\n",
    "model.eval()\n",
    "\n",
    "# Step 2: Prepare your input data (assuming new_input is your raw data)\n",
    "# For example, if your model expects input size of (1, C, H, W)\n",
    "input_tensor = torch.tensor(np.array(cv_df.T), dtype=torch.float32)\n",
    "\n",
    "# Step 3: Move your model and input data to the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "negmodel = negmodel.to(device)\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "predictions = (model(input_tensor) > 0.5).int().to('cpu')\n",
    "neg_predictions = (negmodel(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(predictions))\n",
    "print(len(neg_predictions))\n",
    "predictions = predictions.numpy()\n",
    "neg_predictions = neg_predictions.numpy()\n",
    "neg_predictions = 1 - neg_predictions\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = cv_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "test_pred = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = cv_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(cv_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(cv_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct predictions:\", mean_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4158792e-ed61-4f59-ab88-d1679209bd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63205\n",
      "63205\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1606                4319\n",
      "Actual Negative                 532               56748\n",
      "Positive predictive power:\n",
      "27.11%\n",
      "Positive predictive accuracy:\n",
      "75.12%\n",
      "Confusion Matrix for merged predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1368                4557\n",
      "Actual Negative                 376               56904\n",
      "Positive predictive power:\n",
      "23.09%\n",
      "Positive predictive accuracy:\n",
      "78.44%\n",
      "Mean change for incorrect predictions: 1.032\n",
      "Mean change for correct predictions: 1.126\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Set the model to evaluation mode\n",
    "negmodel.eval()\n",
    "model.eval()\n",
    "\n",
    "# Step 2: Prepare your input data (assuming new_input is your raw data)\n",
    "# For example, if your model expects input size of (1, C, H, W)\n",
    "input_tensor = torch.tensor(np.array(test_df.T), dtype=torch.float32)\n",
    "\n",
    "# Step 3: Move your model and input data to the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "negmodel = negmodel.to(device)\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "predictions = (model(input_tensor) > 0.5).int().to('cpu')\n",
    "neg_predictions = (negmodel(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(predictions))\n",
    "print(len(neg_predictions))\n",
    "predictions = predictions.numpy()\n",
    "neg_predictions = neg_predictions.numpy()\n",
    "neg_predictions = 1 - neg_predictions\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "test_pred = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct predictions:\", mean_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e4ac149-9db9-40c4-aebf-70c951ee3674",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/best_9up10d_model.pt\")\n",
    "\n",
    "torch.save(negmodel.state_dict(), \"E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/best_5down10d_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a646a05-3e59-41dc-8803-14afd1ed2531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "5  0\n",
      "(316022, 1)\n",
      "x\n",
      "0    229013\n",
      "1     87009\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure reproducibility\n",
    "output_file = 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_output_5up10d_for_NN_20210514_to_20240404.tsv'\n",
    "output_dataset = pd.read_csv(output_file, delimiter='\\t')\n",
    "print(output_dataset.iloc[:5,:5])\n",
    "print(output_dataset.shape)\n",
    "print(output_dataset.value_counts())\n",
    "\n",
    "output_dataset.index = input_dataset.columns\n",
    "\n",
    "train_output = output_dataset.T[train_columns].T\n",
    "cv_output = output_dataset.T[cv_columns].T\n",
    "test_output = output_dataset.T[test_columns].T\n",
    "\n",
    "train_output.index = range(1, len(train_output) + 1)\n",
    "cv_output.index = range(1, len(cv_output) + 1)\n",
    "test_output.index = range(1, len(test_output) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bae1db9c-4634-44e9-8299-ff76847b9c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PimaClassifier(\n",
      "  (hidden1): Linear(in_features=1616, out_features=64, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (hidden2): Linear(in_features=64, out_features=12, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (hidden3): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (act3): ReLU()\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (act_output): Sigmoid()\n",
      ")\n",
      "Finished epoch 0, latest loss 0.7778500318527222\n",
      "Finished epoch 1, latest loss 0.772450864315033\n",
      "Finished epoch 2, latest loss 0.7727213501930237\n",
      "Finished epoch 3, latest loss 0.7684698104858398\n",
      "Finished epoch 4, latest loss 0.7645014524459839\n",
      "Finished epoch 5, latest loss 0.7624107003211975\n",
      "Finished epoch 6, latest loss 0.7623335123062134\n",
      "Finished epoch 7, latest loss 0.7573959231376648\n",
      "Finished epoch 8, latest loss 0.7607902884483337\n",
      "Finished epoch 9, latest loss 0.7545563578605652\n",
      "Finished epoch 10, latest loss 0.7526525259017944\n",
      "Finished epoch 11, latest loss 0.7537382245063782\n",
      "Finished epoch 12, latest loss 0.7500900030136108\n",
      "Finished epoch 13, latest loss 0.7501828670501709\n",
      "Finished epoch 14, latest loss 0.752514660358429\n",
      "Finished epoch 15, latest loss 0.7492310404777527\n",
      "Finished epoch 16, latest loss 0.7498273849487305\n",
      "Finished epoch 17, latest loss 0.7539031505584717\n",
      "Finished epoch 18, latest loss 0.7459352612495422\n",
      "Finished epoch 19, latest loss 0.7471673488616943\n",
      "Finished epoch 20, latest loss 0.7512598633766174\n",
      "Finished epoch 21, latest loss 0.7504297494888306\n",
      "Finished epoch 22, latest loss 0.7464503049850464\n",
      "Finished epoch 23, latest loss 0.738183856010437\n",
      "Finished epoch 24, latest loss 0.7394305467605591\n",
      "Finished epoch 25, latest loss 0.743379533290863\n",
      "Finished epoch 26, latest loss 0.7401321530342102\n",
      "Finished epoch 27, latest loss 0.7396701574325562\n",
      "Finished epoch 28, latest loss 0.7409050464630127\n",
      "Finished epoch 29, latest loss 0.7391068339347839\n",
      "Finished epoch 30, latest loss 0.7424473762512207\n",
      "Finished epoch 31, latest loss 0.7413060665130615\n",
      "Finished epoch 32, latest loss 0.7404205203056335\n",
      "Finished epoch 33, latest loss 0.741590678691864\n",
      "Finished epoch 34, latest loss 0.7389205098152161\n",
      "Finished epoch 35, latest loss 0.7403252720832825\n",
      "Finished epoch 36, latest loss 0.7356180548667908\n",
      "Finished epoch 37, latest loss 0.7389014363288879\n",
      "Finished epoch 38, latest loss 0.739409327507019\n",
      "Finished epoch 39, latest loss 0.7375640869140625\n",
      "Finished epoch 40, latest loss 0.7368349432945251\n",
      "Finished epoch 41, latest loss 0.738938570022583\n",
      "Finished epoch 42, latest loss 0.7358188629150391\n",
      "Finished epoch 43, latest loss 0.7379274964332581\n",
      "Finished epoch 44, latest loss 0.7369920611381531\n",
      "Finished epoch 45, latest loss 0.7331180572509766\n",
      "Finished epoch 46, latest loss 0.739452064037323\n",
      "Finished epoch 47, latest loss 0.7359591722488403\n",
      "Finished epoch 48, latest loss 0.7347453236579895\n",
      "Finished epoch 49, latest loss 0.7397209405899048\n",
      "Finished epoch 50, latest loss 0.733401358127594\n",
      "Finished epoch 51, latest loss 0.7363576889038086\n",
      "Finished epoch 52, latest loss 0.7356995344161987\n",
      "Finished epoch 53, latest loss 0.7374351024627686\n",
      "Finished epoch 54, latest loss 0.7353960871696472\n",
      "Finished epoch 55, latest loss 0.7361929416656494\n",
      "Finished epoch 56, latest loss 0.7357282638549805\n",
      "Finished epoch 57, latest loss 0.7313606142997742\n",
      "Finished epoch 58, latest loss 0.7346207499504089\n",
      "Finished epoch 59, latest loss 0.7334052920341492\n",
      "Finished epoch 60, latest loss 0.7350183725357056\n",
      "Finished epoch 61, latest loss 0.7307498455047607\n",
      "Finished epoch 62, latest loss 0.7309988737106323\n",
      "Finished epoch 63, latest loss 0.7331040501594543\n",
      "Finished epoch 64, latest loss 0.7313283085823059\n",
      "Finished epoch 65, latest loss 0.7329034805297852\n",
      "Finished epoch 66, latest loss 0.7309346795082092\n",
      "Finished epoch 67, latest loss 0.7320543527603149\n",
      "Finished epoch 68, latest loss 0.7316664457321167\n",
      "Finished epoch 69, latest loss 0.7343990206718445\n",
      "Finished epoch 70, latest loss 0.7325707077980042\n",
      "Finished epoch 71, latest loss 0.7318731546401978\n",
      "Finished epoch 72, latest loss 0.7327867150306702\n",
      "Finished epoch 73, latest loss 0.7342687249183655\n",
      "Finished epoch 74, latest loss 0.7291123867034912\n",
      "Finished epoch 75, latest loss 0.7337329387664795\n",
      "Finished epoch 76, latest loss 0.7338874936103821\n",
      "Finished epoch 77, latest loss 0.7311166524887085\n",
      "Finished epoch 78, latest loss 0.7318448424339294\n",
      "Finished epoch 79, latest loss 0.7297315001487732\n",
      "Finished epoch 80, latest loss 0.7307407855987549\n",
      "Finished epoch 81, latest loss 0.7353659272193909\n",
      "Finished epoch 82, latest loss 0.7299069762229919\n",
      "Finished epoch 83, latest loss 0.7288667559623718\n",
      "Finished epoch 84, latest loss 0.7325053215026855\n",
      "Finished epoch 85, latest loss 0.7315969467163086\n",
      "Finished epoch 86, latest loss 0.7319470643997192\n",
      "Finished epoch 87, latest loss 0.729456901550293\n",
      "Finished epoch 88, latest loss 0.7310529947280884\n",
      "Finished epoch 89, latest loss 0.7291030883789062\n",
      "Finished epoch 90, latest loss 0.7308048009872437\n",
      "Finished epoch 91, latest loss 0.730867326259613\n",
      "Finished epoch 92, latest loss 0.7302577495574951\n",
      "Finished epoch 93, latest loss 0.7271180748939514\n",
      "Finished epoch 94, latest loss 0.7237746119499207\n",
      "Finished epoch 95, latest loss 0.7254934906959534\n",
      "Finished epoch 96, latest loss 0.7277141809463501\n",
      "Finished epoch 97, latest loss 0.7257489562034607\n",
      "Finished epoch 98, latest loss 0.7250971794128418\n",
      "Finished epoch 99, latest loss 0.7242016792297363\n",
      "Finished epoch 100, latest loss 0.7285398244857788\n",
      "Finished epoch 101, latest loss 0.7243374586105347\n",
      "Finished epoch 102, latest loss 0.7271182537078857\n",
      "Finished epoch 103, latest loss 0.7248477339744568\n",
      "Finished epoch 104, latest loss 0.7239606976509094\n",
      "Finished epoch 105, latest loss 0.7271658182144165\n",
      "Finished epoch 106, latest loss 0.7283595204353333\n",
      "Finished epoch 107, latest loss 0.725078284740448\n",
      "Finished epoch 108, latest loss 0.7238118648529053\n",
      "Finished epoch 109, latest loss 0.7244448661804199\n",
      "Finished epoch 110, latest loss 0.7301322221755981\n",
      "Finished epoch 111, latest loss 0.7222229838371277\n",
      "Finished epoch 112, latest loss 0.7231359481811523\n",
      "Finished epoch 113, latest loss 0.7223094701766968\n",
      "Finished epoch 114, latest loss 0.7248531579971313\n",
      "Finished epoch 115, latest loss 0.7271108031272888\n",
      "Finished epoch 116, latest loss 0.7239225506782532\n",
      "Finished epoch 117, latest loss 0.7217242121696472\n",
      "Finished epoch 118, latest loss 0.7224704623222351\n",
      "Finished epoch 119, latest loss 0.7231072187423706\n",
      "Finished epoch 120, latest loss 0.7233477830886841\n",
      "Finished epoch 121, latest loss 0.7240343689918518\n",
      "Finished epoch 122, latest loss 0.7219255566596985\n",
      "Finished epoch 123, latest loss 0.7210220694541931\n",
      "Finished epoch 124, latest loss 0.722962498664856\n",
      "Finished epoch 125, latest loss 0.7175630331039429\n",
      "Finished epoch 126, latest loss 0.7186058759689331\n",
      "Finished epoch 127, latest loss 0.7218761444091797\n",
      "Finished epoch 128, latest loss 0.7212057709693909\n",
      "Finished epoch 129, latest loss 0.7228476405143738\n",
      "Finished epoch 130, latest loss 0.721211850643158\n",
      "Finished epoch 131, latest loss 0.7197940349578857\n",
      "Finished epoch 132, latest loss 0.7183951735496521\n",
      "Finished epoch 133, latest loss 0.7195987105369568\n",
      "Finished epoch 134, latest loss 0.7207090258598328\n",
      "Finished epoch 135, latest loss 0.7205008864402771\n",
      "Finished epoch 136, latest loss 0.7199317812919617\n",
      "Finished epoch 137, latest loss 0.7232012152671814\n",
      "Finished epoch 138, latest loss 0.7229728698730469\n",
      "Finished epoch 139, latest loss 0.7234899997711182\n",
      "Finished epoch 140, latest loss 0.7207146286964417\n",
      "Finished epoch 141, latest loss 0.7205418348312378\n",
      "Finished epoch 142, latest loss 0.7177329063415527\n",
      "Finished epoch 143, latest loss 0.7186070084571838\n",
      "Finished epoch 144, latest loss 0.7215070724487305\n",
      "Finished epoch 145, latest loss 0.7205605506896973\n",
      "Finished epoch 146, latest loss 0.717917799949646\n",
      "Finished epoch 147, latest loss 0.7170788049697876\n",
      "Finished epoch 148, latest loss 0.7203608751296997\n",
      "Finished epoch 149, latest loss 0.7220667004585266\n",
      "Finished epoch 150, latest loss 0.7235577702522278\n",
      "Finished epoch 151, latest loss 0.7183780074119568\n",
      "Finished epoch 152, latest loss 0.7229775786399841\n",
      "Finished epoch 153, latest loss 0.7178434133529663\n",
      "Finished epoch 154, latest loss 0.721246063709259\n",
      "Finished epoch 155, latest loss 0.7222743034362793\n",
      "Finished epoch 156, latest loss 0.7182818651199341\n",
      "Finished epoch 157, latest loss 0.717902660369873\n",
      "Finished epoch 158, latest loss 0.7203376293182373\n",
      "Finished epoch 159, latest loss 0.7203755378723145\n",
      "Finished epoch 160, latest loss 0.7190759181976318\n",
      "Finished epoch 161, latest loss 0.7155888080596924\n",
      "Finished epoch 162, latest loss 0.7145370841026306\n",
      "Finished epoch 163, latest loss 0.7181503176689148\n",
      "Finished epoch 164, latest loss 0.7167901396751404\n",
      "Finished epoch 165, latest loss 0.7164344787597656\n",
      "Finished epoch 166, latest loss 0.7174724340438843\n",
      "Finished epoch 167, latest loss 0.7166536450386047\n",
      "Finished epoch 168, latest loss 0.7165095210075378\n",
      "Finished epoch 169, latest loss 0.7141079306602478\n",
      "Finished epoch 170, latest loss 0.7132513523101807\n",
      "Finished epoch 171, latest loss 0.7162797451019287\n",
      "Finished epoch 172, latest loss 0.7150250673294067\n",
      "Finished epoch 173, latest loss 0.7181029915809631\n",
      "Finished epoch 174, latest loss 0.7158913016319275\n",
      "Finished epoch 175, latest loss 0.7153216600418091\n",
      "Finished epoch 176, latest loss 0.7133609056472778\n",
      "Finished epoch 177, latest loss 0.7141193151473999\n",
      "Finished epoch 178, latest loss 0.7172016501426697\n",
      "Finished epoch 179, latest loss 0.7170479893684387\n",
      "Finished epoch 180, latest loss 0.7140846252441406\n",
      "Finished epoch 181, latest loss 0.7139788866043091\n",
      "Finished epoch 182, latest loss 0.7152485847473145\n",
      "Finished epoch 183, latest loss 0.7165283560752869\n",
      "Finished epoch 184, latest loss 0.7138478755950928\n",
      "Finished epoch 185, latest loss 0.7134736180305481\n",
      "Finished epoch 186, latest loss 0.7168258428573608\n",
      "Finished epoch 187, latest loss 0.7137596607208252\n",
      "Finished epoch 188, latest loss 0.7127739191055298\n",
      "Finished epoch 189, latest loss 0.7115859985351562\n",
      "Finished epoch 190, latest loss 0.7121638059616089\n",
      "Finished epoch 191, latest loss 0.7120577692985535\n",
      "Finished epoch 192, latest loss 0.7203642129898071\n",
      "Finished epoch 193, latest loss 0.7137932777404785\n",
      "Finished epoch 194, latest loss 0.7119190692901611\n",
      "Finished epoch 195, latest loss 0.7113814949989319\n",
      "Finished epoch 196, latest loss 0.7118463516235352\n",
      "Finished epoch 197, latest loss 0.7144001722335815\n",
      "Finished epoch 198, latest loss 0.7162327766418457\n",
      "Finished epoch 199, latest loss 0.7124856114387512\n",
      "Finished epoch 200, latest loss 0.710923969745636\n",
      "Finished epoch 201, latest loss 0.7151581645011902\n",
      "Finished epoch 202, latest loss 0.7120699286460876\n",
      "Finished epoch 203, latest loss 0.7133743166923523\n",
      "Finished epoch 204, latest loss 0.713397741317749\n",
      "Finished epoch 205, latest loss 0.7110180854797363\n",
      "Finished epoch 206, latest loss 0.7101770043373108\n",
      "Finished epoch 207, latest loss 0.7110936045646667\n",
      "Finished epoch 208, latest loss 0.7139031291007996\n",
      "Finished epoch 209, latest loss 0.7105028629302979\n",
      "Finished epoch 210, latest loss 0.7133377194404602\n",
      "Finished epoch 211, latest loss 0.7139233946800232\n",
      "Finished epoch 212, latest loss 0.7154273986816406\n",
      "Finished epoch 213, latest loss 0.7141242027282715\n",
      "Finished epoch 214, latest loss 0.7123662233352661\n",
      "Finished epoch 215, latest loss 0.7116082906723022\n",
      "Finished epoch 216, latest loss 0.714473307132721\n",
      "Finished epoch 217, latest loss 0.7156750559806824\n",
      "Finished epoch 218, latest loss 0.7110432982444763\n",
      "Finished epoch 219, latest loss 0.7143456935882568\n",
      "Finished epoch 220, latest loss 0.7102702260017395\n",
      "Finished epoch 221, latest loss 0.7151927947998047\n",
      "Finished epoch 222, latest loss 0.7122445106506348\n",
      "Finished epoch 223, latest loss 0.7115682363510132\n",
      "Finished epoch 224, latest loss 0.7140209078788757\n",
      "Finished epoch 225, latest loss 0.7130718231201172\n",
      "Finished epoch 226, latest loss 0.7117985486984253\n",
      "Finished epoch 227, latest loss 0.7125275135040283\n",
      "Finished epoch 228, latest loss 0.7115247249603271\n",
      "Finished epoch 229, latest loss 0.7123969793319702\n",
      "Finished epoch 230, latest loss 0.715654730796814\n",
      "Finished epoch 231, latest loss 0.7092016339302063\n",
      "Finished epoch 232, latest loss 0.7125917077064514\n",
      "Finished epoch 233, latest loss 0.7123454809188843\n",
      "Finished epoch 234, latest loss 0.7113597989082336\n",
      "Finished epoch 235, latest loss 0.7115693688392639\n",
      "Finished epoch 236, latest loss 0.7101553678512573\n",
      "Finished epoch 237, latest loss 0.7119134664535522\n",
      "Finished epoch 238, latest loss 0.7120172381401062\n",
      "Finished epoch 239, latest loss 0.7152937054634094\n",
      "Finished epoch 240, latest loss 0.7139456272125244\n",
      "Finished epoch 241, latest loss 0.7110525965690613\n",
      "Finished epoch 242, latest loss 0.7125535607337952\n",
      "Finished epoch 243, latest loss 0.7130337953567505\n",
      "Finished epoch 244, latest loss 0.7117409110069275\n",
      "Finished epoch 245, latest loss 0.7153564691543579\n",
      "Finished epoch 246, latest loss 0.7118464112281799\n",
      "Finished epoch 247, latest loss 0.7114353179931641\n",
      "Finished epoch 248, latest loss 0.7130159139633179\n",
      "Finished epoch 249, latest loss 0.712006688117981\n",
      "Finished epoch 250, latest loss 0.7117239236831665\n",
      "Finished epoch 251, latest loss 0.7127469778060913\n",
      "Finished epoch 252, latest loss 0.7099815607070923\n",
      "Finished epoch 253, latest loss 0.7123880982398987\n",
      "Finished epoch 254, latest loss 0.714067816734314\n",
      "Finished epoch 255, latest loss 0.7138392925262451\n",
      "Finished epoch 256, latest loss 0.7110543251037598\n",
      "Finished epoch 257, latest loss 0.7119184136390686\n",
      "Finished epoch 258, latest loss 0.7135949730873108\n",
      "Finished epoch 259, latest loss 0.7131085991859436\n",
      "Finished epoch 260, latest loss 0.7153708338737488\n",
      "Finished epoch 261, latest loss 0.7140129804611206\n",
      "Finished epoch 262, latest loss 0.7119602560997009\n",
      "Finished epoch 263, latest loss 0.71232670545578\n",
      "Finished epoch 264, latest loss 0.7104034423828125\n",
      "Finished epoch 265, latest loss 0.711034893989563\n",
      "Finished epoch 266, latest loss 0.713633120059967\n",
      "Finished epoch 267, latest loss 0.7116048336029053\n",
      "Finished epoch 268, latest loss 0.7120736241340637\n",
      "Finished epoch 269, latest loss 0.7119621634483337\n",
      "Finished epoch 270, latest loss 0.7100926041603088\n",
      "Finished epoch 271, latest loss 0.7109795212745667\n",
      "Finished epoch 272, latest loss 0.7126637101173401\n",
      "Finished epoch 273, latest loss 0.7110762596130371\n",
      "Finished epoch 274, latest loss 0.7098749876022339\n",
      "Finished epoch 275, latest loss 0.7127628326416016\n",
      "Finished epoch 276, latest loss 0.7114171981811523\n",
      "Finished epoch 277, latest loss 0.7144916653633118\n",
      "Finished epoch 278, latest loss 0.7128477692604065\n",
      "Finished epoch 279, latest loss 0.7168934345245361\n",
      "Finished epoch 280, latest loss 0.7108980417251587\n",
      "Finished epoch 281, latest loss 0.7101567983627319\n",
      "Finished epoch 282, latest loss 0.7102238535881042\n",
      "Finished epoch 283, latest loss 0.7099391222000122\n",
      "Finished epoch 284, latest loss 0.7114874124526978\n",
      "Finished epoch 285, latest loss 0.7135859131813049\n",
      "Finished epoch 286, latest loss 0.7082099318504333\n",
      "Finished epoch 287, latest loss 0.7122247815132141\n",
      "Finished epoch 288, latest loss 0.7096541523933411\n",
      "Finished epoch 289, latest loss 0.7109670042991638\n",
      "Finished epoch 290, latest loss 0.7108413577079773\n",
      "Finished epoch 291, latest loss 0.7074133157730103\n",
      "Finished epoch 292, latest loss 0.7082074284553528\n",
      "Finished epoch 293, latest loss 0.7101048231124878\n",
      "Finished epoch 294, latest loss 0.7083656787872314\n",
      "Finished epoch 295, latest loss 0.7102804780006409\n",
      "Finished epoch 296, latest loss 0.7125566601753235\n",
      "Finished epoch 297, latest loss 0.7104738354682922\n",
      "Finished epoch 298, latest loss 0.7092075347900391\n",
      "Finished epoch 299, latest loss 0.7085887789726257\n",
      "Finished epoch 300, latest loss 0.7116335034370422\n",
      "Finished epoch 301, latest loss 0.711054265499115\n",
      "Finished epoch 302, latest loss 0.71010422706604\n",
      "Finished epoch 303, latest loss 0.7088040113449097\n",
      "Finished epoch 304, latest loss 0.7082092761993408\n",
      "Finished epoch 305, latest loss 0.7085059881210327\n",
      "Finished epoch 306, latest loss 0.7083969116210938\n",
      "Finished epoch 307, latest loss 0.7073938846588135\n",
      "Finished epoch 308, latest loss 0.7091687321662903\n",
      "Finished epoch 309, latest loss 0.7105593681335449\n",
      "Finished epoch 310, latest loss 0.7070549726486206\n",
      "Finished epoch 311, latest loss 0.708363950252533\n",
      "Finished epoch 312, latest loss 0.7073680758476257\n",
      "Finished epoch 313, latest loss 0.705412745475769\n",
      "Finished epoch 314, latest loss 0.7073196768760681\n",
      "Finished epoch 315, latest loss 0.7102834582328796\n",
      "Finished epoch 316, latest loss 0.7137596607208252\n",
      "Finished epoch 317, latest loss 0.7097659111022949\n",
      "Finished epoch 318, latest loss 0.7080190181732178\n",
      "Finished epoch 319, latest loss 0.7092350125312805\n",
      "Finished epoch 320, latest loss 0.7111906409263611\n",
      "Finished epoch 321, latest loss 0.7094521522521973\n",
      "Finished epoch 322, latest loss 0.709728479385376\n",
      "Finished epoch 323, latest loss 0.7085314393043518\n",
      "Finished epoch 324, latest loss 0.7093067765235901\n",
      "Finished epoch 325, latest loss 0.7084185481071472\n",
      "Finished epoch 326, latest loss 0.7083026766777039\n",
      "Finished epoch 327, latest loss 0.7091599702835083\n",
      "Finished epoch 328, latest loss 0.7103897333145142\n",
      "Finished epoch 329, latest loss 0.7082714438438416\n",
      "Finished epoch 330, latest loss 0.7075912356376648\n",
      "Finished epoch 331, latest loss 0.7083823680877686\n",
      "Finished epoch 332, latest loss 0.7069745659828186\n",
      "Finished epoch 333, latest loss 0.7063015103340149\n",
      "Finished epoch 334, latest loss 0.7092801928520203\n",
      "Finished epoch 335, latest loss 0.7073009610176086\n",
      "Finished epoch 336, latest loss 0.7106866836547852\n",
      "Finished epoch 337, latest loss 0.7072877883911133\n",
      "Finished epoch 338, latest loss 0.7089852690696716\n",
      "Finished epoch 339, latest loss 0.7072058916091919\n",
      "Finished epoch 340, latest loss 0.7066313624382019\n",
      "Finished epoch 341, latest loss 0.7062551975250244\n",
      "Finished epoch 342, latest loss 0.7090187072753906\n",
      "Finished epoch 343, latest loss 0.7089371681213379\n",
      "Finished epoch 344, latest loss 0.7063431143760681\n",
      "Finished epoch 345, latest loss 0.7082588076591492\n",
      "Finished epoch 346, latest loss 0.7083553671836853\n",
      "Finished epoch 347, latest loss 0.7098680734634399\n",
      "Finished epoch 348, latest loss 0.7095019221305847\n",
      "Finished epoch 349, latest loss 0.7092542052268982\n",
      "Finished epoch 350, latest loss 0.7083004713058472\n",
      "Finished epoch 351, latest loss 0.7076274156570435\n",
      "Finished epoch 352, latest loss 0.7087147831916809\n",
      "Finished epoch 353, latest loss 0.7063412070274353\n",
      "Finished epoch 354, latest loss 0.7054111957550049\n",
      "Finished epoch 355, latest loss 0.7066267728805542\n",
      "Finished epoch 356, latest loss 0.7092543840408325\n",
      "Finished epoch 357, latest loss 0.7082567811012268\n",
      "Finished epoch 358, latest loss 0.7091898918151855\n",
      "Finished epoch 359, latest loss 0.7092262506484985\n",
      "Finished epoch 360, latest loss 0.7063625454902649\n",
      "Finished epoch 361, latest loss 0.7101734280586243\n",
      "Finished epoch 362, latest loss 0.7112134099006653\n",
      "Finished epoch 363, latest loss 0.7076330184936523\n",
      "Finished epoch 364, latest loss 0.70833420753479\n",
      "Finished epoch 365, latest loss 0.7089924812316895\n",
      "Finished epoch 366, latest loss 0.7074088454246521\n",
      "Finished epoch 367, latest loss 0.7079752683639526\n",
      "Finished epoch 368, latest loss 0.7082051634788513\n",
      "Finished epoch 369, latest loss 0.7063905596733093\n",
      "Finished epoch 370, latest loss 0.7082333564758301\n",
      "Finished epoch 371, latest loss 0.7071072459220886\n",
      "Finished epoch 372, latest loss 0.7064843773841858\n",
      "Finished epoch 373, latest loss 0.7105846405029297\n",
      "Finished epoch 374, latest loss 0.7100750207901001\n",
      "Finished epoch 375, latest loss 0.706275224685669\n",
      "Finished epoch 376, latest loss 0.7069751024246216\n",
      "Finished epoch 377, latest loss 0.7091827988624573\n",
      "Finished epoch 378, latest loss 0.7082000970840454\n",
      "Finished epoch 379, latest loss 0.7074013352394104\n",
      "Finished epoch 380, latest loss 0.7091365456581116\n",
      "Finished epoch 381, latest loss 0.7092753648757935\n",
      "Finished epoch 382, latest loss 0.7064223885536194\n",
      "Finished epoch 383, latest loss 0.7063961029052734\n",
      "Finished epoch 384, latest loss 0.7090536952018738\n",
      "Finished epoch 385, latest loss 0.7092029452323914\n",
      "Finished epoch 386, latest loss 0.7071440815925598\n",
      "Finished epoch 387, latest loss 0.7084155678749084\n",
      "Finished epoch 388, latest loss 0.7077028751373291\n",
      "Finished epoch 389, latest loss 0.7092621326446533\n",
      "Finished epoch 390, latest loss 0.7072251439094543\n",
      "Finished epoch 391, latest loss 0.7088207006454468\n",
      "Finished epoch 392, latest loss 0.7054155468940735\n",
      "Finished epoch 393, latest loss 0.7061164975166321\n",
      "Finished epoch 394, latest loss 0.7072867751121521\n",
      "Finished epoch 395, latest loss 0.7066866755485535\n",
      "Finished epoch 396, latest loss 0.7102558612823486\n",
      "Finished epoch 397, latest loss 0.7063671946525574\n",
      "Finished epoch 398, latest loss 0.7081803679466248\n",
      "Finished epoch 399, latest loss 0.7084035277366638\n",
      "Finished epoch 400, latest loss 0.7082027196884155\n",
      "Finished epoch 401, latest loss 0.7063403129577637\n",
      "Finished epoch 402, latest loss 0.7072891592979431\n",
      "Finished epoch 403, latest loss 0.7054466605186462\n",
      "Finished epoch 404, latest loss 0.7063548564910889\n",
      "Finished epoch 405, latest loss 0.7077128887176514\n",
      "Finished epoch 406, latest loss 0.7091296911239624\n",
      "Finished epoch 407, latest loss 0.7075343728065491\n",
      "Finished epoch 408, latest loss 0.709086537361145\n",
      "Finished epoch 409, latest loss 0.7073928117752075\n",
      "Finished epoch 410, latest loss 0.7102454304695129\n",
      "Finished epoch 411, latest loss 0.7063905596733093\n",
      "Finished epoch 412, latest loss 0.710098922252655\n",
      "Finished epoch 413, latest loss 0.7094596028327942\n",
      "Finished epoch 414, latest loss 0.7073564529418945\n",
      "Finished epoch 415, latest loss 0.7074511051177979\n",
      "Finished epoch 416, latest loss 0.7082234621047974\n",
      "Finished epoch 417, latest loss 0.7072844505310059\n",
      "Finished epoch 418, latest loss 0.7083320617675781\n",
      "Finished epoch 419, latest loss 0.708590030670166\n",
      "Finished epoch 420, latest loss 0.708862841129303\n",
      "Finished epoch 421, latest loss 0.7054120898246765\n",
      "Finished epoch 422, latest loss 0.7073224782943726\n",
      "Finished epoch 423, latest loss 0.7092770934104919\n",
      "Finished epoch 424, latest loss 0.7072259187698364\n",
      "Finished epoch 425, latest loss 0.7085514068603516\n",
      "Finished epoch 426, latest loss 0.7064260840415955\n",
      "Finished epoch 427, latest loss 0.7055606245994568\n",
      "Finished epoch 428, latest loss 0.7054104208946228\n",
      "Finished epoch 429, latest loss 0.7064068913459778\n",
      "Finished epoch 430, latest loss 0.7082732319831848\n",
      "Finished epoch 431, latest loss 0.7076354026794434\n",
      "Finished epoch 432, latest loss 0.706246554851532\n",
      "Finished epoch 433, latest loss 0.706375241279602\n",
      "Finished epoch 434, latest loss 0.7078505158424377\n",
      "Finished epoch 435, latest loss 0.7068833708763123\n",
      "Finished epoch 436, latest loss 0.7068310976028442\n",
      "Finished epoch 437, latest loss 0.7065895795822144\n",
      "Finished epoch 438, latest loss 0.7111352682113647\n",
      "Finished epoch 439, latest loss 0.7088833451271057\n",
      "Finished epoch 440, latest loss 0.7075884342193604\n",
      "Finished epoch 441, latest loss 0.7100636959075928\n",
      "Finished epoch 442, latest loss 0.7093647122383118\n",
      "Finished epoch 443, latest loss 0.7084276676177979\n",
      "Finished epoch 444, latest loss 0.7095922231674194\n",
      "Finished epoch 445, latest loss 0.7103230953216553\n",
      "Finished epoch 446, latest loss 0.7063406705856323\n",
      "Finished epoch 447, latest loss 0.7066957950592041\n",
      "Finished epoch 448, latest loss 0.7094716429710388\n",
      "Finished epoch 449, latest loss 0.7064706087112427\n",
      "Finished epoch 450, latest loss 0.7090864777565002\n",
      "Finished epoch 451, latest loss 0.7103021740913391\n",
      "Finished epoch 452, latest loss 0.7076039910316467\n",
      "Finished epoch 453, latest loss 0.7073387503623962\n",
      "Finished epoch 454, latest loss 0.7099658250808716\n",
      "Finished epoch 455, latest loss 0.7068888545036316\n",
      "Finished epoch 456, latest loss 0.706447958946228\n",
      "Finished epoch 457, latest loss 0.7060723900794983\n",
      "Finished epoch 458, latest loss 0.7086504101753235\n",
      "Finished epoch 459, latest loss 0.714443027973175\n",
      "Finished epoch 460, latest loss 0.7064594626426697\n",
      "Finished epoch 461, latest loss 0.7074185609817505\n",
      "Finished epoch 462, latest loss 0.7061210870742798\n",
      "Finished epoch 463, latest loss 0.706367015838623\n",
      "Finished epoch 464, latest loss 0.707268476486206\n",
      "Finished epoch 465, latest loss 0.7067323327064514\n",
      "Finished epoch 466, latest loss 0.7075780630111694\n",
      "Finished epoch 467, latest loss 0.7097352743148804\n",
      "Finished epoch 468, latest loss 0.7045045495033264\n",
      "Finished epoch 469, latest loss 0.7057390213012695\n",
      "Finished epoch 470, latest loss 0.7050498723983765\n",
      "Finished epoch 471, latest loss 0.7080634832382202\n",
      "Finished epoch 472, latest loss 0.7102718949317932\n",
      "Finished epoch 473, latest loss 0.7095036506652832\n",
      "Finished epoch 474, latest loss 0.708322286605835\n",
      "Finished epoch 475, latest loss 0.7112395167350769\n",
      "Finished epoch 476, latest loss 0.7047533988952637\n",
      "Finished epoch 477, latest loss 0.7044122219085693\n",
      "Finished epoch 478, latest loss 0.7073792219161987\n",
      "Finished epoch 479, latest loss 0.7058702111244202\n",
      "Finished epoch 480, latest loss 0.7091158032417297\n",
      "Finished epoch 481, latest loss 0.7082506418228149\n",
      "Finished epoch 482, latest loss 0.7061522006988525\n",
      "Finished epoch 483, latest loss 0.7070697546005249\n",
      "Finished epoch 484, latest loss 0.7041895985603333\n",
      "Finished epoch 485, latest loss 0.704671323299408\n",
      "Finished epoch 486, latest loss 0.7036442756652832\n",
      "Finished epoch 487, latest loss 0.7055203914642334\n",
      "Finished epoch 488, latest loss 0.7051917314529419\n",
      "Finished epoch 489, latest loss 0.7035557627677917\n",
      "Finished epoch 490, latest loss 0.7069500684738159\n",
      "Finished epoch 491, latest loss 0.7065973281860352\n",
      "Finished epoch 492, latest loss 0.7083832025527954\n",
      "Finished epoch 493, latest loss 0.7045630812644958\n",
      "Finished epoch 494, latest loss 0.7087754011154175\n",
      "Finished epoch 495, latest loss 0.7070837020874023\n",
      "Finished epoch 496, latest loss 0.7065671682357788\n",
      "Finished epoch 497, latest loss 0.7055566310882568\n",
      "Finished epoch 498, latest loss 0.7083291411399841\n",
      "Finished epoch 499, latest loss 0.7064200043678284\n",
      "Finished epoch 500, latest loss 0.7045892477035522\n",
      "Finished epoch 501, latest loss 0.7079699635505676\n",
      "Finished epoch 502, latest loss 0.7083492279052734\n",
      "Finished epoch 503, latest loss 0.7062068581581116\n",
      "Finished epoch 504, latest loss 0.7088823318481445\n",
      "Finished epoch 505, latest loss 0.7036617994308472\n",
      "Finished epoch 506, latest loss 0.7062065601348877\n",
      "Finished epoch 507, latest loss 0.7089315056800842\n",
      "Finished epoch 508, latest loss 0.7041038274765015\n",
      "Finished epoch 509, latest loss 0.7040032148361206\n",
      "Finished epoch 510, latest loss 0.7055263519287109\n",
      "Finished epoch 511, latest loss 0.7037518620491028\n",
      "Finished epoch 512, latest loss 0.7070796489715576\n",
      "Finished epoch 513, latest loss 0.7038446068763733\n",
      "Finished epoch 514, latest loss 0.7035657167434692\n",
      "Finished epoch 515, latest loss 0.7054980397224426\n",
      "Finished epoch 516, latest loss 0.7054438591003418\n",
      "Finished epoch 517, latest loss 0.705481767654419\n",
      "Finished epoch 518, latest loss 0.7045391798019409\n",
      "Finished epoch 519, latest loss 0.7028021812438965\n",
      "Finished epoch 520, latest loss 0.7055948376655579\n",
      "Finished epoch 521, latest loss 0.7053184509277344\n",
      "Finished epoch 522, latest loss 0.7033158540725708\n",
      "Finished epoch 523, latest loss 0.7026474475860596\n",
      "Finished epoch 524, latest loss 0.7036495208740234\n",
      "Finished epoch 525, latest loss 0.7031079530715942\n",
      "Finished epoch 526, latest loss 0.7045974135398865\n",
      "Finished epoch 527, latest loss 0.7060152888298035\n",
      "Finished epoch 528, latest loss 0.7072547078132629\n",
      "Finished epoch 529, latest loss 0.7043359279632568\n",
      "Finished epoch 530, latest loss 0.7036907076835632\n",
      "Finished epoch 531, latest loss 0.7046565413475037\n",
      "Finished epoch 532, latest loss 0.7055655121803284\n",
      "Finished epoch 533, latest loss 0.704470157623291\n",
      "Finished epoch 534, latest loss 0.7062183022499084\n",
      "Finished epoch 535, latest loss 0.7045921683311462\n",
      "Finished epoch 536, latest loss 0.7044413089752197\n",
      "Finished epoch 537, latest loss 0.7047584056854248\n",
      "Finished epoch 538, latest loss 0.7032000422477722\n",
      "Finished epoch 539, latest loss 0.7044839262962341\n",
      "Finished epoch 540, latest loss 0.704651951789856\n",
      "Finished epoch 541, latest loss 0.7047101855278015\n",
      "Finished epoch 542, latest loss 0.7035657167434692\n",
      "Finished epoch 543, latest loss 0.7044722437858582\n",
      "Finished epoch 544, latest loss 0.705117404460907\n",
      "Finished epoch 545, latest loss 0.7079329490661621\n",
      "Finished epoch 546, latest loss 0.7030097842216492\n",
      "Finished epoch 547, latest loss 0.7043642997741699\n",
      "Finished epoch 548, latest loss 0.7044075131416321\n",
      "Finished epoch 549, latest loss 0.7103328704833984\n",
      "Finished epoch 550, latest loss 0.7026245594024658\n",
      "Finished epoch 551, latest loss 0.703655481338501\n",
      "Finished epoch 552, latest loss 0.7035704851150513\n",
      "Finished epoch 553, latest loss 0.7042915225028992\n",
      "Finished epoch 554, latest loss 0.7055620551109314\n",
      "Finished epoch 555, latest loss 0.7044767141342163\n",
      "Finished epoch 556, latest loss 0.7055187821388245\n",
      "Finished epoch 557, latest loss 0.705921471118927\n",
      "Finished epoch 558, latest loss 0.7056474685668945\n",
      "Finished epoch 559, latest loss 0.7046800851821899\n",
      "Finished epoch 560, latest loss 0.705592691898346\n",
      "Finished epoch 561, latest loss 0.7027701139450073\n",
      "Finished epoch 562, latest loss 0.7035732269287109\n",
      "Finished epoch 563, latest loss 0.7054264545440674\n",
      "Finished epoch 564, latest loss 0.7081726789474487\n",
      "Finished epoch 565, latest loss 0.7054139971733093\n",
      "Finished epoch 566, latest loss 0.7045270204544067\n",
      "Finished epoch 567, latest loss 0.7045935988426208\n",
      "Finished epoch 568, latest loss 0.7052032947540283\n",
      "Finished epoch 569, latest loss 0.7045237421989441\n",
      "Finished epoch 570, latest loss 0.7033768892288208\n",
      "Finished epoch 571, latest loss 0.7038285136222839\n",
      "Finished epoch 572, latest loss 0.7057338953018188\n",
      "Finished epoch 573, latest loss 0.7043973803520203\n",
      "Finished epoch 574, latest loss 0.7026310563087463\n",
      "Finished epoch 575, latest loss 0.703669548034668\n",
      "Finished epoch 576, latest loss 0.7059454917907715\n",
      "Finished epoch 577, latest loss 0.7077418565750122\n",
      "Finished epoch 578, latest loss 0.7044709920883179\n",
      "Finished epoch 579, latest loss 0.7053869366645813\n",
      "Finished epoch 580, latest loss 0.7075287103652954\n",
      "Finished epoch 581, latest loss 0.7044579982757568\n",
      "Finished epoch 582, latest loss 0.7078617811203003\n",
      "Finished epoch 583, latest loss 0.7060750722885132\n",
      "Finished epoch 584, latest loss 0.7037243843078613\n",
      "Finished epoch 585, latest loss 0.7053032517433167\n",
      "Finished epoch 586, latest loss 0.7038930654525757\n",
      "Finished epoch 587, latest loss 0.7043572664260864\n",
      "Finished epoch 588, latest loss 0.7045618295669556\n",
      "Finished epoch 589, latest loss 0.7058114409446716\n",
      "Finished epoch 590, latest loss 0.7027424573898315\n",
      "Finished epoch 591, latest loss 0.7054013013839722\n",
      "Finished epoch 592, latest loss 0.7055659294128418\n",
      "Finished epoch 593, latest loss 0.707103967666626\n",
      "Finished epoch 594, latest loss 0.7055593729019165\n",
      "Finished epoch 595, latest loss 0.7020204663276672\n",
      "Finished epoch 596, latest loss 0.7021481394767761\n",
      "Finished epoch 597, latest loss 0.7057009339332581\n",
      "Finished epoch 598, latest loss 0.7035104632377625\n",
      "Finished epoch 599, latest loss 0.7026225924491882\n",
      "Finished epoch 600, latest loss 0.7060161232948303\n",
      "Finished epoch 601, latest loss 0.7017022371292114\n",
      "Finished epoch 602, latest loss 0.7053160071372986\n",
      "Finished epoch 603, latest loss 0.7052519917488098\n",
      "Finished epoch 604, latest loss 0.7041767239570618\n",
      "Finished epoch 605, latest loss 0.7066112160682678\n",
      "Finished epoch 606, latest loss 0.7019158601760864\n",
      "Finished epoch 607, latest loss 0.70619797706604\n",
      "Finished epoch 608, latest loss 0.7034604549407959\n",
      "Finished epoch 609, latest loss 0.7032502889633179\n",
      "Finished epoch 610, latest loss 0.7038106322288513\n",
      "Finished epoch 611, latest loss 0.7033494710922241\n",
      "Finished epoch 612, latest loss 0.7063699960708618\n",
      "Finished epoch 613, latest loss 0.7026439905166626\n",
      "Finished epoch 614, latest loss 0.7016936540603638\n",
      "Finished epoch 615, latest loss 0.7045644521713257\n",
      "Finished epoch 616, latest loss 0.7027472257614136\n",
      "Finished epoch 617, latest loss 0.7022458910942078\n",
      "Finished epoch 618, latest loss 0.7052651643753052\n",
      "Finished epoch 619, latest loss 0.7049654126167297\n",
      "Finished epoch 620, latest loss 0.7036626935005188\n",
      "Finished epoch 621, latest loss 0.7046516537666321\n",
      "Finished epoch 622, latest loss 0.7032963037490845\n",
      "Finished epoch 623, latest loss 0.7085991501808167\n",
      "Finished epoch 624, latest loss 0.7018866539001465\n",
      "Finished epoch 625, latest loss 0.7026423215866089\n",
      "Finished epoch 626, latest loss 0.7030979990959167\n",
      "Finished epoch 627, latest loss 0.7058025002479553\n",
      "Finished epoch 628, latest loss 0.7052997946739197\n",
      "Finished epoch 629, latest loss 0.7026470899581909\n",
      "Finished epoch 630, latest loss 0.7022102475166321\n",
      "Finished epoch 631, latest loss 0.7038191556930542\n",
      "Finished epoch 632, latest loss 0.7026300430297852\n",
      "Finished epoch 633, latest loss 0.7036473155021667\n",
      "Finished epoch 634, latest loss 0.7028313875198364\n",
      "Finished epoch 635, latest loss 0.7035495638847351\n",
      "Finished epoch 636, latest loss 0.7049439549446106\n",
      "Finished epoch 637, latest loss 0.7054640650749207\n",
      "Finished epoch 638, latest loss 0.705418586730957\n",
      "Finished epoch 639, latest loss 0.7026570439338684\n",
      "Finished epoch 640, latest loss 0.7016921043395996\n",
      "Finished epoch 641, latest loss 0.7042661309242249\n",
      "Finished epoch 642, latest loss 0.7018266320228577\n",
      "Finished epoch 643, latest loss 0.7044975757598877\n",
      "Finished epoch 644, latest loss 0.7018122673034668\n",
      "Finished epoch 645, latest loss 0.7008433938026428\n",
      "Finished epoch 646, latest loss 0.7017741799354553\n",
      "Finished epoch 647, latest loss 0.7067286968231201\n",
      "Finished epoch 648, latest loss 0.7035518288612366\n",
      "Finished epoch 649, latest loss 0.7045705914497375\n",
      "Finished epoch 650, latest loss 0.7067593932151794\n",
      "Finished epoch 651, latest loss 0.7071166634559631\n",
      "Finished epoch 652, latest loss 0.705707311630249\n",
      "Finished epoch 653, latest loss 0.7027058005332947\n",
      "Finished epoch 654, latest loss 0.7065679430961609\n",
      "Finished epoch 655, latest loss 0.7027865052223206\n",
      "Finished epoch 656, latest loss 0.7046171426773071\n",
      "Finished epoch 657, latest loss 0.702785849571228\n",
      "Finished epoch 658, latest loss 0.7027202844619751\n",
      "Finished epoch 659, latest loss 0.7026222944259644\n",
      "Finished epoch 660, latest loss 0.7036339044570923\n",
      "Finished epoch 661, latest loss 0.7033237218856812\n",
      "Finished epoch 662, latest loss 0.7055720686912537\n",
      "Finished epoch 663, latest loss 0.7037120461463928\n",
      "Finished epoch 664, latest loss 0.7050498723983765\n",
      "Finished epoch 665, latest loss 0.701386034488678\n",
      "Finished epoch 666, latest loss 0.7042921185493469\n",
      "Finished epoch 667, latest loss 0.7054388523101807\n",
      "Finished epoch 668, latest loss 0.7036834955215454\n",
      "Finished epoch 669, latest loss 0.7034549713134766\n",
      "Finished epoch 670, latest loss 0.7056318521499634\n",
      "Finished epoch 671, latest loss 0.7027027606964111\n",
      "Finished epoch 672, latest loss 0.7060391902923584\n",
      "Finished epoch 673, latest loss 0.7054925560951233\n",
      "Finished epoch 674, latest loss 0.7040736675262451\n",
      "Finished epoch 675, latest loss 0.7035514116287231\n",
      "Finished epoch 676, latest loss 0.7028087973594666\n",
      "Finished epoch 677, latest loss 0.7029914855957031\n",
      "Finished epoch 678, latest loss 0.7027259469032288\n",
      "Finished epoch 679, latest loss 0.7037580609321594\n",
      "Finished epoch 680, latest loss 0.7018557786941528\n",
      "Finished epoch 681, latest loss 0.7064200639724731\n",
      "Finished epoch 682, latest loss 0.7028027176856995\n",
      "Finished epoch 683, latest loss 0.7008445262908936\n",
      "Finished epoch 684, latest loss 0.7009096741676331\n",
      "Finished epoch 685, latest loss 0.7042298913002014\n",
      "Finished epoch 686, latest loss 0.7027042508125305\n",
      "Finished epoch 687, latest loss 0.7013983726501465\n",
      "Finished epoch 688, latest loss 0.7039086222648621\n",
      "Finished epoch 689, latest loss 0.7046489715576172\n",
      "Finished epoch 690, latest loss 0.7046334147453308\n",
      "Finished epoch 691, latest loss 0.7046682238578796\n",
      "Finished epoch 692, latest loss 0.7016928195953369\n",
      "Finished epoch 693, latest loss 0.7013058662414551\n",
      "Finished epoch 694, latest loss 0.7027037143707275\n",
      "Finished epoch 695, latest loss 0.7048935294151306\n",
      "Finished epoch 696, latest loss 0.7019814848899841\n",
      "Finished epoch 697, latest loss 0.702826201915741\n",
      "Finished epoch 698, latest loss 0.6998339891433716\n",
      "Finished epoch 699, latest loss 0.7008083462715149\n",
      "Finished epoch 700, latest loss 0.7018802165985107\n",
      "Finished epoch 701, latest loss 0.7018527388572693\n",
      "Finished epoch 702, latest loss 0.7048609852790833\n",
      "Finished epoch 703, latest loss 0.7050786018371582\n",
      "Finished epoch 704, latest loss 0.7021111249923706\n",
      "Finished epoch 705, latest loss 0.7084445357322693\n",
      "Finished epoch 706, latest loss 0.7094067931175232\n",
      "Finished epoch 707, latest loss 0.7032859325408936\n",
      "Finished epoch 708, latest loss 0.7055720090866089\n",
      "Finished epoch 709, latest loss 0.7030607461929321\n",
      "Finished epoch 710, latest loss 0.7034305930137634\n",
      "Finished epoch 711, latest loss 0.7045754194259644\n",
      "Finished epoch 712, latest loss 0.7054958939552307\n",
      "Finished epoch 713, latest loss 0.7027857899665833\n",
      "Finished epoch 714, latest loss 0.7009141445159912\n",
      "Finished epoch 715, latest loss 0.701856791973114\n",
      "Finished epoch 716, latest loss 0.7037016153335571\n",
      "Finished epoch 717, latest loss 0.7012060880661011\n",
      "Finished epoch 718, latest loss 0.7053766250610352\n",
      "Finished epoch 719, latest loss 0.7047595977783203\n",
      "Finished epoch 720, latest loss 0.7027193903923035\n",
      "Finished epoch 721, latest loss 0.7008510231971741\n",
      "Finished epoch 722, latest loss 0.7009554505348206\n",
      "Finished epoch 723, latest loss 0.7009011507034302\n",
      "Finished epoch 724, latest loss 0.7047087550163269\n",
      "Finished epoch 725, latest loss 0.7058847546577454\n",
      "Finished epoch 726, latest loss 0.706035852432251\n",
      "Finished epoch 727, latest loss 0.7055333256721497\n",
      "Finished epoch 728, latest loss 0.7038231492042542\n",
      "Finished epoch 729, latest loss 0.7037393450737\n",
      "Finished epoch 730, latest loss 0.7033572196960449\n",
      "Finished epoch 731, latest loss 0.7055502533912659\n",
      "Finished epoch 732, latest loss 0.7008212804794312\n",
      "Finished epoch 733, latest loss 0.6999150514602661\n",
      "Finished epoch 734, latest loss 0.704695999622345\n",
      "Finished epoch 735, latest loss 0.7055853009223938\n",
      "Finished epoch 736, latest loss 0.7050845623016357\n",
      "Finished epoch 737, latest loss 0.7025387287139893\n",
      "Finished epoch 738, latest loss 0.7036938667297363\n",
      "Finished epoch 739, latest loss 0.7009795904159546\n",
      "Finished epoch 740, latest loss 0.702010452747345\n",
      "Finished epoch 741, latest loss 0.7003738880157471\n",
      "Finished epoch 742, latest loss 0.7007626295089722\n",
      "Finished epoch 743, latest loss 0.7008569240570068\n",
      "Finished epoch 744, latest loss 0.7045964598655701\n",
      "Finished epoch 745, latest loss 0.7032487988471985\n",
      "Finished epoch 746, latest loss 0.7020962834358215\n",
      "Finished epoch 747, latest loss 0.7026102542877197\n",
      "Finished epoch 748, latest loss 0.7008457779884338\n",
      "Finished epoch 749, latest loss 0.7037313580513\n",
      "Finished epoch 750, latest loss 0.7043988704681396\n",
      "Finished epoch 751, latest loss 0.7008919715881348\n",
      "Finished epoch 752, latest loss 0.7015367150306702\n",
      "Finished epoch 753, latest loss 0.7029626369476318\n",
      "Finished epoch 754, latest loss 0.7054155468940735\n",
      "Finished epoch 755, latest loss 0.7016953825950623\n",
      "Finished epoch 756, latest loss 0.701445996761322\n",
      "Finished epoch 757, latest loss 0.7025200128555298\n",
      "Finished epoch 758, latest loss 0.7027703523635864\n",
      "Finished epoch 759, latest loss 0.7019144296646118\n",
      "Finished epoch 760, latest loss 0.7008103728294373\n",
      "Finished epoch 761, latest loss 0.7036998867988586\n",
      "Finished epoch 762, latest loss 0.7036234140396118\n",
      "Finished epoch 763, latest loss 0.703790545463562\n",
      "Finished epoch 764, latest loss 0.701774001121521\n",
      "Finished epoch 765, latest loss 0.7031413912773132\n",
      "Finished epoch 766, latest loss 0.7026413083076477\n",
      "Finished epoch 767, latest loss 0.7016102075576782\n",
      "Finished epoch 768, latest loss 0.7016876339912415\n",
      "Finished epoch 769, latest loss 0.7052788138389587\n",
      "Finished epoch 770, latest loss 0.7017163038253784\n",
      "Finished epoch 771, latest loss 0.7032321691513062\n",
      "Finished epoch 772, latest loss 0.7019038796424866\n",
      "Finished epoch 773, latest loss 0.7040742039680481\n",
      "Finished epoch 774, latest loss 0.7054628133773804\n",
      "Finished epoch 775, latest loss 0.7036221623420715\n",
      "Finished epoch 776, latest loss 0.7017744779586792\n",
      "Finished epoch 777, latest loss 0.7023610472679138\n",
      "Finished epoch 778, latest loss 0.7013342976570129\n",
      "Finished epoch 779, latest loss 0.7064967751502991\n",
      "Finished epoch 780, latest loss 0.7038365006446838\n",
      "Finished epoch 781, latest loss 0.7036305665969849\n",
      "Finished epoch 782, latest loss 0.7020934224128723\n",
      "Finished epoch 783, latest loss 0.7026997208595276\n",
      "Finished epoch 784, latest loss 0.7010207176208496\n",
      "Finished epoch 785, latest loss 0.7007817029953003\n",
      "Finished epoch 786, latest loss 0.7042524218559265\n",
      "Finished epoch 787, latest loss 0.7036334872245789\n",
      "Finished epoch 788, latest loss 0.7027103304862976\n",
      "Finished epoch 789, latest loss 0.7045939564704895\n",
      "Finished epoch 790, latest loss 0.7047784328460693\n",
      "Finished epoch 791, latest loss 0.705496072769165\n",
      "Finished epoch 792, latest loss 0.7071182727813721\n",
      "Finished epoch 793, latest loss 0.7009366154670715\n",
      "Finished epoch 794, latest loss 0.7045269012451172\n",
      "Finished epoch 795, latest loss 0.702373743057251\n",
      "Finished epoch 796, latest loss 0.7040203213691711\n",
      "Finished epoch 797, latest loss 0.7041239738464355\n",
      "Finished epoch 798, latest loss 0.7019402980804443\n",
      "Finished epoch 799, latest loss 0.7011334300041199\n",
      "Finished epoch 800, latest loss 0.7018426060676575\n",
      "Finished epoch 801, latest loss 0.7028964757919312\n",
      "Finished epoch 802, latest loss 0.7048952579498291\n",
      "Finished epoch 803, latest loss 0.7037943005561829\n",
      "Finished epoch 804, latest loss 0.7021105289459229\n",
      "Finished epoch 805, latest loss 0.7007260918617249\n",
      "Finished epoch 806, latest loss 0.701774537563324\n",
      "Finished epoch 807, latest loss 0.7017746567726135\n",
      "Finished epoch 808, latest loss 0.7051053643226624\n",
      "Finished epoch 809, latest loss 0.7019412517547607\n",
      "Finished epoch 810, latest loss 0.7046438455581665\n",
      "Finished epoch 811, latest loss 0.7046689987182617\n",
      "Finished epoch 812, latest loss 0.7017821073532104\n",
      "Finished epoch 813, latest loss 0.7005645036697388\n",
      "Finished epoch 814, latest loss 0.7023191452026367\n",
      "Finished epoch 815, latest loss 0.7017729878425598\n",
      "Finished epoch 816, latest loss 0.7008445262908936\n",
      "Finished epoch 817, latest loss 0.6989921927452087\n",
      "Finished epoch 818, latest loss 0.7020611763000488\n",
      "Finished epoch 819, latest loss 0.700248122215271\n",
      "Finished epoch 820, latest loss 0.7009338140487671\n",
      "Finished epoch 821, latest loss 0.7008445262908936\n",
      "Finished epoch 822, latest loss 0.7037978172302246\n",
      "Finished epoch 823, latest loss 0.7025072574615479\n",
      "Finished epoch 824, latest loss 0.7019820213317871\n",
      "Finished epoch 825, latest loss 0.7027849555015564\n",
      "Finished epoch 826, latest loss 0.7014875411987305\n",
      "Finished epoch 827, latest loss 0.7032338380813599\n",
      "Finished epoch 828, latest loss 0.7029416561126709\n",
      "Finished epoch 829, latest loss 0.7029512524604797\n",
      "Finished epoch 830, latest loss 0.7024102210998535\n",
      "Finished epoch 831, latest loss 0.7018407583236694\n",
      "Finished epoch 832, latest loss 0.702334463596344\n",
      "Finished epoch 833, latest loss 0.7003170847892761\n",
      "Finished epoch 834, latest loss 0.7020261883735657\n",
      "Finished epoch 835, latest loss 0.6998767852783203\n",
      "Finished epoch 836, latest loss 0.6990095376968384\n",
      "Finished epoch 837, latest loss 0.7007948756217957\n",
      "Finished epoch 838, latest loss 0.7015032172203064\n",
      "Finished epoch 839, latest loss 0.7020860314369202\n",
      "Finished epoch 840, latest loss 0.6991783976554871\n",
      "Finished epoch 841, latest loss 0.7009328603744507\n",
      "Finished epoch 842, latest loss 0.7020259499549866\n",
      "Finished epoch 843, latest loss 0.7019861340522766\n",
      "Finished epoch 844, latest loss 0.7037415504455566\n",
      "Finished epoch 845, latest loss 0.7018588185310364\n",
      "Finished epoch 846, latest loss 0.7009275555610657\n",
      "Finished epoch 847, latest loss 0.7032910585403442\n",
      "Finished epoch 848, latest loss 0.70278400182724\n",
      "Finished epoch 849, latest loss 0.7016992568969727\n",
      "Finished epoch 850, latest loss 0.6996270418167114\n",
      "Finished epoch 851, latest loss 0.7044658660888672\n",
      "Finished epoch 852, latest loss 0.7018516063690186\n",
      "Finished epoch 853, latest loss 0.7010530233383179\n",
      "Finished epoch 854, latest loss 0.7028136849403381\n",
      "Finished epoch 855, latest loss 0.698904812335968\n",
      "Finished epoch 856, latest loss 0.7057273387908936\n",
      "Finished epoch 857, latest loss 0.7017753720283508\n",
      "Finished epoch 858, latest loss 0.7015167474746704\n",
      "Finished epoch 859, latest loss 0.7000243663787842\n",
      "Finished epoch 860, latest loss 0.7017783522605896\n",
      "Finished epoch 861, latest loss 0.7037858366966248\n",
      "Finished epoch 862, latest loss 0.6999191045761108\n",
      "Finished epoch 863, latest loss 0.7016906142234802\n",
      "Finished epoch 864, latest loss 0.7037152051925659\n",
      "Finished epoch 865, latest loss 0.7008454203605652\n",
      "Finished epoch 866, latest loss 0.7028945088386536\n",
      "Finished epoch 867, latest loss 0.701321005821228\n",
      "Finished epoch 868, latest loss 0.700032114982605\n",
      "Finished epoch 869, latest loss 0.7026218175888062\n",
      "Finished epoch 870, latest loss 0.6999156475067139\n",
      "Finished epoch 871, latest loss 0.7045804858207703\n",
      "Finished epoch 872, latest loss 0.6996729969978333\n",
      "Finished epoch 873, latest loss 0.6991075277328491\n",
      "Finished epoch 874, latest loss 0.7008445262908936\n",
      "Finished epoch 875, latest loss 0.7027036547660828\n",
      "Finished epoch 876, latest loss 0.7004479765892029\n",
      "Finished epoch 877, latest loss 0.7018471360206604\n",
      "Finished epoch 878, latest loss 0.7005713582038879\n",
      "Finished epoch 879, latest loss 0.6999160647392273\n",
      "Finished epoch 880, latest loss 0.7011246085166931\n",
      "Finished epoch 881, latest loss 0.7011536359786987\n",
      "Finished epoch 882, latest loss 0.700158953666687\n",
      "Finished epoch 883, latest loss 0.7028128504753113\n",
      "Finished epoch 884, latest loss 0.706023633480072\n",
      "Finished epoch 885, latest loss 0.7000346779823303\n",
      "Finished epoch 886, latest loss 0.7030778527259827\n",
      "Finished epoch 887, latest loss 0.7009248733520508\n",
      "Finished epoch 888, latest loss 0.7019969820976257\n",
      "Finished epoch 889, latest loss 0.7020533084869385\n",
      "Finished epoch 890, latest loss 0.6999277472496033\n",
      "Finished epoch 891, latest loss 0.7008525729179382\n",
      "Finished epoch 892, latest loss 0.7009287476539612\n",
      "Finished epoch 893, latest loss 0.7009265422821045\n",
      "Finished epoch 894, latest loss 0.7027267813682556\n",
      "Finished epoch 895, latest loss 0.7000997066497803\n",
      "Finished epoch 896, latest loss 0.7009941935539246\n",
      "Finished epoch 897, latest loss 0.7017245888710022\n",
      "Finished epoch 898, latest loss 0.700779378414154\n",
      "Finished epoch 899, latest loss 0.7007336616516113\n",
      "Finished epoch 900, latest loss 0.7018564939498901\n",
      "Finished epoch 901, latest loss 0.704077959060669\n",
      "Finished epoch 902, latest loss 0.6999186277389526\n",
      "Finished epoch 903, latest loss 0.6997286677360535\n",
      "Finished epoch 904, latest loss 0.7030590772628784\n",
      "Finished epoch 905, latest loss 0.7001879215240479\n",
      "Finished epoch 906, latest loss 0.6986739635467529\n",
      "Finished epoch 907, latest loss 0.7010257244110107\n",
      "Finished epoch 908, latest loss 0.7000151872634888\n",
      "Finished epoch 909, latest loss 0.7027058005332947\n",
      "Finished epoch 910, latest loss 0.7019201517105103\n",
      "Finished epoch 911, latest loss 0.6999578475952148\n",
      "Finished epoch 912, latest loss 0.7017304301261902\n",
      "Finished epoch 913, latest loss 0.7008640170097351\n",
      "Finished epoch 914, latest loss 0.7008445262908936\n",
      "Finished epoch 915, latest loss 0.7007926106452942\n",
      "Finished epoch 916, latest loss 0.7027846574783325\n",
      "Finished epoch 917, latest loss 0.7007710933685303\n",
      "Finished epoch 918, latest loss 0.7015938758850098\n",
      "Finished epoch 919, latest loss 0.7016385197639465\n",
      "Finished epoch 920, latest loss 0.6980354189872742\n",
      "Finished epoch 921, latest loss 0.7047221660614014\n",
      "Finished epoch 922, latest loss 0.7027849555015564\n",
      "Finished epoch 923, latest loss 0.7009366154670715\n",
      "Finished epoch 924, latest loss 0.704643726348877\n",
      "Finished epoch 925, latest loss 0.7041298747062683\n",
      "Finished epoch 926, latest loss 0.7009956240653992\n",
      "Finished epoch 927, latest loss 0.6998460292816162\n",
      "Finished epoch 928, latest loss 0.69986492395401\n",
      "Finished epoch 929, latest loss 0.7028314471244812\n",
      "Finished epoch 930, latest loss 0.7034046053886414\n",
      "Finished epoch 931, latest loss 0.6999149322509766\n",
      "Finished epoch 932, latest loss 0.703951895236969\n",
      "Finished epoch 933, latest loss 0.7009207606315613\n",
      "Finished epoch 934, latest loss 0.7031738758087158\n",
      "Finished epoch 935, latest loss 0.7016345858573914\n",
      "Finished epoch 936, latest loss 0.6989033222198486\n",
      "Finished epoch 937, latest loss 0.7037374973297119\n",
      "Finished epoch 938, latest loss 0.7019425630569458\n",
      "Finished epoch 939, latest loss 0.6990370154380798\n",
      "Finished epoch 940, latest loss 0.6981707811355591\n",
      "Finished epoch 941, latest loss 0.7000341415405273\n",
      "Finished epoch 942, latest loss 0.7008773684501648\n",
      "Finished epoch 943, latest loss 0.6989853978157043\n",
      "Finished epoch 944, latest loss 0.702997088432312\n",
      "Finished epoch 945, latest loss 0.7018334269523621\n",
      "Finished epoch 946, latest loss 0.6989913582801819\n",
      "Finished epoch 947, latest loss 0.7001638412475586\n",
      "Finished epoch 948, latest loss 0.7000665068626404\n",
      "Finished epoch 949, latest loss 0.7032644152641296\n",
      "Finished epoch 950, latest loss 0.7000429034233093\n",
      "Finished epoch 951, latest loss 0.6990010738372803\n",
      "Finished epoch 952, latest loss 0.7009497284889221\n",
      "Finished epoch 953, latest loss 0.6993374824523926\n",
      "Finished epoch 954, latest loss 0.6996331810951233\n",
      "Finished epoch 955, latest loss 0.6990675926208496\n",
      "Finished epoch 956, latest loss 0.7001670598983765\n",
      "Finished epoch 957, latest loss 0.6969696283340454\n",
      "Finished epoch 958, latest loss 0.701318621635437\n",
      "Finished epoch 959, latest loss 0.698931097984314\n",
      "Finished epoch 960, latest loss 0.7009231448173523\n",
      "Finished epoch 961, latest loss 0.6990500092506409\n",
      "Finished epoch 962, latest loss 0.7033175230026245\n",
      "Finished epoch 963, latest loss 0.6986889243125916\n",
      "Finished epoch 964, latest loss 0.7000535130500793\n",
      "Finished epoch 965, latest loss 0.7006632089614868\n",
      "Finished epoch 966, latest loss 0.6988232135772705\n",
      "Finished epoch 967, latest loss 0.70091313123703\n",
      "Finished epoch 968, latest loss 0.6998994946479797\n",
      "Finished epoch 969, latest loss 0.7028608322143555\n",
      "Finished epoch 970, latest loss 0.700378954410553\n",
      "Finished epoch 971, latest loss 0.7026984691619873\n",
      "Finished epoch 972, latest loss 0.7039552330970764\n",
      "Finished epoch 973, latest loss 0.6999155879020691\n",
      "Finished epoch 974, latest loss 0.6999624967575073\n",
      "Finished epoch 975, latest loss 0.7027855515480042\n",
      "Finished epoch 976, latest loss 0.7000076770782471\n",
      "Finished epoch 977, latest loss 0.6989367604255676\n",
      "Finished epoch 978, latest loss 0.69963538646698\n",
      "Finished epoch 979, latest loss 0.6979193687438965\n",
      "Finished epoch 980, latest loss 0.699054479598999\n",
      "Finished epoch 981, latest loss 0.7002190947532654\n",
      "Finished epoch 982, latest loss 0.7002045512199402\n",
      "Finished epoch 983, latest loss 0.7009815573692322\n",
      "Finished epoch 984, latest loss 0.7038018703460693\n",
      "Finished epoch 985, latest loss 0.6989080309867859\n",
      "Finished epoch 986, latest loss 0.7004737257957458\n",
      "Finished epoch 987, latest loss 0.6997968554496765\n",
      "Finished epoch 988, latest loss 0.7009642720222473\n",
      "Finished epoch 989, latest loss 0.7011064887046814\n",
      "Finished epoch 990, latest loss 0.6989853978157043\n",
      "Finished epoch 991, latest loss 0.7008904814720154\n",
      "Finished epoch 992, latest loss 0.7017486691474915\n",
      "Finished epoch 993, latest loss 0.7009626626968384\n",
      "Finished epoch 994, latest loss 0.6980425715446472\n",
      "Finished epoch 995, latest loss 0.6989126801490784\n",
      "Finished epoch 996, latest loss 0.6988213062286377\n",
      "Finished epoch 997, latest loss 0.6998200416564941\n",
      "Finished epoch 998, latest loss 0.6989598274230957\n",
      "Finished epoch 999, latest loss 0.6999532580375671\n",
      "Finished epoch 1000, latest loss 0.7017761468887329\n",
      "Finished epoch 1001, latest loss 0.7000786066055298\n",
      "Finished epoch 1002, latest loss 0.7037379741668701\n",
      "Finished epoch 1003, latest loss 0.6979740262031555\n",
      "Finished epoch 1004, latest loss 0.7030326128005981\n",
      "Finished epoch 1005, latest loss 0.7032402753829956\n",
      "Finished epoch 1006, latest loss 0.6995518207550049\n",
      "Finished epoch 1007, latest loss 0.6986362934112549\n",
      "Finished epoch 1008, latest loss 0.6979742646217346\n",
      "Finished epoch 1009, latest loss 0.6999941468238831\n",
      "Finished epoch 1010, latest loss 0.6970697641372681\n",
      "Finished epoch 1011, latest loss 0.7007663249969482\n",
      "Finished epoch 1012, latest loss 0.697970986366272\n",
      "Finished epoch 1013, latest loss 0.698920488357544\n",
      "Finished epoch 1014, latest loss 0.6989342570304871\n",
      "Finished epoch 1015, latest loss 0.6982772350311279\n",
      "Finished epoch 1016, latest loss 0.6992089152336121\n",
      "Finished epoch 1017, latest loss 0.6997379064559937\n",
      "Finished epoch 1018, latest loss 0.7005810737609863\n",
      "Finished epoch 1019, latest loss 0.6979422569274902\n",
      "Finished epoch 1020, latest loss 0.700843334197998\n",
      "Finished epoch 1021, latest loss 0.6999027132987976\n",
      "Finished epoch 1022, latest loss 0.6989545822143555\n",
      "Finished epoch 1023, latest loss 0.6989975571632385\n",
      "Finished epoch 1024, latest loss 0.6988693475723267\n",
      "Finished epoch 1025, latest loss 0.69987553358078\n",
      "Finished epoch 1026, latest loss 0.6978921294212341\n",
      "Finished epoch 1027, latest loss 0.6988561153411865\n",
      "Finished epoch 1028, latest loss 0.7000652551651001\n",
      "Finished epoch 1029, latest loss 0.6999651193618774\n",
      "Finished epoch 1030, latest loss 0.7008422613143921\n",
      "Finished epoch 1031, latest loss 0.7008439898490906\n",
      "Finished epoch 1032, latest loss 0.6980387568473816\n",
      "Finished epoch 1033, latest loss 0.7001184821128845\n",
      "Finished epoch 1034, latest loss 0.6989840865135193\n",
      "Finished epoch 1035, latest loss 0.6960928440093994\n",
      "Finished epoch 1036, latest loss 0.6981468200683594\n",
      "Finished epoch 1037, latest loss 0.7016491293907166\n",
      "Finished epoch 1038, latest loss 0.6969634294509888\n",
      "Finished epoch 1039, latest loss 0.698905885219574\n",
      "Finished epoch 1040, latest loss 0.7010464072227478\n",
      "Finished epoch 1041, latest loss 0.7006146907806396\n",
      "Finished epoch 1042, latest loss 0.6989041566848755\n",
      "Finished epoch 1043, latest loss 0.6980673670768738\n",
      "Finished epoch 1044, latest loss 0.7010406255722046\n",
      "Finished epoch 1045, latest loss 0.6999863386154175\n",
      "Finished epoch 1046, latest loss 0.6989853978157043\n",
      "Finished epoch 1047, latest loss 0.6999146938323975\n",
      "Finished epoch 1048, latest loss 0.698986291885376\n",
      "Finished epoch 1049, latest loss 0.7008965611457825\n",
      "Finished epoch 1050, latest loss 0.6986277103424072\n",
      "Finished epoch 1051, latest loss 0.6980491280555725\n",
      "Finished epoch 1052, latest loss 0.6969621777534485\n",
      "Finished epoch 1053, latest loss 0.7000836730003357\n",
      "Finished epoch 1054, latest loss 0.6984738111495972\n",
      "Finished epoch 1055, latest loss 0.6997538208961487\n",
      "Finished epoch 1056, latest loss 0.6979737281799316\n",
      "Finished epoch 1057, latest loss 0.7026553750038147\n",
      "Finished epoch 1058, latest loss 0.7008445262908936\n",
      "Finished epoch 1059, latest loss 0.6971259117126465\n",
      "Finished epoch 1060, latest loss 0.6996724009513855\n",
      "Finished epoch 1061, latest loss 0.7022687196731567\n",
      "Finished epoch 1062, latest loss 0.7016851305961609\n",
      "Finished epoch 1063, latest loss 0.6999959945678711\n",
      "Finished epoch 1064, latest loss 0.6989033222198486\n",
      "Finished epoch 1065, latest loss 0.6999961137771606\n",
      "Finished epoch 1066, latest loss 0.7032647132873535\n",
      "Finished epoch 1067, latest loss 0.6980386972427368\n",
      "Finished epoch 1068, latest loss 0.7008224725723267\n",
      "Finished epoch 1069, latest loss 0.7038632035255432\n",
      "Finished epoch 1070, latest loss 0.7002741098403931\n",
      "Finished epoch 1071, latest loss 0.6980798244476318\n",
      "Finished epoch 1072, latest loss 0.7016977071762085\n",
      "Finished epoch 1073, latest loss 0.7006799578666687\n",
      "Finished epoch 1074, latest loss 0.6989094018936157\n",
      "Finished epoch 1075, latest loss 0.6999067068099976\n",
      "Finished epoch 1076, latest loss 0.69833904504776\n",
      "Finished epoch 1077, latest loss 0.6997985243797302\n",
      "Finished epoch 1078, latest loss 0.7009283304214478\n",
      "Finished epoch 1079, latest loss 0.6989036202430725\n",
      "Finished epoch 1080, latest loss 0.6997508406639099\n",
      "Finished epoch 1081, latest loss 0.7017563581466675\n",
      "Finished epoch 1082, latest loss 0.6979776620864868\n",
      "Finished epoch 1083, latest loss 0.6999543905258179\n",
      "Finished epoch 1084, latest loss 0.697054922580719\n",
      "Finished epoch 1085, latest loss 0.6989868879318237\n",
      "Finished epoch 1086, latest loss 0.7020640969276428\n",
      "Finished epoch 1087, latest loss 0.6979738473892212\n",
      "Finished epoch 1088, latest loss 0.697982668876648\n",
      "Finished epoch 1089, latest loss 0.6999450325965881\n",
      "Finished epoch 1090, latest loss 0.6988705396652222\n",
      "Finished epoch 1091, latest loss 0.6970459818840027\n",
      "Finished epoch 1092, latest loss 0.7006182074546814\n",
      "Finished epoch 1093, latest loss 0.6991385817527771\n",
      "Finished epoch 1094, latest loss 0.6978738903999329\n",
      "Finished epoch 1095, latest loss 0.6979186534881592\n",
      "Finished epoch 1096, latest loss 0.6969636678695679\n",
      "Finished epoch 1097, latest loss 0.6989576816558838\n",
      "Finished epoch 1098, latest loss 0.6969739198684692\n",
      "Finished epoch 1099, latest loss 0.6979687809944153\n",
      "Finished epoch 1100, latest loss 0.701288104057312\n",
      "Finished epoch 1101, latest loss 0.7011139392852783\n",
      "Finished epoch 1102, latest loss 0.7017727494239807\n",
      "Finished epoch 1103, latest loss 0.7009870409965515\n",
      "Finished epoch 1104, latest loss 0.7008176445960999\n",
      "Finished epoch 1105, latest loss 0.6979779005050659\n",
      "Finished epoch 1106, latest loss 0.6977922916412354\n",
      "Finished epoch 1107, latest loss 0.698064386844635\n",
      "Finished epoch 1108, latest loss 0.6980463862419128\n",
      "Finished epoch 1109, latest loss 0.6998322606086731\n",
      "Finished epoch 1110, latest loss 0.7017749547958374\n",
      "Finished epoch 1111, latest loss 0.6980562806129456\n",
      "Finished epoch 1112, latest loss 0.6979809999465942\n",
      "Finished epoch 1113, latest loss 0.699861466884613\n",
      "Finished epoch 1114, latest loss 0.6970526576042175\n",
      "Finished epoch 1115, latest loss 0.6970505714416504\n",
      "Finished epoch 1116, latest loss 0.697939932346344\n",
      "Finished epoch 1117, latest loss 0.7007179260253906\n",
      "Finished epoch 1118, latest loss 0.6980559229850769\n",
      "Finished epoch 1119, latest loss 0.7021984457969666\n",
      "Finished epoch 1120, latest loss 0.7016264200210571\n",
      "Finished epoch 1121, latest loss 0.6967434287071228\n",
      "Finished epoch 1122, latest loss 0.7005829215049744\n",
      "Finished epoch 1123, latest loss 0.6977354884147644\n",
      "Finished epoch 1124, latest loss 0.6971274018287659\n",
      "Finished epoch 1125, latest loss 0.6951169371604919\n",
      "Finished epoch 1126, latest loss 0.6970697045326233\n",
      "Finished epoch 1127, latest loss 0.6975886821746826\n",
      "Finished epoch 1128, latest loss 0.6987152695655823\n",
      "Finished epoch 1129, latest loss 0.6970526576042175\n",
      "Finished epoch 1130, latest loss 0.6969725489616394\n",
      "Finished epoch 1131, latest loss 0.6989521384239197\n",
      "Finished epoch 1132, latest loss 0.6964378356933594\n",
      "Finished epoch 1133, latest loss 0.6973471641540527\n",
      "Finished epoch 1134, latest loss 0.6951035857200623\n",
      "Finished epoch 1135, latest loss 0.6951951384544373\n",
      "Finished epoch 1136, latest loss 0.6966845393180847\n",
      "Finished epoch 1137, latest loss 0.6951035857200623\n",
      "Finished epoch 1138, latest loss 0.6977624893188477\n",
      "Finished epoch 1139, latest loss 0.6984653472900391\n",
      "Finished epoch 1140, latest loss 0.6961890459060669\n",
      "Finished epoch 1141, latest loss 0.7009069919586182\n",
      "Finished epoch 1142, latest loss 0.6981782913208008\n",
      "Finished epoch 1143, latest loss 0.6979954838752747\n",
      "Finished epoch 1144, latest loss 0.6984342336654663\n",
      "Finished epoch 1145, latest loss 0.6970438957214355\n",
      "Finished epoch 1146, latest loss 0.7002933025360107\n",
      "Finished epoch 1147, latest loss 0.6980558037757874\n",
      "Finished epoch 1148, latest loss 0.6986243724822998\n",
      "Finished epoch 1149, latest loss 0.6970443725585938\n",
      "Finished epoch 1150, latest loss 0.6978767514228821\n",
      "Finished epoch 1151, latest loss 0.6979052424430847\n",
      "Finished epoch 1152, latest loss 0.6989847421646118\n",
      "Finished epoch 1153, latest loss 0.6970446705818176\n",
      "Finished epoch 1154, latest loss 0.6974186301231384\n",
      "Finished epoch 1155, latest loss 0.6961012482643127\n",
      "Finished epoch 1156, latest loss 0.6961143016815186\n",
      "Finished epoch 1157, latest loss 0.6980491280555725\n",
      "Finished epoch 1158, latest loss 0.699982225894928\n",
      "Finished epoch 1159, latest loss 0.6991007328033447\n",
      "Finished epoch 1160, latest loss 0.6979854106903076\n",
      "Finished epoch 1161, latest loss 0.6987214088439941\n",
      "Finished epoch 1162, latest loss 0.6979737877845764\n",
      "Finished epoch 1163, latest loss 0.6963278651237488\n",
      "Finished epoch 1164, latest loss 0.6971251368522644\n",
      "Finished epoch 1165, latest loss 0.6978924870491028\n",
      "Finished epoch 1166, latest loss 0.6986950635910034\n",
      "Finished epoch 1167, latest loss 0.6960325837135315\n",
      "Finished epoch 1168, latest loss 0.6992148756980896\n",
      "Finished epoch 1169, latest loss 0.6973986029624939\n",
      "Finished epoch 1170, latest loss 0.6979479789733887\n",
      "Finished epoch 1171, latest loss 0.6970216631889343\n",
      "Finished epoch 1172, latest loss 0.6970441937446594\n",
      "Finished epoch 1173, latest loss 0.6970877647399902\n",
      "Finished epoch 1174, latest loss 0.6961148977279663\n",
      "Finished epoch 1175, latest loss 0.7006593346595764\n",
      "Finished epoch 1176, latest loss 0.6980682015419006\n",
      "Finished epoch 1177, latest loss 0.6957845091819763\n",
      "Finished epoch 1178, latest loss 0.7007167935371399\n",
      "Finished epoch 1179, latest loss 0.6979683041572571\n",
      "Finished epoch 1180, latest loss 0.6970438957214355\n",
      "Finished epoch 1181, latest loss 0.6988333463668823\n",
      "Finished epoch 1182, latest loss 0.698380708694458\n",
      "Finished epoch 1183, latest loss 0.7007637619972229\n",
      "Finished epoch 1184, latest loss 0.6978917121887207\n",
      "Finished epoch 1185, latest loss 0.6979738473892212\n",
      "Finished epoch 1186, latest loss 0.6981257796287537\n",
      "Finished epoch 1187, latest loss 0.7009598016738892\n",
      "Finished epoch 1188, latest loss 0.6980757117271423\n",
      "Finished epoch 1189, latest loss 0.6989016532897949\n",
      "Finished epoch 1190, latest loss 0.6979767680168152\n",
      "Finished epoch 1191, latest loss 0.6997653245925903\n",
      "Finished epoch 1192, latest loss 0.6980512142181396\n",
      "Finished epoch 1193, latest loss 0.6976087689399719\n",
      "Finished epoch 1194, latest loss 0.6979418992996216\n",
      "Finished epoch 1195, latest loss 0.6994471549987793\n",
      "Finished epoch 1196, latest loss 0.6976613402366638\n",
      "Finished epoch 1197, latest loss 0.6979919672012329\n",
      "Finished epoch 1198, latest loss 0.6980425119400024\n",
      "Finished epoch 1199, latest loss 0.6974037289619446\n",
      "Finished epoch 1200, latest loss 0.6963977217674255\n",
      "Finished epoch 1201, latest loss 0.6970439553260803\n",
      "Finished epoch 1202, latest loss 0.6972107887268066\n",
      "Finished epoch 1203, latest loss 0.6971231698989868\n",
      "Finished epoch 1204, latest loss 0.7021027207374573\n",
      "Finished epoch 1205, latest loss 0.6999967694282532\n",
      "Finished epoch 1206, latest loss 0.699064314365387\n",
      "Finished epoch 1207, latest loss 0.6999951601028442\n",
      "Finished epoch 1208, latest loss 0.6970441937446594\n",
      "Finished epoch 1209, latest loss 0.6973769664764404\n",
      "Finished epoch 1210, latest loss 0.695411205291748\n",
      "Finished epoch 1211, latest loss 0.6970441937446594\n",
      "Finished epoch 1212, latest loss 0.6973367929458618\n",
      "Finished epoch 1213, latest loss 0.6963334083557129\n",
      "Finished epoch 1214, latest loss 0.6992110013961792\n",
      "Finished epoch 1215, latest loss 0.6960393786430359\n",
      "Finished epoch 1216, latest loss 0.6978906393051147\n",
      "Finished epoch 1217, latest loss 0.7019858360290527\n",
      "Finished epoch 1218, latest loss 0.6970272660255432\n",
      "Finished epoch 1219, latest loss 0.6989306807518005\n",
      "Finished epoch 1220, latest loss 0.6971478462219238\n",
      "Finished epoch 1221, latest loss 0.6961141228675842\n",
      "Finished epoch 1222, latest loss 0.6960328221321106\n",
      "Finished epoch 1223, latest loss 0.6971243619918823\n",
      "Finished epoch 1224, latest loss 0.6962979435920715\n",
      "Finished epoch 1225, latest loss 0.6964578628540039\n",
      "Finished epoch 1226, latest loss 0.6988197565078735\n",
      "Finished epoch 1227, latest loss 0.6989860534667969\n",
      "Finished epoch 1228, latest loss 0.6969621777534485\n",
      "Finished epoch 1229, latest loss 0.6960325837135315\n",
      "Finished epoch 1230, latest loss 0.6952333450317383\n",
      "Finished epoch 1231, latest loss 0.6960325837135315\n",
      "Finished epoch 1232, latest loss 0.6956586837768555\n",
      "Finished epoch 1233, latest loss 0.696032702922821\n",
      "Finished epoch 1234, latest loss 0.696032702922821\n",
      "Finished epoch 1235, latest loss 0.6969621777534485\n",
      "Finished epoch 1236, latest loss 0.6966232061386108\n",
      "Finished epoch 1237, latest loss 0.6951029896736145\n",
      "Finished epoch 1238, latest loss 0.6951029896736145\n",
      "Finished epoch 1239, latest loss 0.6991336345672607\n",
      "Finished epoch 1240, latest loss 0.6954649686813354\n",
      "Finished epoch 1241, latest loss 0.6961583495140076\n",
      "Finished epoch 1242, latest loss 0.696032702922821\n",
      "Finished epoch 1243, latest loss 0.6951029896736145\n",
      "Finished epoch 1244, latest loss 0.6961243152618408\n",
      "Finished epoch 1245, latest loss 0.6961275339126587\n",
      "Finished epoch 1246, latest loss 0.697446346282959\n",
      "Finished epoch 1247, latest loss 0.7013072967529297\n",
      "Finished epoch 1248, latest loss 0.698148250579834\n",
      "Finished epoch 1249, latest loss 0.6973824501037598\n",
      "Finished epoch 1250, latest loss 0.6951228976249695\n",
      "Finished epoch 1251, latest loss 0.6960407495498657\n",
      "Finished epoch 1252, latest loss 0.6970308423042297\n",
      "Finished epoch 1253, latest loss 0.6974717378616333\n",
      "Finished epoch 1254, latest loss 0.6975740790367126\n",
      "Finished epoch 1255, latest loss 0.6964025497436523\n",
      "Finished epoch 1256, latest loss 0.6961145997047424\n",
      "Finished epoch 1257, latest loss 0.7000658512115479\n",
      "Finished epoch 1258, latest loss 0.6981340646743774\n",
      "Finished epoch 1259, latest loss 0.6960560083389282\n",
      "Finished epoch 1260, latest loss 0.6980020403862\n",
      "Finished epoch 1261, latest loss 0.6970173120498657\n",
      "Finished epoch 1262, latest loss 0.6968433856964111\n",
      "Finished epoch 1263, latest loss 0.7004027366638184\n",
      "Finished epoch 1264, latest loss 0.6960315704345703\n",
      "Finished epoch 1265, latest loss 0.6960331797599792\n",
      "Finished epoch 1266, latest loss 0.696933925151825\n",
      "Finished epoch 1267, latest loss 0.6980701684951782\n",
      "Finished epoch 1268, latest loss 0.6971232295036316\n",
      "Finished epoch 1269, latest loss 0.6980182528495789\n",
      "Finished epoch 1270, latest loss 0.7021466493606567\n",
      "Finished epoch 1271, latest loss 0.6957561373710632\n",
      "Finished epoch 1272, latest loss 0.6970474123954773\n",
      "Finished epoch 1273, latest loss 0.6985349059104919\n",
      "Finished epoch 1274, latest loss 0.6962835788726807\n",
      "Finished epoch 1275, latest loss 0.6977543234825134\n",
      "Finished epoch 1276, latest loss 0.6979842185974121\n",
      "Finished epoch 1277, latest loss 0.6967331171035767\n",
      "Finished epoch 1278, latest loss 0.6989894509315491\n",
      "Finished epoch 1279, latest loss 0.7000535130500793\n",
      "Finished epoch 1280, latest loss 0.6980542540550232\n",
      "Finished epoch 1281, latest loss 0.7037200331687927\n",
      "Finished epoch 1282, latest loss 0.697974681854248\n",
      "Finished epoch 1283, latest loss 0.696116030216217\n",
      "Finished epoch 1284, latest loss 0.6971328854560852\n",
      "Finished epoch 1285, latest loss 0.6971017718315125\n",
      "Finished epoch 1286, latest loss 0.6968235373497009\n",
      "Finished epoch 1287, latest loss 0.7002480626106262\n",
      "Finished epoch 1288, latest loss 0.696312665939331\n",
      "Finished epoch 1289, latest loss 0.6971222758293152\n",
      "Finished epoch 1290, latest loss 0.6971262097358704\n",
      "Finished epoch 1291, latest loss 0.6969622373580933\n",
      "Finished epoch 1292, latest loss 0.6990674138069153\n",
      "Finished epoch 1293, latest loss 0.7001078724861145\n",
      "Finished epoch 1294, latest loss 0.6987255811691284\n",
      "Finished epoch 1295, latest loss 0.698205292224884\n",
      "Finished epoch 1296, latest loss 0.6961151957511902\n",
      "Finished epoch 1297, latest loss 0.6980266571044922\n",
      "Finished epoch 1298, latest loss 0.6961435079574585\n",
      "Finished epoch 1299, latest loss 0.6980088949203491\n",
      "Finished epoch 1300, latest loss 0.6980374455451965\n",
      "Finished epoch 1301, latest loss 0.7000784873962402\n",
      "Finished epoch 1302, latest loss 0.7029069662094116\n",
      "Finished epoch 1303, latest loss 0.6987862586975098\n",
      "Finished epoch 1304, latest loss 0.6979444026947021\n",
      "Finished epoch 1305, latest loss 0.6988831162452698\n",
      "Finished epoch 1306, latest loss 0.6990376710891724\n",
      "Finished epoch 1307, latest loss 0.6961145997047424\n",
      "Finished epoch 1308, latest loss 0.697894275188446\n",
      "Finished epoch 1309, latest loss 0.698565661907196\n",
      "Finished epoch 1310, latest loss 0.6999136209487915\n",
      "Finished epoch 1311, latest loss 0.6961150169372559\n",
      "Finished epoch 1312, latest loss 0.6980900764465332\n",
      "Finished epoch 1313, latest loss 0.6995192170143127\n",
      "Finished epoch 1314, latest loss 0.6989959478378296\n",
      "Finished epoch 1315, latest loss 0.6989676356315613\n",
      "Finished epoch 1316, latest loss 0.698042631149292\n",
      "Finished epoch 1317, latest loss 0.6970442533493042\n",
      "Finished epoch 1318, latest loss 0.7018676400184631\n",
      "Finished epoch 1319, latest loss 0.6976032853126526\n",
      "Finished epoch 1320, latest loss 0.6980090141296387\n",
      "Finished epoch 1321, latest loss 0.6961261034011841\n",
      "Finished epoch 1322, latest loss 0.6982418298721313\n",
      "Finished epoch 1323, latest loss 0.699045717716217\n",
      "Finished epoch 1324, latest loss 0.6998931169509888\n",
      "Finished epoch 1325, latest loss 0.6979782581329346\n",
      "Finished epoch 1326, latest loss 0.6989032030105591\n",
      "Finished epoch 1327, latest loss 0.697231113910675\n",
      "Finished epoch 1328, latest loss 0.6970500946044922\n",
      "Finished epoch 1329, latest loss 0.6980538964271545\n",
      "Finished epoch 1330, latest loss 0.7010101675987244\n",
      "Finished epoch 1331, latest loss 0.7010904550552368\n",
      "Finished epoch 1332, latest loss 0.6962372660636902\n",
      "Finished epoch 1333, latest loss 0.699187695980072\n",
      "Finished epoch 1334, latest loss 0.6989878416061401\n",
      "Finished epoch 1335, latest loss 0.7009196877479553\n",
      "Finished epoch 1336, latest loss 0.6988747119903564\n",
      "Finished epoch 1337, latest loss 0.6971839070320129\n",
      "Finished epoch 1338, latest loss 0.698046088218689\n",
      "Finished epoch 1339, latest loss 0.6960327625274658\n",
      "Finished epoch 1340, latest loss 0.7013599276542664\n",
      "Finished epoch 1341, latest loss 0.6990816593170166\n",
      "Finished epoch 1342, latest loss 0.698481559753418\n",
      "Finished epoch 1343, latest loss 0.6981549263000488\n",
      "Finished epoch 1344, latest loss 0.6953176856040955\n",
      "Finished epoch 1345, latest loss 0.6988409757614136\n",
      "Finished epoch 1346, latest loss 0.6960106492042542\n",
      "Finished epoch 1347, latest loss 0.6956831216812134\n",
      "Finished epoch 1348, latest loss 0.6969358921051025\n",
      "Finished epoch 1349, latest loss 0.6969621777534485\n",
      "Finished epoch 1350, latest loss 0.7000265121459961\n",
      "Finished epoch 1351, latest loss 0.6977261304855347\n",
      "Finished epoch 1352, latest loss 0.6979737281799316\n",
      "Finished epoch 1353, latest loss 0.6961948871612549\n",
      "Finished epoch 1354, latest loss 0.6970100402832031\n",
      "Finished epoch 1355, latest loss 0.69704270362854\n",
      "Finished epoch 1356, latest loss 0.6971890926361084\n",
      "Finished epoch 1357, latest loss 0.6951068043708801\n",
      "Finished epoch 1358, latest loss 0.6969618201255798\n",
      "Finished epoch 1359, latest loss 0.697682797908783\n",
      "Finished epoch 1360, latest loss 0.696033239364624\n",
      "Finished epoch 1361, latest loss 0.6959623098373413\n",
      "Finished epoch 1362, latest loss 0.7008573412895203\n",
      "Finished epoch 1363, latest loss 0.6979910731315613\n",
      "Finished epoch 1364, latest loss 0.7009180784225464\n",
      "Finished epoch 1365, latest loss 0.6971191167831421\n",
      "Finished epoch 1366, latest loss 0.698056161403656\n",
      "Finished epoch 1367, latest loss 0.69931560754776\n",
      "Finished epoch 1368, latest loss 0.6989853978157043\n",
      "Finished epoch 1369, latest loss 0.6989575624465942\n",
      "Finished epoch 1370, latest loss 0.6960325837135315\n",
      "Finished epoch 1371, latest loss 0.696114718914032\n",
      "Finished epoch 1372, latest loss 0.700815737247467\n",
      "Finished epoch 1373, latest loss 0.6987664699554443\n",
      "Finished epoch 1374, latest loss 0.6970434188842773\n",
      "Finished epoch 1375, latest loss 0.696114718914032\n",
      "Finished epoch 1376, latest loss 0.7015591859817505\n",
      "Finished epoch 1377, latest loss 0.6951292753219604\n",
      "Finished epoch 1378, latest loss 0.6951130628585815\n",
      "Finished epoch 1379, latest loss 0.7000781297683716\n",
      "Finished epoch 1380, latest loss 0.6990101337432861\n",
      "Finished epoch 1381, latest loss 0.6961159110069275\n",
      "Finished epoch 1382, latest loss 0.6971257328987122\n",
      "Finished epoch 1383, latest loss 0.6990589499473572\n",
      "Finished epoch 1384, latest loss 0.6977344751358032\n",
      "Finished epoch 1385, latest loss 0.6970441937446594\n",
      "Finished epoch 1386, latest loss 0.6972082853317261\n",
      "Finished epoch 1387, latest loss 0.69862961769104\n",
      "Finished epoch 1388, latest loss 0.6970483660697937\n",
      "Finished epoch 1389, latest loss 0.6980224847793579\n",
      "Finished epoch 1390, latest loss 0.6971098780632019\n",
      "Finished epoch 1391, latest loss 0.697104275226593\n",
      "Finished epoch 1392, latest loss 0.6978867650032043\n",
      "Finished epoch 1393, latest loss 0.6980530023574829\n",
      "Finished epoch 1394, latest loss 0.6997885704040527\n",
      "Finished epoch 1395, latest loss 0.6969624757766724\n",
      "Finished epoch 1396, latest loss 0.695127546787262\n",
      "Finished epoch 1397, latest loss 0.6991311311721802\n",
      "Finished epoch 1398, latest loss 0.696442186832428\n",
      "Finished epoch 1399, latest loss 0.6979175806045532\n",
      "Finished epoch 1400, latest loss 0.6982660293579102\n",
      "Finished epoch 1401, latest loss 0.6962575316429138\n",
      "Finished epoch 1402, latest loss 0.6942554712295532\n",
      "Finished epoch 1403, latest loss 0.6951857805252075\n",
      "Finished epoch 1404, latest loss 0.6978015899658203\n",
      "Finished epoch 1405, latest loss 0.6951147317886353\n",
      "Finished epoch 1406, latest loss 0.6961148381233215\n",
      "Finished epoch 1407, latest loss 0.6960570812225342\n",
      "Finished epoch 1408, latest loss 0.6965288519859314\n",
      "Finished epoch 1409, latest loss 0.6970508694648743\n",
      "Finished epoch 1410, latest loss 0.6980671286582947\n",
      "Finished epoch 1411, latest loss 0.6951850652694702\n",
      "Finished epoch 1412, latest loss 0.6960338950157166\n",
      "Finished epoch 1413, latest loss 0.6951878666877747\n",
      "Finished epoch 1414, latest loss 0.6965956091880798\n",
      "Finished epoch 1415, latest loss 0.695185661315918\n",
      "Finished epoch 1416, latest loss 0.6979814767837524\n",
      "Finished epoch 1417, latest loss 0.6953409910202026\n",
      "Finished epoch 1418, latest loss 0.6962704658508301\n",
      "Finished epoch 1419, latest loss 0.6962013244628906\n",
      "Finished epoch 1420, latest loss 0.6966575980186462\n",
      "Finished epoch 1421, latest loss 0.7008499503135681\n",
      "Finished epoch 1422, latest loss 0.695508599281311\n",
      "Finished epoch 1423, latest loss 0.6971404552459717\n",
      "Finished epoch 1424, latest loss 0.6968078017234802\n",
      "Finished epoch 1425, latest loss 0.695823073387146\n",
      "Finished epoch 1426, latest loss 0.698138952255249\n",
      "Finished epoch 1427, latest loss 0.6961145997047424\n",
      "Finished epoch 1428, latest loss 0.6970553398132324\n",
      "Finished epoch 1429, latest loss 0.6961966753005981\n",
      "Finished epoch 1430, latest loss 0.6950704455375671\n",
      "Finished epoch 1431, latest loss 0.6968370079994202\n",
      "Finished epoch 1432, latest loss 0.695461630821228\n",
      "Finished epoch 1433, latest loss 0.6961150169372559\n",
      "Finished epoch 1434, latest loss 0.6942163705825806\n",
      "Finished epoch 1435, latest loss 0.6971253156661987\n",
      "Finished epoch 1436, latest loss 0.6972993612289429\n",
      "Finished epoch 1437, latest loss 0.6958140134811401\n",
      "Finished epoch 1438, latest loss 0.6972426176071167\n",
      "Finished epoch 1439, latest loss 0.6992578506469727\n",
      "Finished epoch 1440, latest loss 0.6990654468536377\n",
      "Finished epoch 1441, latest loss 0.6951850652694702\n",
      "Finished epoch 1442, latest loss 0.6961150169372559\n",
      "Finished epoch 1443, latest loss 0.6961145997047424\n",
      "Finished epoch 1444, latest loss 0.6990782022476196\n",
      "Finished epoch 1445, latest loss 0.6969188451766968\n",
      "Finished epoch 1446, latest loss 0.6981379389762878\n",
      "Finished epoch 1447, latest loss 0.6962130069732666\n",
      "Finished epoch 1448, latest loss 0.6962068676948547\n",
      "Finished epoch 1449, latest loss 0.69767826795578\n",
      "Finished epoch 1450, latest loss 0.6971262097358704\n",
      "Finished epoch 1451, latest loss 0.6999567747116089\n",
      "Finished epoch 1452, latest loss 0.6961145997047424\n",
      "Finished epoch 1453, latest loss 0.6941739320755005\n",
      "Finished epoch 1454, latest loss 0.6961966753005981\n",
      "Finished epoch 1455, latest loss 0.6961109638214111\n",
      "Finished epoch 1456, latest loss 0.6970446109771729\n",
      "Finished epoch 1457, latest loss 0.6960325837135315\n",
      "Finished epoch 1458, latest loss 0.6970446109771729\n",
      "Finished epoch 1459, latest loss 0.6998313665390015\n",
      "Finished epoch 1460, latest loss 0.6961145997047424\n",
      "Finished epoch 1461, latest loss 0.6990663409233093\n",
      "Finished epoch 1462, latest loss 0.6961145997047424\n",
      "Finished epoch 1463, latest loss 0.6970658898353577\n",
      "Finished epoch 1464, latest loss 0.6970198750495911\n",
      "Finished epoch 1465, latest loss 0.7007625102996826\n",
      "Finished epoch 1466, latest loss 0.6965203881263733\n",
      "Finished epoch 1467, latest loss 0.6979752779006958\n",
      "Finished epoch 1468, latest loss 0.6961579322814941\n",
      "Finished epoch 1469, latest loss 0.6997347474098206\n",
      "Finished epoch 1470, latest loss 0.6971263885498047\n",
      "Finished epoch 1471, latest loss 0.6989770531654358\n",
      "Finished epoch 1472, latest loss 0.6972197890281677\n",
      "Finished epoch 1473, latest loss 0.6961145997047424\n",
      "Finished epoch 1474, latest loss 0.6971843838691711\n",
      "Finished epoch 1475, latest loss 0.6963493824005127\n",
      "Finished epoch 1476, latest loss 0.6960285902023315\n",
      "Finished epoch 1477, latest loss 0.6961964964866638\n",
      "Finished epoch 1478, latest loss 0.6972681283950806\n",
      "Finished epoch 1479, latest loss 0.6942554712295532\n",
      "Finished epoch 1480, latest loss 0.6952746510505676\n",
      "Finished epoch 1481, latest loss 0.6969719529151917\n",
      "Finished epoch 1482, latest loss 0.6980558037757874\n",
      "Finished epoch 1483, latest loss 0.6952729821205139\n",
      "Finished epoch 1484, latest loss 0.6961966753005981\n",
      "Finished epoch 1485, latest loss 0.6980566382408142\n",
      "Finished epoch 1486, latest loss 0.6961157321929932\n",
      "Finished epoch 1487, latest loss 0.7009847164154053\n",
      "Finished epoch 1488, latest loss 0.6980456113815308\n",
      "Finished epoch 1489, latest loss 0.6990622878074646\n",
      "Finished epoch 1490, latest loss 0.701459527015686\n",
      "Finished epoch 1491, latest loss 0.6951850652694702\n",
      "Finished epoch 1492, latest loss 0.6952516436576843\n",
      "Finished epoch 1493, latest loss 0.6971211433410645\n",
      "Finished epoch 1494, latest loss 0.6944981813430786\n",
      "Finished epoch 1495, latest loss 0.6961093544960022\n",
      "Finished epoch 1496, latest loss 0.698222815990448\n",
      "Finished epoch 1497, latest loss 0.6971422433853149\n",
      "Finished epoch 1498, latest loss 0.6949706673622131\n",
      "Finished epoch 1499, latest loss 0.6951038241386414\n",
      "Finished epoch 1500, latest loss 0.6970183849334717\n",
      "Finished epoch 1501, latest loss 0.6977730393409729\n",
      "Finished epoch 1502, latest loss 0.6953632831573486\n",
      "Finished epoch 1503, latest loss 0.6963819861412048\n",
      "Finished epoch 1504, latest loss 0.6961145401000977\n",
      "Finished epoch 1505, latest loss 0.6951850652694702\n",
      "Finished epoch 1506, latest loss 0.694914698600769\n",
      "Finished epoch 1507, latest loss 0.6952431797981262\n",
      "Finished epoch 1508, latest loss 0.6942182779312134\n",
      "Finished epoch 1509, latest loss 0.6941734552383423\n",
      "Finished epoch 1510, latest loss 0.6952036619186401\n",
      "Finished epoch 1511, latest loss 0.6943469047546387\n",
      "Finished epoch 1512, latest loss 0.6941735148429871\n",
      "Finished epoch 1513, latest loss 0.6951850652694702\n",
      "Finished epoch 1514, latest loss 0.6952082514762878\n",
      "Finished epoch 1515, latest loss 0.6980496048927307\n",
      "Finished epoch 1516, latest loss 0.6978177428245544\n",
      "Finished epoch 1517, latest loss 0.6982687711715698\n",
      "Finished epoch 1518, latest loss 0.6932438611984253\n",
      "Finished epoch 1519, latest loss 0.6941806077957153\n",
      "Finished epoch 1520, latest loss 0.696015477180481\n",
      "Finished epoch 1521, latest loss 0.6970422267913818\n",
      "Finished epoch 1522, latest loss 0.6942437291145325\n",
      "Finished epoch 1523, latest loss 0.6951031684875488\n",
      "Finished epoch 1524, latest loss 0.6951851844787598\n",
      "Finished epoch 1525, latest loss 0.6932438611984253\n",
      "Finished epoch 1526, latest loss 0.6941734552383423\n",
      "Finished epoch 1527, latest loss 0.6932438611984253\n",
      "Finished epoch 1528, latest loss 0.6971637606620789\n",
      "Finished epoch 1529, latest loss 0.6956705451011658\n",
      "Finished epoch 1530, latest loss 0.6941748857498169\n",
      "Finished epoch 1531, latest loss 0.695618748664856\n",
      "Finished epoch 1532, latest loss 0.699198842048645\n",
      "Finished epoch 1533, latest loss 0.6960175037384033\n",
      "Finished epoch 1534, latest loss 0.6932439208030701\n",
      "Finished epoch 1535, latest loss 0.6942554712295532\n",
      "Finished epoch 1536, latest loss 0.6943530440330505\n",
      "Finished epoch 1537, latest loss 0.6932441592216492\n",
      "Finished epoch 1538, latest loss 0.6932439804077148\n",
      "Finished epoch 1539, latest loss 0.6942561864852905\n",
      "Finished epoch 1540, latest loss 0.6963242888450623\n",
      "Finished epoch 1541, latest loss 0.6932442784309387\n",
      "Finished epoch 1542, latest loss 0.6941734552383423\n",
      "Finished epoch 1543, latest loss 0.6963432431221008\n",
      "Finished epoch 1544, latest loss 0.6951831579208374\n",
      "Finished epoch 1545, latest loss 0.6969792246818542\n",
      "Finished epoch 1546, latest loss 0.6971536874771118\n",
      "Finished epoch 1547, latest loss 0.6932438611984253\n",
      "Finished epoch 1548, latest loss 0.6951029896736145\n",
      "Finished epoch 1549, latest loss 0.6942645311355591\n",
      "Finished epoch 1550, latest loss 0.6951830387115479\n",
      "Finished epoch 1551, latest loss 0.6991485357284546\n",
      "Finished epoch 1552, latest loss 0.6951029896736145\n",
      "Finished epoch 1553, latest loss 0.6951640248298645\n",
      "Finished epoch 1554, latest loss 0.6947884559631348\n",
      "Finished epoch 1555, latest loss 0.6961104869842529\n",
      "Finished epoch 1556, latest loss 0.6951850652694702\n",
      "Finished epoch 1557, latest loss 0.6953350305557251\n",
      "Finished epoch 1558, latest loss 0.6972028613090515\n",
      "Finished epoch 1559, latest loss 0.6961876153945923\n",
      "Finished epoch 1560, latest loss 0.6951835751533508\n",
      "Finished epoch 1561, latest loss 0.6954244375228882\n",
      "Finished epoch 1562, latest loss 0.6970080733299255\n",
      "Finished epoch 1563, latest loss 0.6958693265914917\n",
      "Finished epoch 1564, latest loss 0.6952195167541504\n",
      "Finished epoch 1565, latest loss 0.6960716843605042\n",
      "Finished epoch 1566, latest loss 0.693606436252594\n",
      "Finished epoch 1567, latest loss 0.6933386325836182\n",
      "Finished epoch 1568, latest loss 0.6932399272918701\n",
      "Finished epoch 1569, latest loss 0.6952715516090393\n",
      "Finished epoch 1570, latest loss 0.6951767802238464\n",
      "Finished epoch 1571, latest loss 0.6971095204353333\n",
      "Finished epoch 1572, latest loss 0.696719229221344\n",
      "Finished epoch 1573, latest loss 0.6937987804412842\n",
      "Finished epoch 1574, latest loss 0.6964325308799744\n",
      "Finished epoch 1575, latest loss 0.6961138844490051\n",
      "Finished epoch 1576, latest loss 0.6950955390930176\n",
      "Finished epoch 1577, latest loss 0.6968557834625244\n",
      "Finished epoch 1578, latest loss 0.696010172367096\n",
      "Finished epoch 1579, latest loss 0.6944247484207153\n",
      "Finished epoch 1580, latest loss 0.6972895264625549\n",
      "Finished epoch 1581, latest loss 0.6961998343467712\n",
      "Finished epoch 1582, latest loss 0.695986270904541\n",
      "Finished epoch 1583, latest loss 0.6942554712295532\n",
      "Finished epoch 1584, latest loss 0.6942770481109619\n",
      "Finished epoch 1585, latest loss 0.698350727558136\n",
      "Finished epoch 1586, latest loss 0.6951850652694702\n",
      "Finished epoch 1587, latest loss 0.6962162852287292\n",
      "Finished epoch 1588, latest loss 0.6962786912918091\n",
      "Finished epoch 1589, latest loss 0.6970442533493042\n",
      "Finished epoch 1590, latest loss 0.6968340277671814\n",
      "Finished epoch 1591, latest loss 0.6949235796928406\n",
      "Finished epoch 1592, latest loss 0.696198582649231\n",
      "Finished epoch 1593, latest loss 0.6951866745948792\n",
      "Finished epoch 1594, latest loss 0.7038412690162659\n",
      "Finished epoch 1595, latest loss 0.6961145997047424\n",
      "Finished epoch 1596, latest loss 0.6953667998313904\n",
      "Finished epoch 1597, latest loss 0.6952697038650513\n",
      "Finished epoch 1598, latest loss 0.6952719688415527\n",
      "Finished epoch 1599, latest loss 0.6973180174827576\n",
      "Finished epoch 1600, latest loss 0.6969623565673828\n",
      "Finished epoch 1601, latest loss 0.6961268186569214\n",
      "Finished epoch 1602, latest loss 0.696199893951416\n",
      "Finished epoch 1603, latest loss 0.6950288414955139\n",
      "Finished epoch 1604, latest loss 0.6954828500747681\n",
      "Finished epoch 1605, latest loss 0.6961718201637268\n",
      "Finished epoch 1606, latest loss 0.6951690912246704\n",
      "Finished epoch 1607, latest loss 0.6951850652694702\n",
      "Finished epoch 1608, latest loss 0.6961964964866638\n",
      "Finished epoch 1609, latest loss 0.6942554712295532\n",
      "Finished epoch 1610, latest loss 0.6961299777030945\n",
      "Finished epoch 1611, latest loss 0.6980541944503784\n",
      "Finished epoch 1612, latest loss 0.6989811062812805\n",
      "Finished epoch 1613, latest loss 0.6961657404899597\n",
      "Finished epoch 1614, latest loss 0.6961997747421265\n",
      "Finished epoch 1615, latest loss 0.6951850652694702\n",
      "Finished epoch 1616, latest loss 0.6961966753005981\n",
      "Finished epoch 1617, latest loss 0.6942554712295532\n",
      "Finished epoch 1618, latest loss 0.6969649195671082\n",
      "Finished epoch 1619, latest loss 0.6970579028129578\n",
      "Finished epoch 1620, latest loss 0.6950541734695435\n",
      "Finished epoch 1621, latest loss 0.6961973905563354\n",
      "Finished epoch 1622, latest loss 0.69431072473526\n",
      "Finished epoch 1623, latest loss 0.6975247859954834\n",
      "Finished epoch 1624, latest loss 0.6962804198265076\n",
      "Finished epoch 1625, latest loss 0.6990696787834167\n",
      "Finished epoch 1626, latest loss 0.6969844698905945\n",
      "Finished epoch 1627, latest loss 0.695502758026123\n",
      "Finished epoch 1628, latest loss 0.6932438611984253\n",
      "Finished epoch 1629, latest loss 0.6951029896736145\n",
      "Finished epoch 1630, latest loss 0.6981668472290039\n",
      "Finished epoch 1631, latest loss 0.6979377269744873\n",
      "Finished epoch 1632, latest loss 0.6958635449409485\n",
      "Finished epoch 1633, latest loss 0.6980697512626648\n",
      "Finished epoch 1634, latest loss 0.6962927579879761\n",
      "Finished epoch 1635, latest loss 0.6983690857887268\n",
      "Finished epoch 1636, latest loss 0.6979188919067383\n",
      "Finished epoch 1637, latest loss 0.6932472586631775\n",
      "Finished epoch 1638, latest loss 0.6968215703964233\n",
      "Finished epoch 1639, latest loss 0.6951850652694702\n",
      "Finished epoch 1640, latest loss 0.6942591071128845\n",
      "Finished epoch 1641, latest loss 0.695459246635437\n",
      "Finished epoch 1642, latest loss 0.6966685056686401\n",
      "Finished epoch 1643, latest loss 0.695728600025177\n",
      "Finished epoch 1644, latest loss 0.6932598352432251\n",
      "Finished epoch 1645, latest loss 0.6942766308784485\n",
      "Finished epoch 1646, latest loss 0.695185124874115\n",
      "Finished epoch 1647, latest loss 0.6952667832374573\n",
      "Finished epoch 1648, latest loss 0.6962593793869019\n",
      "Finished epoch 1649, latest loss 0.6959623694419861\n",
      "Finished epoch 1650, latest loss 0.6971302032470703\n",
      "Finished epoch 1651, latest loss 0.6962752342224121\n",
      "Finished epoch 1652, latest loss 0.6961939334869385\n",
      "Finished epoch 1653, latest loss 0.6932439208030701\n",
      "Finished epoch 1654, latest loss 0.6942803859710693\n",
      "Finished epoch 1655, latest loss 0.696196973323822\n",
      "Finished epoch 1656, latest loss 0.6981381177902222\n",
      "Finished epoch 1657, latest loss 0.6961077451705933\n",
      "Finished epoch 1658, latest loss 0.6941734552383423\n",
      "Finished epoch 1659, latest loss 0.695037305355072\n",
      "Finished epoch 1660, latest loss 0.6981156468391418\n",
      "Finished epoch 1661, latest loss 0.6951030492782593\n",
      "Finished epoch 1662, latest loss 0.6951851844787598\n",
      "Finished epoch 1663, latest loss 0.695925235748291\n",
      "Finished epoch 1664, latest loss 0.6960325837135315\n",
      "Finished epoch 1665, latest loss 0.6941734552383423\n",
      "Finished epoch 1666, latest loss 0.6981443166732788\n",
      "Finished epoch 1667, latest loss 0.6961144804954529\n",
      "Finished epoch 1668, latest loss 0.6951103806495667\n",
      "Finished epoch 1669, latest loss 0.6951848268508911\n",
      "Finished epoch 1670, latest loss 0.6961207985877991\n",
      "Finished epoch 1671, latest loss 0.695173442363739\n",
      "Finished epoch 1672, latest loss 0.6959227323532104\n",
      "Finished epoch 1673, latest loss 0.6961782574653625\n",
      "Finished epoch 1674, latest loss 0.6942556500434875\n",
      "Finished epoch 1675, latest loss 0.6961967349052429\n",
      "Finished epoch 1676, latest loss 0.69417405128479\n",
      "Finished epoch 1677, latest loss 0.698056161403656\n",
      "Finished epoch 1678, latest loss 0.6941734552383423\n",
      "Finished epoch 1679, latest loss 0.6949671506881714\n",
      "Finished epoch 1680, latest loss 0.6961145997047424\n",
      "Finished epoch 1681, latest loss 0.6943905353546143\n",
      "Finished epoch 1682, latest loss 0.6960315704345703\n",
      "Finished epoch 1683, latest loss 0.694203794002533\n",
      "Finished epoch 1684, latest loss 0.6957266330718994\n",
      "Finished epoch 1685, latest loss 0.6932439208030701\n",
      "Finished epoch 1686, latest loss 0.696391224861145\n",
      "Finished epoch 1687, latest loss 0.6976949572563171\n",
      "Finished epoch 1688, latest loss 0.694340705871582\n",
      "Finished epoch 1689, latest loss 0.69425368309021\n",
      "Finished epoch 1690, latest loss 0.6940149664878845\n",
      "Finished epoch 1691, latest loss 0.6951588988304138\n",
      "Finished epoch 1692, latest loss 0.6944409608840942\n",
      "Finished epoch 1693, latest loss 0.6961971521377563\n",
      "Finished epoch 1694, latest loss 0.6936215758323669\n",
      "Finished epoch 1695, latest loss 0.6962786316871643\n",
      "Finished epoch 1696, latest loss 0.6942533850669861\n",
      "Finished epoch 1697, latest loss 0.693576991558075\n",
      "Finished epoch 1698, latest loss 0.6932438611984253\n",
      "Finished epoch 1699, latest loss 0.6932500600814819\n",
      "Finished epoch 1700, latest loss 0.6932438611984253\n",
      "Finished epoch 1701, latest loss 0.6942554712295532\n",
      "Finished epoch 1702, latest loss 0.6953124403953552\n",
      "Finished epoch 1703, latest loss 0.6923143267631531\n",
      "Finished epoch 1704, latest loss 0.695134699344635\n",
      "Finished epoch 1705, latest loss 0.6932888031005859\n",
      "Finished epoch 1706, latest loss 0.6946941018104553\n",
      "Finished epoch 1707, latest loss 0.6982070803642273\n",
      "Finished epoch 1708, latest loss 0.6933574676513672\n",
      "Finished epoch 1709, latest loss 0.6961978673934937\n",
      "Finished epoch 1710, latest loss 0.6951799988746643\n",
      "Finished epoch 1711, latest loss 0.695099413394928\n",
      "Finished epoch 1712, latest loss 0.6943397521972656\n",
      "Finished epoch 1713, latest loss 0.6934444308280945\n",
      "Finished epoch 1714, latest loss 0.6932438611984253\n",
      "Finished epoch 1715, latest loss 0.6952100396156311\n",
      "Finished epoch 1716, latest loss 0.6960114240646362\n",
      "Finished epoch 1717, latest loss 0.693230926990509\n",
      "Finished epoch 1718, latest loss 0.6942554712295532\n",
      "Finished epoch 1719, latest loss 0.6929510235786438\n",
      "Finished epoch 1720, latest loss 0.6942551732063293\n",
      "Finished epoch 1721, latest loss 0.6971150040626526\n",
      "Finished epoch 1722, latest loss 0.6916773915290833\n",
      "Finished epoch 1723, latest loss 0.6934071779251099\n",
      "Finished epoch 1724, latest loss 0.6941749453544617\n",
      "Finished epoch 1725, latest loss 0.6944105625152588\n",
      "Finished epoch 1726, latest loss 0.6933016180992126\n",
      "Finished epoch 1727, latest loss 0.6958574652671814\n",
      "Finished epoch 1728, latest loss 0.6939504742622375\n",
      "Finished epoch 1729, latest loss 0.6923143267631531\n",
      "Finished epoch 1730, latest loss 0.6961966156959534\n",
      "Finished epoch 1731, latest loss 0.6934078931808472\n",
      "Finished epoch 1732, latest loss 0.6950522065162659\n",
      "Finished epoch 1733, latest loss 0.6965214610099792\n",
      "Finished epoch 1734, latest loss 0.6954244375228882\n",
      "Finished epoch 1735, latest loss 0.6934093236923218\n",
      "Finished epoch 1736, latest loss 0.6932443380355835\n",
      "Finished epoch 1737, latest loss 0.6944354772567749\n",
      "Finished epoch 1738, latest loss 0.6932641863822937\n",
      "Finished epoch 1739, latest loss 0.6933472752571106\n",
      "Finished epoch 1740, latest loss 0.6943045854568481\n",
      "Finished epoch 1741, latest loss 0.6932453513145447\n",
      "Finished epoch 1742, latest loss 0.6937136650085449\n",
      "Finished epoch 1743, latest loss 0.6913886070251465\n",
      "Finished epoch 1744, latest loss 0.6923468112945557\n",
      "Finished epoch 1745, latest loss 0.6923143267631531\n",
      "Finished epoch 1746, latest loss 0.6959543228149414\n",
      "Finished epoch 1747, latest loss 0.69419926404953\n",
      "Finished epoch 1748, latest loss 0.6933103799819946\n",
      "Finished epoch 1749, latest loss 0.692531943321228\n",
      "Finished epoch 1750, latest loss 0.6913848519325256\n",
      "Finished epoch 1751, latest loss 0.6935827136039734\n",
      "Finished epoch 1752, latest loss 0.6933282017707825\n",
      "Finished epoch 1753, latest loss 0.6947457790374756\n",
      "Finished epoch 1754, latest loss 0.6935162544250488\n",
      "Finished epoch 1755, latest loss 0.6932439804077148\n",
      "Finished epoch 1756, latest loss 0.6956969499588013\n",
      "Finished epoch 1757, latest loss 0.6942554116249084\n",
      "Finished epoch 1758, latest loss 0.6946607232093811\n",
      "Finished epoch 1759, latest loss 0.6941465735435486\n",
      "Finished epoch 1760, latest loss 0.6923317313194275\n",
      "Finished epoch 1761, latest loss 0.6947969198226929\n",
      "Finished epoch 1762, latest loss 0.6913847327232361\n",
      "Finished epoch 1763, latest loss 0.6923965811729431\n",
      "Finished epoch 1764, latest loss 0.6942079663276672\n",
      "Finished epoch 1765, latest loss 0.6913855671882629\n",
      "Finished epoch 1766, latest loss 0.6979199051856995\n",
      "Finished epoch 1767, latest loss 0.693325936794281\n",
      "Finished epoch 1768, latest loss 0.6913847923278809\n",
      "Finished epoch 1769, latest loss 0.6934223175048828\n",
      "Finished epoch 1770, latest loss 0.6932507753372192\n",
      "Finished epoch 1771, latest loss 0.6914668083190918\n",
      "Finished epoch 1772, latest loss 0.6923143267631531\n",
      "Finished epoch 1773, latest loss 0.692451000213623\n",
      "Finished epoch 1774, latest loss 0.6944656372070312\n",
      "Finished epoch 1775, latest loss 0.694399893283844\n",
      "Finished epoch 1776, latest loss 0.6932438611984253\n",
      "Finished epoch 1777, latest loss 0.6923143267631531\n",
      "Finished epoch 1778, latest loss 0.6931652426719666\n",
      "Finished epoch 1779, latest loss 0.693325936794281\n",
      "Finished epoch 1780, latest loss 0.6933257579803467\n",
      "Finished epoch 1781, latest loss 0.6934219002723694\n",
      "Finished epoch 1782, latest loss 0.6942300796508789\n",
      "Finished epoch 1783, latest loss 0.6924203038215637\n",
      "Finished epoch 1784, latest loss 0.6974414587020874\n",
      "Finished epoch 1785, latest loss 0.6948604583740234\n",
      "Finished epoch 1786, latest loss 0.6922848224639893\n",
      "Finished epoch 1787, latest loss 0.6913848519325256\n",
      "Finished epoch 1788, latest loss 0.692396342754364\n",
      "Finished epoch 1789, latest loss 0.691329836845398\n",
      "Finished epoch 1790, latest loss 0.6949957609176636\n",
      "Finished epoch 1791, latest loss 0.6934115886688232\n",
      "Finished epoch 1792, latest loss 0.6941734552383423\n",
      "Finished epoch 1793, latest loss 0.6939807534217834\n",
      "Finished epoch 1794, latest loss 0.6924962401390076\n",
      "Finished epoch 1795, latest loss 0.693334698677063\n",
      "Finished epoch 1796, latest loss 0.6941737532615662\n",
      "Finished epoch 1797, latest loss 0.6955122351646423\n",
      "Finished epoch 1798, latest loss 0.6904551982879639\n",
      "Finished epoch 1799, latest loss 0.6946700215339661\n",
      "Finished epoch 1800, latest loss 0.6919723153114319\n",
      "Finished epoch 1801, latest loss 0.6950890421867371\n",
      "Finished epoch 1802, latest loss 0.6971343159675598\n",
      "Finished epoch 1803, latest loss 0.6923617720603943\n",
      "Finished epoch 1804, latest loss 0.6936563849449158\n",
      "Finished epoch 1805, latest loss 0.6934071779251099\n",
      "Finished epoch 1806, latest loss 0.6923141479492188\n",
      "Finished epoch 1807, latest loss 0.6923958659172058\n",
      "Finished epoch 1808, latest loss 0.6925088763237\n",
      "Finished epoch 1809, latest loss 0.6951389312744141\n",
      "Finished epoch 1810, latest loss 0.6913930773735046\n",
      "Finished epoch 1811, latest loss 0.6904551982879639\n",
      "Finished epoch 1812, latest loss 0.6909809708595276\n",
      "Finished epoch 1813, latest loss 0.6910480856895447\n",
      "Finished epoch 1814, latest loss 0.6963288187980652\n",
      "Finished epoch 1815, latest loss 0.6933832764625549\n",
      "Finished epoch 1816, latest loss 0.6934079527854919\n",
      "Finished epoch 1817, latest loss 0.7019187211990356\n",
      "Finished epoch 1818, latest loss 0.694573700428009\n",
      "Finished epoch 1819, latest loss 0.6915154457092285\n",
      "Finished epoch 1820, latest loss 0.6924068927764893\n",
      "Finished epoch 1821, latest loss 0.698330819606781\n",
      "Finished epoch 1822, latest loss 0.6934897303581238\n",
      "Finished epoch 1823, latest loss 0.6944095492362976\n",
      "Finished epoch 1824, latest loss 0.6936994791030884\n",
      "Finished epoch 1825, latest loss 0.6945574879646301\n",
      "Finished epoch 1826, latest loss 0.6961976885795593\n",
      "Finished epoch 1827, latest loss 0.6913854479789734\n",
      "Finished epoch 1828, latest loss 0.6923089623451233\n",
      "Finished epoch 1829, latest loss 0.6937544941902161\n",
      "Finished epoch 1830, latest loss 0.6941699385643005\n",
      "Finished epoch 1831, latest loss 0.691841721534729\n",
      "Finished epoch 1832, latest loss 0.6929327249526978\n",
      "Finished epoch 1833, latest loss 0.6951822638511658\n",
      "Finished epoch 1834, latest loss 0.693325936794281\n",
      "Finished epoch 1835, latest loss 0.6954311728477478\n",
      "Finished epoch 1836, latest loss 0.6934897899627686\n",
      "Finished epoch 1837, latest loss 0.694420337677002\n",
      "Finished epoch 1838, latest loss 0.690958559513092\n",
      "Finished epoch 1839, latest loss 0.6924788951873779\n",
      "Finished epoch 1840, latest loss 0.6923143267631531\n",
      "Finished epoch 1841, latest loss 0.6934049129486084\n",
      "Finished epoch 1842, latest loss 0.6926797032356262\n",
      "Finished epoch 1843, latest loss 0.6923143267631531\n",
      "Finished epoch 1844, latest loss 0.6922392249107361\n",
      "Finished epoch 1845, latest loss 0.6971638202667236\n",
      "Finished epoch 1846, latest loss 0.6952595114707947\n",
      "Finished epoch 1847, latest loss 0.6913148760795593\n",
      "Finished epoch 1848, latest loss 0.6943375468254089\n",
      "Finished epoch 1849, latest loss 0.694541335105896\n",
      "Finished epoch 1850, latest loss 0.6923143267631531\n",
      "Finished epoch 1851, latest loss 0.6964952945709229\n",
      "Finished epoch 1852, latest loss 0.6942403316497803\n",
      "Finished epoch 1853, latest loss 0.6924982666969299\n",
      "Finished epoch 1854, latest loss 0.6917680501937866\n",
      "Finished epoch 1855, latest loss 0.6934182643890381\n",
      "Finished epoch 1856, latest loss 0.6934158205986023\n",
      "Finished epoch 1857, latest loss 0.6923960447311401\n",
      "Finished epoch 1858, latest loss 0.6933190822601318\n",
      "Finished epoch 1859, latest loss 0.6915538311004639\n",
      "Finished epoch 1860, latest loss 0.6919993758201599\n",
      "Finished epoch 1861, latest loss 0.6924775838851929\n",
      "Finished epoch 1862, latest loss 0.6915436387062073\n",
      "Finished epoch 1863, latest loss 0.6924619674682617\n",
      "Finished epoch 1864, latest loss 0.6923960447311401\n",
      "Finished epoch 1865, latest loss 0.6968898773193359\n",
      "Finished epoch 1866, latest loss 0.6933809518814087\n",
      "Finished epoch 1867, latest loss 0.6945397853851318\n",
      "Finished epoch 1868, latest loss 0.694254994392395\n",
      "Finished epoch 1869, latest loss 0.693325936794281\n",
      "Finished epoch 1870, latest loss 0.6913851499557495\n",
      "Finished epoch 1871, latest loss 0.6939403414726257\n",
      "Finished epoch 1872, latest loss 0.6913872361183167\n",
      "Finished epoch 1873, latest loss 0.6934086084365845\n",
      "Finished epoch 1874, latest loss 0.6923920512199402\n",
      "Finished epoch 1875, latest loss 0.692312479019165\n",
      "Finished epoch 1876, latest loss 0.6914277076721191\n",
      "Finished epoch 1877, latest loss 0.6911850571632385\n",
      "Finished epoch 1878, latest loss 0.6963868737220764\n",
      "Finished epoch 1879, latest loss 0.6942654252052307\n",
      "Finished epoch 1880, latest loss 0.6924917697906494\n",
      "Finished epoch 1881, latest loss 0.692396342754364\n",
      "Finished epoch 1882, latest loss 0.6932438015937805\n",
      "Finished epoch 1883, latest loss 0.6917110085487366\n",
      "Finished epoch 1884, latest loss 0.6916664242744446\n",
      "Finished epoch 1885, latest loss 0.6927430629730225\n",
      "Finished epoch 1886, latest loss 0.6943374872207642\n",
      "Finished epoch 1887, latest loss 0.694337010383606\n",
      "Finished epoch 1888, latest loss 0.6955018043518066\n",
      "Finished epoch 1889, latest loss 0.6913857460021973\n",
      "Finished epoch 1890, latest loss 0.6914786696434021\n",
      "Finished epoch 1891, latest loss 0.6933231353759766\n",
      "Finished epoch 1892, latest loss 0.6933244466781616\n",
      "Finished epoch 1893, latest loss 0.6932438611984253\n",
      "Finished epoch 1894, latest loss 0.6904555559158325\n",
      "Finished epoch 1895, latest loss 0.6926981210708618\n",
      "Finished epoch 1896, latest loss 0.6929867267608643\n",
      "Finished epoch 1897, latest loss 0.692478358745575\n",
      "Finished epoch 1898, latest loss 0.6934073567390442\n",
      "Finished epoch 1899, latest loss 0.6919591426849365\n",
      "Finished epoch 1900, latest loss 0.6923143267631531\n",
      "Finished epoch 1901, latest loss 0.6921842098236084\n",
      "Finished epoch 1902, latest loss 0.6913846731185913\n",
      "Finished epoch 1903, latest loss 0.6935417056083679\n",
      "Finished epoch 1904, latest loss 0.6978400349617004\n",
      "Finished epoch 1905, latest loss 0.6923108100891113\n",
      "Finished epoch 1906, latest loss 0.6924784183502197\n",
      "Finished epoch 1907, latest loss 0.6933532953262329\n",
      "Finished epoch 1908, latest loss 0.6969449520111084\n",
      "Finished epoch 1909, latest loss 0.6952580213546753\n",
      "Finished epoch 1910, latest loss 0.6923990845680237\n",
      "Finished epoch 1911, latest loss 0.6933497190475464\n",
      "Finished epoch 1912, latest loss 0.6919013857841492\n",
      "Finished epoch 1913, latest loss 0.6914182901382446\n",
      "Finished epoch 1914, latest loss 0.6935889720916748\n",
      "Finished epoch 1915, latest loss 0.6942858695983887\n",
      "Finished epoch 1916, latest loss 0.6932786703109741\n",
      "Finished epoch 1917, latest loss 0.6932438611984253\n",
      "Finished epoch 1918, latest loss 0.6943374872207642\n",
      "Finished epoch 1919, latest loss 0.6933304071426392\n",
      "Finished epoch 1920, latest loss 0.6943857073783875\n",
      "Finished epoch 1921, latest loss 0.6927832365036011\n",
      "Finished epoch 1922, latest loss 0.6933259963989258\n",
      "Finished epoch 1923, latest loss 0.6941635012626648\n",
      "Finished epoch 1924, latest loss 0.6944131851196289\n",
      "Finished epoch 1925, latest loss 0.692396342754364\n",
      "Finished epoch 1926, latest loss 0.693855345249176\n",
      "Finished epoch 1927, latest loss 0.694338858127594\n",
      "Finished epoch 1928, latest loss 0.6950592994689941\n",
      "Finished epoch 1929, latest loss 0.6941733360290527\n",
      "Finished epoch 1930, latest loss 0.6913847327232361\n",
      "Finished epoch 1931, latest loss 0.6973544359207153\n",
      "Finished epoch 1932, latest loss 0.6943865418434143\n",
      "Finished epoch 1933, latest loss 0.6940940618515015\n",
      "Finished epoch 1934, latest loss 0.6916089057922363\n",
      "Finished epoch 1935, latest loss 0.6962905526161194\n",
      "Finished epoch 1936, latest loss 0.6960735321044922\n",
      "Finished epoch 1937, latest loss 0.6913849711418152\n",
      "Finished epoch 1938, latest loss 0.6923128962516785\n",
      "Finished epoch 1939, latest loss 0.6934937834739685\n",
      "Finished epoch 1940, latest loss 0.6915207505226135\n",
      "Finished epoch 1941, latest loss 0.6923815011978149\n",
      "Finished epoch 1942, latest loss 0.6925461292266846\n",
      "Finished epoch 1943, latest loss 0.6942621469497681\n",
      "Finished epoch 1944, latest loss 0.6932278275489807\n",
      "Finished epoch 1945, latest loss 0.692464292049408\n",
      "Finished epoch 1946, latest loss 0.6933258771896362\n",
      "Finished epoch 1947, latest loss 0.6958600282669067\n",
      "Finished epoch 1948, latest loss 0.6923960447311401\n",
      "Finished epoch 1949, latest loss 0.69633549451828\n",
      "Finished epoch 1950, latest loss 0.6934814453125\n",
      "Finished epoch 1951, latest loss 0.6914666295051575\n",
      "Finished epoch 1952, latest loss 0.6974601149559021\n",
      "Finished epoch 1953, latest loss 0.6934096813201904\n",
      "Finished epoch 1954, latest loss 0.6923826336860657\n",
      "Finished epoch 1955, latest loss 0.6916319131851196\n",
      "Finished epoch 1956, latest loss 0.6924644708633423\n",
      "Finished epoch 1957, latest loss 0.6913877725601196\n",
      "Finished epoch 1958, latest loss 0.6915292739868164\n",
      "Finished epoch 1959, latest loss 0.691376268863678\n",
      "Finished epoch 1960, latest loss 0.694225549697876\n",
      "Finished epoch 1961, latest loss 0.6924784183502197\n",
      "Finished epoch 1962, latest loss 0.6934077143669128\n",
      "Finished epoch 1963, latest loss 0.6914668083190918\n",
      "Finished epoch 1964, latest loss 0.692396342754364\n",
      "Finished epoch 1965, latest loss 0.6979580521583557\n",
      "Finished epoch 1966, latest loss 0.6934078931808472\n",
      "Finished epoch 1967, latest loss 0.6948789954185486\n",
      "Finished epoch 1968, latest loss 0.6950234174728394\n",
      "Finished epoch 1969, latest loss 0.6944027543067932\n",
      "Finished epoch 1970, latest loss 0.6923976540565491\n",
      "Finished epoch 1971, latest loss 0.6918468475341797\n",
      "Finished epoch 1972, latest loss 0.69049072265625\n",
      "Finished epoch 1973, latest loss 0.6923168301582336\n",
      "Finished epoch 1974, latest loss 0.6929323673248291\n",
      "Finished epoch 1975, latest loss 0.6942594647407532\n",
      "Finished epoch 1976, latest loss 0.6934897303581238\n",
      "Finished epoch 1977, latest loss 0.6924156546592712\n",
      "Finished epoch 1978, latest loss 0.6916925311088562\n",
      "Finished epoch 1979, latest loss 0.6904593110084534\n",
      "Finished epoch 1980, latest loss 0.6904551982879639\n",
      "Finished epoch 1981, latest loss 0.6932191848754883\n",
      "Finished epoch 1982, latest loss 0.6904793381690979\n",
      "Finished epoch 1983, latest loss 0.6955755352973938\n",
      "Finished epoch 1984, latest loss 0.6975356936454773\n",
      "Finished epoch 1985, latest loss 0.6968395709991455\n",
      "Finished epoch 1986, latest loss 0.692396342754364\n",
      "Finished epoch 1987, latest loss 0.693325936794281\n",
      "Finished epoch 1988, latest loss 0.6913910508155823\n",
      "Finished epoch 1989, latest loss 0.6973723769187927\n",
      "Finished epoch 1990, latest loss 0.693325936794281\n",
      "Finished epoch 1991, latest loss 0.6944519281387329\n",
      "Finished epoch 1992, latest loss 0.69142746925354\n",
      "Finished epoch 1993, latest loss 0.6933263540267944\n",
      "Finished epoch 1994, latest loss 0.6922823786735535\n",
      "Finished epoch 1995, latest loss 0.6913909316062927\n",
      "Finished epoch 1996, latest loss 0.6913840770721436\n",
      "Finished epoch 1997, latest loss 0.6936570405960083\n",
      "Finished epoch 1998, latest loss 0.6914182901382446\n",
      "Finished epoch 1999, latest loss 0.6931930184364319\n",
      "Accuracy 0.892728865146637\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive               32924               19393\n",
      "Actual Negative                 947              136349\n",
      "Positive predictive power:\n",
      "62.93%\n",
      "Positive predictive accuracy:\n",
      "97.2%\n",
      "Confusion Matrix for merged predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive               30065               22252\n",
      "Actual Negative                 650              136646\n",
      "Positive predictive power:\n",
      "57.47%\n",
      "Positive predictive accuracy:\n",
      "97.88%\n",
      "Mean change for incorrect predictions: 1.013\n",
      "Mean change for correct predictions: 1.075\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(np.array(train_df.T), dtype=torch.float32)\n",
    "y = torch.tensor(np.array(train_output), dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Check for CUDA and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move data to the chosen device\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(train_df.shape[0], 64)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(64, 12)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.hidden3 = nn.Linear(12, 8)\n",
    "        self.act3 = nn.ReLU()\n",
    "        #self.hidden4 = nn.Linear(12, 4)\n",
    "        #self.act4 = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act3(self.hidden3(x))\n",
    "        #x = self.act4(self.hidden4(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    " \n",
    "model = PimaClassifier().to(device)\n",
    "print(model)\n",
    "\n",
    "pos_weight = torch.tensor([1.5], device=device)  # Set your_pos_weight based on your needs\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "#loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 2000\n",
    "batch_size = 1000\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "    \n",
    "# compute accuracy (no_grad is optional)\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    " \n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")\n",
    "\n",
    "# make class predictions with the model\n",
    "predictions = (model(X) > 0.5).int().to('cpu')\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "###\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "actual_values = train_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "#print(predictions)\n",
    "\n",
    "###\n",
    "neg_predictions = (negmodel(X) > 0.5).int().to('cpu')\n",
    "neg_predictions = neg_predictions.numpy()\n",
    "neg_predictions = 1 - neg_predictions\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "merge_predictions = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "merge_predictions.index = range(1, len(merge_predictions) + 1)\n",
    "actual_values = train_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(merge_predictions)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct predictions:\", mean_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "927d4040-de53-4980-a391-41b57572a6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63204\n",
      "63204\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                8149                9169\n",
      "Actual Negative                2239               43647\n",
      "Positive predictive power:\n",
      "47.06%\n",
      "Positive predictive accuracy:\n",
      "78.45%\n",
      "Confusion Matrix for merged predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                7218               10100\n",
      "Actual Negative                1618               44268\n",
      "Positive predictive power:\n",
      "41.68%\n",
      "Positive predictive accuracy:\n",
      "81.69%\n",
      "Mean change for incorrect predictions: 1.005\n",
      "Mean change for correct predictions: 1.082\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Set the model to evaluation mode\n",
    "negmodel.eval()\n",
    "model.eval()\n",
    "\n",
    "# Step 2: Prepare your input data (assuming new_input is your raw data)\n",
    "# For example, if your model expects input size of (1, C, H, W)\n",
    "input_tensor = torch.tensor(np.array(cv_df.T), dtype=torch.float32)\n",
    "\n",
    "# Step 3: Move your model and input data to the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "negmodel = negmodel.to(device)\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "predictions = (model(input_tensor) > 0.5).int().to('cpu')\n",
    "neg_predictions = (negmodel(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(predictions))\n",
    "print(len(neg_predictions))\n",
    "predictions = predictions.numpy()\n",
    "neg_predictions = neg_predictions.numpy()\n",
    "neg_predictions = 1 - neg_predictions\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = cv_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "test_pred = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = cv_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(cv_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(cv_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct predictions:\", mean_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f23f38f1-6a2e-4b71-9f3a-3a6f90f11f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63205\n",
      "63205\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                8209                9165\n",
      "Actual Negative                2309               43522\n",
      "Positive predictive power:\n",
      "47.25%\n",
      "Positive predictive accuracy:\n",
      "78.05%\n",
      "Confusion Matrix for merged predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                7248               10126\n",
      "Actual Negative                1638               44193\n",
      "Positive predictive power:\n",
      "41.72%\n",
      "Positive predictive accuracy:\n",
      "81.57%\n",
      "Mean change for incorrect predictions: 1.006\n",
      "Mean change for correct predictions: 1.081\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Set the model to evaluation mode\n",
    "negmodel.eval()\n",
    "model.eval()\n",
    "\n",
    "# Step 2: Prepare your input data (assuming new_input is your raw data)\n",
    "# For example, if your model expects input size of (1, C, H, W)\n",
    "input_tensor = torch.tensor(np.array(test_df.T), dtype=torch.float32)\n",
    "\n",
    "# Step 3: Move your model and input data to the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "negmodel = negmodel.to(device)\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "predictions = (model(input_tensor) > 0.5).int().to('cpu')\n",
    "neg_predictions = (negmodel(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(predictions))\n",
    "print(len(neg_predictions))\n",
    "predictions = predictions.numpy()\n",
    "neg_predictions = neg_predictions.numpy()\n",
    "neg_predictions = 1 - neg_predictions\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "test_pred = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct predictions:\", mean_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e2175069-d466-4ef8-aa4d-41135873d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/best_5up10d_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c12ce5f-e64b-4a3a-9d5a-b9821007eba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "5  0\n",
      "(316022, 1)\n",
      "x\n",
      "0    265159\n",
      "1     50863\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure reproducibility\n",
    "output_file = 'E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/test_output_7up10d_for_NN_20210514_to_20240404.tsv'\n",
    "output_dataset = pd.read_csv(output_file, delimiter='\\t')\n",
    "print(output_dataset.iloc[:5,:5])\n",
    "print(output_dataset.shape)\n",
    "print(output_dataset.value_counts())\n",
    "\n",
    "output_dataset.index = input_dataset.columns\n",
    "\n",
    "train_output = output_dataset.T[train_columns].T\n",
    "cv_output = output_dataset.T[cv_columns].T\n",
    "test_output = output_dataset.T[test_columns].T\n",
    "\n",
    "train_output.index = range(1, len(train_output) + 1)\n",
    "cv_output.index = range(1, len(cv_output) + 1)\n",
    "test_output.index = range(1, len(test_output) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa1ccbc8-8e8d-492a-99c7-c10a05787d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PimaClassifier(\n",
      "  (hidden1): Linear(in_features=1616, out_features=64, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (hidden2): Linear(in_features=64, out_features=12, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (hidden3): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (act3): ReLU()\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (act_output): Sigmoid()\n",
      ")\n",
      "Finished epoch 0, latest loss 0.7468140125274658\n",
      "Finished epoch 1, latest loss 0.748431921005249\n",
      "Finished epoch 2, latest loss 0.7484720945358276\n",
      "Finished epoch 3, latest loss 0.7478343844413757\n",
      "Finished epoch 4, latest loss 0.7464306950569153\n",
      "Finished epoch 5, latest loss 0.7461487650871277\n",
      "Finished epoch 6, latest loss 0.7465912103652954\n",
      "Finished epoch 7, latest loss 0.7451706528663635\n",
      "Finished epoch 8, latest loss 0.7429878115653992\n",
      "Finished epoch 9, latest loss 0.7421632409095764\n",
      "Finished epoch 10, latest loss 0.7442635893821716\n",
      "Finished epoch 11, latest loss 0.7422481179237366\n",
      "Finished epoch 12, latest loss 0.7377665638923645\n",
      "Finished epoch 13, latest loss 0.7391318678855896\n",
      "Finished epoch 14, latest loss 0.737834632396698\n",
      "Finished epoch 15, latest loss 0.7361390590667725\n",
      "Finished epoch 16, latest loss 0.7370105981826782\n",
      "Finished epoch 17, latest loss 0.7350860238075256\n",
      "Finished epoch 18, latest loss 0.7337914109230042\n",
      "Finished epoch 19, latest loss 0.7334058880805969\n",
      "Finished epoch 20, latest loss 0.7345366477966309\n",
      "Finished epoch 21, latest loss 0.7329819202423096\n",
      "Finished epoch 22, latest loss 0.7341445088386536\n",
      "Finished epoch 23, latest loss 0.7349464297294617\n",
      "Finished epoch 24, latest loss 0.732354462146759\n",
      "Finished epoch 25, latest loss 0.733475923538208\n",
      "Finished epoch 26, latest loss 0.7338839173316956\n",
      "Finished epoch 27, latest loss 0.7351813316345215\n",
      "Finished epoch 28, latest loss 0.733071506023407\n",
      "Finished epoch 29, latest loss 0.7327958345413208\n",
      "Finished epoch 30, latest loss 0.7323124408721924\n",
      "Finished epoch 31, latest loss 0.7324376106262207\n",
      "Finished epoch 32, latest loss 0.7337255477905273\n",
      "Finished epoch 33, latest loss 0.7322080731391907\n",
      "Finished epoch 34, latest loss 0.7308215498924255\n",
      "Finished epoch 35, latest loss 0.7293267846107483\n",
      "Finished epoch 36, latest loss 0.7302109003067017\n",
      "Finished epoch 37, latest loss 0.7316114902496338\n",
      "Finished epoch 38, latest loss 0.7283923625946045\n",
      "Finished epoch 39, latest loss 0.7290822863578796\n",
      "Finished epoch 40, latest loss 0.7297827005386353\n",
      "Finished epoch 41, latest loss 0.7306360602378845\n",
      "Finished epoch 42, latest loss 0.7303096652030945\n",
      "Finished epoch 43, latest loss 0.7312755584716797\n",
      "Finished epoch 44, latest loss 0.7297423481941223\n",
      "Finished epoch 45, latest loss 0.7306609153747559\n",
      "Finished epoch 46, latest loss 0.7284140586853027\n",
      "Finished epoch 47, latest loss 0.730109691619873\n",
      "Finished epoch 48, latest loss 0.7321276068687439\n",
      "Finished epoch 49, latest loss 0.7331454157829285\n",
      "Finished epoch 50, latest loss 0.7305616736412048\n",
      "Finished epoch 51, latest loss 0.7314463257789612\n",
      "Finished epoch 52, latest loss 0.7295405864715576\n",
      "Finished epoch 53, latest loss 0.7303581833839417\n",
      "Finished epoch 54, latest loss 0.7294488549232483\n",
      "Finished epoch 55, latest loss 0.7325889468193054\n",
      "Finished epoch 56, latest loss 0.7302426695823669\n",
      "Finished epoch 57, latest loss 0.7289397120475769\n",
      "Finished epoch 58, latest loss 0.7329311966896057\n",
      "Finished epoch 59, latest loss 0.7311047315597534\n",
      "Finished epoch 60, latest loss 0.7284920811653137\n",
      "Finished epoch 61, latest loss 0.7284563779830933\n",
      "Finished epoch 62, latest loss 0.7295899391174316\n",
      "Finished epoch 63, latest loss 0.7297011613845825\n",
      "Finished epoch 64, latest loss 0.7291877865791321\n",
      "Finished epoch 65, latest loss 0.7302652597427368\n",
      "Finished epoch 66, latest loss 0.7293625473976135\n",
      "Finished epoch 67, latest loss 0.7301785349845886\n",
      "Finished epoch 68, latest loss 0.728186309337616\n",
      "Finished epoch 69, latest loss 0.727449357509613\n",
      "Finished epoch 70, latest loss 0.727471113204956\n",
      "Finished epoch 71, latest loss 0.7307332158088684\n",
      "Finished epoch 72, latest loss 0.729889988899231\n",
      "Finished epoch 73, latest loss 0.7274288535118103\n",
      "Finished epoch 74, latest loss 0.7290949821472168\n",
      "Finished epoch 75, latest loss 0.7274208664894104\n",
      "Finished epoch 76, latest loss 0.7266212701797485\n",
      "Finished epoch 77, latest loss 0.7285234928131104\n",
      "Finished epoch 78, latest loss 0.727380633354187\n",
      "Finished epoch 79, latest loss 0.7294624447822571\n",
      "Finished epoch 80, latest loss 0.7275781631469727\n",
      "Finished epoch 81, latest loss 0.7291537523269653\n",
      "Finished epoch 82, latest loss 0.7285404205322266\n",
      "Finished epoch 83, latest loss 0.7284319400787354\n",
      "Finished epoch 84, latest loss 0.7275180816650391\n",
      "Finished epoch 85, latest loss 0.7270067930221558\n",
      "Finished epoch 86, latest loss 0.7271844744682312\n",
      "Finished epoch 87, latest loss 0.7261506915092468\n",
      "Finished epoch 88, latest loss 0.7275024652481079\n",
      "Finished epoch 89, latest loss 0.7277432084083557\n",
      "Finished epoch 90, latest loss 0.7265123128890991\n",
      "Finished epoch 91, latest loss 0.727164089679718\n",
      "Finished epoch 92, latest loss 0.7266696691513062\n",
      "Finished epoch 93, latest loss 0.7271026372909546\n",
      "Finished epoch 94, latest loss 0.7296435236930847\n",
      "Finished epoch 95, latest loss 0.7290453910827637\n",
      "Finished epoch 96, latest loss 0.7256797552108765\n",
      "Finished epoch 97, latest loss 0.7288010120391846\n",
      "Finished epoch 98, latest loss 0.7265658974647522\n",
      "Finished epoch 99, latest loss 0.7266359925270081\n",
      "Finished epoch 100, latest loss 0.7259088158607483\n",
      "Finished epoch 101, latest loss 0.7271925806999207\n",
      "Finished epoch 102, latest loss 0.7293378710746765\n",
      "Finished epoch 103, latest loss 0.7275708317756653\n",
      "Finished epoch 104, latest loss 0.7285972833633423\n",
      "Finished epoch 105, latest loss 0.7280681729316711\n",
      "Finished epoch 106, latest loss 0.7266933917999268\n",
      "Finished epoch 107, latest loss 0.7275694012641907\n",
      "Finished epoch 108, latest loss 0.7256995439529419\n",
      "Finished epoch 109, latest loss 0.7276701331138611\n",
      "Finished epoch 110, latest loss 0.725560188293457\n",
      "Finished epoch 111, latest loss 0.7255719304084778\n",
      "Finished epoch 112, latest loss 0.7276624441146851\n",
      "Finished epoch 113, latest loss 0.7275873422622681\n",
      "Finished epoch 114, latest loss 0.7268734574317932\n",
      "Finished epoch 115, latest loss 0.7264219522476196\n",
      "Finished epoch 116, latest loss 0.7280654311180115\n",
      "Finished epoch 117, latest loss 0.7262004613876343\n",
      "Finished epoch 118, latest loss 0.7266805171966553\n",
      "Finished epoch 119, latest loss 0.7280830144882202\n",
      "Finished epoch 120, latest loss 0.7246307134628296\n",
      "Finished epoch 121, latest loss 0.7274470925331116\n",
      "Finished epoch 122, latest loss 0.7254833579063416\n",
      "Finished epoch 123, latest loss 0.7291074395179749\n",
      "Finished epoch 124, latest loss 0.7256417870521545\n",
      "Finished epoch 125, latest loss 0.7256945967674255\n",
      "Finished epoch 126, latest loss 0.7250822186470032\n",
      "Finished epoch 127, latest loss 0.7258888483047485\n",
      "Finished epoch 128, latest loss 0.7259021997451782\n",
      "Finished epoch 129, latest loss 0.7259894609451294\n",
      "Finished epoch 130, latest loss 0.7246358394622803\n",
      "Finished epoch 131, latest loss 0.7251567244529724\n",
      "Finished epoch 132, latest loss 0.7277858853340149\n",
      "Finished epoch 133, latest loss 0.7265713810920715\n",
      "Finished epoch 134, latest loss 0.7257710695266724\n",
      "Finished epoch 135, latest loss 0.7246301770210266\n",
      "Finished epoch 136, latest loss 0.7265697121620178\n",
      "Finished epoch 137, latest loss 0.7271869778633118\n",
      "Finished epoch 138, latest loss 0.7254220843315125\n",
      "Finished epoch 139, latest loss 0.7255575060844421\n",
      "Finished epoch 140, latest loss 0.7259153723716736\n",
      "Finished epoch 141, latest loss 0.7256446480751038\n",
      "Finished epoch 142, latest loss 0.7246299982070923\n",
      "Finished epoch 143, latest loss 0.7248871922492981\n",
      "Finished epoch 144, latest loss 0.7247002720832825\n",
      "Finished epoch 145, latest loss 0.7248697280883789\n",
      "Finished epoch 146, latest loss 0.7245771884918213\n",
      "Finished epoch 147, latest loss 0.7264499664306641\n",
      "Finished epoch 148, latest loss 0.7286853194236755\n",
      "Finished epoch 149, latest loss 0.7257299423217773\n",
      "Finished epoch 150, latest loss 0.7247229814529419\n",
      "Finished epoch 151, latest loss 0.725914478302002\n",
      "Finished epoch 152, latest loss 0.7246767282485962\n",
      "Finished epoch 153, latest loss 0.7256489992141724\n",
      "Finished epoch 154, latest loss 0.7246206998825073\n",
      "Finished epoch 155, latest loss 0.7246327996253967\n",
      "Finished epoch 156, latest loss 0.7255973219871521\n",
      "Finished epoch 157, latest loss 0.7268018126487732\n",
      "Finished epoch 158, latest loss 0.7257935404777527\n",
      "Finished epoch 159, latest loss 0.7256014347076416\n",
      "Finished epoch 160, latest loss 0.7262448072433472\n",
      "Finished epoch 161, latest loss 0.7283527851104736\n",
      "Finished epoch 162, latest loss 0.7256417870521545\n",
      "Finished epoch 163, latest loss 0.7237213253974915\n",
      "Finished epoch 164, latest loss 0.7257223725318909\n",
      "Finished epoch 165, latest loss 0.7266554236412048\n",
      "Finished epoch 166, latest loss 0.7261276841163635\n",
      "Finished epoch 167, latest loss 0.7267858386039734\n",
      "Finished epoch 168, latest loss 0.7280693650245667\n",
      "Finished epoch 169, latest loss 0.728950023651123\n",
      "Finished epoch 170, latest loss 0.7263762950897217\n",
      "Finished epoch 171, latest loss 0.725656270980835\n",
      "Finished epoch 172, latest loss 0.7254454493522644\n",
      "Finished epoch 173, latest loss 0.7247135043144226\n",
      "Finished epoch 174, latest loss 0.7262489795684814\n",
      "Finished epoch 175, latest loss 0.7265337109565735\n",
      "Finished epoch 176, latest loss 0.7237460017204285\n",
      "Finished epoch 177, latest loss 0.7249383330345154\n",
      "Finished epoch 178, latest loss 0.7255728244781494\n",
      "Finished epoch 179, latest loss 0.7254201769828796\n",
      "Finished epoch 180, latest loss 0.7273824214935303\n",
      "Finished epoch 181, latest loss 0.7252641916275024\n",
      "Finished epoch 182, latest loss 0.7261172533035278\n",
      "Finished epoch 183, latest loss 0.7273659706115723\n",
      "Finished epoch 184, latest loss 0.725641131401062\n",
      "Finished epoch 185, latest loss 0.7261064648628235\n",
      "Finished epoch 186, latest loss 0.7237561345100403\n",
      "Finished epoch 187, latest loss 0.7265174984931946\n",
      "Finished epoch 188, latest loss 0.7258391380310059\n",
      "Finished epoch 189, latest loss 0.7247224450111389\n",
      "Finished epoch 190, latest loss 0.723701000213623\n",
      "Finished epoch 191, latest loss 0.7240698933601379\n",
      "Finished epoch 192, latest loss 0.7241237759590149\n",
      "Finished epoch 193, latest loss 0.7247112393379211\n",
      "Finished epoch 194, latest loss 0.7264307737350464\n",
      "Finished epoch 195, latest loss 0.7240098714828491\n",
      "Finished epoch 196, latest loss 0.7256470918655396\n",
      "Finished epoch 197, latest loss 0.7255821228027344\n",
      "Finished epoch 198, latest loss 0.724294126033783\n",
      "Finished epoch 199, latest loss 0.7237004637718201\n",
      "Finished epoch 200, latest loss 0.7247611284255981\n",
      "Finished epoch 201, latest loss 0.7257077097892761\n",
      "Finished epoch 202, latest loss 0.7247200012207031\n",
      "Finished epoch 203, latest loss 0.7237010598182678\n",
      "Finished epoch 204, latest loss 0.7260982394218445\n",
      "Finished epoch 205, latest loss 0.7246299982070923\n",
      "Finished epoch 206, latest loss 0.7237004041671753\n",
      "Finished epoch 207, latest loss 0.7247127294540405\n",
      "Finished epoch 208, latest loss 0.7257589101791382\n",
      "Finished epoch 209, latest loss 0.7237109541893005\n",
      "Finished epoch 210, latest loss 0.7245488166809082\n",
      "Finished epoch 211, latest loss 0.7247191071510315\n",
      "Finished epoch 212, latest loss 0.7246394753456116\n",
      "Finished epoch 213, latest loss 0.7270313501358032\n",
      "Finished epoch 214, latest loss 0.7247257828712463\n",
      "Finished epoch 215, latest loss 0.7252463102340698\n",
      "Finished epoch 216, latest loss 0.7237842679023743\n",
      "Finished epoch 217, latest loss 0.7244398593902588\n",
      "Finished epoch 218, latest loss 0.7237004041671753\n",
      "Finished epoch 219, latest loss 0.7237008810043335\n",
      "Finished epoch 220, latest loss 0.7248330116271973\n",
      "Finished epoch 221, latest loss 0.7237005829811096\n",
      "Finished epoch 222, latest loss 0.7265770435333252\n",
      "Finished epoch 223, latest loss 0.7239327430725098\n",
      "Finished epoch 224, latest loss 0.7264106869697571\n",
      "Finished epoch 225, latest loss 0.7241508960723877\n",
      "Finished epoch 226, latest loss 0.7247162461280823\n",
      "Finished epoch 227, latest loss 0.7237120270729065\n",
      "Finished epoch 228, latest loss 0.7237681150436401\n",
      "Finished epoch 229, latest loss 0.7241799831390381\n",
      "Finished epoch 230, latest loss 0.7256117463111877\n",
      "Finished epoch 231, latest loss 0.7257310152053833\n",
      "Finished epoch 232, latest loss 0.7262753248214722\n",
      "Finished epoch 233, latest loss 0.7264934182167053\n",
      "Finished epoch 234, latest loss 0.7237042784690857\n",
      "Finished epoch 235, latest loss 0.7237004041671753\n",
      "Finished epoch 236, latest loss 0.7256190776824951\n",
      "Finished epoch 237, latest loss 0.7247269153594971\n",
      "Finished epoch 238, latest loss 0.7239516377449036\n",
      "Finished epoch 239, latest loss 0.7245929837226868\n",
      "Finished epoch 240, latest loss 0.7246297001838684\n",
      "Finished epoch 241, latest loss 0.7254900336265564\n",
      "Finished epoch 242, latest loss 0.7237719893455505\n",
      "Finished epoch 243, latest loss 0.7277180552482605\n",
      "Finished epoch 244, latest loss 0.7255948185920715\n",
      "Finished epoch 245, latest loss 0.7246159315109253\n",
      "Finished epoch 246, latest loss 0.7254601120948792\n",
      "Finished epoch 247, latest loss 0.7296873331069946\n",
      "Finished epoch 248, latest loss 0.7246348261833191\n",
      "Finished epoch 249, latest loss 0.7237871289253235\n",
      "Finished epoch 250, latest loss 0.7237027883529663\n",
      "Finished epoch 251, latest loss 0.7246316075325012\n",
      "Finished epoch 252, latest loss 0.7237004041671753\n",
      "Finished epoch 253, latest loss 0.7228772044181824\n",
      "Finished epoch 254, latest loss 0.7237876057624817\n",
      "Finished epoch 255, latest loss 0.7233386039733887\n",
      "Finished epoch 256, latest loss 0.7228233218193054\n",
      "Finished epoch 257, latest loss 0.7237821817398071\n",
      "Finished epoch 258, latest loss 0.7248594164848328\n",
      "Finished epoch 259, latest loss 0.7238955497741699\n",
      "Finished epoch 260, latest loss 0.7228434085845947\n",
      "Finished epoch 261, latest loss 0.7227707505226135\n",
      "Finished epoch 262, latest loss 0.7227789759635925\n",
      "Finished epoch 263, latest loss 0.7247089743614197\n",
      "Finished epoch 264, latest loss 0.7247163653373718\n",
      "Finished epoch 265, latest loss 0.7237823605537415\n",
      "Finished epoch 266, latest loss 0.722771167755127\n",
      "Finished epoch 267, latest loss 0.7256344556808472\n",
      "Finished epoch 268, latest loss 0.725771963596344\n",
      "Finished epoch 269, latest loss 0.7228215336799622\n",
      "Finished epoch 270, latest loss 0.7237823605537415\n",
      "Finished epoch 271, latest loss 0.7256413102149963\n",
      "Finished epoch 272, latest loss 0.7237411737442017\n",
      "Finished epoch 273, latest loss 0.7239682674407959\n",
      "Finished epoch 274, latest loss 0.7247929573059082\n",
      "Finished epoch 275, latest loss 0.7235550880432129\n",
      "Finished epoch 276, latest loss 0.7238239049911499\n",
      "Finished epoch 277, latest loss 0.7258055210113525\n",
      "Finished epoch 278, latest loss 0.7245096564292908\n",
      "Finished epoch 279, latest loss 0.7236752510070801\n",
      "Finished epoch 280, latest loss 0.7233773469924927\n",
      "Finished epoch 281, latest loss 0.7246995568275452\n",
      "Finished epoch 282, latest loss 0.7231791615486145\n",
      "Finished epoch 283, latest loss 0.7252991795539856\n",
      "Finished epoch 284, latest loss 0.7218416929244995\n",
      "Finished epoch 285, latest loss 0.7227964997291565\n",
      "Finished epoch 286, latest loss 0.7229435443878174\n",
      "Finished epoch 287, latest loss 0.7259087562561035\n",
      "Finished epoch 288, latest loss 0.7247403264045715\n",
      "Finished epoch 289, latest loss 0.7251380085945129\n",
      "Finished epoch 290, latest loss 0.724643886089325\n",
      "Finished epoch 291, latest loss 0.7227742671966553\n",
      "Finished epoch 292, latest loss 0.7238180637359619\n",
      "Finished epoch 293, latest loss 0.7233629822731018\n",
      "Finished epoch 294, latest loss 0.723799467086792\n",
      "Finished epoch 295, latest loss 0.7227709293365479\n",
      "Finished epoch 296, latest loss 0.7246754169464111\n",
      "Finished epoch 297, latest loss 0.7237875461578369\n",
      "Finished epoch 298, latest loss 0.7237913608551025\n",
      "Finished epoch 299, latest loss 0.7257915735244751\n",
      "Finished epoch 300, latest loss 0.7234106063842773\n",
      "Finished epoch 301, latest loss 0.7247022986412048\n",
      "Finished epoch 302, latest loss 0.72381192445755\n",
      "Finished epoch 303, latest loss 0.723864734172821\n",
      "Finished epoch 304, latest loss 0.7240233421325684\n",
      "Finished epoch 305, latest loss 0.7247070670127869\n",
      "Finished epoch 306, latest loss 0.7238765954971313\n",
      "Finished epoch 307, latest loss 0.7238983511924744\n",
      "Finished epoch 308, latest loss 0.7247177958488464\n",
      "Finished epoch 309, latest loss 0.7236804366111755\n",
      "Finished epoch 310, latest loss 0.7238123416900635\n",
      "Finished epoch 311, latest loss 0.7261161804199219\n",
      "Finished epoch 312, latest loss 0.7247896790504456\n",
      "Finished epoch 313, latest loss 0.7256476879119873\n",
      "Finished epoch 314, latest loss 0.7238729596138\n",
      "Finished epoch 315, latest loss 0.7218421697616577\n",
      "Finished epoch 316, latest loss 0.7222744226455688\n",
      "Finished epoch 317, latest loss 0.7245791554450989\n",
      "Finished epoch 318, latest loss 0.7237955927848816\n",
      "Finished epoch 319, latest loss 0.7255564332008362\n",
      "Finished epoch 320, latest loss 0.7250871658325195\n",
      "Finished epoch 321, latest loss 0.7247137427330017\n",
      "Finished epoch 322, latest loss 0.7237054109573364\n",
      "Finished epoch 323, latest loss 0.7227741479873657\n",
      "Finished epoch 324, latest loss 0.7237030267715454\n",
      "Finished epoch 325, latest loss 0.7251232862472534\n",
      "Finished epoch 326, latest loss 0.725511372089386\n",
      "Finished epoch 327, latest loss 0.7228161692619324\n",
      "Finished epoch 328, latest loss 0.7229205965995789\n",
      "Finished epoch 329, latest loss 0.7243300676345825\n",
      "Finished epoch 330, latest loss 0.7251920104026794\n",
      "Finished epoch 331, latest loss 0.723803699016571\n",
      "Finished epoch 332, latest loss 0.7243940234184265\n",
      "Finished epoch 333, latest loss 0.7234137654304504\n",
      "Finished epoch 334, latest loss 0.7245011329650879\n",
      "Finished epoch 335, latest loss 0.7238667011260986\n",
      "Finished epoch 336, latest loss 0.7240424156188965\n",
      "Finished epoch 337, latest loss 0.7228564620018005\n",
      "Finished epoch 338, latest loss 0.7240115404129028\n",
      "Finished epoch 339, latest loss 0.7247869372367859\n",
      "Finished epoch 340, latest loss 0.7227707505226135\n",
      "Finished epoch 341, latest loss 0.7247122526168823\n",
      "Finished epoch 342, latest loss 0.7264289855957031\n",
      "Finished epoch 343, latest loss 0.7239248752593994\n",
      "Finished epoch 344, latest loss 0.7236959934234619\n",
      "Finished epoch 345, latest loss 0.7227707505226135\n",
      "Finished epoch 346, latest loss 0.7237626314163208\n",
      "Finished epoch 347, latest loss 0.7220087647438049\n",
      "Finished epoch 348, latest loss 0.7232799530029297\n",
      "Finished epoch 349, latest loss 0.7226925492286682\n",
      "Finished epoch 350, latest loss 0.7227628231048584\n",
      "Finished epoch 351, latest loss 0.723197340965271\n",
      "Finished epoch 352, latest loss 0.7218523025512695\n",
      "Finished epoch 353, latest loss 0.7224645614624023\n",
      "Finished epoch 354, latest loss 0.722857654094696\n",
      "Finished epoch 355, latest loss 0.7230997085571289\n",
      "Finished epoch 356, latest loss 0.7218412160873413\n",
      "Finished epoch 357, latest loss 0.7218416929244995\n",
      "Finished epoch 358, latest loss 0.72377610206604\n",
      "Finished epoch 359, latest loss 0.7221142053604126\n",
      "Finished epoch 360, latest loss 0.7228530645370483\n",
      "Finished epoch 361, latest loss 0.7225760221481323\n",
      "Finished epoch 362, latest loss 0.7238680720329285\n",
      "Finished epoch 363, latest loss 0.7255573868751526\n",
      "Finished epoch 364, latest loss 0.7238053679466248\n",
      "Finished epoch 365, latest loss 0.7250315546989441\n",
      "Finished epoch 366, latest loss 0.7227707505226135\n",
      "Finished epoch 367, latest loss 0.7262229323387146\n",
      "Finished epoch 368, latest loss 0.7228959202766418\n",
      "Finished epoch 369, latest loss 0.7228198051452637\n",
      "Finished epoch 370, latest loss 0.7235842347145081\n",
      "Finished epoch 371, latest loss 0.724707841873169\n",
      "Finished epoch 372, latest loss 0.7227393984794617\n",
      "Finished epoch 373, latest loss 0.7218524217605591\n",
      "Finished epoch 374, latest loss 0.7219101190567017\n",
      "Finished epoch 375, latest loss 0.7235199213027954\n",
      "Finished epoch 376, latest loss 0.7242113351821899\n",
      "Finished epoch 377, latest loss 0.7218490242958069\n",
      "Finished epoch 378, latest loss 0.7218412160873413\n",
      "Finished epoch 379, latest loss 0.7246971130371094\n",
      "Finished epoch 380, latest loss 0.7224209904670715\n",
      "Finished epoch 381, latest loss 0.7234269976615906\n",
      "Finished epoch 382, latest loss 0.722642719745636\n",
      "Finished epoch 383, latest loss 0.7218414545059204\n",
      "Finished epoch 384, latest loss 0.7218412160873413\n",
      "Finished epoch 385, latest loss 0.7218412756919861\n",
      "Finished epoch 386, latest loss 0.7222848534584045\n",
      "Finished epoch 387, latest loss 0.721002459526062\n",
      "Finished epoch 388, latest loss 0.7228889465332031\n",
      "Finished epoch 389, latest loss 0.7227730751037598\n",
      "Finished epoch 390, latest loss 0.7215016484260559\n",
      "Finished epoch 391, latest loss 0.7217500805854797\n",
      "Finished epoch 392, latest loss 0.7229405641555786\n",
      "Finished epoch 393, latest loss 0.7230685949325562\n",
      "Finished epoch 394, latest loss 0.7218459844589233\n",
      "Finished epoch 395, latest loss 0.7219759225845337\n",
      "Finished epoch 396, latest loss 0.7228453159332275\n",
      "Finished epoch 397, latest loss 0.7215020656585693\n",
      "Finished epoch 398, latest loss 0.7228555679321289\n",
      "Finished epoch 399, latest loss 0.7209688425064087\n",
      "Finished epoch 400, latest loss 0.7211428284645081\n",
      "Finished epoch 401, latest loss 0.7218939661979675\n",
      "Finished epoch 402, latest loss 0.7210937142372131\n",
      "Finished epoch 403, latest loss 0.7209129929542542\n",
      "Finished epoch 404, latest loss 0.7229407429695129\n",
      "Finished epoch 405, latest loss 0.7209270596504211\n",
      "Finished epoch 406, latest loss 0.7229368686676025\n",
      "Finished epoch 407, latest loss 0.7226543426513672\n",
      "Finished epoch 408, latest loss 0.721806526184082\n",
      "Finished epoch 409, latest loss 0.7219171524047852\n",
      "Finished epoch 410, latest loss 0.7219380736351013\n",
      "Finished epoch 411, latest loss 0.7209117412567139\n",
      "Finished epoch 412, latest loss 0.7229295969009399\n",
      "Finished epoch 413, latest loss 0.7229390144348145\n",
      "Finished epoch 414, latest loss 0.7219233512878418\n",
      "Finished epoch 415, latest loss 0.7219892740249634\n",
      "Finished epoch 416, latest loss 0.7209116220474243\n",
      "Finished epoch 417, latest loss 0.7237809896469116\n",
      "Finished epoch 418, latest loss 0.7229343056678772\n",
      "Finished epoch 419, latest loss 0.7209116220474243\n",
      "Finished epoch 420, latest loss 0.7209116816520691\n",
      "Finished epoch 421, latest loss 0.7218581438064575\n",
      "Finished epoch 422, latest loss 0.7227813005447388\n",
      "Finished epoch 423, latest loss 0.7219970226287842\n",
      "Finished epoch 424, latest loss 0.7216145992279053\n",
      "Finished epoch 425, latest loss 0.7209116220474243\n",
      "Finished epoch 426, latest loss 0.7209116220474243\n",
      "Finished epoch 427, latest loss 0.7219239473342896\n",
      "Finished epoch 428, latest loss 0.7220343351364136\n",
      "Finished epoch 429, latest loss 0.7231301069259644\n",
      "Finished epoch 430, latest loss 0.7229526042938232\n",
      "Finished epoch 431, latest loss 0.7219109535217285\n",
      "Finished epoch 432, latest loss 0.7199831604957581\n",
      "Finished epoch 433, latest loss 0.7212101221084595\n",
      "Finished epoch 434, latest loss 0.721968412399292\n",
      "Finished epoch 435, latest loss 0.721928596496582\n",
      "Finished epoch 436, latest loss 0.7223863005638123\n",
      "Finished epoch 437, latest loss 0.7210015654563904\n",
      "Finished epoch 438, latest loss 0.7223890423774719\n",
      "Finished epoch 439, latest loss 0.7215604782104492\n",
      "Finished epoch 440, latest loss 0.7189852595329285\n",
      "Finished epoch 441, latest loss 0.7201260328292847\n",
      "Finished epoch 442, latest loss 0.7200493812561035\n",
      "Finished epoch 443, latest loss 0.7207008600234985\n",
      "Finished epoch 444, latest loss 0.7202032804489136\n",
      "Finished epoch 445, latest loss 0.719986617565155\n",
      "Finished epoch 446, latest loss 0.7209116220474243\n",
      "Finished epoch 447, latest loss 0.7209935188293457\n",
      "Finished epoch 448, latest loss 0.7220051884651184\n",
      "Finished epoch 449, latest loss 0.7202057838439941\n",
      "Finished epoch 450, latest loss 0.7207341194152832\n",
      "Finished epoch 451, latest loss 0.720870316028595\n",
      "Finished epoch 452, latest loss 0.721344530582428\n",
      "Finished epoch 453, latest loss 0.720581591129303\n",
      "Finished epoch 454, latest loss 0.719142735004425\n",
      "Finished epoch 455, latest loss 0.7216832041740417\n",
      "Finished epoch 456, latest loss 0.7201372981071472\n",
      "Finished epoch 457, latest loss 0.7190305590629578\n",
      "Finished epoch 458, latest loss 0.718123197555542\n",
      "Finished epoch 459, latest loss 0.7209075093269348\n",
      "Finished epoch 460, latest loss 0.72350013256073\n",
      "Finished epoch 461, latest loss 0.7213031053543091\n",
      "Finished epoch 462, latest loss 0.7198551893234253\n",
      "Finished epoch 463, latest loss 0.719088077545166\n",
      "Finished epoch 464, latest loss 0.720313310623169\n",
      "Finished epoch 465, latest loss 0.7183916568756104\n",
      "Finished epoch 466, latest loss 0.7190565466880798\n",
      "Finished epoch 467, latest loss 0.719051718711853\n",
      "Finished epoch 468, latest loss 0.7200612425804138\n",
      "Finished epoch 469, latest loss 0.7181228995323181\n",
      "Finished epoch 470, latest loss 0.7220977544784546\n",
      "Finished epoch 471, latest loss 0.7205514907836914\n",
      "Finished epoch 472, latest loss 0.7181321382522583\n",
      "Finished epoch 473, latest loss 0.7191561460494995\n",
      "Finished epoch 474, latest loss 0.720069408416748\n",
      "Finished epoch 475, latest loss 0.7181363701820374\n",
      "Finished epoch 476, latest loss 0.7181228995323181\n",
      "Finished epoch 477, latest loss 0.7191339135169983\n",
      "Finished epoch 478, latest loss 0.7181408405303955\n",
      "Finished epoch 479, latest loss 0.7182610034942627\n",
      "Finished epoch 480, latest loss 0.7201098799705505\n",
      "Finished epoch 481, latest loss 0.7200639843940735\n",
      "Finished epoch 482, latest loss 0.7192196846008301\n",
      "Finished epoch 483, latest loss 0.7181485295295715\n",
      "Finished epoch 484, latest loss 0.7186643481254578\n",
      "Finished epoch 485, latest loss 0.7186874151229858\n",
      "Finished epoch 486, latest loss 0.7198107838630676\n",
      "Finished epoch 487, latest loss 0.7190524339675903\n",
      "Finished epoch 488, latest loss 0.7201459407806396\n",
      "Finished epoch 489, latest loss 0.7182164788246155\n",
      "Finished epoch 490, latest loss 0.7181228995323181\n",
      "Finished epoch 491, latest loss 0.7184523344039917\n",
      "Finished epoch 492, latest loss 0.7181228995323181\n",
      "Finished epoch 493, latest loss 0.7183513641357422\n",
      "Finished epoch 494, latest loss 0.7206353545188904\n",
      "Finished epoch 495, latest loss 0.7196924686431885\n",
      "Finished epoch 496, latest loss 0.7200611233711243\n",
      "Finished epoch 497, latest loss 0.7199805378913879\n",
      "Finished epoch 498, latest loss 0.7190505862236023\n",
      "Finished epoch 499, latest loss 0.7190524339675903\n",
      "Finished epoch 500, latest loss 0.7190524935722351\n",
      "Finished epoch 501, latest loss 0.7200114130973816\n",
      "Finished epoch 502, latest loss 0.7190524339675903\n",
      "Finished epoch 503, latest loss 0.7201183438301086\n",
      "Finished epoch 504, latest loss 0.7202591896057129\n",
      "Finished epoch 505, latest loss 0.7200645804405212\n",
      "Finished epoch 506, latest loss 0.7200590968132019\n",
      "Finished epoch 507, latest loss 0.71871417760849\n",
      "Finished epoch 508, latest loss 0.7183971405029297\n",
      "Finished epoch 509, latest loss 0.7191309332847595\n",
      "Finished epoch 510, latest loss 0.7184084057807922\n",
      "Finished epoch 511, latest loss 0.7181230783462524\n",
      "Finished epoch 512, latest loss 0.7181240320205688\n",
      "Finished epoch 513, latest loss 0.7181335091590881\n",
      "Finished epoch 514, latest loss 0.7181228995323181\n",
      "Finished epoch 515, latest loss 0.7181228995323181\n",
      "Finished epoch 516, latest loss 0.720252275466919\n",
      "Finished epoch 517, latest loss 0.719134509563446\n",
      "Finished epoch 518, latest loss 0.7190567851066589\n",
      "Finished epoch 519, latest loss 0.7181433439254761\n",
      "Finished epoch 520, latest loss 0.718129575252533\n",
      "Finished epoch 521, latest loss 0.7181228995323181\n",
      "Finished epoch 522, latest loss 0.7196389436721802\n",
      "Finished epoch 523, latest loss 0.7181228995323181\n",
      "Finished epoch 524, latest loss 0.7181228995323181\n",
      "Finished epoch 525, latest loss 0.7199790477752686\n",
      "Finished epoch 526, latest loss 0.7182831168174744\n",
      "Finished epoch 527, latest loss 0.7194315791130066\n",
      "Finished epoch 528, latest loss 0.7201175093650818\n",
      "Finished epoch 529, latest loss 0.7218599915504456\n",
      "Finished epoch 530, latest loss 0.7199868559837341\n",
      "Finished epoch 531, latest loss 0.7200639247894287\n",
      "Finished epoch 532, latest loss 0.7201746106147766\n",
      "Finished epoch 533, latest loss 0.7198394536972046\n",
      "Finished epoch 534, latest loss 0.7181231379508972\n",
      "Finished epoch 535, latest loss 0.7190524935722351\n",
      "Finished epoch 536, latest loss 0.7190511226654053\n",
      "Finished epoch 537, latest loss 0.7185627818107605\n",
      "Finished epoch 538, latest loss 0.7191239595413208\n",
      "Finished epoch 539, latest loss 0.7201464176177979\n",
      "Finished epoch 540, latest loss 0.718742847442627\n",
      "Finished epoch 541, latest loss 0.7181292772293091\n",
      "Finished epoch 542, latest loss 0.7184303998947144\n",
      "Finished epoch 543, latest loss 0.7181229591369629\n",
      "Finished epoch 544, latest loss 0.7181228995323181\n",
      "Finished epoch 545, latest loss 0.7181228995323181\n",
      "Finished epoch 546, latest loss 0.7192378640174866\n",
      "Finished epoch 547, latest loss 0.719134509563446\n",
      "Finished epoch 548, latest loss 0.7191305160522461\n",
      "Finished epoch 549, latest loss 0.7190806269645691\n",
      "Finished epoch 550, latest loss 0.7191019654273987\n",
      "Finished epoch 551, latest loss 0.7181228995323181\n",
      "Finished epoch 552, latest loss 0.7195725440979004\n",
      "Finished epoch 553, latest loss 0.7183403372764587\n",
      "Finished epoch 554, latest loss 0.718170702457428\n",
      "Finished epoch 555, latest loss 0.7191309332847595\n",
      "Finished epoch 556, latest loss 0.7190523743629456\n",
      "Finished epoch 557, latest loss 0.718133270740509\n",
      "Finished epoch 558, latest loss 0.7201297283172607\n",
      "Finished epoch 559, latest loss 0.7184663414955139\n",
      "Finished epoch 560, latest loss 0.7181296348571777\n",
      "Finished epoch 561, latest loss 0.7181228995323181\n",
      "Finished epoch 562, latest loss 0.720420241355896\n",
      "Finished epoch 563, latest loss 0.7207057476043701\n",
      "Finished epoch 564, latest loss 0.7181872725486755\n",
      "Finished epoch 565, latest loss 0.7185864448547363\n",
      "Finished epoch 566, latest loss 0.7181228995323181\n",
      "Finished epoch 567, latest loss 0.7189499139785767\n",
      "Finished epoch 568, latest loss 0.7190406322479248\n",
      "Finished epoch 569, latest loss 0.721070408821106\n",
      "Finished epoch 570, latest loss 0.7190526723861694\n",
      "Finished epoch 571, latest loss 0.7191348075866699\n",
      "Finished epoch 572, latest loss 0.7181265354156494\n",
      "Finished epoch 573, latest loss 0.7191457748413086\n",
      "Finished epoch 574, latest loss 0.7181409597396851\n",
      "Finished epoch 575, latest loss 0.7181806564331055\n",
      "Finished epoch 576, latest loss 0.7189270853996277\n",
      "Finished epoch 577, latest loss 0.7181228995323181\n",
      "Finished epoch 578, latest loss 0.719134509563446\n",
      "Finished epoch 579, latest loss 0.7191382646560669\n",
      "Finished epoch 580, latest loss 0.7181228995323181\n",
      "Finished epoch 581, latest loss 0.719134509563446\n",
      "Finished epoch 582, latest loss 0.7191342115402222\n",
      "Finished epoch 583, latest loss 0.7201462984085083\n",
      "Finished epoch 584, latest loss 0.7181235551834106\n",
      "Finished epoch 585, latest loss 0.7181298136711121\n",
      "Finished epoch 586, latest loss 0.7220461964607239\n",
      "Finished epoch 587, latest loss 0.7184665203094482\n",
      "Finished epoch 588, latest loss 0.7191335558891296\n",
      "Finished epoch 589, latest loss 0.7191146612167358\n",
      "Finished epoch 590, latest loss 0.7201460599899292\n",
      "Finished epoch 591, latest loss 0.7182419896125793\n",
      "Finished epoch 592, latest loss 0.7190284729003906\n",
      "Finished epoch 593, latest loss 0.7181228995323181\n",
      "Finished epoch 594, latest loss 0.7181277275085449\n",
      "Finished epoch 595, latest loss 0.719038724899292\n",
      "Finished epoch 596, latest loss 0.7181228995323181\n",
      "Finished epoch 597, latest loss 0.7189016342163086\n",
      "Finished epoch 598, latest loss 0.7201548218727112\n",
      "Finished epoch 599, latest loss 0.7187910079956055\n",
      "Finished epoch 600, latest loss 0.7201458215713501\n",
      "Finished epoch 601, latest loss 0.7190274596214294\n",
      "Finished epoch 602, latest loss 0.7181233763694763\n",
      "Finished epoch 603, latest loss 0.7182140350341797\n",
      "Finished epoch 604, latest loss 0.720146119594574\n",
      "Finished epoch 605, latest loss 0.7181597352027893\n",
      "Finished epoch 606, latest loss 0.7210667133331299\n",
      "Finished epoch 607, latest loss 0.718205451965332\n",
      "Finished epoch 608, latest loss 0.7200648784637451\n",
      "Finished epoch 609, latest loss 0.7218987345695496\n",
      "Finished epoch 610, latest loss 0.719440221786499\n",
      "Finished epoch 611, latest loss 0.719134509563446\n",
      "Finished epoch 612, latest loss 0.7193281054496765\n",
      "Finished epoch 613, latest loss 0.7191344499588013\n",
      "Finished epoch 614, latest loss 0.7181235551834106\n",
      "Finished epoch 615, latest loss 0.719134509563446\n",
      "Finished epoch 616, latest loss 0.7181228995323181\n",
      "Finished epoch 617, latest loss 0.7209845185279846\n",
      "Finished epoch 618, latest loss 0.7191175818443298\n",
      "Finished epoch 619, latest loss 0.7181228995323181\n",
      "Finished epoch 620, latest loss 0.719134509563446\n",
      "Finished epoch 621, latest loss 0.7181226015090942\n",
      "Finished epoch 622, latest loss 0.7190524339675903\n",
      "Finished epoch 623, latest loss 0.718295156955719\n",
      "Finished epoch 624, latest loss 0.7201444506645203\n",
      "Finished epoch 625, latest loss 0.7190439105033875\n",
      "Finished epoch 626, latest loss 0.7181255221366882\n",
      "Finished epoch 627, latest loss 0.7209093570709229\n",
      "Finished epoch 628, latest loss 0.7211195826530457\n",
      "Finished epoch 629, latest loss 0.7191344499588013\n",
      "Finished epoch 630, latest loss 0.7191346287727356\n",
      "Finished epoch 631, latest loss 0.7201327681541443\n",
      "Finished epoch 632, latest loss 0.7193562984466553\n",
      "Finished epoch 633, latest loss 0.7184626460075378\n",
      "Finished epoch 634, latest loss 0.7181228995323181\n",
      "Finished epoch 635, latest loss 0.7190524339675903\n",
      "Finished epoch 636, latest loss 0.7181666493415833\n",
      "Finished epoch 637, latest loss 0.7181317806243896\n",
      "Finished epoch 638, latest loss 0.7191300392150879\n",
      "Finished epoch 639, latest loss 0.7191306352615356\n",
      "Finished epoch 640, latest loss 0.7181228995323181\n",
      "Finished epoch 641, latest loss 0.7181960344314575\n",
      "Finished epoch 642, latest loss 0.7202004790306091\n",
      "Finished epoch 643, latest loss 0.7191137671470642\n",
      "Finished epoch 644, latest loss 0.7200646996498108\n",
      "Finished epoch 645, latest loss 0.7194910049438477\n",
      "Finished epoch 646, latest loss 0.7190187573432922\n",
      "Finished epoch 647, latest loss 0.7181243300437927\n",
      "Finished epoch 648, latest loss 0.7191344499588013\n",
      "Finished epoch 649, latest loss 0.7181230187416077\n",
      "Finished epoch 650, latest loss 0.7191398739814758\n",
      "Finished epoch 651, latest loss 0.719169557094574\n",
      "Finished epoch 652, latest loss 0.7202093601226807\n",
      "Finished epoch 653, latest loss 0.7201511263847351\n",
      "Finished epoch 654, latest loss 0.7211645245552063\n",
      "Finished epoch 655, latest loss 0.7201414108276367\n",
      "Finished epoch 656, latest loss 0.7181252837181091\n",
      "Finished epoch 657, latest loss 0.7201255559921265\n",
      "Finished epoch 658, latest loss 0.7190524935722351\n",
      "Finished epoch 659, latest loss 0.7181228995323181\n",
      "Finished epoch 660, latest loss 0.720146119594574\n",
      "Finished epoch 661, latest loss 0.7194637656211853\n",
      "Finished epoch 662, latest loss 0.7185853719711304\n",
      "Finished epoch 663, latest loss 0.7184808850288391\n",
      "Finished epoch 664, latest loss 0.7181235551834106\n",
      "Finished epoch 665, latest loss 0.7191445827484131\n",
      "Finished epoch 666, latest loss 0.7181228995323181\n",
      "Finished epoch 667, latest loss 0.7189257740974426\n",
      "Finished epoch 668, latest loss 0.7181228995323181\n",
      "Finished epoch 669, latest loss 0.7194669842720032\n",
      "Finished epoch 670, latest loss 0.7200653553009033\n",
      "Finished epoch 671, latest loss 0.7209116220474243\n",
      "Finished epoch 672, latest loss 0.7193705439567566\n",
      "Finished epoch 673, latest loss 0.7200640439987183\n",
      "Finished epoch 674, latest loss 0.71901535987854\n",
      "Finished epoch 675, latest loss 0.7181228995323181\n",
      "Finished epoch 676, latest loss 0.7181228995323181\n",
      "Finished epoch 677, latest loss 0.7181245684623718\n",
      "Finished epoch 678, latest loss 0.7192012667655945\n",
      "Finished epoch 679, latest loss 0.7210767269134521\n",
      "Finished epoch 680, latest loss 0.7200629115104675\n",
      "Finished epoch 681, latest loss 0.7211154699325562\n",
      "Finished epoch 682, latest loss 0.7212651371955872\n",
      "Finished epoch 683, latest loss 0.7201271057128906\n",
      "Finished epoch 684, latest loss 0.7181230187416077\n",
      "Finished epoch 685, latest loss 0.7185608744621277\n",
      "Finished epoch 686, latest loss 0.7183153629302979\n",
      "Finished epoch 687, latest loss 0.7181344032287598\n",
      "Finished epoch 688, latest loss 0.719134509563446\n",
      "Finished epoch 689, latest loss 0.7195799946784973\n",
      "Finished epoch 690, latest loss 0.7206640243530273\n",
      "Finished epoch 691, latest loss 0.7191339135169983\n",
      "Finished epoch 692, latest loss 0.7181240320205688\n",
      "Finished epoch 693, latest loss 0.7181228995323181\n",
      "Finished epoch 694, latest loss 0.7181228995323181\n",
      "Finished epoch 695, latest loss 0.719134509563446\n",
      "Finished epoch 696, latest loss 0.7185883522033691\n",
      "Finished epoch 697, latest loss 0.7181228995323181\n",
      "Finished epoch 698, latest loss 0.7190326452255249\n",
      "Finished epoch 699, latest loss 0.7181228995323181\n",
      "Finished epoch 700, latest loss 0.7180896401405334\n",
      "Finished epoch 701, latest loss 0.7176242470741272\n",
      "Finished epoch 702, latest loss 0.7181403636932373\n",
      "Finished epoch 703, latest loss 0.7172174453735352\n",
      "Finished epoch 704, latest loss 0.7181228995323181\n",
      "Finished epoch 705, latest loss 0.7201686501502991\n",
      "Finished epoch 706, latest loss 0.7191329598426819\n",
      "Finished epoch 707, latest loss 0.7212160229682922\n",
      "Finished epoch 708, latest loss 0.7191303372383118\n",
      "Finished epoch 709, latest loss 0.7191421985626221\n",
      "Finished epoch 710, latest loss 0.7200640439987183\n",
      "Finished epoch 711, latest loss 0.7181229591369629\n",
      "Finished epoch 712, latest loss 0.7212300300598145\n",
      "Finished epoch 713, latest loss 0.720151424407959\n",
      "Finished epoch 714, latest loss 0.7182019352912903\n",
      "Finished epoch 715, latest loss 0.7181231379508972\n",
      "Finished epoch 716, latest loss 0.719138503074646\n",
      "Finished epoch 717, latest loss 0.7210707068443298\n",
      "Finished epoch 718, latest loss 0.7191846966743469\n",
      "Finished epoch 719, latest loss 0.7181800603866577\n",
      "Finished epoch 720, latest loss 0.7172322273254395\n",
      "Finished epoch 721, latest loss 0.7183961868286133\n",
      "Finished epoch 722, latest loss 0.7174088954925537\n",
      "Finished epoch 723, latest loss 0.7182066440582275\n",
      "Finished epoch 724, latest loss 0.7192530035972595\n",
      "Finished epoch 725, latest loss 0.7182042598724365\n",
      "Finished epoch 726, latest loss 0.7179647088050842\n",
      "Finished epoch 727, latest loss 0.7171933054924011\n",
      "Finished epoch 728, latest loss 0.7171933054924011\n",
      "Finished epoch 729, latest loss 0.7190907001495361\n",
      "Finished epoch 730, latest loss 0.7187171578407288\n",
      "Finished epoch 731, latest loss 0.7171933054924011\n",
      "Finished epoch 732, latest loss 0.7192755341529846\n",
      "Finished epoch 733, latest loss 0.7179194688796997\n",
      "Finished epoch 734, latest loss 0.718204915523529\n",
      "Finished epoch 735, latest loss 0.717194139957428\n",
      "Finished epoch 736, latest loss 0.7181437015533447\n",
      "Finished epoch 737, latest loss 0.7181228995323181\n",
      "Finished epoch 738, latest loss 0.719134509563446\n",
      "Finished epoch 739, latest loss 0.7209157943725586\n",
      "Finished epoch 740, latest loss 0.7181228399276733\n",
      "Finished epoch 741, latest loss 0.7179068326950073\n",
      "Finished epoch 742, latest loss 0.7180712223052979\n",
      "Finished epoch 743, latest loss 0.7171933054924011\n",
      "Finished epoch 744, latest loss 0.7191342115402222\n",
      "Finished epoch 745, latest loss 0.7182230949401855\n",
      "Finished epoch 746, latest loss 0.7192307710647583\n",
      "Finished epoch 747, latest loss 0.7191040515899658\n",
      "Finished epoch 748, latest loss 0.7219998836517334\n",
      "Finished epoch 749, latest loss 0.7171933054924011\n",
      "Finished epoch 750, latest loss 0.718142569065094\n",
      "Finished epoch 751, latest loss 0.7182048559188843\n",
      "Finished epoch 752, latest loss 0.7191370129585266\n",
      "Finished epoch 753, latest loss 0.7191987633705139\n",
      "Finished epoch 754, latest loss 0.7171933054924011\n",
      "Finished epoch 755, latest loss 0.7190393805503845\n",
      "Finished epoch 756, latest loss 0.7191345691680908\n",
      "Finished epoch 757, latest loss 0.7184467315673828\n",
      "Finished epoch 758, latest loss 0.7172006368637085\n",
      "Finished epoch 759, latest loss 0.7171933650970459\n",
      "Finished epoch 760, latest loss 0.7182140350341797\n",
      "Finished epoch 761, latest loss 0.719134509563446\n",
      "Finished epoch 762, latest loss 0.7190659642219543\n",
      "Finished epoch 763, latest loss 0.717696487903595\n",
      "Finished epoch 764, latest loss 0.7181044816970825\n",
      "Finished epoch 765, latest loss 0.7181228995323181\n",
      "Finished epoch 766, latest loss 0.718124270439148\n",
      "Finished epoch 767, latest loss 0.7201440930366516\n",
      "Finished epoch 768, latest loss 0.7190524339675903\n",
      "Finished epoch 769, latest loss 0.7182048559188843\n",
      "Finished epoch 770, latest loss 0.7191740870475769\n",
      "Finished epoch 771, latest loss 0.7171933054924011\n",
      "Finished epoch 772, latest loss 0.719131588935852\n",
      "Finished epoch 773, latest loss 0.719134509563446\n",
      "Finished epoch 774, latest loss 0.7200286388397217\n",
      "Finished epoch 775, latest loss 0.7171935439109802\n",
      "Finished epoch 776, latest loss 0.7181228995323181\n",
      "Finished epoch 777, latest loss 0.7181310057640076\n",
      "Finished epoch 778, latest loss 0.7190524935722351\n",
      "Finished epoch 779, latest loss 0.7190524935722351\n",
      "Finished epoch 780, latest loss 0.719134509563446\n",
      "Finished epoch 781, latest loss 0.7191390991210938\n",
      "Finished epoch 782, latest loss 0.7181228995323181\n",
      "Finished epoch 783, latest loss 0.7191348075866699\n",
      "Finished epoch 784, latest loss 0.7181240916252136\n",
      "Finished epoch 785, latest loss 0.7171937227249146\n",
      "Finished epoch 786, latest loss 0.7171933054924011\n",
      "Finished epoch 787, latest loss 0.7191336154937744\n",
      "Finished epoch 788, latest loss 0.7201162576675415\n",
      "Finished epoch 789, latest loss 0.7182050943374634\n",
      "Finished epoch 790, latest loss 0.7183890342712402\n",
      "Finished epoch 791, latest loss 0.7183054089546204\n",
      "Finished epoch 792, latest loss 0.7192276120185852\n",
      "Finished epoch 793, latest loss 0.7197103500366211\n",
      "Finished epoch 794, latest loss 0.7171952724456787\n",
      "Finished epoch 795, latest loss 0.7182191014289856\n",
      "Finished epoch 796, latest loss 0.7202048897743225\n",
      "Finished epoch 797, latest loss 0.719216525554657\n",
      "Finished epoch 798, latest loss 0.7182049751281738\n",
      "Finished epoch 799, latest loss 0.7192230224609375\n",
      "Finished epoch 800, latest loss 0.7171933054924011\n",
      "Finished epoch 801, latest loss 0.7181190848350525\n",
      "Finished epoch 802, latest loss 0.7190908193588257\n",
      "Finished epoch 803, latest loss 0.7171933650970459\n",
      "Finished epoch 804, latest loss 0.7172994613647461\n",
      "Finished epoch 805, latest loss 0.721224308013916\n",
      "Finished epoch 806, latest loss 0.7172112464904785\n",
      "Finished epoch 807, latest loss 0.7192381620407104\n",
      "Finished epoch 808, latest loss 0.7182290554046631\n",
      "Finished epoch 809, latest loss 0.7172324061393738\n",
      "Finished epoch 810, latest loss 0.7193276882171631\n",
      "Finished epoch 811, latest loss 0.7215454578399658\n",
      "Finished epoch 812, latest loss 0.7172497510910034\n",
      "Finished epoch 813, latest loss 0.7199916243553162\n",
      "Finished epoch 814, latest loss 0.7181228995323181\n",
      "Finished epoch 815, latest loss 0.7181228995323181\n",
      "Finished epoch 816, latest loss 0.7221794128417969\n",
      "Finished epoch 817, latest loss 0.7182049751281738\n",
      "Finished epoch 818, latest loss 0.7172064185142517\n",
      "Finished epoch 819, latest loss 0.7201440334320068\n",
      "Finished epoch 820, latest loss 0.7190524339675903\n",
      "Finished epoch 821, latest loss 0.7190524339675903\n",
      "Finished epoch 822, latest loss 0.7199790477752686\n",
      "Finished epoch 823, latest loss 0.7171933054924011\n",
      "Finished epoch 824, latest loss 0.7191339135169983\n",
      "Finished epoch 825, latest loss 0.717972993850708\n",
      "Finished epoch 826, latest loss 0.7171934843063354\n",
      "Finished epoch 827, latest loss 0.7177451848983765\n",
      "Finished epoch 828, latest loss 0.7191904783248901\n",
      "Finished epoch 829, latest loss 0.7171933054924011\n",
      "Finished epoch 830, latest loss 0.7192178964614868\n",
      "Finished epoch 831, latest loss 0.7192867994308472\n",
      "Finished epoch 832, latest loss 0.7171955704689026\n",
      "Finished epoch 833, latest loss 0.7171933650970459\n",
      "Finished epoch 834, latest loss 0.7191353440284729\n",
      "Finished epoch 835, latest loss 0.7200544476509094\n",
      "Finished epoch 836, latest loss 0.7172171473503113\n",
      "Finished epoch 837, latest loss 0.7181141376495361\n",
      "Finished epoch 838, latest loss 0.7172225117683411\n",
      "Finished epoch 839, latest loss 0.7201448082923889\n",
      "Finished epoch 840, latest loss 0.718128502368927\n",
      "Finished epoch 841, latest loss 0.7201498746871948\n",
      "Finished epoch 842, latest loss 0.7187339663505554\n",
      "Finished epoch 843, latest loss 0.7180871963500977\n",
      "Finished epoch 844, latest loss 0.7172113060951233\n",
      "Finished epoch 845, latest loss 0.7171933054924011\n",
      "Finished epoch 846, latest loss 0.7200617790222168\n",
      "Finished epoch 847, latest loss 0.7191852927207947\n",
      "Finished epoch 848, latest loss 0.7171933650970459\n",
      "Finished epoch 849, latest loss 0.7192367911338806\n",
      "Finished epoch 850, latest loss 0.7192113995552063\n",
      "Finished epoch 851, latest loss 0.7182214260101318\n",
      "Finished epoch 852, latest loss 0.7172321677207947\n",
      "Finished epoch 853, latest loss 0.7175116539001465\n",
      "Finished epoch 854, latest loss 0.718204915523529\n",
      "Finished epoch 855, latest loss 0.7182263731956482\n",
      "Finished epoch 856, latest loss 0.7171933054924011\n",
      "Finished epoch 857, latest loss 0.718123197555542\n",
      "Finished epoch 858, latest loss 0.7173696160316467\n",
      "Finished epoch 859, latest loss 0.7189637422561646\n",
      "Finished epoch 860, latest loss 0.7162637710571289\n",
      "Finished epoch 861, latest loss 0.7172753810882568\n",
      "Finished epoch 862, latest loss 0.7172753810882568\n",
      "Finished epoch 863, latest loss 0.7162651419639587\n",
      "Finished epoch 864, latest loss 0.7163026332855225\n",
      "Finished epoch 865, latest loss 0.7202271223068237\n",
      "Finished epoch 866, latest loss 0.718429684638977\n",
      "Finished epoch 867, latest loss 0.7174856662750244\n",
      "Finished epoch 868, latest loss 0.7193013429641724\n",
      "Finished epoch 869, latest loss 0.7194913029670715\n",
      "Finished epoch 870, latest loss 0.7181228995323181\n",
      "Finished epoch 871, latest loss 0.7182049751281738\n",
      "Finished epoch 872, latest loss 0.7171452045440674\n",
      "Finished epoch 873, latest loss 0.7172905802726746\n",
      "Finished epoch 874, latest loss 0.7201812863349915\n",
      "Finished epoch 875, latest loss 0.7162649631500244\n",
      "Finished epoch 876, latest loss 0.7172755002975464\n",
      "Finished epoch 877, latest loss 0.7184650301933289\n",
      "Finished epoch 878, latest loss 0.7201313972473145\n",
      "Finished epoch 879, latest loss 0.7203102111816406\n",
      "Finished epoch 880, latest loss 0.7181753516197205\n",
      "Finished epoch 881, latest loss 0.7171951532363892\n",
      "Finished epoch 882, latest loss 0.7182062864303589\n",
      "Finished epoch 883, latest loss 0.7182105183601379\n",
      "Finished epoch 884, latest loss 0.7173140048980713\n",
      "Finished epoch 885, latest loss 0.7191599011421204\n",
      "Finished epoch 886, latest loss 0.7179301381111145\n",
      "Finished epoch 887, latest loss 0.7171933650970459\n",
      "Finished epoch 888, latest loss 0.7171933650970459\n",
      "Finished epoch 889, latest loss 0.7162639498710632\n",
      "Finished epoch 890, latest loss 0.7171942591667175\n",
      "Finished epoch 891, latest loss 0.7211694121360779\n",
      "Finished epoch 892, latest loss 0.7192373275756836\n",
      "Finished epoch 893, latest loss 0.7192167043685913\n",
      "Finished epoch 894, latest loss 0.719216525554657\n",
      "Finished epoch 895, latest loss 0.7162637710571289\n",
      "Finished epoch 896, latest loss 0.7181477546691895\n",
      "Finished epoch 897, latest loss 0.7213245034217834\n",
      "Finished epoch 898, latest loss 0.7174167037010193\n",
      "Finished epoch 899, latest loss 0.7172753810882568\n",
      "Finished epoch 900, latest loss 0.718204915523529\n",
      "Finished epoch 901, latest loss 0.7201460003852844\n",
      "Finished epoch 902, latest loss 0.718031644821167\n",
      "Finished epoch 903, latest loss 0.7190302610397339\n",
      "Finished epoch 904, latest loss 0.7172496914863586\n",
      "Finished epoch 905, latest loss 0.7192081212997437\n",
      "Finished epoch 906, latest loss 0.7192160487174988\n",
      "Finished epoch 907, latest loss 0.7181228995323181\n",
      "Finished epoch 908, latest loss 0.7182048559188843\n",
      "Finished epoch 909, latest loss 0.7171958684921265\n",
      "Finished epoch 910, latest loss 0.7172010540962219\n",
      "Finished epoch 911, latest loss 0.7162662744522095\n",
      "Finished epoch 912, latest loss 0.7171933054924011\n",
      "Finished epoch 913, latest loss 0.7182102203369141\n",
      "Finished epoch 914, latest loss 0.7163196802139282\n",
      "Finished epoch 915, latest loss 0.7174125909805298\n",
      "Finished epoch 916, latest loss 0.7182050943374634\n",
      "Finished epoch 917, latest loss 0.7182527184486389\n",
      "Finished epoch 918, latest loss 0.7182049751281738\n",
      "Finished epoch 919, latest loss 0.7173121571540833\n",
      "Finished epoch 920, latest loss 0.7187057733535767\n",
      "Finished epoch 921, latest loss 0.7163679599761963\n",
      "Finished epoch 922, latest loss 0.7181933522224426\n",
      "Finished epoch 923, latest loss 0.7154889702796936\n",
      "Finished epoch 924, latest loss 0.7156201601028442\n",
      "Finished epoch 925, latest loss 0.7159910798072815\n",
      "Finished epoch 926, latest loss 0.7167655229568481\n",
      "Finished epoch 927, latest loss 0.7162637710571289\n",
      "Finished epoch 928, latest loss 0.7162637710571289\n",
      "Finished epoch 929, latest loss 0.7162660956382751\n",
      "Finished epoch 930, latest loss 0.7153362035751343\n",
      "Finished epoch 931, latest loss 0.7165471911430359\n",
      "Finished epoch 932, latest loss 0.7168496251106262\n",
      "Finished epoch 933, latest loss 0.7163457870483398\n",
      "Finished epoch 934, latest loss 0.7173475027084351\n",
      "Finished epoch 935, latest loss 0.7153342962265015\n",
      "Finished epoch 936, latest loss 0.7153386473655701\n",
      "Finished epoch 937, latest loss 0.7153341770172119\n",
      "Finished epoch 938, latest loss 0.7153341770172119\n",
      "Finished epoch 939, latest loss 0.7161807417869568\n",
      "Finished epoch 940, latest loss 0.7153343558311462\n",
      "Finished epoch 941, latest loss 0.7153416872024536\n",
      "Finished epoch 942, latest loss 0.715334415435791\n",
      "Finished epoch 943, latest loss 0.7165423035621643\n",
      "Finished epoch 944, latest loss 0.7153341770172119\n",
      "Finished epoch 945, latest loss 0.7153341770172119\n",
      "Finished epoch 946, latest loss 0.7163464426994324\n",
      "Finished epoch 947, latest loss 0.7173433303833008\n",
      "Finished epoch 948, latest loss 0.715334415435791\n",
      "Finished epoch 949, latest loss 0.7174809575080872\n",
      "Finished epoch 950, latest loss 0.7153341770172119\n",
      "Finished epoch 951, latest loss 0.7171928286552429\n",
      "Finished epoch 952, latest loss 0.7163360118865967\n",
      "Finished epoch 953, latest loss 0.7174418568611145\n",
      "Finished epoch 954, latest loss 0.7173573970794678\n",
      "Finished epoch 955, latest loss 0.7181047201156616\n",
      "Finished epoch 956, latest loss 0.7166180610656738\n",
      "Finished epoch 957, latest loss 0.7162637710571289\n",
      "Finished epoch 958, latest loss 0.7162637710571289\n",
      "Finished epoch 959, latest loss 0.7171083688735962\n",
      "Finished epoch 960, latest loss 0.7160636186599731\n",
      "Finished epoch 961, latest loss 0.7163450717926025\n",
      "Finished epoch 962, latest loss 0.7162637710571289\n",
      "Finished epoch 963, latest loss 0.7163457870483398\n",
      "Finished epoch 964, latest loss 0.7172753214836121\n",
      "Finished epoch 965, latest loss 0.7193906903266907\n",
      "Finished epoch 966, latest loss 0.7173575162887573\n",
      "Finished epoch 967, latest loss 0.7164141535758972\n",
      "Finished epoch 968, latest loss 0.7172753810882568\n",
      "Finished epoch 969, latest loss 0.7162513732910156\n",
      "Finished epoch 970, latest loss 0.717357337474823\n",
      "Finished epoch 971, latest loss 0.7163457870483398\n",
      "Finished epoch 972, latest loss 0.7163456678390503\n",
      "Finished epoch 973, latest loss 0.7167708277702332\n",
      "Finished epoch 974, latest loss 0.7182624936103821\n",
      "Finished epoch 975, latest loss 0.7153346538543701\n",
      "Finished epoch 976, latest loss 0.71759033203125\n",
      "Finished epoch 977, latest loss 0.7158118486404419\n",
      "Finished epoch 978, latest loss 0.7163457274436951\n",
      "Finished epoch 979, latest loss 0.7153346538543701\n",
      "Finished epoch 980, latest loss 0.7162408232688904\n",
      "Finished epoch 981, latest loss 0.7158247232437134\n",
      "Finished epoch 982, latest loss 0.7173150181770325\n",
      "Finished epoch 983, latest loss 0.7153341770172119\n",
      "Finished epoch 984, latest loss 0.7155784368515015\n",
      "Finished epoch 985, latest loss 0.7163457870483398\n",
      "Finished epoch 986, latest loss 0.7153404951095581\n",
      "Finished epoch 987, latest loss 0.715328574180603\n",
      "Finished epoch 988, latest loss 0.716302752494812\n",
      "Finished epoch 989, latest loss 0.7163457870483398\n",
      "Finished epoch 990, latest loss 0.7163456678390503\n",
      "Finished epoch 991, latest loss 0.7160060405731201\n",
      "Finished epoch 992, latest loss 0.7153341770172119\n",
      "Finished epoch 993, latest loss 0.7163482308387756\n",
      "Finished epoch 994, latest loss 0.7153341770172119\n",
      "Finished epoch 995, latest loss 0.71634441614151\n",
      "Finished epoch 996, latest loss 0.7153341770172119\n",
      "Finished epoch 997, latest loss 0.7165207862854004\n",
      "Finished epoch 998, latest loss 0.7153462171554565\n",
      "Finished epoch 999, latest loss 0.7181298732757568\n",
      "Finished epoch 1000, latest loss 0.715457022190094\n",
      "Finished epoch 1001, latest loss 0.7153382897377014\n",
      "Finished epoch 1002, latest loss 0.7153341770172119\n",
      "Finished epoch 1003, latest loss 0.7153341770172119\n",
      "Finished epoch 1004, latest loss 0.7162943482398987\n",
      "Finished epoch 1005, latest loss 0.7176913022994995\n",
      "Finished epoch 1006, latest loss 0.7153366208076477\n",
      "Finished epoch 1007, latest loss 0.7153341770172119\n",
      "Finished epoch 1008, latest loss 0.7163457870483398\n",
      "Finished epoch 1009, latest loss 0.71626877784729\n",
      "Finished epoch 1010, latest loss 0.716412365436554\n",
      "Finished epoch 1011, latest loss 0.7172753810882568\n",
      "Finished epoch 1012, latest loss 0.7162719368934631\n",
      "Finished epoch 1013, latest loss 0.7163457274436951\n",
      "Finished epoch 1014, latest loss 0.7153341770172119\n",
      "Finished epoch 1015, latest loss 0.7163457870483398\n",
      "Finished epoch 1016, latest loss 0.716614305973053\n",
      "Finished epoch 1017, latest loss 0.7173573970794678\n",
      "Finished epoch 1018, latest loss 0.7153341770172119\n",
      "Finished epoch 1019, latest loss 0.7163457870483398\n",
      "Finished epoch 1020, latest loss 0.7163453698158264\n",
      "Finished epoch 1021, latest loss 0.7163447141647339\n",
      "Finished epoch 1022, latest loss 0.7160869836807251\n",
      "Finished epoch 1023, latest loss 0.7153342366218567\n",
      "Finished epoch 1024, latest loss 0.7153341770172119\n",
      "Finished epoch 1025, latest loss 0.7153341770172119\n",
      "Finished epoch 1026, latest loss 0.7162640690803528\n",
      "Finished epoch 1027, latest loss 0.7162637710571289\n",
      "Finished epoch 1028, latest loss 0.7182720303535461\n",
      "Finished epoch 1029, latest loss 0.715509295463562\n",
      "Finished epoch 1030, latest loss 0.7153341770172119\n",
      "Finished epoch 1031, latest loss 0.7163518667221069\n",
      "Finished epoch 1032, latest loss 0.7162637710571289\n",
      "Finished epoch 1033, latest loss 0.7153439521789551\n",
      "Finished epoch 1034, latest loss 0.7162637710571289\n",
      "Finished epoch 1035, latest loss 0.7173545360565186\n",
      "Finished epoch 1036, latest loss 0.7153341770172119\n",
      "Finished epoch 1037, latest loss 0.7163481116294861\n",
      "Finished epoch 1038, latest loss 0.7163457870483398\n",
      "Finished epoch 1039, latest loss 0.7180843949317932\n",
      "Finished epoch 1040, latest loss 0.7163317799568176\n",
      "Finished epoch 1041, latest loss 0.7163779139518738\n",
      "Finished epoch 1042, latest loss 0.7168267369270325\n",
      "Finished epoch 1043, latest loss 0.7163506150245667\n",
      "Finished epoch 1044, latest loss 0.7162935137748718\n",
      "Finished epoch 1045, latest loss 0.7173133492469788\n",
      "Finished epoch 1046, latest loss 0.7173573970794678\n",
      "Finished epoch 1047, latest loss 0.7164923548698425\n",
      "Finished epoch 1048, latest loss 0.7163406610488892\n",
      "Finished epoch 1049, latest loss 0.7182737588882446\n",
      "Finished epoch 1050, latest loss 0.7153341770172119\n",
      "Finished epoch 1051, latest loss 0.716570258140564\n",
      "Finished epoch 1052, latest loss 0.7153578400611877\n",
      "Finished epoch 1053, latest loss 0.7158119082450867\n",
      "Finished epoch 1054, latest loss 0.721452534198761\n",
      "Finished epoch 1055, latest loss 0.7192287445068359\n",
      "Finished epoch 1056, latest loss 0.7173567414283752\n",
      "Finished epoch 1057, latest loss 0.7153351902961731\n",
      "Finished epoch 1058, latest loss 0.7181212902069092\n",
      "Finished epoch 1059, latest loss 0.7182610630989075\n",
      "Finished epoch 1060, latest loss 0.7163457870483398\n",
      "Finished epoch 1061, latest loss 0.7163485884666443\n",
      "Finished epoch 1062, latest loss 0.7163457870483398\n",
      "Finished epoch 1063, latest loss 0.7153342366218567\n",
      "Finished epoch 1064, latest loss 0.7162253856658936\n",
      "Finished epoch 1065, latest loss 0.7163457870483398\n",
      "Finished epoch 1066, latest loss 0.7162846326828003\n",
      "Finished epoch 1067, latest loss 0.7163461446762085\n",
      "Finished epoch 1068, latest loss 0.7187498807907104\n",
      "Finished epoch 1069, latest loss 0.7176831364631653\n",
      "Finished epoch 1070, latest loss 0.7172755002975464\n",
      "Finished epoch 1071, latest loss 0.7163458466529846\n",
      "Finished epoch 1072, latest loss 0.7163457870483398\n",
      "Finished epoch 1073, latest loss 0.7172806859016418\n",
      "Finished epoch 1074, latest loss 0.7182849049568176\n",
      "Finished epoch 1075, latest loss 0.7163458466529846\n",
      "Finished epoch 1076, latest loss 0.7156800031661987\n",
      "Finished epoch 1077, latest loss 0.7173573970794678\n",
      "Finished epoch 1078, latest loss 0.717385470867157\n",
      "Finished epoch 1079, latest loss 0.7163457274436951\n",
      "Finished epoch 1080, latest loss 0.7183529138565063\n",
      "Finished epoch 1081, latest loss 0.7163457274436951\n",
      "Finished epoch 1082, latest loss 0.7153846025466919\n",
      "Finished epoch 1083, latest loss 0.7163457870483398\n",
      "Finished epoch 1084, latest loss 0.7153359651565552\n",
      "Finished epoch 1085, latest loss 0.7163457870483398\n",
      "Finished epoch 1086, latest loss 0.7163457870483398\n",
      "Finished epoch 1087, latest loss 0.717580258846283\n",
      "Finished epoch 1088, latest loss 0.7153342366218567\n",
      "Finished epoch 1089, latest loss 0.7153348326683044\n",
      "Finished epoch 1090, latest loss 0.7163475155830383\n",
      "Finished epoch 1091, latest loss 0.7153342366218567\n",
      "Finished epoch 1092, latest loss 0.7163457870483398\n",
      "Finished epoch 1093, latest loss 0.7167690992355347\n",
      "Finished epoch 1094, latest loss 0.7153341770172119\n",
      "Finished epoch 1095, latest loss 0.7163457274436951\n",
      "Finished epoch 1096, latest loss 0.7153341770172119\n",
      "Finished epoch 1097, latest loss 0.7155776023864746\n",
      "Finished epoch 1098, latest loss 0.7163457870483398\n",
      "Finished epoch 1099, latest loss 0.7162127494812012\n",
      "Finished epoch 1100, latest loss 0.715334415435791\n",
      "Finished epoch 1101, latest loss 0.715334415435791\n",
      "Finished epoch 1102, latest loss 0.716344952583313\n",
      "Finished epoch 1103, latest loss 0.7153341770172119\n",
      "Finished epoch 1104, latest loss 0.7180601954460144\n",
      "Finished epoch 1105, latest loss 0.7173672318458557\n",
      "Finished epoch 1106, latest loss 0.717341423034668\n",
      "Finished epoch 1107, latest loss 0.7153341770172119\n",
      "Finished epoch 1108, latest loss 0.7163583040237427\n",
      "Finished epoch 1109, latest loss 0.7170047760009766\n",
      "Finished epoch 1110, latest loss 0.7153341770172119\n",
      "Finished epoch 1111, latest loss 0.7161955833435059\n",
      "Finished epoch 1112, latest loss 0.7163457274436951\n",
      "Finished epoch 1113, latest loss 0.7153343558311462\n",
      "Finished epoch 1114, latest loss 0.7191285490989685\n",
      "Finished epoch 1115, latest loss 0.7163273096084595\n",
      "Finished epoch 1116, latest loss 0.7153370380401611\n",
      "Finished epoch 1117, latest loss 0.7162580490112305\n",
      "Finished epoch 1118, latest loss 0.7153341770172119\n",
      "Finished epoch 1119, latest loss 0.7153342366218567\n",
      "Finished epoch 1120, latest loss 0.7153407335281372\n",
      "Finished epoch 1121, latest loss 0.7153306603431702\n",
      "Finished epoch 1122, latest loss 0.7153341770172119\n",
      "Finished epoch 1123, latest loss 0.7153578996658325\n",
      "Finished epoch 1124, latest loss 0.7153674960136414\n",
      "Finished epoch 1125, latest loss 0.7153341770172119\n",
      "Finished epoch 1126, latest loss 0.7163457274436951\n",
      "Finished epoch 1127, latest loss 0.7153721451759338\n",
      "Finished epoch 1128, latest loss 0.7183768153190613\n",
      "Finished epoch 1129, latest loss 0.7163457274436951\n",
      "Finished epoch 1130, latest loss 0.717357337474823\n",
      "Finished epoch 1131, latest loss 0.7183688879013062\n",
      "Finished epoch 1132, latest loss 0.7159872651100159\n",
      "Finished epoch 1133, latest loss 0.7173028588294983\n",
      "Finished epoch 1134, latest loss 0.714406430721283\n",
      "Finished epoch 1135, latest loss 0.7153210043907166\n",
      "Finished epoch 1136, latest loss 0.7163457274436951\n",
      "Finished epoch 1137, latest loss 0.7144045829772949\n",
      "Finished epoch 1138, latest loss 0.7172457575798035\n",
      "Finished epoch 1139, latest loss 0.7164095640182495\n",
      "Finished epoch 1140, latest loss 0.7152832746505737\n",
      "Finished epoch 1141, latest loss 0.7150354981422424\n",
      "Finished epoch 1142, latest loss 0.7144046425819397\n",
      "Finished epoch 1143, latest loss 0.7154161930084229\n",
      "Finished epoch 1144, latest loss 0.7144047617912292\n",
      "Finished epoch 1145, latest loss 0.7173565030097961\n",
      "Finished epoch 1146, latest loss 0.7154313921928406\n",
      "Finished epoch 1147, latest loss 0.7154222726821899\n",
      "Finished epoch 1148, latest loss 0.7144046425819397\n",
      "Finished epoch 1149, latest loss 0.7144123315811157\n",
      "Finished epoch 1150, latest loss 0.7163292169570923\n",
      "Finished epoch 1151, latest loss 0.7173423171043396\n",
      "Finished epoch 1152, latest loss 0.7154161930084229\n",
      "Finished epoch 1153, latest loss 0.7164278030395508\n",
      "Finished epoch 1154, latest loss 0.7164278030395508\n",
      "Finished epoch 1155, latest loss 0.7173571586608887\n",
      "Finished epoch 1156, latest loss 0.7164278030395508\n",
      "Finished epoch 1157, latest loss 0.7164214253425598\n",
      "Finished epoch 1158, latest loss 0.7164278030395508\n",
      "Finished epoch 1159, latest loss 0.7144160866737366\n",
      "Finished epoch 1160, latest loss 0.7163268327713013\n",
      "Finished epoch 1161, latest loss 0.7144203186035156\n",
      "Finished epoch 1162, latest loss 0.7153507471084595\n",
      "Finished epoch 1163, latest loss 0.7154285311698914\n",
      "Finished epoch 1164, latest loss 0.7153341770172119\n",
      "Finished epoch 1165, latest loss 0.7162668108940125\n",
      "Finished epoch 1166, latest loss 0.717232882976532\n",
      "Finished epoch 1167, latest loss 0.7162637710571289\n",
      "Finished epoch 1168, latest loss 0.7147394418716431\n",
      "Finished epoch 1169, latest loss 0.7153341770172119\n",
      "Finished epoch 1170, latest loss 0.7153300642967224\n",
      "Finished epoch 1171, latest loss 0.7153341770172119\n",
      "Finished epoch 1172, latest loss 0.7154161930084229\n",
      "Finished epoch 1173, latest loss 0.7153341770172119\n",
      "Finished epoch 1174, latest loss 0.7153319716453552\n",
      "Finished epoch 1175, latest loss 0.7154666781425476\n",
      "Finished epoch 1176, latest loss 0.7173566222190857\n",
      "Finished epoch 1177, latest loss 0.7154161930084229\n",
      "Finished epoch 1178, latest loss 0.7173575758934021\n",
      "Finished epoch 1179, latest loss 0.7181161046028137\n",
      "Finished epoch 1180, latest loss 0.7144302129745483\n",
      "Finished epoch 1181, latest loss 0.7153342366218567\n",
      "Finished epoch 1182, latest loss 0.7164276838302612\n",
      "Finished epoch 1183, latest loss 0.7154159545898438\n",
      "Finished epoch 1184, latest loss 0.7154162526130676\n",
      "Finished epoch 1185, latest loss 0.7144045829772949\n",
      "Finished epoch 1186, latest loss 0.7154161930084229\n",
      "Finished epoch 1187, latest loss 0.715415894985199\n",
      "Finished epoch 1188, latest loss 0.7144045829772949\n",
      "Finished epoch 1189, latest loss 0.7144045829772949\n",
      "Finished epoch 1190, latest loss 0.7144141793251038\n",
      "Finished epoch 1191, latest loss 0.7158932685852051\n",
      "Finished epoch 1192, latest loss 0.7153341770172119\n",
      "Finished epoch 1193, latest loss 0.7144047021865845\n",
      "Finished epoch 1194, latest loss 0.7150881886482239\n",
      "Finished epoch 1195, latest loss 0.7144045829772949\n",
      "Finished epoch 1196, latest loss 0.7144045829772949\n",
      "Finished epoch 1197, latest loss 0.7144045829772949\n",
      "Finished epoch 1198, latest loss 0.7150037884712219\n",
      "Finished epoch 1199, latest loss 0.7144199013710022\n",
      "Finished epoch 1200, latest loss 0.7144047021865845\n",
      "Finished epoch 1201, latest loss 0.7164279818534851\n",
      "Finished epoch 1202, latest loss 0.7153540253639221\n",
      "Finished epoch 1203, latest loss 0.7144045829772949\n",
      "Finished epoch 1204, latest loss 0.7163457870483398\n",
      "Finished epoch 1205, latest loss 0.7144045829772949\n",
      "Finished epoch 1206, latest loss 0.7144045829772949\n",
      "Finished epoch 1207, latest loss 0.7144045829772949\n",
      "Finished epoch 1208, latest loss 0.7144045829772949\n",
      "Finished epoch 1209, latest loss 0.7172483205795288\n",
      "Finished epoch 1210, latest loss 0.7154161930084229\n",
      "Finished epoch 1211, latest loss 0.7144045829772949\n",
      "Finished epoch 1212, latest loss 0.7154161930084229\n",
      "Finished epoch 1213, latest loss 0.7145893573760986\n",
      "Finished epoch 1214, latest loss 0.7154161930084229\n",
      "Finished epoch 1215, latest loss 0.7169880270957947\n",
      "Finished epoch 1216, latest loss 0.715416669845581\n",
      "Finished epoch 1217, latest loss 0.7154161930084229\n",
      "Finished epoch 1218, latest loss 0.7163740992546082\n",
      "Finished epoch 1219, latest loss 0.7154161930084229\n",
      "Finished epoch 1220, latest loss 0.7144045829772949\n",
      "Finished epoch 1221, latest loss 0.7144045829772949\n",
      "Finished epoch 1222, latest loss 0.7144045829772949\n",
      "Finished epoch 1223, latest loss 0.7144046425819397\n",
      "Finished epoch 1224, latest loss 0.7144048810005188\n",
      "Finished epoch 1225, latest loss 0.7144423723220825\n",
      "Finished epoch 1226, latest loss 0.71659916639328\n",
      "Finished epoch 1227, latest loss 0.7153612375259399\n",
      "Finished epoch 1228, latest loss 0.7164152264595032\n",
      "Finished epoch 1229, latest loss 0.7144045829772949\n",
      "Finished epoch 1230, latest loss 0.7164714932441711\n",
      "Finished epoch 1231, latest loss 0.7152491807937622\n",
      "Finished epoch 1232, latest loss 0.7144080400466919\n",
      "Finished epoch 1233, latest loss 0.7154161930084229\n",
      "Finished epoch 1234, latest loss 0.7164278626441956\n",
      "Finished epoch 1235, latest loss 0.7144055366516113\n",
      "Finished epoch 1236, latest loss 0.7174296379089355\n",
      "Finished epoch 1237, latest loss 0.7154163122177124\n",
      "Finished epoch 1238, latest loss 0.7153333425521851\n",
      "Finished epoch 1239, latest loss 0.7153343558311462\n",
      "Finished epoch 1240, latest loss 0.7144045829772949\n",
      "Finished epoch 1241, latest loss 0.7160422205924988\n",
      "Finished epoch 1242, latest loss 0.714406430721283\n",
      "Finished epoch 1243, latest loss 0.7153341770172119\n",
      "Finished epoch 1244, latest loss 0.7134750485420227\n",
      "Finished epoch 1245, latest loss 0.7164287567138672\n",
      "Finished epoch 1246, latest loss 0.7168107032775879\n",
      "Finished epoch 1247, latest loss 0.716426432132721\n",
      "Finished epoch 1248, latest loss 0.7162795662879944\n",
      "Finished epoch 1249, latest loss 0.7147179841995239\n",
      "Finished epoch 1250, latest loss 0.7144045829772949\n",
      "Finished epoch 1251, latest loss 0.7144061326980591\n",
      "Finished epoch 1252, latest loss 0.7154161930084229\n",
      "Finished epoch 1253, latest loss 0.7150406241416931\n",
      "Finished epoch 1254, latest loss 0.714404284954071\n",
      "Finished epoch 1255, latest loss 0.7150734066963196\n",
      "Finished epoch 1256, latest loss 0.7145684361457825\n",
      "Finished epoch 1257, latest loss 0.7144865989685059\n",
      "Finished epoch 1258, latest loss 0.7154041528701782\n",
      "Finished epoch 1259, latest loss 0.7144864797592163\n",
      "Finished epoch 1260, latest loss 0.7134750485420227\n",
      "Finished epoch 1261, latest loss 0.7144866585731506\n",
      "Finished epoch 1262, latest loss 0.7134764790534973\n",
      "Finished epoch 1263, latest loss 0.7151631116867065\n",
      "Finished epoch 1264, latest loss 0.7146393060684204\n",
      "Finished epoch 1265, latest loss 0.7134750485420227\n",
      "Finished epoch 1266, latest loss 0.7140755653381348\n",
      "Finished epoch 1267, latest loss 0.7134750485420227\n",
      "Finished epoch 1268, latest loss 0.7138689160346985\n",
      "Finished epoch 1269, latest loss 0.7134978771209717\n",
      "Finished epoch 1270, latest loss 0.7145182490348816\n",
      "Finished epoch 1271, latest loss 0.7134751677513123\n",
      "Finished epoch 1272, latest loss 0.7134750485420227\n",
      "Finished epoch 1273, latest loss 0.7134805917739868\n",
      "Finished epoch 1274, latest loss 0.7144044637680054\n",
      "Finished epoch 1275, latest loss 0.7144866585731506\n",
      "Finished epoch 1276, latest loss 0.7155070900917053\n",
      "Finished epoch 1277, latest loss 0.7144871950149536\n",
      "Finished epoch 1278, latest loss 0.7134750485420227\n",
      "Finished epoch 1279, latest loss 0.7134751081466675\n",
      "Finished epoch 1280, latest loss 0.7134750485420227\n",
      "Finished epoch 1281, latest loss 0.7134750485420227\n",
      "Finished epoch 1282, latest loss 0.7153356075286865\n",
      "Finished epoch 1283, latest loss 0.7154982089996338\n",
      "Finished epoch 1284, latest loss 0.7153330445289612\n",
      "Finished epoch 1285, latest loss 0.7134751677513123\n",
      "Finished epoch 1286, latest loss 0.7154982686042786\n",
      "Finished epoch 1287, latest loss 0.71440190076828\n",
      "Finished epoch 1288, latest loss 0.7144866585731506\n",
      "Finished epoch 1289, latest loss 0.7144901156425476\n",
      "Finished epoch 1290, latest loss 0.7154173254966736\n",
      "Finished epoch 1291, latest loss 0.7153598666191101\n",
      "Finished epoch 1292, latest loss 0.7144046425819397\n",
      "Finished epoch 1293, latest loss 0.7154982686042786\n",
      "Finished epoch 1294, latest loss 0.7144867777824402\n",
      "Finished epoch 1295, latest loss 0.7171668410301208\n",
      "Finished epoch 1296, latest loss 0.7144867181777954\n",
      "Finished epoch 1297, latest loss 0.7144896984100342\n",
      "Finished epoch 1298, latest loss 0.7165133357048035\n",
      "Finished epoch 1299, latest loss 0.7145265340805054\n",
      "Finished epoch 1300, latest loss 0.7144862413406372\n",
      "Finished epoch 1301, latest loss 0.7144866585731506\n",
      "Finished epoch 1302, latest loss 0.7134750485420227\n",
      "Finished epoch 1303, latest loss 0.7145711779594421\n",
      "Finished epoch 1304, latest loss 0.7135059833526611\n",
      "Finished epoch 1305, latest loss 0.7164278626441956\n",
      "Finished epoch 1306, latest loss 0.7144206166267395\n",
      "Finished epoch 1307, latest loss 0.715404212474823\n",
      "Finished epoch 1308, latest loss 0.7137874960899353\n",
      "Finished epoch 1309, latest loss 0.7154536843299866\n",
      "Finished epoch 1310, latest loss 0.7139737010002136\n",
      "Finished epoch 1311, latest loss 0.715047299861908\n",
      "Finished epoch 1312, latest loss 0.7134750485420227\n",
      "Finished epoch 1313, latest loss 0.7134750485420227\n",
      "Finished epoch 1314, latest loss 0.7134750485420227\n",
      "Finished epoch 1315, latest loss 0.7134750485420227\n",
      "Finished epoch 1316, latest loss 0.7144866585731506\n",
      "Finished epoch 1317, latest loss 0.7134750485420227\n",
      "Finished epoch 1318, latest loss 0.7134750485420227\n",
      "Finished epoch 1319, latest loss 0.7134750485420227\n",
      "Finished epoch 1320, latest loss 0.713750958442688\n",
      "Finished epoch 1321, latest loss 0.7144866585731506\n",
      "Finished epoch 1322, latest loss 0.7134750485420227\n",
      "Finished epoch 1323, latest loss 0.7144866585731506\n",
      "Finished epoch 1324, latest loss 0.713665246963501\n",
      "Finished epoch 1325, latest loss 0.7140630483627319\n",
      "Finished epoch 1326, latest loss 0.7134750485420227\n",
      "Finished epoch 1327, latest loss 0.7134750485420227\n",
      "Finished epoch 1328, latest loss 0.7134750485420227\n",
      "Finished epoch 1329, latest loss 0.7134750485420227\n",
      "Finished epoch 1330, latest loss 0.7144045829772949\n",
      "Finished epoch 1331, latest loss 0.7134750485420227\n",
      "Finished epoch 1332, latest loss 0.7144045829772949\n",
      "Finished epoch 1333, latest loss 0.7134805917739868\n",
      "Finished epoch 1334, latest loss 0.7134750485420227\n",
      "Finished epoch 1335, latest loss 0.7154746651649475\n",
      "Finished epoch 1336, latest loss 0.7134750485420227\n",
      "Finished epoch 1337, latest loss 0.7134750485420227\n",
      "Finished epoch 1338, latest loss 0.7134758830070496\n",
      "Finished epoch 1339, latest loss 0.7144866585731506\n",
      "Finished epoch 1340, latest loss 0.7144891023635864\n",
      "Finished epoch 1341, latest loss 0.7134751081466675\n",
      "Finished epoch 1342, latest loss 0.7134750485420227\n",
      "Finished epoch 1343, latest loss 0.7134750485420227\n",
      "Finished epoch 1344, latest loss 0.7134750485420227\n",
      "Finished epoch 1345, latest loss 0.7134750485420227\n",
      "Finished epoch 1346, latest loss 0.7134750485420227\n",
      "Finished epoch 1347, latest loss 0.7134750485420227\n",
      "Finished epoch 1348, latest loss 0.7134750485420227\n",
      "Finished epoch 1349, latest loss 0.7134750485420227\n",
      "Finished epoch 1350, latest loss 0.7134760022163391\n",
      "Finished epoch 1351, latest loss 0.7134750485420227\n",
      "Finished epoch 1352, latest loss 0.7153241038322449\n",
      "Finished epoch 1353, latest loss 0.7134750485420227\n",
      "Finished epoch 1354, latest loss 0.7134750485420227\n",
      "Finished epoch 1355, latest loss 0.7147011160850525\n",
      "Finished epoch 1356, latest loss 0.7144045829772949\n",
      "Finished epoch 1357, latest loss 0.7153341770172119\n",
      "Finished epoch 1358, latest loss 0.7134752869606018\n",
      "Finished epoch 1359, latest loss 0.7154161930084229\n",
      "Finished epoch 1360, latest loss 0.7154161930084229\n",
      "Finished epoch 1361, latest loss 0.7144045829772949\n",
      "Finished epoch 1362, latest loss 0.715415894985199\n",
      "Finished epoch 1363, latest loss 0.7154167294502258\n",
      "Finished epoch 1364, latest loss 0.7134787440299988\n",
      "Finished epoch 1365, latest loss 0.7142683863639832\n",
      "Finished epoch 1366, latest loss 0.716027021408081\n",
      "Finished epoch 1367, latest loss 0.7134750485420227\n",
      "Finished epoch 1368, latest loss 0.7144045829772949\n",
      "Finished epoch 1369, latest loss 0.7135080695152283\n",
      "Finished epoch 1370, latest loss 0.7134750485420227\n",
      "Finished epoch 1371, latest loss 0.7134759426116943\n",
      "Finished epoch 1372, latest loss 0.7134750485420227\n",
      "Finished epoch 1373, latest loss 0.7134948372840881\n",
      "Finished epoch 1374, latest loss 0.7134750485420227\n",
      "Finished epoch 1375, latest loss 0.7143677473068237\n",
      "Finished epoch 1376, latest loss 0.7156850099563599\n",
      "Finished epoch 1377, latest loss 0.7134857773780823\n",
      "Finished epoch 1378, latest loss 0.7134750485420227\n",
      "Finished epoch 1379, latest loss 0.7134750485420227\n",
      "Finished epoch 1380, latest loss 0.7134750485420227\n",
      "Finished epoch 1381, latest loss 0.7134750485420227\n",
      "Finished epoch 1382, latest loss 0.7134750485420227\n",
      "Finished epoch 1383, latest loss 0.7134645581245422\n",
      "Finished epoch 1384, latest loss 0.7134750485420227\n",
      "Finished epoch 1385, latest loss 0.7134748101234436\n",
      "Finished epoch 1386, latest loss 0.7134750485420227\n",
      "Finished epoch 1387, latest loss 0.7144045829772949\n",
      "Finished epoch 1388, latest loss 0.7144045829772949\n",
      "Finished epoch 1389, latest loss 0.7138420343399048\n",
      "Finished epoch 1390, latest loss 0.7125454545021057\n",
      "Finished epoch 1391, latest loss 0.7125454545021057\n",
      "Finished epoch 1392, latest loss 0.7134750485420227\n",
      "Finished epoch 1393, latest loss 0.7125454545021057\n",
      "Finished epoch 1394, latest loss 0.7154935002326965\n",
      "Finished epoch 1395, latest loss 0.7144866585731506\n",
      "Finished epoch 1396, latest loss 0.7144864797592163\n",
      "Finished epoch 1397, latest loss 0.7134750485420227\n",
      "Finished epoch 1398, latest loss 0.7144865989685059\n",
      "Finished epoch 1399, latest loss 0.7134750485420227\n",
      "Finished epoch 1400, latest loss 0.7140504717826843\n",
      "Finished epoch 1401, latest loss 0.7134751677513123\n",
      "Finished epoch 1402, latest loss 0.7134750485420227\n",
      "Finished epoch 1403, latest loss 0.7144816517829895\n",
      "Finished epoch 1404, latest loss 0.7151473164558411\n",
      "Finished epoch 1405, latest loss 0.7142144441604614\n",
      "Finished epoch 1406, latest loss 0.7134750485420227\n",
      "Finished epoch 1407, latest loss 0.7134750485420227\n",
      "Finished epoch 1408, latest loss 0.7134750485420227\n",
      "Finished epoch 1409, latest loss 0.7134751081466675\n",
      "Finished epoch 1410, latest loss 0.7134750485420227\n",
      "Finished epoch 1411, latest loss 0.7134750485420227\n",
      "Finished epoch 1412, latest loss 0.7144866585731506\n",
      "Finished epoch 1413, latest loss 0.7136044502258301\n",
      "Finished epoch 1414, latest loss 0.7134750485420227\n",
      "Finished epoch 1415, latest loss 0.7134750485420227\n",
      "Finished epoch 1416, latest loss 0.7143818140029907\n",
      "Finished epoch 1417, latest loss 0.7143421769142151\n",
      "Finished epoch 1418, latest loss 0.7134750485420227\n",
      "Finished epoch 1419, latest loss 0.713476300239563\n",
      "Finished epoch 1420, latest loss 0.7144866585731506\n",
      "Finished epoch 1421, latest loss 0.7135437726974487\n",
      "Finished epoch 1422, latest loss 0.7144865989685059\n",
      "Finished epoch 1423, latest loss 0.7144044637680054\n",
      "Finished epoch 1424, latest loss 0.7144045829772949\n",
      "Finished epoch 1425, latest loss 0.7134752869606018\n",
      "Finished epoch 1426, latest loss 0.7134750485420227\n",
      "Finished epoch 1427, latest loss 0.7154004573822021\n",
      "Finished epoch 1428, latest loss 0.7144734263420105\n",
      "Finished epoch 1429, latest loss 0.7134750485420227\n",
      "Finished epoch 1430, latest loss 0.7134750485420227\n",
      "Finished epoch 1431, latest loss 0.7134750485420227\n",
      "Finished epoch 1432, latest loss 0.7144866585731506\n",
      "Finished epoch 1433, latest loss 0.7145467400550842\n",
      "Finished epoch 1434, latest loss 0.7144573330879211\n",
      "Finished epoch 1435, latest loss 0.7134799957275391\n",
      "Finished epoch 1436, latest loss 0.7127464413642883\n",
      "Finished epoch 1437, latest loss 0.714263379573822\n",
      "Finished epoch 1438, latest loss 0.7144866585731506\n",
      "Finished epoch 1439, latest loss 0.7134750485420227\n",
      "Finished epoch 1440, latest loss 0.7134753465652466\n",
      "Finished epoch 1441, latest loss 0.7154982089996338\n",
      "Finished epoch 1442, latest loss 0.7137184143066406\n",
      "Finished epoch 1443, latest loss 0.7144840359687805\n",
      "Finished epoch 1444, latest loss 0.7158591747283936\n",
      "Finished epoch 1445, latest loss 0.7158938646316528\n",
      "Finished epoch 1446, latest loss 0.7144045829772949\n",
      "Finished epoch 1447, latest loss 0.7144865989685059\n",
      "Finished epoch 1448, latest loss 0.7134750485420227\n",
      "Finished epoch 1449, latest loss 0.713475227355957\n",
      "Finished epoch 1450, latest loss 0.7134750485420227\n",
      "Finished epoch 1451, latest loss 0.7134750485420227\n",
      "Finished epoch 1452, latest loss 0.7144866585731506\n",
      "Finished epoch 1453, latest loss 0.7143577933311462\n",
      "Finished epoch 1454, latest loss 0.7134750485420227\n",
      "Finished epoch 1455, latest loss 0.7154982089996338\n",
      "Finished epoch 1456, latest loss 0.7143009305000305\n",
      "Finished epoch 1457, latest loss 0.7125454545021057\n",
      "Finished epoch 1458, latest loss 0.7126165628433228\n",
      "Finished epoch 1459, latest loss 0.7125454545021057\n",
      "Finished epoch 1460, latest loss 0.7125458717346191\n",
      "Finished epoch 1461, latest loss 0.7128772735595703\n",
      "Finished epoch 1462, latest loss 0.7139196395874023\n",
      "Finished epoch 1463, latest loss 0.7125454545021057\n",
      "Finished epoch 1464, latest loss 0.7125454545021057\n",
      "Finished epoch 1465, latest loss 0.7135588526725769\n",
      "Finished epoch 1466, latest loss 0.7125454545021057\n",
      "Finished epoch 1467, latest loss 0.7125454545021057\n",
      "Finished epoch 1468, latest loss 0.7126908302307129\n",
      "Finished epoch 1469, latest loss 0.714486300945282\n",
      "Finished epoch 1470, latest loss 0.7144866585731506\n",
      "Finished epoch 1471, latest loss 0.7138450741767883\n",
      "Finished epoch 1472, latest loss 0.7125455141067505\n",
      "Finished epoch 1473, latest loss 0.714596152305603\n",
      "Finished epoch 1474, latest loss 0.7125837802886963\n",
      "Finished epoch 1475, latest loss 0.7135567665100098\n",
      "Finished epoch 1476, latest loss 0.7125455141067505\n",
      "Finished epoch 1477, latest loss 0.7125455141067505\n",
      "Finished epoch 1478, latest loss 0.7125454545021057\n",
      "Finished epoch 1479, latest loss 0.7145686745643616\n",
      "Finished epoch 1480, latest loss 0.7125454545021057\n",
      "Finished epoch 1481, latest loss 0.7135524749755859\n",
      "Finished epoch 1482, latest loss 0.7135846614837646\n",
      "Finished epoch 1483, latest loss 0.7134792804718018\n",
      "Finished epoch 1484, latest loss 0.7134751081466675\n",
      "Finished epoch 1485, latest loss 0.7126471996307373\n",
      "Finished epoch 1486, latest loss 0.7135420441627502\n",
      "Finished epoch 1487, latest loss 0.7125454545021057\n",
      "Finished epoch 1488, latest loss 0.7125454545021057\n",
      "Finished epoch 1489, latest loss 0.7125454545021057\n",
      "Finished epoch 1490, latest loss 0.7125454545021057\n",
      "Finished epoch 1491, latest loss 0.7125457525253296\n",
      "Finished epoch 1492, latest loss 0.7125454545021057\n",
      "Finished epoch 1493, latest loss 0.7135568261146545\n",
      "Finished epoch 1494, latest loss 0.7131174206733704\n",
      "Finished epoch 1495, latest loss 0.7135917544364929\n",
      "Finished epoch 1496, latest loss 0.7125454545021057\n",
      "Finished epoch 1497, latest loss 0.7125454545021057\n",
      "Finished epoch 1498, latest loss 0.7125454545021057\n",
      "Finished epoch 1499, latest loss 0.7145686745643616\n",
      "Finished epoch 1500, latest loss 0.7155805826187134\n",
      "Finished epoch 1501, latest loss 0.7144805192947388\n",
      "Finished epoch 1502, latest loss 0.7145686745643616\n",
      "Finished epoch 1503, latest loss 0.7145686745643616\n",
      "Finished epoch 1504, latest loss 0.7125455141067505\n",
      "Finished epoch 1505, latest loss 0.7125454545021057\n",
      "Finished epoch 1506, latest loss 0.7145686745643616\n",
      "Finished epoch 1507, latest loss 0.7135570645332336\n",
      "Finished epoch 1508, latest loss 0.7135570645332336\n",
      "Finished epoch 1509, latest loss 0.7135582566261292\n",
      "Finished epoch 1510, latest loss 0.7134749889373779\n",
      "Finished epoch 1511, latest loss 0.713557243347168\n",
      "Finished epoch 1512, latest loss 0.7135570645332336\n",
      "Finished epoch 1513, latest loss 0.7144866585731506\n",
      "Finished epoch 1514, latest loss 0.7134750485420227\n",
      "Finished epoch 1515, latest loss 0.7155044078826904\n",
      "Finished epoch 1516, latest loss 0.7134750485420227\n",
      "Finished epoch 1517, latest loss 0.7154289484024048\n",
      "Finished epoch 1518, latest loss 0.7125454545021057\n",
      "Finished epoch 1519, latest loss 0.7154816389083862\n",
      "Finished epoch 1520, latest loss 0.7134751677513123\n",
      "Finished epoch 1521, latest loss 0.7154161930084229\n",
      "Finished epoch 1522, latest loss 0.7154982089996338\n",
      "Finished epoch 1523, latest loss 0.7144865989685059\n",
      "Finished epoch 1524, latest loss 0.7135862112045288\n",
      "Finished epoch 1525, latest loss 0.7135640978813171\n",
      "Finished epoch 1526, latest loss 0.7144866585731506\n",
      "Finished epoch 1527, latest loss 0.7144866585731506\n",
      "Finished epoch 1528, latest loss 0.7134750485420227\n",
      "Finished epoch 1529, latest loss 0.7154161930084229\n",
      "Finished epoch 1530, latest loss 0.7144936323165894\n",
      "Finished epoch 1531, latest loss 0.7146132588386536\n",
      "Finished epoch 1532, latest loss 0.7134750485420227\n",
      "Finished epoch 1533, latest loss 0.7134750485420227\n",
      "Finished epoch 1534, latest loss 0.7136557698249817\n",
      "Finished epoch 1535, latest loss 0.7125454545021057\n",
      "Finished epoch 1536, latest loss 0.7136151790618896\n",
      "Finished epoch 1537, latest loss 0.712547242641449\n",
      "Finished epoch 1538, latest loss 0.7134749889373779\n",
      "Finished epoch 1539, latest loss 0.7144864797592163\n",
      "Finished epoch 1540, latest loss 0.7134791612625122\n",
      "Finished epoch 1541, latest loss 0.7144865989685059\n",
      "Finished epoch 1542, latest loss 0.7125455141067505\n",
      "Finished epoch 1543, latest loss 0.7154982686042786\n",
      "Finished epoch 1544, latest loss 0.7153290510177612\n",
      "Finished epoch 1545, latest loss 0.7125454545021057\n",
      "Finished epoch 1546, latest loss 0.713603138923645\n",
      "Finished epoch 1547, latest loss 0.7125659584999084\n",
      "Finished epoch 1548, latest loss 0.7134750485420227\n",
      "Finished epoch 1549, latest loss 0.7145698070526123\n",
      "Finished epoch 1550, latest loss 0.7135570645332336\n",
      "Finished epoch 1551, latest loss 0.7125454545021057\n",
      "Finished epoch 1552, latest loss 0.7135570645332336\n",
      "Finished epoch 1553, latest loss 0.7152832746505737\n",
      "Finished epoch 1554, latest loss 0.7135570645332336\n",
      "Finished epoch 1555, latest loss 0.7154982089996338\n",
      "Finished epoch 1556, latest loss 0.7125454545021057\n",
      "Finished epoch 1557, latest loss 0.7125580310821533\n",
      "Finished epoch 1558, latest loss 0.7145785689353943\n",
      "Finished epoch 1559, latest loss 0.7125219702720642\n",
      "Finished epoch 1560, latest loss 0.7134649157524109\n",
      "Finished epoch 1561, latest loss 0.7134730219841003\n",
      "Finished epoch 1562, latest loss 0.7133252024650574\n",
      "Finished epoch 1563, latest loss 0.7125454545021057\n",
      "Finished epoch 1564, latest loss 0.7125688791275024\n",
      "Finished epoch 1565, latest loss 0.7146101593971252\n",
      "Finished epoch 1566, latest loss 0.7144865989685059\n",
      "Finished epoch 1567, latest loss 0.7134906053543091\n",
      "Finished epoch 1568, latest loss 0.7143890261650085\n",
      "Finished epoch 1569, latest loss 0.7164815664291382\n",
      "Finished epoch 1570, latest loss 0.7134750485420227\n",
      "Finished epoch 1571, latest loss 0.7144865989685059\n",
      "Finished epoch 1572, latest loss 0.7143023014068604\n",
      "Finished epoch 1573, latest loss 0.7144045829772949\n",
      "Finished epoch 1574, latest loss 0.7134750485420227\n",
      "Finished epoch 1575, latest loss 0.7144865989685059\n",
      "Finished epoch 1576, latest loss 0.7144865989685059\n",
      "Finished epoch 1577, latest loss 0.7145044803619385\n",
      "Finished epoch 1578, latest loss 0.7144855856895447\n",
      "Finished epoch 1579, latest loss 0.7144865989685059\n",
      "Finished epoch 1580, latest loss 0.7134750485420227\n",
      "Finished epoch 1581, latest loss 0.7134751677513123\n",
      "Finished epoch 1582, latest loss 0.7134750485420227\n",
      "Finished epoch 1583, latest loss 0.7134750485420227\n",
      "Finished epoch 1584, latest loss 0.7134750485420227\n",
      "Finished epoch 1585, latest loss 0.7134759426116943\n",
      "Finished epoch 1586, latest loss 0.7174355983734131\n",
      "Finished epoch 1587, latest loss 0.7134750485420227\n",
      "Finished epoch 1588, latest loss 0.7134750485420227\n",
      "Finished epoch 1589, latest loss 0.7144866585731506\n",
      "Finished epoch 1590, latest loss 0.7165198922157288\n",
      "Finished epoch 1591, latest loss 0.7134750485420227\n",
      "Finished epoch 1592, latest loss 0.7154175639152527\n",
      "Finished epoch 1593, latest loss 0.7144086360931396\n",
      "Finished epoch 1594, latest loss 0.7134751677513123\n",
      "Finished epoch 1595, latest loss 0.7145568132400513\n",
      "Finished epoch 1596, latest loss 0.71347576379776\n",
      "Finished epoch 1597, latest loss 0.7134750485420227\n",
      "Finished epoch 1598, latest loss 0.7144866585731506\n",
      "Finished epoch 1599, latest loss 0.7153751850128174\n",
      "Finished epoch 1600, latest loss 0.7144870162010193\n",
      "Finished epoch 1601, latest loss 0.7154191732406616\n",
      "Finished epoch 1602, latest loss 0.715968132019043\n",
      "Finished epoch 1603, latest loss 0.7144865989685059\n",
      "Finished epoch 1604, latest loss 0.7134798169136047\n",
      "Finished epoch 1605, latest loss 0.7147136926651001\n",
      "Finished epoch 1606, latest loss 0.7125454545021057\n",
      "Finished epoch 1607, latest loss 0.7144784331321716\n",
      "Finished epoch 1608, latest loss 0.7144866585731506\n",
      "Finished epoch 1609, latest loss 0.7144865989685059\n",
      "Finished epoch 1610, latest loss 0.7144864797592163\n",
      "Finished epoch 1611, latest loss 0.7174386978149414\n",
      "Finished epoch 1612, latest loss 0.7144922614097595\n",
      "Finished epoch 1613, latest loss 0.7134750485420227\n",
      "Finished epoch 1614, latest loss 0.7144903540611267\n",
      "Finished epoch 1615, latest loss 0.7134799957275391\n",
      "Finished epoch 1616, latest loss 0.7154991030693054\n",
      "Finished epoch 1617, latest loss 0.7154982089996338\n",
      "Finished epoch 1618, latest loss 0.7154925465583801\n",
      "Finished epoch 1619, latest loss 0.7144865989685059\n",
      "Finished epoch 1620, latest loss 0.7164382338523865\n",
      "Finished epoch 1621, latest loss 0.7134901285171509\n",
      "Finished epoch 1622, latest loss 0.7144855260848999\n",
      "Finished epoch 1623, latest loss 0.7134750485420227\n",
      "Finished epoch 1624, latest loss 0.7134764194488525\n",
      "Finished epoch 1625, latest loss 0.7134750485420227\n",
      "Finished epoch 1626, latest loss 0.7144166827201843\n",
      "Finished epoch 1627, latest loss 0.7134750485420227\n",
      "Finished epoch 1628, latest loss 0.7134793996810913\n",
      "Finished epoch 1629, latest loss 0.7125454545021057\n",
      "Finished epoch 1630, latest loss 0.7134812474250793\n",
      "Finished epoch 1631, latest loss 0.7144046425819397\n",
      "Finished epoch 1632, latest loss 0.7144865989685059\n",
      "Finished epoch 1633, latest loss 0.7135573625564575\n",
      "Finished epoch 1634, latest loss 0.7144955396652222\n",
      "Finished epoch 1635, latest loss 0.7145532965660095\n",
      "Finished epoch 1636, latest loss 0.7143309712409973\n",
      "Finished epoch 1637, latest loss 0.7125454545021057\n",
      "Finished epoch 1638, latest loss 0.7125454545021057\n",
      "Finished epoch 1639, latest loss 0.7125454545021057\n",
      "Finished epoch 1640, latest loss 0.7125454545021057\n",
      "Finished epoch 1641, latest loss 0.7145791053771973\n",
      "Finished epoch 1642, latest loss 0.7148416638374329\n",
      "Finished epoch 1643, latest loss 0.7125454545021057\n",
      "Finished epoch 1644, latest loss 0.7133767008781433\n",
      "Finished epoch 1645, latest loss 0.7125454545021057\n",
      "Finished epoch 1646, latest loss 0.7125454545021057\n",
      "Finished epoch 1647, latest loss 0.7125454545021057\n",
      "Finished epoch 1648, latest loss 0.7134553790092468\n",
      "Finished epoch 1649, latest loss 0.7155801653862\n",
      "Finished epoch 1650, latest loss 0.7151367664337158\n",
      "Finished epoch 1651, latest loss 0.7125454545021057\n",
      "Finished epoch 1652, latest loss 0.7125454545021057\n",
      "Finished epoch 1653, latest loss 0.7125454545021057\n",
      "Finished epoch 1654, latest loss 0.7134750485420227\n",
      "Finished epoch 1655, latest loss 0.7125454545021057\n",
      "Finished epoch 1656, latest loss 0.7125454545021057\n",
      "Finished epoch 1657, latest loss 0.7143819332122803\n",
      "Finished epoch 1658, latest loss 0.7145875096321106\n",
      "Finished epoch 1659, latest loss 0.7125454545021057\n",
      "Finished epoch 1660, latest loss 0.7135570645332336\n",
      "Finished epoch 1661, latest loss 0.7127021551132202\n",
      "Finished epoch 1662, latest loss 0.7125454545021057\n",
      "Finished epoch 1663, latest loss 0.7125454545021057\n",
      "Finished epoch 1664, latest loss 0.7135376334190369\n",
      "Finished epoch 1665, latest loss 0.7142661213874817\n",
      "Finished epoch 1666, latest loss 0.7147358655929565\n",
      "Finished epoch 1667, latest loss 0.7125454545021057\n",
      "Finished epoch 1668, latest loss 0.7144865989685059\n",
      "Finished epoch 1669, latest loss 0.7143388390541077\n",
      "Finished epoch 1670, latest loss 0.7125454545021057\n",
      "Finished epoch 1671, latest loss 0.7125454545021057\n",
      "Finished epoch 1672, latest loss 0.7125454545021057\n",
      "Finished epoch 1673, latest loss 0.7125454545021057\n",
      "Finished epoch 1674, latest loss 0.7135559320449829\n",
      "Finished epoch 1675, latest loss 0.71254563331604\n",
      "Finished epoch 1676, latest loss 0.7125454545021057\n",
      "Finished epoch 1677, latest loss 0.7125454545021057\n",
      "Finished epoch 1678, latest loss 0.7125767469406128\n",
      "Finished epoch 1679, latest loss 0.7135570645332336\n",
      "Finished epoch 1680, latest loss 0.7135570645332336\n",
      "Finished epoch 1681, latest loss 0.7125454545021057\n",
      "Finished epoch 1682, latest loss 0.7125454545021057\n",
      "Finished epoch 1683, latest loss 0.71254563331604\n",
      "Finished epoch 1684, latest loss 0.7139683365821838\n",
      "Finished epoch 1685, latest loss 0.7134751081466675\n",
      "Finished epoch 1686, latest loss 0.7142496109008789\n",
      "Finished epoch 1687, latest loss 0.7134782671928406\n",
      "Finished epoch 1688, latest loss 0.7125454545021057\n",
      "Finished epoch 1689, latest loss 0.7135570645332336\n",
      "Finished epoch 1690, latest loss 0.7145851850509644\n",
      "Finished epoch 1691, latest loss 0.7134729623794556\n",
      "Finished epoch 1692, latest loss 0.7125454545021057\n",
      "Finished epoch 1693, latest loss 0.7125454545021057\n",
      "Finished epoch 1694, latest loss 0.7125484347343445\n",
      "Finished epoch 1695, latest loss 0.7125454545021057\n",
      "Finished epoch 1696, latest loss 0.7125454545021057\n",
      "Finished epoch 1697, latest loss 0.7135568261146545\n",
      "Finished epoch 1698, latest loss 0.7125454545021057\n",
      "Finished epoch 1699, latest loss 0.7125454545021057\n",
      "Finished epoch 1700, latest loss 0.7125455141067505\n",
      "Finished epoch 1701, latest loss 0.713468074798584\n",
      "Finished epoch 1702, latest loss 0.7125454545021057\n",
      "Finished epoch 1703, latest loss 0.7125454545021057\n",
      "Finished epoch 1704, latest loss 0.7133819460868835\n",
      "Finished epoch 1705, latest loss 0.7125454545021057\n",
      "Finished epoch 1706, latest loss 0.7134684324264526\n",
      "Finished epoch 1707, latest loss 0.7134802937507629\n",
      "Finished epoch 1708, latest loss 0.7125454545021057\n",
      "Finished epoch 1709, latest loss 0.7125454545021057\n",
      "Finished epoch 1710, latest loss 0.7125454545021057\n",
      "Finished epoch 1711, latest loss 0.7125454545021057\n",
      "Finished epoch 1712, latest loss 0.7134684324264526\n",
      "Finished epoch 1713, latest loss 0.7126776576042175\n",
      "Finished epoch 1714, latest loss 0.7125454545021057\n",
      "Finished epoch 1715, latest loss 0.7123664021492004\n",
      "Finished epoch 1716, latest loss 0.7119342088699341\n",
      "Finished epoch 1717, latest loss 0.7125473022460938\n",
      "Finished epoch 1718, latest loss 0.7125454545021057\n",
      "Finished epoch 1719, latest loss 0.7116158604621887\n",
      "Finished epoch 1720, latest loss 0.711616039276123\n",
      "Finished epoch 1721, latest loss 0.7135570645332336\n",
      "Finished epoch 1722, latest loss 0.712263822555542\n",
      "Finished epoch 1723, latest loss 0.7125454545021057\n",
      "Finished epoch 1724, latest loss 0.7125454545021057\n",
      "Finished epoch 1725, latest loss 0.7116158604621887\n",
      "Finished epoch 1726, latest loss 0.7126114964485168\n",
      "Finished epoch 1727, latest loss 0.711620569229126\n",
      "Finished epoch 1728, latest loss 0.7125006914138794\n",
      "Finished epoch 1729, latest loss 0.7116158604621887\n",
      "Finished epoch 1730, latest loss 0.7125454545021057\n",
      "Finished epoch 1731, latest loss 0.7125454545021057\n",
      "Finished epoch 1732, latest loss 0.7125454545021057\n",
      "Finished epoch 1733, latest loss 0.7125408053398132\n",
      "Finished epoch 1734, latest loss 0.7125453352928162\n",
      "Finished epoch 1735, latest loss 0.7125454545021057\n",
      "Finished epoch 1736, latest loss 0.7125476002693176\n",
      "Finished epoch 1737, latest loss 0.7127531170845032\n",
      "Finished epoch 1738, latest loss 0.7126274704933167\n",
      "Finished epoch 1739, latest loss 0.7116158604621887\n",
      "Finished epoch 1740, latest loss 0.7126274704933167\n",
      "Finished epoch 1741, latest loss 0.7134755253791809\n",
      "Finished epoch 1742, latest loss 0.7135507464408875\n",
      "Finished epoch 1743, latest loss 0.7125454545021057\n",
      "Finished epoch 1744, latest loss 0.7125401496887207\n",
      "Finished epoch 1745, latest loss 0.7124488353729248\n",
      "Finished epoch 1746, latest loss 0.711616039276123\n",
      "Finished epoch 1747, latest loss 0.7134749889373779\n",
      "Finished epoch 1748, latest loss 0.7125454545021057\n",
      "Finished epoch 1749, latest loss 0.7126274704933167\n",
      "Finished epoch 1750, latest loss 0.7116289734840393\n",
      "Finished epoch 1751, latest loss 0.7116158604621887\n",
      "Finished epoch 1752, latest loss 0.7116158604621887\n",
      "Finished epoch 1753, latest loss 0.7126274704933167\n",
      "Finished epoch 1754, latest loss 0.7136395573616028\n",
      "Finished epoch 1755, latest loss 0.7136402130126953\n",
      "Finished epoch 1756, latest loss 0.7126293182373047\n",
      "Finished epoch 1757, latest loss 0.713567316532135\n",
      "Finished epoch 1758, latest loss 0.7126274704933167\n",
      "Finished epoch 1759, latest loss 0.7136037349700928\n",
      "Finished epoch 1760, latest loss 0.7116159796714783\n",
      "Finished epoch 1761, latest loss 0.7134749293327332\n",
      "Finished epoch 1762, latest loss 0.7145686745643616\n",
      "Finished epoch 1763, latest loss 0.7164550423622131\n",
      "Finished epoch 1764, latest loss 0.7152189612388611\n",
      "Finished epoch 1765, latest loss 0.7135570645332336\n",
      "Finished epoch 1766, latest loss 0.7125454545021057\n",
      "Finished epoch 1767, latest loss 0.7125454545021057\n",
      "Finished epoch 1768, latest loss 0.7116158604621887\n",
      "Finished epoch 1769, latest loss 0.7125454545021057\n",
      "Finished epoch 1770, latest loss 0.7125454545021057\n",
      "Finished epoch 1771, latest loss 0.7116158604621887\n",
      "Finished epoch 1772, latest loss 0.7126602530479431\n",
      "Finished epoch 1773, latest loss 0.7125454545021057\n",
      "Finished epoch 1774, latest loss 0.7130857110023499\n",
      "Finished epoch 1775, latest loss 0.7134750485420227\n",
      "Finished epoch 1776, latest loss 0.7125455141067505\n",
      "Finished epoch 1777, latest loss 0.7134751677513123\n",
      "Finished epoch 1778, latest loss 0.7134751677513123\n",
      "Finished epoch 1779, latest loss 0.7134750485420227\n",
      "Finished epoch 1780, latest loss 0.7116158604621887\n",
      "Finished epoch 1781, latest loss 0.7125457525253296\n",
      "Finished epoch 1782, latest loss 0.7125454545021057\n",
      "Finished epoch 1783, latest loss 0.7125454545021057\n",
      "Finished epoch 1784, latest loss 0.7125454545021057\n",
      "Finished epoch 1785, latest loss 0.71354079246521\n",
      "Finished epoch 1786, latest loss 0.7154982089996338\n",
      "Finished epoch 1787, latest loss 0.7161009311676025\n",
      "Finished epoch 1788, latest loss 0.7134630680084229\n",
      "Finished epoch 1789, latest loss 0.7126386165618896\n",
      "Finished epoch 1790, latest loss 0.7135570049285889\n",
      "Finished epoch 1791, latest loss 0.7135570645332336\n",
      "Finished epoch 1792, latest loss 0.7125454545021057\n",
      "Finished epoch 1793, latest loss 0.7143752574920654\n",
      "Finished epoch 1794, latest loss 0.7129340171813965\n",
      "Finished epoch 1795, latest loss 0.712541401386261\n",
      "Finished epoch 1796, latest loss 0.7134750485420227\n",
      "Finished epoch 1797, latest loss 0.7134537100791931\n",
      "Finished epoch 1798, latest loss 0.7134749889373779\n",
      "Finished epoch 1799, latest loss 0.7134749889373779\n",
      "Finished epoch 1800, latest loss 0.7126480340957642\n",
      "Finished epoch 1801, latest loss 0.7125454545021057\n",
      "Finished epoch 1802, latest loss 0.7134951949119568\n",
      "Finished epoch 1803, latest loss 0.7126274704933167\n",
      "Finished epoch 1804, latest loss 0.7126300930976868\n",
      "Finished epoch 1805, latest loss 0.7126274704933167\n",
      "Finished epoch 1806, latest loss 0.7135537266731262\n",
      "Finished epoch 1807, latest loss 0.7126280665397644\n",
      "Finished epoch 1808, latest loss 0.7143952250480652\n",
      "Finished epoch 1809, latest loss 0.7154980897903442\n",
      "Finished epoch 1810, latest loss 0.7125433087348938\n",
      "Finished epoch 1811, latest loss 0.7121020555496216\n",
      "Finished epoch 1812, latest loss 0.7126274704933167\n",
      "Finished epoch 1813, latest loss 0.7135569453239441\n",
      "Finished epoch 1814, latest loss 0.7126274704933167\n",
      "Finished epoch 1815, latest loss 0.7126274704933167\n",
      "Finished epoch 1816, latest loss 0.7126274704933167\n",
      "Finished epoch 1817, latest loss 0.7135570645332336\n",
      "Finished epoch 1818, latest loss 0.7136296629905701\n",
      "Finished epoch 1819, latest loss 0.7126274704933167\n",
      "Finished epoch 1820, latest loss 0.7135570645332336\n",
      "Finished epoch 1821, latest loss 0.7135570049285889\n",
      "Finished epoch 1822, latest loss 0.7149708271026611\n",
      "Finished epoch 1823, latest loss 0.7133026123046875\n",
      "Finished epoch 1824, latest loss 0.7128912210464478\n",
      "Finished epoch 1825, latest loss 0.7135570645332336\n",
      "Finished epoch 1826, latest loss 0.7130582332611084\n",
      "Finished epoch 1827, latest loss 0.7135570645332336\n",
      "Finished epoch 1828, latest loss 0.7135570645332336\n",
      "Finished epoch 1829, latest loss 0.711616039276123\n",
      "Finished epoch 1830, latest loss 0.7116158604621887\n",
      "Finished epoch 1831, latest loss 0.7116379141807556\n",
      "Finished epoch 1832, latest loss 0.7116158604621887\n",
      "Finished epoch 1833, latest loss 0.7126274704933167\n",
      "Finished epoch 1834, latest loss 0.7136387825012207\n",
      "Finished epoch 1835, latest loss 0.7116158604621887\n",
      "Finished epoch 1836, latest loss 0.7135570645332336\n",
      "Finished epoch 1837, latest loss 0.7126274704933167\n",
      "Finished epoch 1838, latest loss 0.7135570645332336\n",
      "Finished epoch 1839, latest loss 0.7144672870635986\n",
      "Finished epoch 1840, latest loss 0.7116163372993469\n",
      "Finished epoch 1841, latest loss 0.7126274704933167\n",
      "Finished epoch 1842, latest loss 0.7126274704933167\n",
      "Finished epoch 1843, latest loss 0.7135570645332336\n",
      "Finished epoch 1844, latest loss 0.7116158604621887\n",
      "Finished epoch 1845, latest loss 0.7126274704933167\n",
      "Finished epoch 1846, latest loss 0.7126274704933167\n",
      "Finished epoch 1847, latest loss 0.7126376032829285\n",
      "Finished epoch 1848, latest loss 0.7126274704933167\n",
      "Finished epoch 1849, latest loss 0.7125454545021057\n",
      "Finished epoch 1850, latest loss 0.7116245627403259\n",
      "Finished epoch 1851, latest loss 0.711847186088562\n",
      "Finished epoch 1852, latest loss 0.7126263976097107\n",
      "Finished epoch 1853, latest loss 0.7157723307609558\n",
      "Finished epoch 1854, latest loss 0.7116158604621887\n",
      "Finished epoch 1855, latest loss 0.7116190195083618\n",
      "Finished epoch 1856, latest loss 0.711999237537384\n",
      "Finished epoch 1857, latest loss 0.7125454545021057\n",
      "Finished epoch 1858, latest loss 0.711616039276123\n",
      "Finished epoch 1859, latest loss 0.7125454545021057\n",
      "Finished epoch 1860, latest loss 0.7116175293922424\n",
      "Finished epoch 1861, latest loss 0.7116158604621887\n",
      "Finished epoch 1862, latest loss 0.7116158604621887\n",
      "Finished epoch 1863, latest loss 0.7116158604621887\n",
      "Finished epoch 1864, latest loss 0.7116158604621887\n",
      "Finished epoch 1865, latest loss 0.7126274704933167\n",
      "Finished epoch 1866, latest loss 0.7116158604621887\n",
      "Finished epoch 1867, latest loss 0.7116158604621887\n",
      "Finished epoch 1868, latest loss 0.7125355005264282\n",
      "Finished epoch 1869, latest loss 0.7135564684867859\n",
      "Finished epoch 1870, latest loss 0.7125454545021057\n",
      "Finished epoch 1871, latest loss 0.7116158604621887\n",
      "Finished epoch 1872, latest loss 0.7125499844551086\n",
      "Finished epoch 1873, latest loss 0.7116158604621887\n",
      "Finished epoch 1874, latest loss 0.7126275897026062\n",
      "Finished epoch 1875, latest loss 0.7147889733314514\n",
      "Finished epoch 1876, latest loss 0.7125454545021057\n",
      "Finished epoch 1877, latest loss 0.7134749889373779\n",
      "Finished epoch 1878, latest loss 0.7125633358955383\n",
      "Finished epoch 1879, latest loss 0.7125459313392639\n",
      "Finished epoch 1880, latest loss 0.7144045829772949\n",
      "Finished epoch 1881, latest loss 0.7140921950340271\n",
      "Finished epoch 1882, latest loss 0.7144865989685059\n",
      "Finished epoch 1883, latest loss 0.7125537991523743\n",
      "Finished epoch 1884, latest loss 0.7125454545021057\n",
      "Finished epoch 1885, latest loss 0.7125454545021057\n",
      "Finished epoch 1886, latest loss 0.7125454545021057\n",
      "Finished epoch 1887, latest loss 0.7134749889373779\n",
      "Finished epoch 1888, latest loss 0.7125465273857117\n",
      "Finished epoch 1889, latest loss 0.7144865989685059\n",
      "Finished epoch 1890, latest loss 0.7125279903411865\n",
      "Finished epoch 1891, latest loss 0.7116327285766602\n",
      "Finished epoch 1892, latest loss 0.7116158604621887\n",
      "Finished epoch 1893, latest loss 0.7125311493873596\n",
      "Finished epoch 1894, latest loss 0.711617112159729\n",
      "Finished epoch 1895, latest loss 0.7126267552375793\n",
      "Finished epoch 1896, latest loss 0.7116187214851379\n",
      "Finished epoch 1897, latest loss 0.7143384218215942\n",
      "Finished epoch 1898, latest loss 0.7125548720359802\n",
      "Finished epoch 1899, latest loss 0.7131900787353516\n",
      "Finished epoch 1900, latest loss 0.7116158604621887\n",
      "Finished epoch 1901, latest loss 0.7116158604621887\n",
      "Finished epoch 1902, latest loss 0.7153341174125671\n",
      "Finished epoch 1903, latest loss 0.7116158604621887\n",
      "Finished epoch 1904, latest loss 0.7116158604621887\n",
      "Finished epoch 1905, latest loss 0.7116158604621887\n",
      "Finished epoch 1906, latest loss 0.7116158604621887\n",
      "Finished epoch 1907, latest loss 0.7124910354614258\n",
      "Finished epoch 1908, latest loss 0.7126193642616272\n",
      "Finished epoch 1909, latest loss 0.7125454545021057\n",
      "Finished epoch 1910, latest loss 0.7125454545021057\n",
      "Finished epoch 1911, latest loss 0.7116158604621887\n",
      "Finished epoch 1912, latest loss 0.7141809463500977\n",
      "Finished epoch 1913, latest loss 0.7125454545021057\n",
      "Finished epoch 1914, latest loss 0.7116159200668335\n",
      "Finished epoch 1915, latest loss 0.7125454545021057\n",
      "Finished epoch 1916, latest loss 0.7116158604621887\n",
      "Finished epoch 1917, latest loss 0.711979866027832\n",
      "Finished epoch 1918, latest loss 0.7126274108886719\n",
      "Finished epoch 1919, latest loss 0.7126274704933167\n",
      "Finished epoch 1920, latest loss 0.7116249203681946\n",
      "Finished epoch 1921, latest loss 0.7116158604621887\n",
      "Finished epoch 1922, latest loss 0.7116158604621887\n",
      "Finished epoch 1923, latest loss 0.7116158604621887\n",
      "Finished epoch 1924, latest loss 0.7116158604621887\n",
      "Finished epoch 1925, latest loss 0.7116158604621887\n",
      "Finished epoch 1926, latest loss 0.7116211652755737\n",
      "Finished epoch 1927, latest loss 0.7116158604621887\n",
      "Finished epoch 1928, latest loss 0.7116158604621887\n",
      "Finished epoch 1929, latest loss 0.7116158604621887\n",
      "Finished epoch 1930, latest loss 0.7126274704933167\n",
      "Finished epoch 1931, latest loss 0.7126274704933167\n",
      "Finished epoch 1932, latest loss 0.7136390805244446\n",
      "Finished epoch 1933, latest loss 0.7136390805244446\n",
      "Finished epoch 1934, latest loss 0.7126274704933167\n",
      "Finished epoch 1935, latest loss 0.7126274704933167\n",
      "Finished epoch 1936, latest loss 0.7116158604621887\n",
      "Finished epoch 1937, latest loss 0.7125410437583923\n",
      "Finished epoch 1938, latest loss 0.7126274704933167\n",
      "Finished epoch 1939, latest loss 0.7116158604621887\n",
      "Finished epoch 1940, latest loss 0.7116158604621887\n",
      "Finished epoch 1941, latest loss 0.7134708166122437\n",
      "Finished epoch 1942, latest loss 0.7126274704933167\n",
      "Finished epoch 1943, latest loss 0.7145587205886841\n",
      "Finished epoch 1944, latest loss 0.7133267521858215\n",
      "Finished epoch 1945, latest loss 0.7126274704933167\n",
      "Finished epoch 1946, latest loss 0.7136390805244446\n",
      "Finished epoch 1947, latest loss 0.7135570645332336\n",
      "Finished epoch 1948, latest loss 0.7116158604621887\n",
      "Finished epoch 1949, latest loss 0.7135569453239441\n",
      "Finished epoch 1950, latest loss 0.713388204574585\n",
      "Finished epoch 1951, latest loss 0.7124363780021667\n",
      "Finished epoch 1952, latest loss 0.7116171717643738\n",
      "Finished epoch 1953, latest loss 0.7116158604621887\n",
      "Finished epoch 1954, latest loss 0.7116158604621887\n",
      "Finished epoch 1955, latest loss 0.7116158604621887\n",
      "Finished epoch 1956, latest loss 0.7116158604621887\n",
      "Finished epoch 1957, latest loss 0.7116163372993469\n",
      "Finished epoch 1958, latest loss 0.7155804634094238\n",
      "Finished epoch 1959, latest loss 0.7136390805244446\n",
      "Finished epoch 1960, latest loss 0.7126273512840271\n",
      "Finished epoch 1961, latest loss 0.7126274704933167\n",
      "Finished epoch 1962, latest loss 0.7116158604621887\n",
      "Finished epoch 1963, latest loss 0.7116158604621887\n",
      "Finished epoch 1964, latest loss 0.7126321792602539\n",
      "Finished epoch 1965, latest loss 0.7126274704933167\n",
      "Finished epoch 1966, latest loss 0.7125454545021057\n",
      "Finished epoch 1967, latest loss 0.7125454545021057\n",
      "Finished epoch 1968, latest loss 0.7117528319358826\n",
      "Finished epoch 1969, latest loss 0.7125454545021057\n",
      "Finished epoch 1970, latest loss 0.7116601467132568\n",
      "Finished epoch 1971, latest loss 0.7125454545021057\n",
      "Finished epoch 1972, latest loss 0.711616039276123\n",
      "Finished epoch 1973, latest loss 0.7116158604621887\n",
      "Finished epoch 1974, latest loss 0.7125454545021057\n",
      "Finished epoch 1975, latest loss 0.7125381231307983\n",
      "Finished epoch 1976, latest loss 0.7125455141067505\n",
      "Finished epoch 1977, latest loss 0.7125454545021057\n",
      "Finished epoch 1978, latest loss 0.7133975028991699\n",
      "Finished epoch 1979, latest loss 0.7116159200668335\n",
      "Finished epoch 1980, latest loss 0.7116158604621887\n",
      "Finished epoch 1981, latest loss 0.7116158604621887\n",
      "Finished epoch 1982, latest loss 0.7116158604621887\n",
      "Finished epoch 1983, latest loss 0.7116158604621887\n",
      "Finished epoch 1984, latest loss 0.7116159200668335\n",
      "Finished epoch 1985, latest loss 0.7134749889373779\n",
      "Finished epoch 1986, latest loss 0.7135084867477417\n",
      "Finished epoch 1987, latest loss 0.7116158604621887\n",
      "Finished epoch 1988, latest loss 0.7125454545021057\n",
      "Finished epoch 1989, latest loss 0.7116158604621887\n",
      "Finished epoch 1990, latest loss 0.7126274704933167\n",
      "Finished epoch 1991, latest loss 0.7116158604621887\n",
      "Finished epoch 1992, latest loss 0.7116299867630005\n",
      "Finished epoch 1993, latest loss 0.7116448879241943\n",
      "Finished epoch 1994, latest loss 0.7116159796714783\n",
      "Finished epoch 1995, latest loss 0.7116471529006958\n",
      "Finished epoch 1996, latest loss 0.7126286625862122\n",
      "Finished epoch 1997, latest loss 0.7135552763938904\n",
      "Finished epoch 1998, latest loss 0.7143465280532837\n",
      "Finished epoch 1999, latest loss 0.7134703993797302\n",
      "Accuracy 0.9172788858413696\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive               15223               15408\n",
      "Actual Negative                 277              158705\n",
      "Positive predictive power:\n",
      "49.7%\n",
      "Positive predictive accuracy:\n",
      "98.21%\n",
      "Confusion Matrix for merged predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive               13868               16763\n",
      "Actual Negative                 204              158778\n",
      "Positive predictive power:\n",
      "45.27%\n",
      "Positive predictive accuracy:\n",
      "98.55%\n",
      "Mean change for incorrect predictions: 1.029\n",
      "Mean change for correct predictions: 1.098\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(np.array(train_df.T), dtype=torch.float32)\n",
    "y = torch.tensor(np.array(train_output), dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Check for CUDA and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move data to the chosen device\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(train_df.shape[0], 64)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(64, 12)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.hidden3 = nn.Linear(12, 8)\n",
    "        self.act3 = nn.ReLU()\n",
    "        #self.hidden4 = nn.Linear(12, 4)\n",
    "        #self.act4 = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act3(self.hidden3(x))\n",
    "        #x = self.act4(self.hidden4(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    " \n",
    "model = PimaClassifier().to(device)\n",
    "print(model)\n",
    "\n",
    "pos_weight = torch.tensor([1.5], device=device)  # Set your_pos_weight based on your needs\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "#loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 2000\n",
    "batch_size = 1000\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "    \n",
    "# compute accuracy (no_grad is optional)\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    " \n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")\n",
    "\n",
    "# make class predictions with the model\n",
    "predictions = (model(X) > 0.5).int().to('cpu')\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "###\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "actual_values = train_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "#print(predictions)\n",
    "\n",
    "###\n",
    "neg_predictions = (negmodel(X) > 0.5).int().to('cpu')\n",
    "neg_predictions = neg_predictions.numpy()\n",
    "neg_predictions = 1 - neg_predictions\n",
    "\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "merge_predictions = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "merge_predictions.index = range(1, len(merge_predictions) + 1)\n",
    "actual_values = train_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(merge_predictions)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(train_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct predictions:\", mean_value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f146856-bc1e-48ec-b98c-00cd091c5ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63204\n",
      "63204\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                3628                6483\n",
      "Actual Negative                1123               51970\n",
      "Positive predictive power:\n",
      "35.88%\n",
      "Positive predictive accuracy:\n",
      "76.36%\n",
      "Confusion Matrix for merged predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                3209                6902\n",
      "Actual Negative                 852               52241\n",
      "Positive predictive power:\n",
      "31.74%\n",
      "Positive predictive accuracy:\n",
      "79.02%\n",
      "Mean change for incorrect predictions: 1.02\n",
      "Mean change for correct predictions: 1.105\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Set the model to evaluation mode\n",
    "negmodel.eval()\n",
    "model.eval()\n",
    "\n",
    "# Step 2: Prepare your input data (assuming new_input is your raw data)\n",
    "# For example, if your model expects input size of (1, C, H, W)\n",
    "input_tensor = torch.tensor(np.array(cv_df.T), dtype=torch.float32)\n",
    "\n",
    "# Step 3: Move your model and input data to the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "negmodel = negmodel.to(device)\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "predictions = (model(input_tensor) > 0.5).int().to('cpu')\n",
    "neg_predictions = (negmodel(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(predictions))\n",
    "print(len(neg_predictions))\n",
    "predictions = predictions.numpy()\n",
    "neg_predictions = neg_predictions.numpy()\n",
    "neg_predictions = 1 - neg_predictions\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = cv_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "test_pred = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = cv_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(cv_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(cv_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct predictions:\", mean_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4824a814-02a5-4e89-a4e9-6c432747494e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63205\n",
      "63205\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                3667                6454\n",
      "Actual Negative                1114               51970\n",
      "Positive predictive power:\n",
      "36.23%\n",
      "Positive predictive accuracy:\n",
      "76.7%\n",
      "Confusion Matrix for merged predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                3239                6882\n",
      "Actual Negative                 822               52262\n",
      "Positive predictive power:\n",
      "32.0%\n",
      "Positive predictive accuracy:\n",
      "79.76%\n",
      "Mean change for incorrect predictions: 1.019\n",
      "Mean change for correct predictions: 1.104\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Set the model to evaluation mode\n",
    "negmodel.eval()\n",
    "model.eval()\n",
    "\n",
    "# Step 2: Prepare your input data (assuming new_input is your raw data)\n",
    "# For example, if your model expects input size of (1, C, H, W)\n",
    "input_tensor = torch.tensor(np.array(test_df.T), dtype=torch.float32)\n",
    "\n",
    "# Step 3: Move your model and input data to the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "negmodel = negmodel.to(device)\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "predictions = (model(input_tensor) > 0.5).int().to('cpu')\n",
    "neg_predictions = (negmodel(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(predictions))\n",
    "print(len(neg_predictions))\n",
    "predictions = predictions.numpy()\n",
    "neg_predictions = neg_predictions.numpy()\n",
    "neg_predictions = 1 - neg_predictions\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "test_pred = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = test_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct predictions:\", mean_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7d7b0cdc-fa52-4dc5-bbb9-49f17bf7066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/best_7up10d_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abb555c6-acea-414c-a4ea-4057d4f1fff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x\n",
      "1  1.02226\n",
      "2  1.04186\n",
      "3  1.04381\n",
      "4  1.03341\n",
      "5  1.03589\n",
      "(316022, 1)\n",
      "Mean of selected rows: 1.0035831841302136\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1cb0300a-d2d2-4710-8069-c964dfc5a685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PimaClassifier(\n",
       "  (hidden1): Linear(in_features=1616, out_features=64, bias=True)\n",
       "  (act1): ReLU()\n",
       "  (hidden2): Linear(in_features=64, out_features=12, bias=True)\n",
       "  (act2): ReLU()\n",
       "  (hidden3): Linear(in_features=12, out_features=8, bias=True)\n",
       "  (act3): ReLU()\n",
       "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
       "  (act_output): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for CUDA and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(train_df.shape[0], 64)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(64, 12)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.hidden3 = nn.Linear(12, 8)\n",
    "        self.act3 = nn.ReLU()\n",
    "        #self.hidden4 = nn.Linear(12, 4)\n",
    "        #self.act4 = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act3(self.hidden3(x))\n",
    "        #x = self.act4(self.hidden4(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    " \n",
    "model = PimaClassifier().to(device)\n",
    "model.load_state_dict(torch.load(\"E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/best_9up10d_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "negmodel = PimaClassifier().to(device)\n",
    "negmodel.load_state_dict(torch.load(\"E:/Market_Data/DiscountOptionData/DTNSubscription/revised_derived_aggregates/best_5down10d_model.pt\"))\n",
    "negmodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e3629ac4-8c0a-4122-8f13-9dad842567aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63204\n",
      "63204\n",
      "Confusion Matrix for positive predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1854                8257\n",
      "Actual Negative                 270               52823\n",
      "Positive predictive power:\n",
      "18.34%\n",
      "Positive predictive accuracy:\n",
      "87.29%\n",
      "Confusion Matrix for merged predictions:\n",
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                1582                8529\n",
      "Actual Negative                 175               52918\n",
      "Positive predictive power:\n",
      "15.65%\n",
      "Positive predictive accuracy:\n",
      "90.04%\n",
      "(63204, 2)\n",
      "(63205, 1)\n",
      "(1616, 63204)\n",
      "(63204, 1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Boolean index has wrong length: 63204 instead of 63205",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 85\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(cv_output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Use the mask to filter rows and calculate the mean\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m mean_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(\u001b[43mtest_10dChange\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean(),\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean change for incorrect predictions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_value)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Convert the list to a boolean array\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1066\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1247\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1246\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(tup)\n\u001b[1;32m-> 1247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_lowerdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:991\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    989\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m section\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;66;03m# This is an elided recursive call to iloc/loc\u001b[39;00m\n\u001b[1;32m--> 991\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot applicable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1070\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1072\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1292\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_slice_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getbool_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m   1294\u001b[0m \n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m# an iterable multi-selection\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, MultiIndex)):\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1091\u001b[0m, in \u001b[0;36m_LocationIndexer._getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getbool_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, axis: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;66;03m# caller is responsible for ensuring non-None axis\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m-> 1091\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1092\u001b[0m     inds \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(inds, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:2571\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_array_like(result):\n\u001b[0;32m   2568\u001b[0m     \u001b[38;5;66;03m# GH 33924\u001b[39;00m\n\u001b[0;32m   2569\u001b[0m     \u001b[38;5;66;03m# key may contain nan elements, check_array_indexer needs bool array\u001b[39;00m\n\u001b[0;32m   2570\u001b[0m     result \u001b[38;5;241m=\u001b[39m pd_array(result, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m-> 2571\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_array_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexers\\utils.py:552\u001b[0m, in \u001b[0;36mcheck_array_indexer\u001b[1;34m(array, indexer)\u001b[0m\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;66;03m# GH26658\u001b[39;00m\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(array):\n\u001b[1;32m--> 552\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[0;32m    553\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoolean index has wrong length: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    554\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(indexer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(array)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    555\u001b[0m         )\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer_dtype(dtype):\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: Boolean index has wrong length: 63204 instead of 63205"
     ]
    }
   ],
   "source": [
    "# Step 1: Set the model to evaluation mode\n",
    "negmodel.eval()\n",
    "model.eval()\n",
    "\n",
    "# Step 2: Prepare your input data (assuming new_input is your raw data)\n",
    "# For example, if your model expects input size of (1, C, H, W)\n",
    "input_tensor = torch.tensor(np.array(cv_df.T), dtype=torch.float32)\n",
    "\n",
    "# Step 3: Move your model and input data to the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "negmodel = negmodel.to(device)\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "predictions = (model(input_tensor) > 0.5).int().to('cpu')\n",
    "neg_predictions = (negmodel(input_tensor) > 0.5).int().to('cpu')\n",
    "print(len(predictions))\n",
    "print(len(neg_predictions))\n",
    "predictions = predictions.numpy()\n",
    "neg_predictions = neg_predictions.numpy()\n",
    "neg_predictions = 1 - neg_predictions\n",
    "merge_predictions = np.logical_and(neg_predictions, predictions)\n",
    "\n",
    "test_pred = pd.DataFrame(predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = cv_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for positive predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "test_pred = pd.DataFrame(merge_predictions,columns=['Predicted'])\n",
    "test_pred.index = range(1, len(test_pred) + 1)\n",
    "\n",
    "actual_values = cv_output\n",
    "actual_values.columns = ['Actual']\n",
    "\n",
    "test = actual_values.join(test_pred)\n",
    "\n",
    "TP = ((test['Actual'] == 1) & (test['Predicted'] == 1)).sum()\n",
    "TN = ((test['Actual'] == 0) & (test['Predicted'] == 0)).sum()\n",
    "FP = ((test['Actual'] == 0) & (test['Predicted'] == 1)).sum()\n",
    "FN = ((test['Actual'] == 1) & (test['Predicted'] == 0)).sum()\n",
    "\n",
    "# Creating a DataFrame for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame([[TP, FN], [FP, TN]],\n",
    "                                columns=['Predicted Positive', 'Predicted Negative'],\n",
    "                                index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(\"Confusion Matrix for merged predictions:\")\n",
    "print(confusion_matrix)\n",
    "print(\"Positive predictive power:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[0,1]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "print(\"Positive predictive accuracy:\")\n",
    "test_val = (confusion_matrix.iloc[0,0] / (confusion_matrix.iloc[0,0] + confusion_matrix.iloc[1,0]))*100\n",
    "print(str(round(test_val,2)) + \"%\")\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 0) & (test['Predicted'] == 1)), dtype=bool)\n",
    "print(test.shape)\n",
    "print(test_10dChange.shape)\n",
    "print(cv_df.shape)\n",
    "print(cv_output.shape)\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for incorrect predictions:\", mean_value)\n",
    "\n",
    "# Convert the list to a boolean array\n",
    "mask = np.array(((test['Actual'] == 1) & (test['Predicted'] == 1)), dtype=bool)\n",
    "\n",
    "# Use the mask to filter rows and calculate the mean\n",
    "mean_value = round(test_10dChange.loc[mask,'x'].mean(),3)\n",
    "\n",
    "print(\"Mean change for correct predictions:\", mean_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94507881-a82b-413f-a800-0565e25ab7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49ec72-f9ba-4c26-8217-908ff9d00c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433198e2-f74a-4d49-9c65-bbfbb7f8f584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a9b92f-0d8f-4536-b5e3-d72e3f8dd65b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

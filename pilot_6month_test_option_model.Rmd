---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r save all current and previous SP500 tickers}

source("C:/Users/Andy/Downloads/Investing files/Investing_Project_Rstudio/finance_functions.R")
new_directory = "C:/Users/Andy/Downloads/Investing files/"

# Change the working directory
setwd(new_directory)

# Print the current working directory to verify the change
print(getwd())

# Get list of option and stock files

# Load SP500 tickers
sp500_table = read_xlsx('SP500_companies.xlsx')
#print(sp500_table.head())
#print(sp500_table['Symbol'])
sp500_extras = read_xlsx('SP500_changes.xlsx')
sp500_tickers = unique(c(sp500_table$Symbol,sp500_extras$Added_Ticker,sp500_extras$Removed_Ticker))
sp500_tickers = sp500_tickers[!is.na(sp500_tickers)]
saveRDS(sp500_tickers,file="SP500_tickers.RDS")

```

```{r aggregate all stock data}

source("C:/Users/Andy/Downloads/Investing files/Investing_Project_Rstudio/finance_functions.R")
new_directory = "C:/Users/Andy/Downloads/Investing files/stock_files/"

# Change the working directory
setwd(new_directory)

# Print the current working directory to verify the change
print(getwd())

# Get list of option and stock files
temp_files = list.files("C:/Users/Andy/Downloads/Investing files/stock_files/")
temp_files = temp_files[grepl("stocks.cvs",temp_files)]
# Merge all stock data into one dataframe
full_df = NULL
for(temp_file_i in 1:length(temp_files)){
  temp_filename = temp_files[temp_file_i]
  temp_date = str_replace(temp_filename,"stocks.cvs","")
  temp_df = read.delim(temp_filename,header=TRUE,sep=",")
  temp_df$stock_quote_date = temp_date
  if(is.null(full_df)){
    full_df = temp_df
  }else{
    full_df = rbind(full_df,temp_df)
  }
  print(paste0("Finished with ",temp_date))
}
saveRDS(full_df,file="C:/Users/Andy/Downloads/Investing files/stock_aggregate.RDS")
# Get list of all stock dates
temp_date_list = unique(full_df$stock_quote_date)

# Iterate through each ticker and calculate initial SMA20, SMA8, SMV20, and SMV8 from the earliest available dates
# Note the initial SMA20 and SMA8 as well as the earliest starting date for each ticker

# Use the SMA and SMV values to calculate the EMA20, EMA8, EMV20, and EMV8 values for each ticker

```

```{r explore options data and aggregation}

source("C:/Users/Andy/Downloads/Investing files/Investing_Project_Rstudio/finance_functions.R")

# Function to process a single file in parallel
process_file <- function(file_i) {
  source("C:/Users/Andy/Downloads/Investing files/Investing_Project_Rstudio/finance_functions.R")
  new_directory = "C:/Users/Andy/Downloads/Investing files/"
  # Change the working directory
  setwd(new_directory)
  
  sp500_tickers = readRDS("SP500_tickers.RDS")
  
  all_option_files = list.files('./option_files')
  all_stock_files = list.files('./stock_files')

  temp_option_file <- all_option_files[file_i]
  temp_stock_file <- sub('options', 'stocks', temp_option_file)
  temp_date <- sub('options.cvs', '', temp_option_file)
  
  # Load options data
  dfOptions <- read.delim(paste0("option_files/", temp_option_file), header = TRUE, sep = ",")
  
  # Load stock data
  dfStocks <- read.delim(paste0("stock_files/", temp_stock_file), header = TRUE, sep = ",")
  
  # Filter stocks to SP500 tickers
  filteredStocks <- dfStocks %>% filter(symbol %in% sp500_tickers)
  
  # Filter options to SP500 tickers
  filteredOptions <- dfOptions %>% filter(underlying %in% sp500_tickers)
  
  # Determine daily average from open and close values for each ticker
  filteredStocks <- filteredStocks %>% mutate(open_close_avg = (open + close) / 2)
  
  # Add stock open-close average to options df and ratio with strike price
  filteredOptions$open_close_avg <- NA
  for (temp_i in 1:length(filteredStocks$symbol)) {
    temp_symbol <- filteredStocks$symbol[temp_i]
    filteredOptions$open_close_avg[filteredOptions$underlying == temp_symbol] <- filteredStocks$open_close_avg[filteredStocks$symbol == temp_symbol]
  }
  filteredOptions$option_ratio <- filteredOptions$strike / filteredOptions$open_close_avg
  
  new_chain <- NULL
  
  for (temp_ticker_i in 1:length(sp500_tickers)) {
    temp_ticker <- sp500_tickers[temp_ticker_i]
    if (temp_ticker %in% filteredOptions$underlying) {
      test_chain <- filteredOptions[filteredOptions$underlying == temp_ticker, ]
      
      # Suggest starting with <10, 10-25, 25-50, 50-100, 100-200, 200-350, >350
      min_strike_set = c(NA, 0.5, 0.75, 0.9, 0.95, 1, 1.05, 1.1, 1.25, 1.5)
      max_strike_set = c(0.5, 0.75, 0.9, 0.95, 1, 1.05, 1.1, 1.25, 1.5, NA)
      min_day_set = c(NA, 10, 25, 50, 100, 200, 350)
      max_day_set = c(10, 25, 50, 100, 200, 350, NA)
      merge_chain = NULL
      for (temp_strike_i in 1:length(min_strike_set)) {
        for (temp_day_i in 1:length(min_day_set)) {
          # Aggregate over all strike ranges
          test_result = option_chain_aggregator(
            test_chain,
            min_strike_ratio = min_strike_set[temp_strike_i],
            max_strike_ratio = max_strike_set[temp_strike_i],
            min_avg_days_to_expiry = min_day_set[temp_day_i],
            max_avg_days_to_expiry = max_day_set[temp_day_i]
          )
          partial_chain = test_result[,c("option_underlying_ticker",
                                        "option_quote_date",
                                        "option_underlying_open_close_avg",
                                        "option_style")]
          add_chain = test_result[,!(colnames(test_result) %in% c(colnames(partial_chain),"option_strike_range","option_expiry_range"))]
          colnames(add_chain) = paste0(colnames(add_chain),
                                       "_strike_",str_replace_all(test_result$option_strike_range,"[ ]",""),
                                       "_expiry_",str_replace_all(test_result$option_expiry_range,"[ ]",""))
          if(temp_strike_i == 1 & temp_day_i == 1){
            merge_chain = cbind(partial_chain,add_chain)
          }else{
            merge_chain = cbind(merge_chain,add_chain)
          }
        }
      }
      if(is.null(new_chain)){
        new_chain = merge_chain
      }else{
        new_chain = rbind(new_chain,merge_chain)
      }
    }
    if (temp_ticker_i %% 100 == 0) {
      print(paste0("Finished with ", temp_ticker_i, " tickers for ", temp_date))
      timestamp()
    }
  }
  
  saveRDS(new_chain, paste0("new_aggregate_files/", temp_date, "aggregate.RDS"))
  print(paste0("Finished with ", temp_date))
  timestamp()
}

##First merge stock data by date and calculate averages
##Second aggregate options by strike ranges
##Third aggregate options by expiry ranges (use average of days and business days to expiry)
##  Suggest starting with <10, 10-25, 25-50, 50-100, 100-200, 200-350, >350
##Fourth merge option ratio and expiry ranges by date and calculate averages

new_directory = "C:/Users/Andy/Downloads/Investing files/"

# Change the working directory
setwd(new_directory)

# Print the current working directory to verify the change
print(getwd())

# Get list of option and stock files

all_option_files = list.files('./option_files')
all_stock_files = list.files('./stock_files')

# Use parallel processing to process files concurrently
num_cores <- detectCores()
cl <- makeCluster(num_cores)
timestamp()
result <- parLapply(cl, 1:length(all_option_files), process_file)
stopCluster(cl)

timestamp()

##Merge individual aggregate files
setwd("C:/Users/Andy/Downloads/Investing files/new_aggregate_files/")
aggregate_files <- list.files()
full_aggregate = NULL
for(temp_file_i in 1:length(aggregate_files)){
    temp_aggregate = readRDS(aggregate_files[temp_file_i])
    if(is.null(full_aggregate)){
        full_aggregate = as.data.frame(temp_aggregate)
    }else{
        full_aggregate = rbind(full_aggregate,as.data.frame(temp_aggregate))
    }
    print(paste0(temp_file_i))
}
saveRDS(full_aggregate,file="C:/Users/Andy/Downloads/Investing files/full_options_aggregate.RDS")

#full_aggregate = readRDS("C:/Users/Andy/Downloads/Investing files/full_options_aggregate.RDS")

##Calculate moving average volume for options at each strike range and expiry date with 8 and 20 day window

#Start by calculating simple moving average volume

#Create a list of dates that options first appear for each stock
#first_20days = c("2013-01-02","2013-01-03","2013-01-04","2013-01-07","2013-01-08",
#                 "2013-01-09","2013-01-10","2013-01-11","2013-01-14","2013-01-15",
#                 "2013-01-16","2013-01-17","2013-01-18","2013-01-22","2013-01-23",
#                 "2013-01-24","2013-01-25","2013-01-28","2013-01-29","2013-01-30")
full_aggregate = full_aggregate[order(full_aggregate$option_underlying_ticker,full_aggregate$option_quote_date),]
all_tickers = unique(full_aggregate$option_underlying_ticker)

ticker_dates = list()
for(temp_ticker_i in 1:length(all_tickers)){
  temp_ticker = all_tickers[temp_ticker_i]
  test_df = full_aggregate[full_aggregate$option_underlying_ticker == temp_ticker,]
  temp_dates = unique(test_df$option_quote_date)
  contract_sum = 0
  temp_counter_i = 1
  while(contract_sum == 0 & temp_counter_i <= length(temp_dates)){
    sub_df = test_df[test_df$option_quote_date == temp_dates[temp_counter_i],]
    contract_sum = sum(sub_df[,grepl("_listings_",colnames(sub_df))])
    temp_counter_i = temp_counter_i + 1
    if(contract_sum > 0){
      temp_counter_i = temp_counter_i - 1
    }
  }
  if(contract_sum > 0){
    ticker_dates[[temp_ticker]] = temp_dates[temp_counter_i]
  }else{
    ticker_dates[[temp_ticker]] = NA
  }
  print(paste0("Finished with ",temp_ticker))
}

saveRDS(ticker_dates,file="C:/Users/Andy/Downloads/Investing files/SMA_options_ticker_dates.RDS")

stocks_for_SMA = names(ticker_dates)[(ticker_dates == "2013-01-02")]
all_dates = unique(full_aggregate$option_quote_date)

#Calculate SMA8 and SMA20 for all call and put specific features
sma_df = full_aggregate[full_aggregate$option_quote_date %in% all_dates[1:20],]
all_sma20s = list()
all_sma8s = list()
for(temp_ticker_i in 1:length(stocks_for_SMA)){
  temp_ticker = stocks_for_SMA[temp_ticker_i]
  test_df = sma_df[sma_df$option_underlying_ticker == temp_ticker,]
  #Calculate SMA20 values
  sub_df = test_df[test_df$option_quote_date %in% all_dates[1:20],]
  if(nrow(sub_df) == 20){
    all_sma20s[[temp_ticker]] = colSums(sub_df[,!(colnames(sub_df) %in% c("option_underlying_ticker","option_quote_date","option_style"))],na.rm=TRUE) / 
      colSums(!is.na(sub_df[,!(colnames(sub_df) %in% c("option_underlying_ticker","option_quote_date","option_style"))]))
  }else{
    print(paste0("Insufficient data for initial SMA20 calculation for ",temp_ticker))
  }
  sub_df = test_df[test_df$option_quote_date %in% all_dates[1:8],]
  if(nrow(sub_df) == 8){
    all_sma8s[[temp_ticker]] = colSums(sub_df[,!(colnames(sub_df) %in% c("option_underlying_ticker","option_quote_date","option_style"))],na.rm=TRUE) / 
      colSums(!is.na(sub_df[,!(colnames(sub_df) %in% c("option_underlying_ticker","option_quote_date","option_style"))]))
  }else{
    print(paste0("Insufficient data for initial SMA8 calculation for ",temp_ticker))
  }
  print(paste0("Finished with ",temp_ticker))
}
all_sma20s = as.data.frame(t(as.data.frame(all_sma20s)))
all_sma8s = as.data.frame(t(as.data.frame(all_sma8s)))
all_sma20s$option_underlying_ticker = rownames(all_sma20s)
all_sma20s$option_quote_date = "2013-01-14"
all_sma8s$option_underlying_ticker = rownames(all_sma8s)
all_sma8s$option_quote_date = "2013-01-31"

saveRDS(all_sma20s,file="C:/Users/Andy/Downloads/Investing files/initial_option_SMA20s.RDS")
saveRDS(all_sma8s,file="C:/Users/Andy/Downloads/Investing files/initial_option_SMA8s.RDS")

#Calculate EMA8 and EMA20 for all following dates
###Replaced with parallized code below
#all_ema20s = all_sma20s[all_sma20s$option_quote_date == "1900-01-01",]
#all_ema8s = all_sma8s[all_sma8s$option_quote_date == "1900-01-01",]
#error_log = list()
#timestamp()
#for(temp_ticker_i in 1:length(stocks_for_SMA)){
#  temp_errors = list()
#  temp_ticker = stocks_for_SMA[temp_ticker_i]
#  test_df = full_aggregate[full_aggregate$option_underlying_ticker == temp_ticker,]
#  dates_to_run = all_dates[9:length(all_dates)]
#  for(temp_date_i in 1:length(dates_to_run)){
#    temp_date = dates_to_run[temp_date_i]
#    sub_df = test_df[test_df$option_quote_date == temp_date,!(colnames(test_df) %in% c("option_underlying_ticker","option_quote_date","option_style"))]
#    if(nrow(sub_df) == 1){
#      if(temp_date == all_dates[9]){
#        temp_sma8 = all_sma8s[rownames(all_sma8s) == temp_ticker,
#                              !(colnames(all_sma8s) %in% c("option_underlying_ticker","option_quote_date"))]
#      }else{
#        temp_sma8 = all_ema8s[all_ema8s$option_underlying_ticker == temp_ticker & 
#                                all_ema8s$option_quote_date == dates_to_run[temp_date_i-1],
#                              !(colnames(all_ema8s) %in% c("option_underlying_ticker","option_quote_date"))]
#      }
#      if(nrow(temp_sma8) == 1){
#        temp_ema8 = (sub_df) * (2/9) + (temp_sma8) * (1 - (2/9))
#        temp_ema8$option_underlying_ticker = temp_ticker
#        temp_ema8$option_quote_date = temp_date
#        all_ema8s = rbind(all_ema8s,temp_ema8)
#      }else{
#        print(paste0("Error: No prior SMA8/EMA8 for ", temp_ticker, " for ", temp_date))
#        temp_errors = c(temp_errors,paste0("Error: No SMA8 for ", temp_ticker, " for ", temp_date))
#      }
#      if(temp_date %in% all_dates[21:length(all_dates)]){
#        if(temp_date == all_dates[21]){
#          temp_sma20 = all_sma20s[rownames(all_sma20s) == temp_ticker,
#                              !(colnames(all_sma20s) %in% c("option_underlying_ticker","option_quote_date"))]
#        }else{
#          temp_sma20 = all_ema20s[all_ema20s$option_underlying_ticker == temp_ticker & 
#                                  all_ema20s$option_quote_date == dates_to_run[temp_date_i-1],
#                                !(colnames(all_ema20s) %in% c("option_underlying_ticker","option_quote_date"))]
#        }
#        if(nrow(temp_sma20) == 1){
#          temp_ema20 = (sub_df) * (2/21) + (temp_sma20) * (1 - (2/21))
#          temp_ema20$option_underlying_ticker = temp_ticker
#          temp_ema20$option_quote_date = temp_date
#          all_ema20s = rbind(all_ema20s,temp_ema20)
#        }else{
#          print(paste0("Error: No prior SMA20/EMA20 for ", temp_ticker, " for ", temp_date))
#          temp_errors = c(temp_errors,paste0("Error: No prior SMA20/EMA20 for ", temp_ticker, " for ", temp_date))
#        }
#      }
#    }else{
#      print(paste0("Error: No new data for EMA calculation for ", temp_ticker, " for ", temp_date))
#      temp_errors = c(temp_errors,paste0("Error: No new data for EMA calculation for ", temp_ticker, " for ", temp_date))
#      break
#    }
#  }
#  error_log[[temp_ticker]] = temp_errors
#  print(paste0("Finished with ",temp_ticker))
#  timestamp()
#}

###

# Install and load the required packages if not already installed
# install.packages("foreach")
# install.packages("doParallel")
library(foreach)
library(doParallel)

full_aggregate = readRDS("C:/Users/Andy/Downloads/Investing files/full_options_aggregate.RDS")
full_aggregate = full_aggregate[order(full_aggregate$option_underlying_ticker,full_aggregate$option_quote_date),]
ticker_dates = readRDS("C:/Users/Andy/Downloads/Investing files/SMA_options_ticker_dates.RDS")
stocks_for_SMA = names(ticker_dates)[(ticker_dates == "2013-01-02")]
all_dates = unique(full_aggregate$option_quote_date)
all_sma20s = readRDS("C:/Users/Andy/Downloads/Investing files/initial_option_SMA20s.RDS")
all_sma8s = readRDS("C:/Users/Andy/Downloads/Investing files/initial_option_SMA8s.RDS")


# Set the number of CPU cores/threads to use
num_cores <- detectCores()  # Adjust this number as needed

# Initialize a parallel backend
cl <- makeCluster(num_cores, outfile="C:/Users/Andy/Downloads/Investing files/ema_option_log.txt")
registerDoParallel(cl)

# Calculate EMA8 and EMA20 for all following dates in parallel
all_ema20s <- all_sma20s[all_sma20s$option_quote_date == "1900-01-01",]
all_ema8s <- all_sma8s[all_sma8s$option_quote_date == "1900-01-01",]
error_log <- list()
timestamp()

# Create a function for the parallelized work
calculate_ema <- function(full_aggregate,temp_ticker,all_dates,all_sma8s,all_sma20s) {
  temp_errors = list()
  temp_ema8s = all_sma8s[all_sma8s$option_quote_date == "1900-01-01",]
  temp_ema20s = all_sma20s[all_sma20s$option_quote_date == "1900-01-01",]
  test_df <- full_aggregate[full_aggregate$option_underlying_ticker == temp_ticker,]
  dates_to_run <- all_dates[9:length(all_dates)]

  for (temp_date_i in 1:length(dates_to_run)) {
    temp_date <- dates_to_run[temp_date_i]
    sub_df <- test_df[test_df$option_quote_date == temp_date, !(colnames(test_df) %in% c("option_underlying_ticker","option_quote_date","option_style"))]

    if (nrow(sub_df) == 1) {
      if (temp_date == all_dates[9]) {
        temp_sma8 <- all_sma8s[rownames(all_sma8s) == temp_ticker, !(colnames(all_sma8s) %in% c("option_underlying_ticker","option_quote_date"))]
      } else {
        temp_sma8 <- temp_ema8s[temp_ema8s$option_underlying_ticker == temp_ticker & temp_ema8s$option_quote_date == dates_to_run[temp_date_i-1], 
                                !(colnames(temp_ema8s) %in% c("option_underlying_ticker","option_quote_date"))]
      }

      if (nrow(temp_sma8) == 1) {
        temp_ema8 <- (sub_df) * (2/9) + (temp_sma8) * (1 - (2/9))
        temp_ema8$option_underlying_ticker <- temp_ticker
        temp_ema8$option_quote_date <- temp_date
        temp_ema8s <- rbind(temp_ema8s, temp_ema8)
      } else {
        print(paste0("Error: No prior SMA8/EMA8 for ", temp_ticker, " for ", temp_date))
        temp_errors <- c(temp_errors, paste0("Error: No SMA8 for ", temp_ticker, " for ", temp_date))
      }

      if (temp_date %in% all_dates[21:length(all_dates)]) {
        if (temp_date == all_dates[21]) {
          temp_sma20 <- all_sma20s[rownames(all_sma20s) == temp_ticker, !(colnames(all_sma20s) %in% c("option_underlying_ticker","option_quote_date"))]
        } else {
          temp_sma20 <- temp_ema20s[temp_ema20s$option_underlying_ticker == temp_ticker & temp_ema20s$option_quote_date == dates_to_run[temp_date_i-1], 
                                    !(colnames(temp_ema20s) %in% c("option_underlying_ticker","option_quote_date"))]
        }

        if (nrow(temp_sma20) == 1) {
          temp_ema20 <- (sub_df) * (2/21) + (temp_sma20) * (1 - (2/21))
          temp_ema20$option_underlying_ticker <- temp_ticker
          temp_ema20$option_quote_date <- temp_date
          temp_ema20s <- rbind(temp_ema20s, temp_ema20)
        } else {
          print(paste0("Error: No prior SMA20/EMA20 for ", temp_ticker, " for ", temp_date))
          temp_errors <- c(temp_errors, paste0("Error: No prior SMA20/EMA20 for ", temp_ticker, " for ", temp_date))
        }
      }
    } else {
      print(paste0("Error: No new data for EMA calculation for ", temp_ticker, " for ", temp_date))
      temp_errors <- c(temp_errors, paste0("Error: No new data for EMA calculation for ", temp_ticker, " for ", temp_date))
      break
    }
  }
  temp_result = list(ticker=temp_ticker, errors = temp_errors, ema20s=temp_ema20s, ema8s=temp_ema8s)
  timestamp()
  print(paste0("Finished with ",temp_ticker))
  return(temp_result)
}

# Use foreach to parallelize the calculations
timestamp()
results <- foreach(temp_ticker = stocks_for_SMA, .packages = c("dplyr")) %dopar% {
  calculate_ema(full_aggregate,temp_ticker,all_dates,all_sma8s,all_sma20s)
}

# Close the parallel backend
stopCluster(cl)

# Collect and process the results
test = results
for (temp_result_i in 1:length(test)) {
  if(temp_result_i == 1){
    all_ema20s = test[[temp_result_i]]$ema20s
    all_ema8s = test[[temp_result_i]]$ema8s
  }else{
    all_ema20s = rbind(all_ema20s,test[[temp_result_i]]$ema20s)
    all_ema8s = rbind(all_ema8s,test[[temp_result_i]]$ema8s)
  }
  temp_ticker = test[[temp_result_i]]$ticker
  temp_error = test[[temp_result_i]]$errors
  error_log[[temp_ticker]] <- temp_error
  print(paste0("Finished with ", temp_ticker))
  timestamp()
}

saveRDS(all_ema8s,file="C:/Users/Andy/Downloads/Investing files/all_option_ema8s.RDS")
saveRDS(all_ema20s,file="C:/Users/Andy/Downloads/Investing files/all_option_ema20s.RDS")

# Print error log if needed
print("Error Log:")
print(error_log)

###

##Calculate moving average price and volume for stock with 8 and 20 day window
stock_aggregate = readRDS("C:/Users/Andy/Downloads/Investing files/stock_aggregate.RDS")
stock_aggregate = stock_aggregate[order(stock_aggregate$symbol,stock_aggregate$stock_quote_date),]
stock_aggregate$avg_open_close = ((stock_aggregate$open + stock_aggregate$close) / 2)
ticker_dates = readRDS("C:/Users/Andy/Downloads/Investing files/SMA_options_ticker_dates.RDS")
stocks_for_SMA = names(ticker_dates)[(ticker_dates == "2013-01-02")]
all_dates = unique(stock_aggregate$stock_quote_date)

#Calculate SMA8 and SMA20 for all call and put specific features
sma_df = stock_aggregate[stock_aggregate$stock_quote_date %in% all_dates[1:20],]
all_sma20s = list()
all_sma8s = list()
for(temp_ticker_i in 1:length(stocks_for_SMA)){
  temp_ticker = stocks_for_SMA[temp_ticker_i]
  test_df = sma_df[sma_df$symbol == temp_ticker,]
  #Calculate SMA20 values
  sub_df = test_df[test_df$stock_quote_date %in% all_dates[1:20],]
  if(nrow(sub_df) == 20){
    all_sma20s[[temp_ticker]] = colSums(sub_df[,!(colnames(sub_df) %in% c("symbol","stock_quote_date","adjust_close"))],na.rm=TRUE) / 
      colSums(!is.na(sub_df[,!(colnames(sub_df) %in% c("symbol","stock_quote_date","adjust_close"))]))
  }else{
    print(paste0("Insufficient data for initial SMA20 calculation for ",temp_ticker))
  }
  sub_df = test_df[test_df$stock_quote_date %in% all_dates[1:8],]
  if(nrow(sub_df) == 8){
    all_sma8s[[temp_ticker]] = colSums(sub_df[,!(colnames(sub_df) %in% c("symbol","stock_quote_date","adjust_close"))],na.rm=TRUE) / 
      colSums(!is.na(sub_df[,!(colnames(sub_df) %in% c("symbol","stock_quote_date","adjust_close"))]))
  }else{
    print(paste0("Insufficient data for initial SMA8 calculation for ",temp_ticker))
  }
  print(paste0("Finished with ",temp_ticker))
}
all_sma20s = as.data.frame(t(as.data.frame(all_sma20s)))
all_sma8s = as.data.frame(t(as.data.frame(all_sma8s)))
all_sma20s$symbol = rownames(all_sma20s)
all_sma20s$stock_quote_date = "2013-01-14"
all_sma8s$symbol = rownames(all_sma8s)
all_sma8s$stock_quote_date = "2013-01-31"

saveRDS(all_sma20s,file="C:/Users/Andy/Downloads/Investing files/initial_stock_SMA20s.RDS")
saveRDS(all_sma8s,file="C:/Users/Andy/Downloads/Investing files/initial_stock_SMA8s.RDS")

##

library(foreach)
library(doParallel)

stock_aggregate = readRDS("C:/Users/Andy/Downloads/Investing files/stock_aggregate.RDS")
stock_aggregate = stock_aggregate[order(stock_aggregate$symbol,stock_aggregate$stock_quote_date),]
stock_aggregate$avg_open_close = ((stock_aggregate$open + stock_aggregate$close) / 2)
ticker_dates = readRDS("C:/Users/Andy/Downloads/Investing files/SMA_options_ticker_dates.RDS")
stocks_for_SMA = names(ticker_dates)[(ticker_dates == "2013-01-02")]
all_dates = unique(stock_aggregate$stock_quote_date)
all_sma20s = readRDS("C:/Users/Andy/Downloads/Investing files/initial_stock_SMA20s.RDS")
all_sma8s = readRDS("C:/Users/Andy/Downloads/Investing files/initial_stock_SMA8s.RDS")


# Set the number of CPU cores/threads to use
num_cores <- detectCores()  # Adjust this number as needed

# Initialize a parallel backend
cl <- makeCluster(num_cores, outfile="C:/Users/Andy/Downloads/Investing files/ema_stock_log.txt")
registerDoParallel(cl)

# Calculate EMA8 and EMA20 for all following dates in parallel
all_ema20s <- all_sma20s[all_sma20s$stock_quote_date == "1900-01-01",]
all_ema8s <- all_sma8s[all_sma8s$stock_quote_date == "1900-01-01",]
error_log <- list()
timestamp()

# Create a function for the parallelized work
calculate_stock_ema <- function(stock_aggregate,temp_ticker,all_dates,all_sma8s,all_sma20s) {
  temp_errors = list()
  temp_ema8s = all_sma8s[all_sma8s$stock_quote_date == "1900-01-01",]
  temp_ema20s = all_sma20s[all_sma20s$stock_quote_date == "1900-01-01",]
  test_df <- stock_aggregate[stock_aggregate$symbol == temp_ticker,]
  dates_to_run <- all_dates[9:length(all_dates)]

  for (temp_date_i in 1:length(dates_to_run)) {
    temp_date <- dates_to_run[temp_date_i]
    sub_df <- test_df[test_df$stock_quote_date == temp_date, !(colnames(test_df) %in% c("symbol","stock_quote_date","adjust_close"))]

    if (nrow(sub_df) == 1) {
      if (temp_date == all_dates[9]) {
        temp_sma8 <- all_sma8s[rownames(all_sma8s) == temp_ticker, !(colnames(all_sma8s) %in% c("symbol","stock_quote_date"))]
      } else {
        temp_sma8 <- temp_ema8s[temp_ema8s$symbol == temp_ticker & temp_ema8s$stock_quote_date == dates_to_run[temp_date_i-1], 
                                !(colnames(temp_ema8s) %in% c("symbol","stock_quote_date"))]
      }

      if (nrow(temp_sma8) == 1) {
        temp_ema8 <- (sub_df) * (2/9) + (temp_sma8) * (1 - (2/9))
        temp_ema8$symbol <- temp_ticker
        temp_ema8$stock_quote_date <- temp_date
        temp_ema8s <- rbind(temp_ema8s, temp_ema8)
      } else {
        print(paste0("Error: No prior SMA8/EMA8 for ", temp_ticker, " for ", temp_date))
        temp_errors <- c(temp_errors, paste0("Error: No SMA8 for ", temp_ticker, " for ", temp_date))
      }

      if (temp_date %in% all_dates[21:length(all_dates)]) {
        if (temp_date == all_dates[21]) {
          temp_sma20 <- all_sma20s[rownames(all_sma20s) == temp_ticker, !(colnames(all_sma20s) %in% c("symbol","stock_quote_date"))]
        } else {
          temp_sma20 <- temp_ema20s[temp_ema20s$symbol == temp_ticker & temp_ema20s$stock_quote_date == dates_to_run[temp_date_i-1], 
                                    !(colnames(temp_ema20s) %in% c("symbol","stock_quote_date"))]
        }

        if (nrow(temp_sma20) == 1) {
          temp_ema20 <- (sub_df) * (2/21) + (temp_sma20) * (1 - (2/21))
          temp_ema20$symbol <- temp_ticker
          temp_ema20$stock_quote_date <- temp_date
          temp_ema20s <- rbind(temp_ema20s, temp_ema20)
        } else {
          print(paste0("Error: No prior SMA20/EMA20 for ", temp_ticker, " for ", temp_date))
          temp_errors <- c(temp_errors, paste0("Error: No prior SMA20/EMA20 for ", temp_ticker, " for ", temp_date))
        }
      }
    } else {
      print(paste0("Error: No new data for EMA calculation for ", temp_ticker, " for ", temp_date))
      temp_errors <- c(temp_errors, paste0("Error: No new data for EMA calculation for ", temp_ticker, " for ", temp_date))
      break
    }
  }
  temp_result = list(ticker=temp_ticker, errors = temp_errors, ema20s=temp_ema20s, ema8s=temp_ema8s)
  timestamp()
  print(paste0("Finished with ",temp_ticker))
  return(temp_result)
}

# Use foreach to parallelize the calculations
timestamp()
results <- foreach(temp_ticker = stocks_for_SMA, .packages = c("dplyr")) %dopar% {
  calculate_stock_ema(stock_aggregate,temp_ticker,all_dates,all_sma8s,all_sma20s)
}

# Close the parallel backend
stopCluster(cl)

# Collect and process the results
test = results
for (temp_result_i in 1:length(test)) {
  if(temp_result_i == 1){
    all_ema20s = test[[temp_result_i]]$ema20s
    all_ema8s = test[[temp_result_i]]$ema8s
  }else{
    all_ema20s = rbind(all_ema20s,test[[temp_result_i]]$ema20s)
    all_ema8s = rbind(all_ema8s,test[[temp_result_i]]$ema8s)
  }
  temp_ticker = test[[temp_result_i]]$ticker
  temp_error = test[[temp_result_i]]$errors
  error_log[[temp_ticker]] <- temp_error
  print(paste0("Finished with ", temp_ticker))
  timestamp()
}

saveRDS(all_ema8s,file="C:/Users/Andy/Downloads/Investing files/all_stock_ema8s.RDS")
saveRDS(all_ema20s,file="C:/Users/Andy/Downloads/Investing files/all_stock_ema20s.RDS")

# Print error log if needed
print("Error Log:")
print(error_log)


##

##Remove stocks with errors or splits during the 6 month test data window

##Create outcome tables
stock_aggregate = readRDS("C:/Users/Andy/Downloads/Investing files/stock_aggregate.RDS")
stock_aggregate = stock_aggregate[order(stock_aggregate$symbol,stock_aggregate$stock_quote_date),]
stock_aggregate$avg_open_close = ((stock_aggregate$open + stock_aggregate$close) / 2)
ticker_dates = readRDS("C:/Users/Andy/Downloads/Investing files/SMA_options_ticker_dates.RDS")
stocks_for_SMA = names(ticker_dates)[(ticker_dates == "2013-01-02")]
all_dates = unique(stock_aggregate$stock_quote_date)

full_outcomes = NULL
input_aggregate = stock_aggregate[stock_aggregate$symbol %in% stocks_for_SMA,]
for(temp_date_i in 1:length(all_dates)){
  temp_aggregate = input_aggregate[input_aggregate$stock_quote_date == all_dates[temp_date_i],]
  rownames(temp_aggregate) = temp_aggregate$symbol
  temp_result = temp_aggregate[,c("symbol","stock_quote_date")]
  for(temp_counter_i in 1:10){
    if((temp_date_i+temp_counter_i) < length(all_dates)){
      comp_aggregate = input_aggregate[input_aggregate$stock_quote_date == all_dates[temp_date_i+temp_counter_i],]
      rownames(comp_aggregate) = comp_aggregate$symbol
      temp_result[,paste0("time",temp_counter_i,"_increase2")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] >= 1.02*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_increase5")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] >= 1.05*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_increase10")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] >= 1.1*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_increase20")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] >= 1.2*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_increase50")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] >= 1.5*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_decrease2")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] <= 0.98*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_decrease5")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] <= 0.95*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_decrease10")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] <= 0.9*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_decrease20")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] <= 0.8*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_decrease50")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] <= 0.5*temp_aggregate$avg_open_close)
    }else{
      temp_result[,paste0("time",temp_counter_i,"_increase2")] = NA
      temp_result[,paste0("time",temp_counter_i,"_increase5")] = NA
      temp_result[,paste0("time",temp_counter_i,"_increase10")] = NA
      temp_result[,paste0("time",temp_counter_i,"_increase20")] = NA
      temp_result[,paste0("time",temp_counter_i,"_increase50")] = NA
      temp_result[,paste0("time",temp_counter_i,"_decrease2")] = NA
      temp_result[,paste0("time",temp_counter_i,"_decrease5")] = NA
      temp_result[,paste0("time",temp_counter_i,"_decrease10")] = NA
      temp_result[,paste0("time",temp_counter_i,"_decrease20")] = NA
      temp_result[,paste0("time",temp_counter_i,"_decrease50")] = NA
    }
  }
  if(is.null(full_outcomes)){
    full_outcomes = temp_result
  }else{
    full_outcomes = rbind(full_outcomes,temp_result)
  }
  print(paste0("Finished with day ",temp_date_i))
}
saveRDS(full_outcomes,file="C:/Users/Andy/Downloads/Investing files/full_outcomes.RDS")

###

##Create outcome tables
stock_aggregate = readRDS("C:/Users/Andy/Downloads/Investing files/stock_aggregate.RDS")
stock_aggregate = stock_aggregate[order(stock_aggregate$symbol,stock_aggregate$stock_quote_date),]
stock_aggregate$avg_open_close = ((stock_aggregate$open + stock_aggregate$close) / 2)
ticker_dates = readRDS("C:/Users/Andy/Downloads/Investing files/SMA_options_ticker_dates.RDS")
stocks_for_SMA = names(ticker_dates)[(ticker_dates == "2013-01-02")]
all_dates = unique(stock_aggregate$stock_quote_date)

full_outcomes = NULL
input_aggregate = stock_aggregate[stock_aggregate$symbol %in% stocks_for_SMA,]
for(temp_date_i in 1:length(all_dates)){
  temp_aggregate = input_aggregate[input_aggregate$stock_quote_date == all_dates[temp_date_i],]
  rownames(temp_aggregate) = temp_aggregate$symbol
  temp_result = temp_aggregate[,c("symbol","stock_quote_date")]
  for(temp_counter_i in 1:10){
    if((temp_date_i+temp_counter_i) < length(all_dates)){
      comp_aggregate = input_aggregate[input_aggregate$stock_quote_date == all_dates[temp_date_i+temp_counter_i],]
      rownames(comp_aggregate) = comp_aggregate$symbol
      temp_result[,paste0("time",temp_counter_i,"_increase2")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] >= 1.02*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_increase5")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] >= 1.05*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_increase10")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] >= 1.1*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_increase20")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] >= 1.2*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_increase50")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] >= 1.5*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_decrease2")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] <= 0.98*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_decrease5")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] <= 0.95*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_decrease10")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] <= 0.9*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_decrease20")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] <= 0.8*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_decrease50")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] <= 0.5*temp_aggregate$avg_open_close)
      temp_result[,paste0("time",temp_counter_i,"_total_change")] = as.numeric(comp_aggregate[rownames(temp_aggregate),"avg_open_close"] / temp_aggregate$avg_open_close)
    }else{
      temp_result[,paste0("time",temp_counter_i,"_increase2")] = NA
      temp_result[,paste0("time",temp_counter_i,"_increase5")] = NA
      temp_result[,paste0("time",temp_counter_i,"_increase10")] = NA
      temp_result[,paste0("time",temp_counter_i,"_increase20")] = NA
      temp_result[,paste0("time",temp_counter_i,"_increase50")] = NA
      temp_result[,paste0("time",temp_counter_i,"_decrease2")] = NA
      temp_result[,paste0("time",temp_counter_i,"_decrease5")] = NA
      temp_result[,paste0("time",temp_counter_i,"_decrease10")] = NA
      temp_result[,paste0("time",temp_counter_i,"_decrease20")] = NA
      temp_result[,paste0("time",temp_counter_i,"_decrease50")] = NA
      temp_result[,paste0("time",temp_counter_i,"_total_change")] = NA
    }
  }
  if(is.null(full_outcomes)){
    full_outcomes = temp_result
  }else{
    full_outcomes = rbind(full_outcomes,temp_result)
  }
  print(paste0("Finished with day ",temp_date_i))
}
saveRDS(full_outcomes,file="C:/Users/Andy/Downloads/Investing files/full_outcomes.RDS")

##Subset to option EMA volume + open interest and stock EMA price (divided by day avg_open_close?) + volume + absolute_stock_avg_open_close
##Add in day values for options and stocks

##Save and test predictive utility
  
```

```{r get stock splits}

#install.packages("quantmod")

library(quantmod)

stock_aggregate = readRDS("C:/Users/Andy/Downloads/Investing files/stock_aggregate.RDS")
stock_aggregate = stock_aggregate[order(stock_aggregate$symbol,stock_aggregate$stock_quote_date),]
stock_aggregate$avg_open_close = ((stock_aggregate$open + stock_aggregate$close) / 2)
ticker_dates = readRDS("C:/Users/Andy/Downloads/Investing files/SMA_options_ticker_dates.RDS")
stocks_for_SMA = names(ticker_dates)[(ticker_dates == "2013-01-02")]
all_dates = unique(stock_aggregate$stock_quote_date)
stocks_to_drop = c("ADS","AGN","AKS","ALXN","APC","AVP",
                   "BBBY","BRK.B","CELG","CERN","COG","CTXS","CXO",
                   "DF","DISCK","DLPH","DNR","DRE","DTV","ENDP","ESV","ETFC",
                   "FB","FBHS","FII","FLIR","FRC","FRX","FTR","GRA","HFC","HRS",
                   "JCP","JEC","KSU","LLL","LM","LSI","MON","MXIM",
                   "NBL","NLSN","NYX","PBCT","QEP","RDC","RE","RHT","RRD","RTN",
                   "SIVB","STI","TIF","TSS","VAR","VIAB","WCG","WIN","WPX","XEC","XL","XLNX","YHOO")
all_splits = NULL
for(temp_ticker_i in 1:length(stocks_for_SMA)){
  temp_ticker = stocks_for_SMA[temp_ticker_i]
  if(!(temp_ticker %in% stocks_to_drop)){
    splits <- getSplits(temp_ticker)
    temp_splits = as.data.frame(list(ticker=c(rep(temp_ticker,length(index(splits)))),date=c(index(splits))))
    if(is.null(all_splits)){
      all_splits = temp_splits
    }else{
      all_splits = rbind(all_splits,temp_splits)
    }
  }
}
saveRDS(all_splits,file="C:/Users/Andy/Downloads/Investing files/all_splits.RDS")

```

```{r create predictive model input object}

full_aggregate = readRDS("C:/Users/Andy/Downloads/Investing files/full_options_aggregate.RDS")
full_aggregate = full_aggregate[order(full_aggregate$option_underlying_ticker,full_aggregate$option_quote_date),]
all_option_ema20s = readRDS("C:/Users/Andy/Downloads/Investing files/all_option_ema20s.RDS")
all_option_ema8s = readRDS("C:/Users/Andy/Downloads/Investing files/all_option_ema8s.RDS")
ticker_dates = readRDS("C:/Users/Andy/Downloads/Investing files/SMA_options_ticker_dates.RDS")
stocks_for_SMA = names(ticker_dates)[(ticker_dates == "2013-01-02")]
all_dates = unique(stock_aggregate$stock_quote_date)
all_stock_ema20s = readRDS("C:/Users/Andy/Downloads/Investing files/all_stock_ema20s.RDS")
all_stock_ema8s = readRDS("C:/Users/Andy/Downloads/Investing files/all_stock_ema8s.RDS")
stock_aggregate = readRDS("C:/Users/Andy/Downloads/Investing files/stock_aggregate.RDS")
stock_aggregate = stock_aggregate[order(stock_aggregate$symbol,stock_aggregate$stock_quote_date),]
stock_aggregate$avg_open_close = ((stock_aggregate$open + stock_aggregate$close) / 2)
stock_aggregate = stock_aggregate[stock_aggregate$symbol %in% stocks_for_SMA,]
all_outcomes = readRDS("C:/Users/Andy/Downloads/Investing files/full_outcomes.RDS")
rownames(all_outcomes) = paste0(all_outcomes$symbol,"_",all_outcomes$stock_quote_date)

temp_option_agg = full_aggregate[,grepl("_listings_",colnames(full_aggregate)) | grepl("_total_volume_",colnames(full_aggregate)) | 
                                   grepl("_open_interest_",colnames(full_aggregate)) | grepl("option_underlying_ticker",colnames(full_aggregate)) | 
                                   grepl("option_quote_date",colnames(full_aggregate))]
rownames(temp_option_agg) = paste0(temp_option_agg$option_underlying_ticker,"_",temp_option_agg$option_quote_date)
temp_option_ema20s = all_option_ema20s[,grepl("_listings_",colnames(all_option_ema20s)) | grepl("_total_volume_",colnames(all_option_ema20s)) | 
                                   grepl("_open_interest_",colnames(all_option_ema20s)) | grepl("option_underlying_ticker",colnames(all_option_ema20s)) | 
                                   grepl("option_quote_date",colnames(all_option_ema20s))]
colnames(temp_option_ema20s) = paste0(colnames(temp_option_ema20s),"_ema20")
rownames(temp_option_ema20s) = paste0(temp_option_ema20s$option_underlying_ticker,"_",temp_option_ema20s$option_quote_date)
temp_option_ema8s = all_option_ema20s[,grepl("_listings_",colnames(all_option_ema8s)) | grepl("_total_volume_",colnames(all_option_ema8s)) | 
                                   grepl("_open_interest_",colnames(all_option_ema8s)) | grepl("option_underlying_ticker",colnames(all_option_ema8s)) | 
                                   grepl("option_quote_date",colnames(all_option_ema8s))]
colnames(temp_option_ema8s) = paste0(colnames(temp_option_ema8s),"_ema8")
rownames(temp_option_ema8s) = paste0(temp_option_ema8s$option_underlying_ticker,"_",temp_option_ema8s$option_quote_date)

temp_stock_agg = stock_aggregate[,c("symbol","stock_quote_date","volume","avg_open_close")]
rownames(temp_stock_agg) = paste0(temp_stock_agg$symbol,"_",temp_stock_agg$stock_quote_date)
temp_stock_ema20s = all_stock_ema20s[,c("symbol","stock_quote_date","volume","avg_open_close")]
colnames(temp_stock_ema20s) = paste0(colnames(temp_stock_ema20s),"_ema20")
rownames(temp_stock_ema20s) = paste0(temp_stock_ema20s$symbol,"_",temp_stock_ema20s$stock_quote_date)
temp_stock_ema8s = all_stock_ema8s[,c("symbol","stock_quote_date","volume","avg_open_close")]
colnames(temp_stock_ema8s) = paste0(colnames(temp_stock_ema8s),"_ema8")
rownames(temp_stock_ema8s) = paste0(temp_stock_ema8s$symbol,"_",temp_stock_ema8s$stock_quote_date)

merge_df = as.data.frame(cbind(temp_option_agg,
                               temp_option_ema20s[rownames(temp_option_agg),],
                               temp_option_ema8s[rownames(temp_option_agg),],
                               temp_stock_agg[rownames(temp_option_agg),],
                               temp_stock_ema20s[rownames(temp_option_agg),],
                               temp_stock_ema8s[rownames(temp_option_agg),],
                               all_outcomes[rownames(temp_option_agg),]))

###Remove any tickers with stock splits during the test date range
all_splits = readRDS("C:/Users/Andy/Downloads/Investing files/all_splits.RDS")
stocks_to_drop = c("ADS","AGN","AKS","ALXN","APC","AVP",
                   "BBBY","BRK.B","CELG","CERN","COG","CTXS","CXO",
                   "DF","DISCK","DLPH","DNR","DRE","DTV","ENDP","ESV","ETFC",
                   "FB","FBHS","FII","FLIR","FRC","FRX","FTR","GRA","HFC","HRS",
                   "JCP","JEC","KSU","LLL","LM","LSI","MON","MXIM",
                   "NBL","NLSN","NYX","PBCT","QEP","RDC","RE","RHT","RRD","RTN",
                   "SIVB","STI","TIF","TSS","VAR","VIAB","WCG","WIN","WPX","XEC","XL","XLNX","YHOO")
temp_splits = all_splits[all_splits$date %in% all_dates,]
stocks_to_drop = c(stocks_to_drop,unique(temp_splits$ticker))
stocks_to_drop = unique(stocks_to_drop)

filtered_df = merge_df[!(merge_df$option_underlying_ticker %in% stocks_to_drop),]

filtered_df[,grepl("volume",colnames(filtered_df)) | grepl("_open_interest_",colnames(filtered_df))] = 
  log10(filtered_df[,grepl("volume",colnames(filtered_df)) | grepl("_open_interest_",colnames(filtered_df))] + 1)

###Check correlation between features and total stock change for candidate finmarkers
test_cor = cor(filtered_df$time1_total_change,filtered_df[,grepl("volume",colnames(filtered_df)) | grepl("_open_interest_",colnames(filtered_df))],use="pairwise.complete.obs")

##Derive TSPs for predicting selected outcomes
test_mat = filtered_df[rowSums(is.na(filtered_df)) == 0,]
test_input = as.matrix(t(test_mat[,grepl("volume",colnames(test_mat)) | grepl("_open_interest_",colnames(test_mat))]))
test_group = as.factor(test_mat$time1_increase2 > 0 | 
                         test_mat$time2_increase2 > 0 | 
                         test_mat$time3_increase2 > 0 | 
                         test_mat$time4_increase2 > 0 | 
                         test_mat$time5_increase2 > 0 | 
                         test_mat$time6_increase2 > 0 | 
                         test_mat$time7_increase2 > 0 | 
                         test_mat$time8_increase2 > 0 | 
                         test_mat$time9_increase2 > 0 | 
                         test_mat$time10_increase2 > 0)

##Save test input and output data for use in other models
test_output = as.numeric(test_group)-1
write.table(t(test_input),file="test_input.tsv",sep="\t")
write.table(test_output,file="test_output.tsv",sep="\t")

library(switchBox)
library(ncvreg)

test_classifier = SWAP.Train.KTSP(test_input, test_group, krange=c(3:50))
test_classifier = as.data.frame(test_classifier$TSPs)

temp_mat = as.data.frame(t(test_input))
for(tsp_i in 1:nrow(test_classifier)){
  temp_mat[,paste0("tsp_comparison",tsp_i)] = as.numeric(temp_mat[,test_classifier$gene1[tsp_i]] > temp_mat[,test_classifier$gene2[tsp_i]])
}

input_x = temp_mat[,grepl("tsp_comparison",colnames(temp_mat))]
input_y = test_group
test_cvfit = cv.ncvreg(input_x, input_y,nfolds = 10,trace = TRUE)
test_coefs = coef(test_cvfit)
test_score = t(t(input_x) * test_coefs[2:length(test_coefs)])
test_score = rowSums(test_score)
test_score = exp(test_score)/(1+exp(test_score))

test_group2 = as.factor(test_mat$time10_decrease2 > 0)
test_classifier = SWAP.Train.KTSP(test_input, test_group2, krange=c(3:50))
test_classifier = as.data.frame(test_classifier$TSPs)

temp_mat = as.data.frame(t(test_input))
for(tsp_i in 1:nrow(test_classifier)){
  temp_mat[,paste0("tsp_comparison",tsp_i)] = as.numeric(temp_mat[,test_classifier$gene1[tsp_i]] > temp_mat[,test_classifier$gene2[tsp_i]])
}

input_x2 = temp_mat[,grepl("tsp_comparison",colnames(temp_mat))]
input_y2 = test_group2
test_cvfit = cv.ncvreg(input_x2, input_y2,nfolds = 10,trace = TRUE)
test_coefs = coef(test_cvfit)
test_score2 = t(t(input_x2) * test_coefs[2:length(test_coefs)])
test_score2 = rowSums(test_score2)
test_score2 = exp(test_score2)/(1+exp(test_score2))

```

```{r develop XGBoost model}

library(xgboost)

test_input <- as.data.frame(read.table("test_input.tsv",sep="\t"))
test_output <- as.data.frame(read.table("test_output.tsv",sep="\t"))

# Creating a sample dataset
set.seed(123)
data_matrix <- as.matrix(data.frame(cbind(test_input,test_output))) # last column as binary target

# Splitting the data
train_rows <- sample(1:nrow(data_matrix), 0.8 * nrow(data_matrix))
train_data <- data_matrix[train_rows, ]
test_data <- data_matrix[-train_rows, ]

# Create DMatrix
dtrain <- xgb.DMatrix(data = train_data[, -ncol(train_data)], label = train_data[, ncol(train_data)])
dtest <- xgb.DMatrix(data = test_data[, -ncol(test_data)], label = test_data[, ncol(test_data)])

params <- list(
  booster = "gbtree",
  objective = "binary:logistic",
  eta = 0.1,
  max_depth = 6,
  min_child_weight = 1,
  subsample = 0.8,
  colsample_bytree = 0.8
)

num_rounds <- 100
xgb_model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = num_rounds,
  watchlist = list(train = dtrain, eval = dtest),
  early_stopping_rounds = 10,
  print_every_n = 10
)

predictions <- predict(xgb_model, dtest)
predicted_classes <- ifelse(predictions > 0.5, 1, 0)

# Evaluating the model
library(caret)

confusionMatrix(factor(predicted_classes), factor(test_data[, ncol(test_data)]))

```

```{r run exploratory predictions}

library(quantmod)

# Define the stock symbol
symbol <- 'AAPL' # You can replace this with your desired stock symbol

# Fetch option chain data
options_data <- getOptionChain(symbol, NULL)

# View the data
print(options_data)

```



Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
